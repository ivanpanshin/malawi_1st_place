2024-03-18 18:04:40,962 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.9.18 (main, Sep 11 2023, 13:41:44) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
PyTorch: 1.13.1+cu117
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.1+cu117
OpenCV: 4.9.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.7
MMDetection: 2.25.3+bf3d49d
------------------------------------------------------------

2024-03-18 18:04:45,222 - mmdet - INFO - Distributed training: True
2024-03-18 18:04:49,565 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
data_root = '/mnt/md0/arm_unicef/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='AutoAugment',
        policies=[[{
            'type':
            'Resize',
            'img_scale':
            [(480, 1536), (512, 1536), (544, 1536), (576, 1536), (608, 1536),
             (640, 1536), (672, 1536), (704, 1536), (736, 1536), (768, 1536),
             (800, 1536), (832, 1536), (864, 1536), (896, 1536), (928, 1536),
             (960, 1536), (992, 1536), (1024, 1536), (1056, 1536),
             (1088, 1536), (1120, 1536), (1152, 1536), (1184, 1536),
             (1216, 1536), (1248, 1536), (1280, 1536), (1312, 1536),
             (1344, 1536), (1376, 1536), (1408, 1536), (1440, 1536),
             (1472, 1536), (1504, 1536), (1536, 1536)],
            'multiscale_mode':
            'value',
            'keep_ratio':
            True
        }],
                  [{
                      'type': 'Resize',
                      'img_scale': [(400, 4200), (500, 4200), (600, 4200)],
                      'multiscale_mode': 'value',
                      'keep_ratio': True
                  }, {
                      'type': 'RandomCrop',
                      'crop_type': 'absolute_range',
                      'crop_size': (384, 600),
                      'allow_negative_crop': True
                  }, {
                      'type':
                      'Resize',
                      'img_scale': [(480, 1536), (512, 1536), (544, 1536),
                                    (576, 1536), (608, 1536), (640, 1536),
                                    (672, 1536), (704, 1536), (736, 1536),
                                    (768, 1536), (800, 1536), (832, 1536),
                                    (864, 1536), (896, 1536), (928, 1536),
                                    (960, 1536), (992, 1536), (1024, 1536),
                                    (1056, 1536), (1088, 1536), (1120, 1536),
                                    (1152, 1536), (1184, 1536), (1216, 1536),
                                    (1248, 1536), (1280, 1536), (1312, 1536),
                                    (1344, 1536), (1376, 1536), (1408, 1536),
                                    (1440, 1536), (1472, 1536), (1504, 1536),
                                    (1536, 1536)],
                      'multiscale_mode':
                      'value',
                      'override':
                      True,
                      'keep_ratio':
                      True
                  }]]),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(2048, 1280),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=1,
    workers_per_gpu=1,
    train=dict(
        type='CocoDataset',
        ann_file='/mnt/md0/arm_unicef/mmdet_data_v1//Fold_0/train_data.json',
        img_prefix='/mnt/md0/arm_unicef/train_images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='AutoAugment',
                policies=[[{
                    'type':
                    'Resize',
                    'img_scale': [(480, 1536), (512, 1536), (544, 1536),
                                  (576, 1536), (608, 1536), (640, 1536),
                                  (672, 1536), (704, 1536), (736, 1536),
                                  (768, 1536), (800, 1536), (832, 1536),
                                  (864, 1536), (896, 1536), (928, 1536),
                                  (960, 1536), (992, 1536), (1024, 1536),
                                  (1056, 1536), (1088, 1536), (1120, 1536),
                                  (1152, 1536), (1184, 1536), (1216, 1536),
                                  (1248, 1536), (1280, 1536), (1312, 1536),
                                  (1344, 1536), (1376, 1536), (1408, 1536),
                                  (1440, 1536), (1472, 1536), (1504, 1536),
                                  (1536, 1536)],
                    'multiscale_mode':
                    'value',
                    'keep_ratio':
                    True
                }],
                          [{
                              'type': 'Resize',
                              'img_scale': [(400, 4200), (500, 4200),
                                            (600, 4200)],
                              'multiscale_mode': 'value',
                              'keep_ratio': True
                          }, {
                              'type': 'RandomCrop',
                              'crop_type': 'absolute_range',
                              'crop_size': (384, 600),
                              'allow_negative_crop': True
                          }, {
                              'type':
                              'Resize',
                              'img_scale': [(480, 1536), (512, 1536),
                                            (544, 1536), (576, 1536),
                                            (608, 1536), (640, 1536),
                                            (672, 1536), (704, 1536),
                                            (736, 1536), (768, 1536),
                                            (800, 1536), (832, 1536),
                                            (864, 1536), (896, 1536),
                                            (928, 1536), (960, 1536),
                                            (992, 1536), (1024, 1536),
                                            (1056, 1536), (1088, 1536),
                                            (1120, 1536), (1152, 1536),
                                            (1184, 1536), (1216, 1536),
                                            (1248, 1536), (1280, 1536),
                                            (1312, 1536), (1344, 1536),
                                            (1376, 1536), (1408, 1536),
                                            (1440, 1536), (1472, 1536),
                                            (1504, 1536), (1536, 1536)],
                              'multiscale_mode':
                              'value',
                              'override':
                              True,
                              'keep_ratio':
                              True
                          }]]),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ],
        filter_empty_gt=False),
    val=dict(
        type='CocoDataset',
        ann_file='/mnt/md0/arm_unicef/mmdet_data_v1//Fold_0/valid_data.json',
        img_prefix='/mnt/md0/arm_unicef/train_images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1280),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file='/mnt/md0/arm_unicef/mmdet_data_v1//Fold_0/valid_data.json',
        img_prefix='/mnt/md0/arm_unicef/train_images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(2048, 1280),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(
    interval=1, metric='bbox', classwise=True, save_best='bbox_mAP')
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = './pretrained/co_dino_5scale_swin_large_16e_o365tococo.pth'
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
auto_scale_lr = dict(enable=False, base_batch_size=4)
num_dec_layer = 6
lambda_2 = 2.0
model = dict(
    type='CoDETR',
    backbone=dict(
        type='SwinTransformerV1',
        embed_dim=192,
        depths=[2, 2, 18, 2],
        num_heads=[6, 12, 24, 48],
        out_indices=(0, 1, 2, 3),
        window_size=12,
        ape=False,
        drop_path_rate=0.3,
        patch_norm=True,
        use_checkpoint=True,
        pretrained=None),
    neck=dict(
        type='ChannelMapper',
        in_channels=[192, 384, 768, 1536],
        kernel_size=1,
        out_channels=256,
        act_cfg=None,
        norm_cfg=dict(type='GN', num_groups=32),
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            octave_base_scale=4,
            scales_per_octave=3,
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64, 128]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=12.0),
        loss_bbox=dict(type='L1Loss', loss_weight=12.0)),
    query_head=dict(
        type='CoDINOHead',
        num_query=900,
        num_classes=2,
        num_feature_levels=5,
        in_channels=2048,
        sync_cls_avg_factor=True,
        as_two_stage=True,
        with_box_refine=True,
        mixed_selection=True,
        dn_cfg=dict(
            type='CdnQueryGenerator',
            noise_scale=dict(label=0.5, box=0.4),
            group_cfg=dict(dynamic=True, num_groups=None, num_dn_queries=500)),
        transformer=dict(
            type='CoDinoTransformer',
            with_pos_coord=True,
            with_coord_feat=False,
            num_co_heads=2,
            num_feature_levels=5,
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                with_cp=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention',
                        embed_dims=256,
                        num_levels=5,
                        dropout=0.0),
                    feedforward_channels=2048,
                    ffn_dropout=0.0,
                    operation_order=('self_attn', 'norm', 'ffn', 'norm'))),
            decoder=dict(
                type='DinoTransformerDecoder',
                num_layers=6,
                return_intermediate=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.0),
                        dict(
                            type='MultiScaleDeformableAttention',
                            embed_dims=256,
                            num_levels=5,
                            dropout=0.0)
                    ],
                    feedforward_channels=2048,
                    ffn_dropout=0.0,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            temperature=20,
            normalize=True),
        loss_cls=dict(
            type='QualityFocalLoss',
            use_sigmoid=True,
            beta=2.0,
            loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=5.0),
        loss_iou=dict(type='GIoULoss', loss_weight=2.0)),
    roi_head=[
        dict(
            type='CoStandardRoIHead',
            bbox_roi_extractor=dict(
                type='SingleRoIExtractor',
                roi_layer=dict(
                    type='RoIAlign', output_size=7, sampling_ratio=0),
                out_channels=256,
                featmap_strides=[4, 8, 16, 32, 64],
                finest_scale=56),
            bbox_head=dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=2,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=False,
                reg_decoded_bbox=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=12.0),
                loss_bbox=dict(type='GIoULoss', loss_weight=120.0)))
    ],
    bbox_head=[
        dict(
            type='CoATSSHead',
            num_classes=2,
            in_channels=256,
            stacked_convs=1,
            feat_channels=256,
            anchor_generator=dict(
                type='AnchorGenerator',
                ratios=[1.0],
                octave_base_scale=8,
                scales_per_octave=1,
                strides=[4, 8, 16, 32, 64, 128]),
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            loss_cls=dict(
                type='FocalLoss',
                use_sigmoid=True,
                gamma=2.0,
                alpha=0.25,
                loss_weight=12.0),
            loss_bbox=dict(type='GIoULoss', loss_weight=24.0),
            loss_centerness=dict(
                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=12.0))
    ],
    train_cfg=[
        dict(
            assigner=dict(
                type='HungarianAssigner',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(
                    type='BBoxL1Cost', weight=5.0, box_format='xywh'),
                iou_cost=dict(type='IoUCost', iou_mode='giou', weight=2.0))),
        dict(
            rpn=dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.3,
                    min_pos_iou=0.3,
                    match_low_quality=True,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=256,
                    pos_fraction=0.5,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=False),
                allowed_border=-1,
                pos_weight=-1,
                debug=False),
            rpn_proposal=dict(
                nms_pre=4000,
                max_per_img=1000,
                nms=dict(type='nms', iou_threshold=0.7),
                min_bbox_size=0),
            rcnn=dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)),
        dict(
            assigner=dict(type='ATSSAssigner', topk=9),
            allowed_border=-1,
            pos_weight=-1,
            debug=False)
    ],
    test_cfg=[
        dict(max_per_img=300, nms=dict(type='soft_nms', iou_threshold=0.8)),
        dict(
            rpn=dict(
                nms_pre=1000,
                max_per_img=1000,
                nms=dict(type='nms', iou_threshold=0.7),
                min_bbox_size=0),
            rcnn=dict(
                score_thr=0.0,
                nms=dict(type='nms', iou_threshold=0.5),
                max_per_img=100)),
        dict(
            nms_pre=1000,
            min_bbox_size=0,
            score_thr=0.0,
            nms=dict(type='nms', iou_threshold=0.6),
            max_per_img=100)
    ])
optimizer = dict(
    type='AdamW',
    lr=0.0001,
    weight_decay=0.0001,
    paramwise_cfg=dict(custom_keys=dict(backbone=dict(lr_mult=0.1))))
optimizer_config = dict(grad_clip=dict(max_norm=0.1, norm_type=2))
lr_config = dict(policy='step', step=[8])
runner = dict(type='EpochBasedRunner', max_epochs=16)
pretrained = None
image_size = 1536
work_dir = './work_dirs/exp_004'
auto_resume = False
gpu_ids = range(0, 4)

2024-03-18 18:04:51,364 - mmdet - INFO - Set random seed to 80004455, deterministic: True
2024-03-18 18:04:52,721 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
Name of parameter - Initialization information

rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_cls.weight - torch.Size([9, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_cls.bias - torch.Size([9]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_reg.weight - torch.Size([36, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_reg.bias - torch.Size([36]): 
NormalInit: mean=0, std=0.01, bias=0 
2024-03-18 18:04:52,807 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
Name of parameter - Initialization information

bbox_head.fc_cls.weight - torch.Size([3, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.fc_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.fc_reg.weight - torch.Size([8, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

bbox_head.fc_reg.bias - torch.Size([8]): 
NormalInit: mean=0, std=0.001, bias=0 

bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

bbox_head.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 
2024-03-18 18:04:52,894 - mmdet - INFO - initialize CoATSSHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'atss_cls', 'std': 0.01, 'bias_prob': 0.01}}
Name of parameter - Initialization information

cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

cls_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

cls_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

reg_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

reg_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

atss_cls.weight - torch.Size([2, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

atss_cls.bias - torch.Size([2]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

atss_reg.weight - torch.Size([4, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

atss_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.01, bias=0 

atss_centerness.weight - torch.Size([1, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

atss_centerness.bias - torch.Size([1]): 
NormalInit: mean=0, std=0.01, bias=0 

scales.0.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

scales.1.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

scales.2.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

scales.3.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

scales.4.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

scales.5.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoATSSHead  
2024-03-18 18:04:54,399 - mmdet - INFO - initialize ChannelMapper with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
Name of parameter - Initialization information

backbone.patch_embed.proj.weight - torch.Size([192, 3, 4, 4]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.patch_embed.proj.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.patch_embed.norm.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.patch_embed.norm.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.attn.relative_position_bias_table - torch.Size([529, 6]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.attn.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.attn.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.attn.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.attn.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.mlp.fc1.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.mlp.fc1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.mlp.fc2.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.mlp.fc2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.norm1.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.1.norm1.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.1.attn.relative_position_bias_table - torch.Size([529, 6]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.1.attn.qkv.weight - torch.Size([576, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.attn.qkv.bias - torch.Size([576]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.attn.proj.weight - torch.Size([192, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.attn.proj.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.norm2.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.1.norm2.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.1.mlp.fc1.weight - torch.Size([768, 192]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.mlp.fc1.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.mlp.fc2.weight - torch.Size([192, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.mlp.fc2.bias - torch.Size([192]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.downsample.reduction.weight - torch.Size([384, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.downsample.norm.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.downsample.norm.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.attn.relative_position_bias_table - torch.Size([529, 12]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.attn.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.attn.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.attn.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.attn.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.mlp.fc1.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.mlp.fc1.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.mlp.fc2.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.mlp.fc2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.1.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.1.attn.relative_position_bias_table - torch.Size([529, 12]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.1.attn.qkv.weight - torch.Size([1152, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.attn.qkv.bias - torch.Size([1152]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.attn.proj.weight - torch.Size([384, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.attn.proj.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.norm2.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.1.norm2.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.1.mlp.fc1.weight - torch.Size([1536, 384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.mlp.fc1.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.mlp.fc2.weight - torch.Size([384, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.mlp.fc2.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.downsample.reduction.weight - torch.Size([768, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.downsample.norm.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.downsample.norm.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.1.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.1.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.1.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.1.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.1.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.2.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.2.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.2.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.2.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.2.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.3.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.3.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.3.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.3.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.3.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.4.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.4.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.4.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.4.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.4.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.5.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.5.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.5.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.5.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.5.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.6.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.6.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.6.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.6.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.6.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.7.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.7.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.7.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.7.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.7.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.8.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.8.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.8.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.8.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.8.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.9.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.9.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.9.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.9.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.9.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.10.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.10.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.10.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.10.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.10.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.11.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.11.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.11.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.11.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.11.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.12.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.12.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.12.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.12.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.12.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.13.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.13.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.13.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.13.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.13.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.14.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.14.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.14.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.14.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.14.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.15.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.15.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.15.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.15.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.15.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.16.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.16.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.16.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.16.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.16.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.norm1.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.17.norm1.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.17.attn.relative_position_bias_table - torch.Size([529, 24]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.17.attn.qkv.weight - torch.Size([2304, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.attn.qkv.bias - torch.Size([2304]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.attn.proj.weight - torch.Size([768, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.attn.proj.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.17.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.17.mlp.fc1.weight - torch.Size([3072, 768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.mlp.fc1.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.mlp.fc2.weight - torch.Size([768, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.mlp.fc2.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.downsample.reduction.weight - torch.Size([1536, 3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.downsample.norm.weight - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.downsample.norm.bias - torch.Size([3072]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.norm1.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.norm1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.attn.relative_position_bias_table - torch.Size([529, 48]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.attn.qkv.weight - torch.Size([4608, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.attn.qkv.bias - torch.Size([4608]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.attn.proj.weight - torch.Size([1536, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.attn.proj.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.norm2.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.norm2.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.mlp.fc1.weight - torch.Size([6144, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.mlp.fc1.bias - torch.Size([6144]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.mlp.fc2.weight - torch.Size([1536, 6144]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.mlp.fc2.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.norm1.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.1.norm1.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.1.attn.relative_position_bias_table - torch.Size([529, 48]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.1.attn.qkv.weight - torch.Size([4608, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.attn.qkv.bias - torch.Size([4608]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.attn.proj.weight - torch.Size([1536, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.attn.proj.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.norm2.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.1.norm2.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.1.mlp.fc1.weight - torch.Size([6144, 1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.mlp.fc1.bias - torch.Size([6144]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.mlp.fc2.weight - torch.Size([1536, 6144]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.mlp.fc2.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.norm0.weight - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm0.bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm1.weight - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm1.bias - torch.Size([384]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm2.weight - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm2.bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm3.weight - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm3.bias - torch.Size([1536]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.0.conv.weight - torch.Size([256, 192, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.1.conv.weight - torch.Size([256, 384, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.2.conv.weight - torch.Size([256, 768, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.3.conv.weight - torch.Size([256, 1536, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.convs.3.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.3.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.extra_convs.0.conv.weight - torch.Size([256, 1536, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.extra_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.extra_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.level_embeds - torch.Size([5, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.attentions.0.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.attentions.0.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.0.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.0.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.1.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.1.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.2.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.2.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.3.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.3.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.4.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.4.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.5.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.5.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.0.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.1.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.2.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.3.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.4.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight - torch.Size([160, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.5.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.ref_point_head.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.ref_point_head.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.ref_point_head.2.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.decoder.ref_point_head.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.enc_output.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.enc_output.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.enc_output_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.enc_output_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.query_embed.weight - torch.Size([900, 256]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.aux_pos_trans.0.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.aux_pos_trans.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.aux_pos_trans.1.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in CoDINOHead  

query_head.transformer.aux_pos_trans.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.aux_pos_trans_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.aux_pos_trans_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.aux_pos_trans_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.aux_pos_trans_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.downsample.0.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.downsample.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.0.weight - torch.Size([2, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.0.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.1.weight - torch.Size([2, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.1.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.2.weight - torch.Size([2, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.2.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.3.weight - torch.Size([2, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.3.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.4.weight - torch.Size([2, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.4.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.5.weight - torch.Size([2, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.5.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.6.weight - torch.Size([2, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.6.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.label_embedding.weight - torch.Size([2, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_cls.weight - torch.Size([9, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_cls.bias - torch.Size([9]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_reg.weight - torch.Size([36, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_reg.bias - torch.Size([36]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.fc_cls.weight - torch.Size([3, 1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.fc_cls.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.fc_reg.weight - torch.Size([8, 1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.fc_reg.bias - torch.Size([8]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.shared_fcs.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.cls_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.cls_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.reg_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.reg_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_cls.weight - torch.Size([2, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_cls.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_reg.weight - torch.Size([4, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_reg.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_centerness.weight - torch.Size([1, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_centerness.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.scales.0.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.scales.1.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.scales.2.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.scales.3.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.scales.4.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.scales.5.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoDETR  
2024-03-18 18:04:55,079 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.
2024-03-18 18:04:55,242 - mmdet - INFO - load checkpoint from local path: ./pretrained/co_dino_5scale_swin_large_16e_o365tococo.pth
2024-03-18 18:04:57,124 - mmdet - WARNING - The model and loaded state dict do not match exactly

size mismatch for query_head.cls_branches.0.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for query_head.cls_branches.0.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for query_head.cls_branches.1.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for query_head.cls_branches.1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for query_head.cls_branches.2.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for query_head.cls_branches.2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for query_head.cls_branches.3.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for query_head.cls_branches.3.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for query_head.cls_branches.4.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for query_head.cls_branches.4.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for query_head.cls_branches.5.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for query_head.cls_branches.5.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for query_head.cls_branches.6.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for query_head.cls_branches.6.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
size mismatch for query_head.label_embedding.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([2, 256]).
size mismatch for roi_head.0.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([3, 1024]).
size mismatch for roi_head.0.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([3]).
size mismatch for roi_head.0.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([8, 1024]).
size mismatch for roi_head.0.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([8]).
size mismatch for bbox_head.0.atss_cls.weight: copying a param with shape torch.Size([80, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([2, 256, 3, 3]).
size mismatch for bbox_head.0.atss_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([2]).
2024-03-18 18:04:57,214 - mmdet - INFO - Start running, host: harshit@harshit, work_dir: /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_004
2024-03-18 18:04:57,214 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) NumClassCheckHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2024-03-18 18:04:57,214 - mmdet - INFO - workflow: [('train', 1)], max: 16 epochs
2024-03-18 18:04:57,215 - mmdet - INFO - Checkpoints will be saved to /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_004 by HardDiskBackend.
2024-03-18 18:07:12,645 - mmdet - INFO - Epoch [1][50/463]	lr: 1.000e-05, eta: 5:32:08, time: 2.708, data_time: 0.062, memory: 17512, enc_loss_cls: 0.7002, enc_loss_bbox: 0.3075, enc_loss_iou: 1.2789, loss_cls: 0.5482, loss_bbox: 0.2214, loss_iou: 0.8398, d0.loss_cls: 0.7567, d0.loss_bbox: 0.2677, d0.loss_iou: 1.0522, d1.loss_cls: 0.5917, d1.loss_bbox: 0.2403, d1.loss_iou: 0.9347, d2.loss_cls: 0.5496, d2.loss_bbox: 0.2297, d2.loss_iou: 0.8869, d3.loss_cls: 0.5179, d3.loss_bbox: 0.2207, d3.loss_iou: 0.8378, d4.loss_cls: 0.5036, d4.loss_bbox: 0.2220, d4.loss_iou: 0.8388, dn_loss_cls: 0.7960, dn_loss_bbox: 0.0633, dn_loss_iou: 0.3516, d0.dn_loss_cls: 1.8761, d0.dn_loss_bbox: 0.0648, d0.dn_loss_iou: 0.3696, d1.dn_loss_cls: 1.0867, d1.dn_loss_bbox: 0.0618, d1.dn_loss_iou: 0.3469, d2.dn_loss_cls: 0.9983, d2.dn_loss_bbox: 0.0640, d2.dn_loss_iou: 0.3536, d3.dn_loss_cls: 0.8990, d3.dn_loss_bbox: 0.0669, d3.dn_loss_iou: 0.3585, d4.dn_loss_cls: 0.8505, d4.dn_loss_bbox: 0.0633, d4.dn_loss_iou: 0.3513, loss_rpn_cls: 0.2197, loss_rpn_bbox: 0.1685, loss_cls0: 5.1471, acc0: 86.5654, loss_bbox0: 4.3170, loss_cls1: 10.1324, loss_bbox1: 4.3104, loss_centerness1: 7.1937, loss_cls_aux0: 0.8090, loss_bbox_aux0: 0.0231, loss_iou_aux0: 0.1323, d0.loss_cls_aux0: 1.4182, d0.loss_bbox_aux0: 0.0534, d0.loss_iou_aux0: 0.2972, d1.loss_cls_aux0: 1.1946, d1.loss_bbox_aux0: 0.0302, d1.loss_iou_aux0: 0.1718, d2.loss_cls_aux0: 1.0102, d2.loss_bbox_aux0: 0.0232, d2.loss_iou_aux0: 0.1319, d3.loss_cls_aux0: 1.0188, d3.loss_bbox_aux0: 0.0229, d3.loss_iou_aux0: 0.1309, d4.loss_cls_aux0: 0.9404, d4.loss_bbox_aux0: 0.0229, d4.loss_iou_aux0: 0.1312, loss_cls_aux1: 0.6254, loss_bbox_aux1: 0.0470, loss_iou_aux1: 0.2675, d0.loss_cls_aux1: 1.3284, d0.loss_bbox_aux1: 0.0565, d0.loss_iou_aux1: 0.3184, d1.loss_cls_aux1: 0.9324, d1.loss_bbox_aux1: 0.0470, d1.loss_iou_aux1: 0.2695, d2.loss_cls_aux1: 0.7881, d2.loss_bbox_aux1: 0.0467, d2.loss_iou_aux1: 0.2668, d3.loss_cls_aux1: 0.7929, d3.loss_bbox_aux1: 0.0471, d3.loss_iou_aux1: 0.2675, d4.loss_cls_aux1: 0.7219, d4.loss_bbox_aux1: 0.0470, d4.loss_iou_aux1: 0.2674, loss: 67.7568, grad_norm: 229.5185
2024-03-18 18:09:17,283 - mmdet - INFO - Epoch [1][100/463]	lr: 1.000e-05, eta: 5:16:44, time: 2.493, data_time: 0.009, memory: 17512, enc_loss_cls: 2.0026, enc_loss_bbox: 0.0964, enc_loss_iou: 0.4641, loss_cls: 0.3887, loss_bbox: 0.0885, loss_iou: 0.4096, d0.loss_cls: 0.7594, d0.loss_bbox: 0.0909, d0.loss_iou: 0.4149, d1.loss_cls: 0.6108, d1.loss_bbox: 0.0886, d1.loss_iou: 0.4072, d2.loss_cls: 0.4494, d2.loss_bbox: 0.0893, d2.loss_iou: 0.4098, d3.loss_cls: 0.3874, d3.loss_bbox: 0.0874, d3.loss_iou: 0.4070, d4.loss_cls: 0.3844, d4.loss_bbox: 0.0886, d4.loss_iou: 0.4109, dn_loss_cls: 0.2706, dn_loss_bbox: 0.0581, dn_loss_iou: 0.3013, d0.dn_loss_cls: 0.6147, d0.dn_loss_bbox: 0.0594, d0.dn_loss_iou: 0.3260, d1.dn_loss_cls: 0.3694, d1.dn_loss_bbox: 0.0537, d1.dn_loss_iou: 0.2918, d2.dn_loss_cls: 0.2878, d2.dn_loss_bbox: 0.0555, d2.dn_loss_iou: 0.2968, d3.dn_loss_cls: 0.3001, d3.dn_loss_bbox: 0.0563, d3.dn_loss_iou: 0.3004, d4.dn_loss_cls: 0.2806, d4.dn_loss_bbox: 0.0561, d4.dn_loss_iou: 0.2998, loss_rpn_cls: 0.1041, loss_rpn_bbox: 0.1511, loss_cls0: 3.0335, acc0: 90.8916, loss_bbox0: 5.4462, loss_cls1: 3.5358, loss_bbox1: 4.0913, loss_centerness1: 7.1778, loss_cls_aux0: 0.1266, loss_bbox_aux0: 0.0283, loss_iou_aux0: 0.1494, d0.loss_cls_aux0: 0.3228, d0.loss_bbox_aux0: 0.0561, d0.loss_iou_aux0: 0.2957, d1.loss_cls_aux0: 0.2356, d1.loss_bbox_aux0: 0.0334, d1.loss_iou_aux0: 0.1801, d2.loss_cls_aux0: 0.1558, d2.loss_bbox_aux0: 0.0283, d2.loss_iou_aux0: 0.1483, d3.loss_cls_aux0: 0.1297, d3.loss_bbox_aux0: 0.0279, d3.loss_iou_aux0: 0.1472, d4.loss_cls_aux0: 0.1220, d4.loss_bbox_aux0: 0.0281, d4.loss_iou_aux0: 0.1479, loss_cls_aux1: 0.1149, loss_bbox_aux1: 0.0483, loss_iou_aux1: 0.2572, d0.loss_cls_aux1: 0.3363, d0.loss_bbox_aux1: 0.0608, d0.loss_iou_aux1: 0.3159, d1.loss_cls_aux1: 0.2204, d1.loss_bbox_aux1: 0.0491, d1.loss_iou_aux1: 0.2602, d2.loss_cls_aux1: 0.1325, d2.loss_bbox_aux1: 0.0481, d2.loss_iou_aux1: 0.2565, d3.loss_cls_aux1: 0.1147, d3.loss_bbox_aux1: 0.0481, d3.loss_iou_aux1: 0.2563, d4.loss_cls_aux1: 0.1090, d4.loss_bbox_aux1: 0.0482, d4.loss_iou_aux1: 0.2567, loss: 41.6503, grad_norm: 336.7097
2024-03-18 18:11:27,314 - mmdet - INFO - Epoch [1][150/463]	lr: 1.000e-05, eta: 5:14:34, time: 2.601, data_time: 0.009, memory: 17512, enc_loss_cls: 1.6902, enc_loss_bbox: 0.0824, enc_loss_iou: 0.3613, loss_cls: 0.2511, loss_bbox: 0.0885, loss_iou: 0.3870, d0.loss_cls: 0.6098, d0.loss_bbox: 0.0874, d0.loss_iou: 0.3847, d1.loss_cls: 0.4539, d1.loss_bbox: 0.0878, d1.loss_iou: 0.3893, d2.loss_cls: 0.3234, d2.loss_bbox: 0.0884, d2.loss_iou: 0.3870, d3.loss_cls: 0.2718, d3.loss_bbox: 0.0874, d3.loss_iou: 0.3844, d4.loss_cls: 0.2498, d4.loss_bbox: 0.0884, d4.loss_iou: 0.3867, dn_loss_cls: 0.1333, dn_loss_bbox: 0.0506, dn_loss_iou: 0.2628, d0.dn_loss_cls: 0.3877, d0.dn_loss_bbox: 0.0574, d0.dn_loss_iou: 0.2971, d1.dn_loss_cls: 0.1789, d1.dn_loss_bbox: 0.0513, d1.dn_loss_iou: 0.2655, d2.dn_loss_cls: 0.1301, d2.dn_loss_bbox: 0.0506, d2.dn_loss_iou: 0.2630, d3.dn_loss_cls: 0.1398, d3.dn_loss_bbox: 0.0506, d3.dn_loss_iou: 0.2628, d4.dn_loss_cls: 0.1330, d4.dn_loss_bbox: 0.0506, d4.dn_loss_iou: 0.2627, loss_rpn_cls: 0.0825, loss_rpn_bbox: 0.1753, loss_cls0: 2.9938, acc0: 89.6699, loss_bbox0: 3.9998, loss_cls1: 2.5809, loss_bbox1: 3.8419, loss_centerness1: 7.1211, loss_cls_aux0: 0.0731, loss_bbox_aux0: 0.0271, loss_iou_aux0: 0.1362, d0.loss_cls_aux0: 0.1721, d0.loss_bbox_aux0: 0.0559, d0.loss_iou_aux0: 0.2765, d1.loss_cls_aux0: 0.1130, d1.loss_bbox_aux0: 0.0319, d1.loss_iou_aux0: 0.1617, d2.loss_cls_aux0: 0.0811, d2.loss_bbox_aux0: 0.0273, d2.loss_iou_aux0: 0.1371, d3.loss_cls_aux0: 0.0721, d3.loss_bbox_aux0: 0.0270, d3.loss_iou_aux0: 0.1354, d4.loss_cls_aux0: 0.0708, d4.loss_bbox_aux0: 0.0270, d4.loss_iou_aux0: 0.1357, loss_cls_aux1: 0.0549, loss_bbox_aux1: 0.0474, loss_iou_aux1: 0.2373, d0.loss_cls_aux1: 0.1390, d0.loss_bbox_aux1: 0.0592, d0.loss_iou_aux1: 0.2903, d1.loss_cls_aux1: 0.0846, d1.loss_bbox_aux1: 0.0484, d1.loss_iou_aux1: 0.2408, d2.loss_cls_aux1: 0.0599, d2.loss_bbox_aux1: 0.0473, d2.loss_iou_aux1: 0.2368, d3.loss_cls_aux1: 0.0536, d3.loss_bbox_aux1: 0.0474, d3.loss_iou_aux1: 0.2372, d4.loss_cls_aux1: 0.0538, d4.loss_bbox_aux1: 0.0474, d4.loss_iou_aux1: 0.2372, loss: 34.9471, grad_norm: 228.1570
2024-03-18 18:13:40,349 - mmdet - INFO - Epoch [1][200/463]	lr: 1.000e-05, eta: 5:14:13, time: 2.661, data_time: 0.010, memory: 17512, enc_loss_cls: 0.9104, enc_loss_bbox: 0.0778, enc_loss_iou: 0.3649, loss_cls: 0.2240, loss_bbox: 0.0880, loss_iou: 0.4088, d0.loss_cls: 0.6796, d0.loss_bbox: 0.0851, d0.loss_iou: 0.3898, d1.loss_cls: 0.4573, d1.loss_bbox: 0.0875, d1.loss_iou: 0.3992, d2.loss_cls: 0.2911, d2.loss_bbox: 0.0863, d2.loss_iou: 0.4030, d3.loss_cls: 0.2421, d3.loss_bbox: 0.0863, d3.loss_iou: 0.4053, d4.loss_cls: 0.2297, d4.loss_bbox: 0.0875, d4.loss_iou: 0.4078, dn_loss_cls: 0.1096, dn_loss_bbox: 0.0481, dn_loss_iou: 0.2689, d0.dn_loss_cls: 0.3748, d0.dn_loss_bbox: 0.0567, d0.dn_loss_iou: 0.3138, d1.dn_loss_cls: 0.1683, d1.dn_loss_bbox: 0.0486, d1.dn_loss_iou: 0.2715, d2.dn_loss_cls: 0.1103, d2.dn_loss_bbox: 0.0481, d2.dn_loss_iou: 0.2691, d3.dn_loss_cls: 0.1144, d3.dn_loss_bbox: 0.0481, d3.dn_loss_iou: 0.2689, d4.dn_loss_cls: 0.1068, d4.dn_loss_bbox: 0.0480, d4.dn_loss_iou: 0.2684, loss_rpn_cls: 0.0637, loss_rpn_bbox: 0.1479, loss_cls0: 2.7045, acc0: 90.7410, loss_bbox0: 3.7855, loss_cls1: 2.4458, loss_bbox1: 4.0747, loss_centerness1: 7.1385, loss_cls_aux0: 0.0430, loss_bbox_aux0: 0.0221, loss_iou_aux0: 0.1256, d0.loss_cls_aux0: 0.1051, d0.loss_bbox_aux0: 0.0497, d0.loss_iou_aux0: 0.2764, d1.loss_cls_aux0: 0.0696, d1.loss_bbox_aux0: 0.0265, d1.loss_iou_aux0: 0.1509, d2.loss_cls_aux0: 0.0485, d2.loss_bbox_aux0: 0.0225, d2.loss_iou_aux0: 0.1277, d3.loss_cls_aux0: 0.0453, d3.loss_bbox_aux0: 0.0220, d3.loss_iou_aux0: 0.1247, d4.loss_cls_aux0: 0.0425, d4.loss_bbox_aux0: 0.0220, d4.loss_iou_aux0: 0.1251, loss_cls_aux1: 0.0430, loss_bbox_aux1: 0.0451, loss_iou_aux1: 0.2512, d0.loss_cls_aux1: 0.0923, d0.loss_bbox_aux1: 0.0558, d0.loss_iou_aux1: 0.3040, d1.loss_cls_aux1: 0.0571, d1.loss_bbox_aux1: 0.0456, d1.loss_iou_aux1: 0.2534, d2.loss_cls_aux1: 0.0439, d2.loss_bbox_aux1: 0.0450, d2.loss_iou_aux1: 0.2511, d3.loss_cls_aux1: 0.0421, d3.loss_bbox_aux1: 0.0451, d3.loss_iou_aux1: 0.2509, d4.loss_cls_aux1: 0.0407, d4.loss_bbox_aux1: 0.0451, d4.loss_iou_aux1: 0.2510, loss: 33.3263, grad_norm: 193.1203
2024-03-18 18:15:52,712 - mmdet - INFO - Epoch [1][250/463]	lr: 1.000e-05, eta: 5:12:47, time: 2.647, data_time: 0.009, memory: 17512, enc_loss_cls: 0.6072, enc_loss_bbox: 0.0762, enc_loss_iou: 0.3801, loss_cls: 0.1770, loss_bbox: 0.0817, loss_iou: 0.3876, d0.loss_cls: 0.5794, d0.loss_bbox: 0.0772, d0.loss_iou: 0.3722, d1.loss_cls: 0.3317, d1.loss_bbox: 0.0794, d1.loss_iou: 0.3835, d2.loss_cls: 0.2159, d2.loss_bbox: 0.0813, d2.loss_iou: 0.3860, d3.loss_cls: 0.1859, d3.loss_bbox: 0.0812, d3.loss_iou: 0.3860, d4.loss_cls: 0.1742, d4.loss_bbox: 0.0809, d4.loss_iou: 0.3877, dn_loss_cls: 0.0571, dn_loss_bbox: 0.0454, dn_loss_iou: 0.2567, d0.dn_loss_cls: 0.2763, d0.dn_loss_bbox: 0.0540, d0.dn_loss_iou: 0.3026, d1.dn_loss_cls: 0.1021, d1.dn_loss_bbox: 0.0455, d1.dn_loss_iou: 0.2585, d2.dn_loss_cls: 0.0628, d2.dn_loss_bbox: 0.0453, d2.dn_loss_iou: 0.2563, d3.dn_loss_cls: 0.0626, d3.dn_loss_bbox: 0.0454, d3.dn_loss_iou: 0.2567, d4.dn_loss_cls: 0.0582, d4.dn_loss_bbox: 0.0454, d4.dn_loss_iou: 0.2565, loss_rpn_cls: 0.0591, loss_rpn_bbox: 0.1722, loss_cls0: 2.6807, acc0: 91.0023, loss_bbox0: 3.9388, loss_cls1: 2.0851, loss_bbox1: 3.9787, loss_centerness1: 7.1577, loss_cls_aux0: 0.0329, loss_bbox_aux0: 0.0220, loss_iou_aux0: 0.1211, d0.loss_cls_aux0: 0.0749, d0.loss_bbox_aux0: 0.0472, d0.loss_iou_aux0: 0.2624, d1.loss_cls_aux0: 0.0462, d1.loss_bbox_aux0: 0.0261, d1.loss_iou_aux0: 0.1451, d2.loss_cls_aux0: 0.0376, d2.loss_bbox_aux0: 0.0223, d2.loss_iou_aux0: 0.1231, d3.loss_cls_aux0: 0.0348, d3.loss_bbox_aux0: 0.0218, d3.loss_iou_aux0: 0.1198, d4.loss_cls_aux0: 0.0331, d4.loss_bbox_aux0: 0.0219, d4.loss_iou_aux0: 0.1205, loss_cls_aux1: 0.0235, loss_bbox_aux1: 0.0450, loss_iou_aux1: 0.2461, d0.loss_cls_aux1: 0.0567, d0.loss_bbox_aux1: 0.0546, d0.loss_iou_aux1: 0.2917, d1.loss_cls_aux1: 0.0324, d1.loss_bbox_aux1: 0.0459, d1.loss_iou_aux1: 0.2495, d2.loss_cls_aux1: 0.0272, d2.loss_bbox_aux1: 0.0449, d2.loss_iou_aux1: 0.2453, d3.loss_cls_aux1: 0.0249, d3.loss_bbox_aux1: 0.0449, d3.loss_iou_aux1: 0.2456, d4.loss_cls_aux1: 0.0243, d4.loss_bbox_aux1: 0.0450, d4.loss_iou_aux1: 0.2459, loss: 31.3783, grad_norm: 209.5988
2024-03-18 18:18:08,695 - mmdet - INFO - Epoch [1][300/463]	lr: 1.000e-05, eta: 5:12:32, time: 2.720, data_time: 0.010, memory: 17512, enc_loss_cls: 0.5072, enc_loss_bbox: 0.0853, enc_loss_iou: 0.4049, loss_cls: 0.1767, loss_bbox: 0.0835, loss_iou: 0.3938, d0.loss_cls: 0.5249, d0.loss_bbox: 0.0818, d0.loss_iou: 0.3857, d1.loss_cls: 0.3182, d1.loss_bbox: 0.0838, d1.loss_iou: 0.3931, d2.loss_cls: 0.2099, d2.loss_bbox: 0.0827, d2.loss_iou: 0.3915, d3.loss_cls: 0.1881, d3.loss_bbox: 0.0815, d3.loss_iou: 0.3903, d4.loss_cls: 0.1792, d4.loss_bbox: 0.0826, d4.loss_iou: 0.3922, dn_loss_cls: 0.0861, dn_loss_bbox: 0.0455, dn_loss_iou: 0.2488, d0.dn_loss_cls: 0.2395, d0.dn_loss_bbox: 0.0567, d0.dn_loss_iou: 0.3042, d1.dn_loss_cls: 0.1038, d1.dn_loss_bbox: 0.0458, d1.dn_loss_iou: 0.2509, d2.dn_loss_cls: 0.0821, d2.dn_loss_bbox: 0.0453, d2.dn_loss_iou: 0.2478, d3.dn_loss_cls: 0.0843, d3.dn_loss_bbox: 0.0456, d3.dn_loss_iou: 0.2492, d4.dn_loss_cls: 0.0851, d4.dn_loss_bbox: 0.0454, d4.dn_loss_iou: 0.2487, loss_rpn_cls: 0.0838, loss_rpn_bbox: 0.1663, loss_cls0: 2.6933, acc0: 90.7579, loss_bbox0: 3.6911, loss_cls1: 2.0988, loss_bbox1: 4.1665, loss_centerness1: 7.1591, loss_cls_aux0: 0.0679, loss_bbox_aux0: 0.0234, loss_iou_aux0: 0.1162, d0.loss_cls_aux0: 0.0714, d0.loss_bbox_aux0: 0.0513, d0.loss_iou_aux0: 0.2649, d1.loss_cls_aux0: 0.0630, d1.loss_bbox_aux0: 0.0277, d1.loss_iou_aux0: 0.1397, d2.loss_cls_aux0: 0.0651, d2.loss_bbox_aux0: 0.0241, d2.loss_iou_aux0: 0.1194, d3.loss_cls_aux0: 0.0650, d3.loss_bbox_aux0: 0.0233, d3.loss_iou_aux0: 0.1154, d4.loss_cls_aux0: 0.0641, d4.loss_bbox_aux0: 0.0234, d4.loss_iou_aux0: 0.1157, loss_cls_aux1: 0.0494, loss_bbox_aux1: 0.0477, loss_iou_aux1: 0.2506, d0.loss_cls_aux1: 0.0539, d0.loss_bbox_aux1: 0.0594, d0.loss_iou_aux1: 0.3057, d1.loss_cls_aux1: 0.0483, d1.loss_bbox_aux1: 0.0487, d1.loss_iou_aux1: 0.2544, d2.loss_cls_aux1: 0.0487, d2.loss_bbox_aux1: 0.0479, d2.loss_iou_aux1: 0.2514, d3.loss_cls_aux1: 0.0476, d3.loss_bbox_aux1: 0.0477, d3.loss_iou_aux1: 0.2504, d4.loss_cls_aux1: 0.0465, d4.loss_bbox_aux1: 0.0477, d4.loss_iou_aux1: 0.2506, loss: 31.6081, grad_norm: 232.6315
2024-03-18 18:20:12,635 - mmdet - INFO - Epoch [1][350/463]	lr: 1.000e-05, eta: 5:07:39, time: 2.479, data_time: 0.010, memory: 17512, enc_loss_cls: 0.4421, enc_loss_bbox: 0.0786, enc_loss_iou: 0.3810, loss_cls: 0.1744, loss_bbox: 0.0732, loss_iou: 0.3565, d0.loss_cls: 0.5489, d0.loss_bbox: 0.0736, d0.loss_iou: 0.3557, d1.loss_cls: 0.2733, d1.loss_bbox: 0.0746, d1.loss_iou: 0.3579, d2.loss_cls: 0.1963, d2.loss_bbox: 0.0734, d2.loss_iou: 0.3581, d3.loss_cls: 0.1767, d3.loss_bbox: 0.0733, d3.loss_iou: 0.3587, d4.loss_cls: 0.1737, d4.loss_bbox: 0.0729, d4.loss_iou: 0.3560, dn_loss_cls: 0.0567, dn_loss_bbox: 0.0406, dn_loss_iou: 0.2298, d0.dn_loss_cls: 0.1904, d0.dn_loss_bbox: 0.0518, d0.dn_loss_iou: 0.2885, d1.dn_loss_cls: 0.0686, d1.dn_loss_bbox: 0.0408, d1.dn_loss_iou: 0.2317, d2.dn_loss_cls: 0.0505, d2.dn_loss_bbox: 0.0405, d2.dn_loss_iou: 0.2296, d3.dn_loss_cls: 0.0555, d3.dn_loss_bbox: 0.0406, d3.dn_loss_iou: 0.2297, d4.dn_loss_cls: 0.0564, d4.dn_loss_bbox: 0.0406, d4.dn_loss_iou: 0.2297, loss_rpn_cls: 0.0416, loss_rpn_bbox: 0.1591, loss_cls0: 2.6273, acc0: 91.1512, loss_bbox0: 3.5323, loss_cls1: 2.0971, loss_bbox1: 3.8706, loss_centerness1: 7.1658, loss_cls_aux0: 0.0618, loss_bbox_aux0: 0.0186, loss_iou_aux0: 0.1027, d0.loss_cls_aux0: 0.0640, d0.loss_bbox_aux0: 0.0451, d0.loss_iou_aux0: 0.2530, d1.loss_cls_aux0: 0.0571, d1.loss_bbox_aux0: 0.0224, d1.loss_iou_aux0: 0.1246, d2.loss_cls_aux0: 0.0583, d2.loss_bbox_aux0: 0.0191, d2.loss_iou_aux0: 0.1056, d3.loss_cls_aux0: 0.0557, d3.loss_bbox_aux0: 0.0185, d3.loss_iou_aux0: 0.1019, d4.loss_cls_aux0: 0.0595, d4.loss_bbox_aux0: 0.0185, d4.loss_iou_aux0: 0.1022, loss_cls_aux1: 0.0443, loss_bbox_aux1: 0.0417, loss_iou_aux1: 0.2319, d0.loss_cls_aux1: 0.0510, d0.loss_bbox_aux1: 0.0517, d0.loss_iou_aux1: 0.2829, d1.loss_cls_aux1: 0.0446, d1.loss_bbox_aux1: 0.0426, d1.loss_iou_aux1: 0.2351, d2.loss_cls_aux1: 0.0439, d2.loss_bbox_aux1: 0.0416, d2.loss_iou_aux1: 0.2311, d3.loss_cls_aux1: 0.0418, d3.loss_bbox_aux1: 0.0417, d3.loss_iou_aux1: 0.2316, d4.loss_cls_aux1: 0.0439, d4.loss_bbox_aux1: 0.0417, d4.loss_iou_aux1: 0.2317, loss: 29.9584, grad_norm: 230.1386
2024-03-18 18:22:30,077 - mmdet - INFO - Epoch [1][400/463]	lr: 1.000e-05, eta: 5:07:25, time: 2.749, data_time: 0.008, memory: 17512, enc_loss_cls: 0.3992, enc_loss_bbox: 0.0724, enc_loss_iou: 0.3663, loss_cls: 0.1406, loss_bbox: 0.0701, loss_iou: 0.3529, d0.loss_cls: 0.5069, d0.loss_bbox: 0.0700, d0.loss_iou: 0.3506, d1.loss_cls: 0.2060, d1.loss_bbox: 0.0719, d1.loss_iou: 0.3564, d2.loss_cls: 0.1617, d2.loss_bbox: 0.0699, d2.loss_iou: 0.3537, d3.loss_cls: 0.1474, d3.loss_bbox: 0.0698, d3.loss_iou: 0.3536, d4.loss_cls: 0.1440, d4.loss_bbox: 0.0703, d4.loss_iou: 0.3535, dn_loss_cls: 0.0352, dn_loss_bbox: 0.0394, dn_loss_iou: 0.2297, d0.dn_loss_cls: 0.1739, d0.dn_loss_bbox: 0.0513, d0.dn_loss_iou: 0.2905, d1.dn_loss_cls: 0.0577, d1.dn_loss_bbox: 0.0410, d1.dn_loss_iou: 0.2341, d2.dn_loss_cls: 0.0361, d2.dn_loss_bbox: 0.0395, d2.dn_loss_iou: 0.2291, d3.dn_loss_cls: 0.0357, d3.dn_loss_bbox: 0.0394, d3.dn_loss_iou: 0.2287, d4.dn_loss_cls: 0.0351, d4.dn_loss_bbox: 0.0394, d4.dn_loss_iou: 0.2294, loss_rpn_cls: 0.0277, loss_rpn_bbox: 0.1733, loss_cls0: 2.6294, acc0: 90.9059, loss_bbox0: 3.7551, loss_cls1: 1.9829, loss_bbox1: 3.9441, loss_centerness1: 7.1346, loss_cls_aux0: 0.0447, loss_bbox_aux0: 0.0199, loss_iou_aux0: 0.1107, d0.loss_cls_aux0: 0.0497, d0.loss_bbox_aux0: 0.0459, d0.loss_iou_aux0: 0.2563, d1.loss_cls_aux0: 0.0447, d1.loss_bbox_aux0: 0.0238, d1.loss_iou_aux0: 0.1324, d2.loss_cls_aux0: 0.0431, d2.loss_bbox_aux0: 0.0204, d2.loss_iou_aux0: 0.1138, d3.loss_cls_aux0: 0.0430, d3.loss_bbox_aux0: 0.0197, d3.loss_iou_aux0: 0.1097, d4.loss_cls_aux0: 0.0441, d4.loss_bbox_aux0: 0.0198, d4.loss_iou_aux0: 0.1102, loss_cls_aux1: 0.0256, loss_bbox_aux1: 0.0417, loss_iou_aux1: 0.2325, d0.loss_cls_aux1: 0.0367, d0.loss_bbox_aux1: 0.0519, d0.loss_iou_aux1: 0.2838, d1.loss_cls_aux1: 0.0281, d1.loss_bbox_aux1: 0.0426, d1.loss_iou_aux1: 0.2359, d2.loss_cls_aux1: 0.0260, d2.loss_bbox_aux1: 0.0416, d2.loss_iou_aux1: 0.2322, d3.loss_cls_aux1: 0.0255, d3.loss_bbox_aux1: 0.0416, d3.loss_iou_aux1: 0.2322, d4.loss_cls_aux1: 0.0255, d4.loss_bbox_aux1: 0.0416, d4.loss_iou_aux1: 0.2324, loss: 29.5290, grad_norm: 206.9907
2024-03-18 18:24:47,910 - mmdet - INFO - Epoch [1][450/463]	lr: 1.000e-05, eta: 5:06:50, time: 2.757, data_time: 0.010, memory: 17512, enc_loss_cls: 0.3560, enc_loss_bbox: 0.0696, enc_loss_iou: 0.3503, loss_cls: 0.1553, loss_bbox: 0.0688, loss_iou: 0.3340, d0.loss_cls: 0.4965, d0.loss_bbox: 0.0673, d0.loss_iou: 0.3308, d1.loss_cls: 0.2147, d1.loss_bbox: 0.0616, d1.loss_iou: 0.3315, d2.loss_cls: 0.1708, d2.loss_bbox: 0.0628, d2.loss_iou: 0.3327, d3.loss_cls: 0.1594, d3.loss_bbox: 0.0635, d3.loss_iou: 0.3317, d4.loss_cls: 0.1539, d4.loss_bbox: 0.0696, d4.loss_iou: 0.3342, dn_loss_cls: 0.0363, dn_loss_bbox: 0.0380, dn_loss_iou: 0.2223, d0.dn_loss_cls: 0.1498, d0.dn_loss_bbox: 0.0491, d0.dn_loss_iou: 0.2815, d1.dn_loss_cls: 0.0526, d1.dn_loss_bbox: 0.0385, d1.dn_loss_iou: 0.2240, d2.dn_loss_cls: 0.0358, d2.dn_loss_bbox: 0.0380, d2.dn_loss_iou: 0.2218, d3.dn_loss_cls: 0.0367, d3.dn_loss_bbox: 0.0380, d3.dn_loss_iou: 0.2221, d4.dn_loss_cls: 0.0363, d4.dn_loss_bbox: 0.0380, d4.dn_loss_iou: 0.2222, loss_rpn_cls: 0.0300, loss_rpn_bbox: 0.1479, loss_cls0: 2.5049, acc0: 91.5774, loss_bbox0: 3.4560, loss_cls1: 1.8553, loss_bbox1: 3.5900, loss_centerness1: 7.1254, loss_cls_aux0: 0.0547, loss_bbox_aux0: 0.0177, loss_iou_aux0: 0.0990, d0.loss_cls_aux0: 0.0564, d0.loss_bbox_aux0: 0.0427, d0.loss_iou_aux0: 0.2419, d1.loss_cls_aux0: 0.0555, d1.loss_bbox_aux0: 0.0214, d1.loss_iou_aux0: 0.1206, d2.loss_cls_aux0: 0.0549, d2.loss_bbox_aux0: 0.0185, d2.loss_iou_aux0: 0.1023, d3.loss_cls_aux0: 0.0545, d3.loss_bbox_aux0: 0.0176, d3.loss_iou_aux0: 0.0976, d4.loss_cls_aux0: 0.0559, d4.loss_bbox_aux0: 0.0177, d4.loss_iou_aux0: 0.0983, loss_cls_aux1: 0.0435, loss_bbox_aux1: 0.0396, loss_iou_aux1: 0.2247, d0.loss_cls_aux1: 0.0486, d0.loss_bbox_aux1: 0.0477, d0.loss_iou_aux1: 0.2669, d1.loss_cls_aux1: 0.0484, d1.loss_bbox_aux1: 0.0400, d1.loss_iou_aux1: 0.2274, d2.loss_cls_aux1: 0.0463, d2.loss_bbox_aux1: 0.0394, d2.loss_iou_aux1: 0.2242, d3.loss_cls_aux1: 0.0448, d3.loss_bbox_aux1: 0.0396, d3.loss_iou_aux1: 0.2245, d4.loss_cls_aux1: 0.0444, d4.loss_bbox_aux1: 0.0396, d4.loss_iou_aux1: 0.2245, loss: 28.3467, grad_norm: 173.9962
2024-03-18 18:25:21,684 - mmdet - INFO - Saving checkpoint at 1 epochs
2024-03-18 18:26:50,758 - mmdet - INFO - Evaluating bbox...
2024-03-18 18:27:06,820 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.562
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.828
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.686
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.442
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.543
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.789
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.743
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.749
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.749
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.706
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.744
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.849

2024-03-18 18:27:06,820 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.634 | Thatch   | 0.494 |
+----------+-------+----------+-------+
2024-03-18 18:27:13,320 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_1.pth.
2024-03-18 18:27:13,321 - mmdet - INFO - Best bbox_mAP is 0.5620 at 1 epoch.
2024-03-18 18:27:13,321 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 18:27:13,321 - mmdet - INFO - Epoch(val) [1][154]	bbox_mAP: 0.5620, bbox_mAP_50: 0.8280, bbox_mAP_75: 0.6860, bbox_mAP_s: 0.4420, bbox_mAP_m: 0.5430, bbox_mAP_l: 0.7890, bbox_mAP_copypaste: 0.562 0.828 0.686 0.442 0.543 0.789
2024-03-18 18:29:27,857 - mmdet - INFO - Epoch [2][50/463]	lr: 1.000e-05, eta: 4:56:51, time: 2.690, data_time: 0.057, memory: 17512, enc_loss_cls: 0.3178, enc_loss_bbox: 0.0762, enc_loss_iou: 0.3822, loss_cls: 0.1387, loss_bbox: 0.0713, loss_iou: 0.3583, d0.loss_cls: 0.4277, d0.loss_bbox: 0.0712, d0.loss_iou: 0.3595, d1.loss_cls: 0.1779, d1.loss_bbox: 0.0711, d1.loss_iou: 0.3589, d2.loss_cls: 0.1496, d2.loss_bbox: 0.0705, d2.loss_iou: 0.3599, d3.loss_cls: 0.1486, d3.loss_bbox: 0.0709, d3.loss_iou: 0.3578, d4.loss_cls: 0.1387, d4.loss_bbox: 0.0711, d4.loss_iou: 0.3579, dn_loss_cls: 0.0244, dn_loss_bbox: 0.0400, dn_loss_iou: 0.2223, d0.dn_loss_cls: 0.1183, d0.dn_loss_bbox: 0.0538, d0.dn_loss_iou: 0.2894, d1.dn_loss_cls: 0.0377, d1.dn_loss_bbox: 0.0406, d1.dn_loss_iou: 0.2245, d2.dn_loss_cls: 0.0242, d2.dn_loss_bbox: 0.0400, d2.dn_loss_iou: 0.2220, d3.dn_loss_cls: 0.0239, d3.dn_loss_bbox: 0.0400, d3.dn_loss_iou: 0.2220, d4.dn_loss_cls: 0.0237, d4.dn_loss_bbox: 0.0400, d4.dn_loss_iou: 0.2222, loss_rpn_cls: 0.0429, loss_rpn_bbox: 0.1567, loss_cls0: 2.6558, acc0: 90.7155, loss_bbox0: 3.6562, loss_cls1: 2.0034, loss_bbox1: 3.9437, loss_centerness1: 7.1527, loss_cls_aux0: 0.0296, loss_bbox_aux0: 0.0201, loss_iou_aux0: 0.1095, d0.loss_cls_aux0: 0.0357, d0.loss_bbox_aux0: 0.0462, d0.loss_iou_aux0: 0.2514, d1.loss_cls_aux0: 0.0299, d1.loss_bbox_aux0: 0.0243, d1.loss_iou_aux0: 0.1320, d2.loss_cls_aux0: 0.0295, d2.loss_bbox_aux0: 0.0206, d2.loss_iou_aux0: 0.1125, d3.loss_cls_aux0: 0.0289, d3.loss_bbox_aux0: 0.0199, d3.loss_iou_aux0: 0.1081, d4.loss_cls_aux0: 0.0290, d4.loss_bbox_aux0: 0.0200, d4.loss_iou_aux0: 0.1088, loss_cls_aux1: 0.0338, loss_bbox_aux1: 0.0438, loss_iou_aux1: 0.2414, d0.loss_cls_aux1: 0.0360, d0.loss_bbox_aux1: 0.0523, d0.loss_iou_aux1: 0.2822, d1.loss_cls_aux1: 0.0326, d1.loss_bbox_aux1: 0.0448, d1.loss_iou_aux1: 0.2454, d2.loss_cls_aux1: 0.0350, d2.loss_bbox_aux1: 0.0437, d2.loss_iou_aux1: 0.2408, d3.loss_cls_aux1: 0.0339, d3.loss_bbox_aux1: 0.0437, d3.loss_iou_aux1: 0.2411, d4.loss_cls_aux1: 0.0338, d4.loss_bbox_aux1: 0.0438, d4.loss_iou_aux1: 0.2412, loss: 29.1815, grad_norm: 189.5468
2024-03-18 18:31:36,284 - mmdet - INFO - Epoch [2][100/463]	lr: 1.000e-05, eta: 4:54:33, time: 2.569, data_time: 0.010, memory: 17512, enc_loss_cls: 0.2791, enc_loss_bbox: 0.0714, enc_loss_iou: 0.3761, loss_cls: 0.1346, loss_bbox: 0.0652, loss_iou: 0.3461, d0.loss_cls: 0.3991, d0.loss_bbox: 0.0650, d0.loss_iou: 0.3461, d1.loss_cls: 0.1817, d1.loss_bbox: 0.0646, d1.loss_iou: 0.3455, d2.loss_cls: 0.1497, d2.loss_bbox: 0.0648, d2.loss_iou: 0.3452, d3.loss_cls: 0.1385, d3.loss_bbox: 0.0645, d3.loss_iou: 0.3435, d4.loss_cls: 0.1348, d4.loss_bbox: 0.0652, d4.loss_iou: 0.3463, dn_loss_cls: 0.0189, dn_loss_bbox: 0.0367, dn_loss_iou: 0.2223, d0.dn_loss_cls: 0.1089, d0.dn_loss_bbox: 0.0495, d0.dn_loss_iou: 0.2903, d1.dn_loss_cls: 0.0341, d1.dn_loss_bbox: 0.0373, d1.dn_loss_iou: 0.2249, d2.dn_loss_cls: 0.0202, d2.dn_loss_bbox: 0.0366, d2.dn_loss_iou: 0.2213, d3.dn_loss_cls: 0.0191, d3.dn_loss_bbox: 0.0367, d3.dn_loss_iou: 0.2222, d4.dn_loss_cls: 0.0185, d4.dn_loss_bbox: 0.0367, d4.dn_loss_iou: 0.2222, loss_rpn_cls: 0.0439, loss_rpn_bbox: 0.1615, loss_cls0: 2.4224, acc0: 91.7385, loss_bbox0: 3.5173, loss_cls1: 1.9125, loss_bbox1: 3.7986, loss_centerness1: 7.1378, loss_cls_aux0: 0.0277, loss_bbox_aux0: 0.0179, loss_iou_aux0: 0.1007, d0.loss_cls_aux0: 0.0336, d0.loss_bbox_aux0: 0.0417, d0.loss_iou_aux0: 0.2420, d1.loss_cls_aux0: 0.0299, d1.loss_bbox_aux0: 0.0212, d1.loss_iou_aux0: 0.1217, d2.loss_cls_aux0: 0.0279, d2.loss_bbox_aux0: 0.0185, d2.loss_iou_aux0: 0.1052, d3.loss_cls_aux0: 0.0268, d3.loss_bbox_aux0: 0.0177, d3.loss_iou_aux0: 0.0996, d4.loss_cls_aux0: 0.0263, d4.loss_bbox_aux0: 0.0178, d4.loss_iou_aux0: 0.1002, loss_cls_aux1: 0.0272, loss_bbox_aux1: 0.0392, loss_iou_aux1: 0.2281, d0.loss_cls_aux1: 0.0315, d0.loss_bbox_aux1: 0.0488, d0.loss_iou_aux1: 0.2770, d1.loss_cls_aux1: 0.0295, d1.loss_bbox_aux1: 0.0399, d1.loss_iou_aux1: 0.2316, d2.loss_cls_aux1: 0.0279, d2.loss_bbox_aux1: 0.0391, d2.loss_iou_aux1: 0.2277, d3.loss_cls_aux1: 0.0259, d3.loss_bbox_aux1: 0.0391, d3.loss_iou_aux1: 0.2279, d4.loss_cls_aux1: 0.0260, d4.loss_bbox_aux1: 0.0391, d4.loss_iou_aux1: 0.2279, loss: 28.0872, grad_norm: 182.6460
2024-03-18 18:33:48,945 - mmdet - INFO - Epoch [2][150/463]	lr: 1.000e-05, eta: 4:53:03, time: 2.653, data_time: 0.009, memory: 17512, enc_loss_cls: 0.2673, enc_loss_bbox: 0.0703, enc_loss_iou: 0.3411, loss_cls: 0.1275, loss_bbox: 0.0637, loss_iou: 0.3161, d0.loss_cls: 0.3865, d0.loss_bbox: 0.0639, d0.loss_iou: 0.3182, d1.loss_cls: 0.1680, d1.loss_bbox: 0.0627, d1.loss_iou: 0.3163, d2.loss_cls: 0.1379, d2.loss_bbox: 0.0623, d2.loss_iou: 0.3156, d3.loss_cls: 0.1282, d3.loss_bbox: 0.0631, d3.loss_iou: 0.3156, d4.loss_cls: 0.1274, d4.loss_bbox: 0.0636, d4.loss_iou: 0.3160, dn_loss_cls: 0.0326, dn_loss_bbox: 0.0370, dn_loss_iou: 0.2168, d0.dn_loss_cls: 0.1077, d0.dn_loss_bbox: 0.0484, d0.dn_loss_iou: 0.2774, d1.dn_loss_cls: 0.0412, d1.dn_loss_bbox: 0.0374, d1.dn_loss_iou: 0.2176, d2.dn_loss_cls: 0.0320, d2.dn_loss_bbox: 0.0370, d2.dn_loss_iou: 0.2166, d3.dn_loss_cls: 0.0321, d3.dn_loss_bbox: 0.0370, d3.dn_loss_iou: 0.2166, d4.dn_loss_cls: 0.0321, d4.dn_loss_bbox: 0.0370, d4.dn_loss_iou: 0.2166, loss_rpn_cls: 0.0287, loss_rpn_bbox: 0.1318, loss_cls0: 2.2598, acc0: 92.3476, loss_bbox0: 3.2646, loss_cls1: 1.7984, loss_bbox1: 3.4833, loss_centerness1: 7.1169, loss_cls_aux0: 0.0371, loss_bbox_aux0: 0.0169, loss_iou_aux0: 0.0947, d0.loss_cls_aux0: 0.0375, d0.loss_bbox_aux0: 0.0425, d0.loss_iou_aux0: 0.2388, d1.loss_cls_aux0: 0.0384, d1.loss_bbox_aux0: 0.0212, d1.loss_iou_aux0: 0.1181, d2.loss_cls_aux0: 0.0374, d2.loss_bbox_aux0: 0.0179, d2.loss_iou_aux0: 0.0996, d3.loss_cls_aux0: 0.0363, d3.loss_bbox_aux0: 0.0168, d3.loss_iou_aux0: 0.0937, d4.loss_cls_aux0: 0.0366, d4.loss_bbox_aux0: 0.0169, d4.loss_iou_aux0: 0.0940, loss_cls_aux1: 0.0333, loss_bbox_aux1: 0.0389, loss_iou_aux1: 0.2139, d0.loss_cls_aux1: 0.0345, d0.loss_bbox_aux1: 0.0475, d0.loss_iou_aux1: 0.2571, d1.loss_cls_aux1: 0.0358, d1.loss_bbox_aux1: 0.0398, d1.loss_iou_aux1: 0.2180, d2.loss_cls_aux1: 0.0355, d2.loss_bbox_aux1: 0.0388, d2.loss_iou_aux1: 0.2139, d3.loss_cls_aux1: 0.0338, d3.loss_bbox_aux1: 0.0389, d3.loss_iou_aux1: 0.2138, d4.loss_cls_aux1: 0.0334, d4.loss_bbox_aux1: 0.0389, d4.loss_iou_aux1: 0.2138, loss: 26.8621, grad_norm: 196.5293
2024-03-18 18:36:02,189 - mmdet - INFO - Epoch [2][200/463]	lr: 1.000e-05, eta: 4:51:33, time: 2.665, data_time: 0.010, memory: 17512, enc_loss_cls: 0.2466, enc_loss_bbox: 0.0843, enc_loss_iou: 0.4150, loss_cls: 0.1201, loss_bbox: 0.0693, loss_iou: 0.3567, d0.loss_cls: 0.3557, d0.loss_bbox: 0.0700, d0.loss_iou: 0.3607, d1.loss_cls: 0.1582, d1.loss_bbox: 0.0692, d1.loss_iou: 0.3568, d2.loss_cls: 0.1338, d2.loss_bbox: 0.0691, d2.loss_iou: 0.3558, d3.loss_cls: 0.1254, d3.loss_bbox: 0.0690, d3.loss_iou: 0.3554, d4.loss_cls: 0.1194, d4.loss_bbox: 0.0693, d4.loss_iou: 0.3571, dn_loss_cls: 0.0238, dn_loss_bbox: 0.0384, dn_loss_iou: 0.2170, d0.dn_loss_cls: 0.1016, d0.dn_loss_bbox: 0.0525, d0.dn_loss_iou: 0.2902, d1.dn_loss_cls: 0.0347, d1.dn_loss_bbox: 0.0390, d1.dn_loss_iou: 0.2198, d2.dn_loss_cls: 0.0249, d2.dn_loss_bbox: 0.0383, d2.dn_loss_iou: 0.2166, d3.dn_loss_cls: 0.0235, d3.dn_loss_bbox: 0.0383, d3.dn_loss_iou: 0.2167, d4.dn_loss_cls: 0.0233, d4.dn_loss_bbox: 0.0384, d4.dn_loss_iou: 0.2168, loss_rpn_cls: 0.0244, loss_rpn_bbox: 0.1526, loss_cls0: 2.4441, acc0: 91.7139, loss_bbox0: 3.6072, loss_cls1: 1.8934, loss_bbox1: 3.9468, loss_centerness1: 7.1584, loss_cls_aux0: 0.0383, loss_bbox_aux0: 0.0185, loss_iou_aux0: 0.1006, d0.loss_cls_aux0: 0.0409, d0.loss_bbox_aux0: 0.0467, d0.loss_iou_aux0: 0.2496, d1.loss_cls_aux0: 0.0414, d1.loss_bbox_aux0: 0.0226, d1.loss_iou_aux0: 0.1225, d2.loss_cls_aux0: 0.0403, d2.loss_bbox_aux0: 0.0191, d2.loss_iou_aux0: 0.1035, d3.loss_cls_aux0: 0.0386, d3.loss_bbox_aux0: 0.0184, d3.loss_iou_aux0: 0.0995, d4.loss_cls_aux0: 0.0377, d4.loss_bbox_aux0: 0.0184, d4.loss_iou_aux0: 0.1001, loss_cls_aux1: 0.0309, loss_bbox_aux1: 0.0429, loss_iou_aux1: 0.2334, d0.loss_cls_aux1: 0.0338, d0.loss_bbox_aux1: 0.0535, d0.loss_iou_aux1: 0.2850, d1.loss_cls_aux1: 0.0331, d1.loss_bbox_aux1: 0.0438, d1.loss_iou_aux1: 0.2383, d2.loss_cls_aux1: 0.0325, d2.loss_bbox_aux1: 0.0429, d2.loss_iou_aux1: 0.2335, d3.loss_cls_aux1: 0.0314, d3.loss_bbox_aux1: 0.0429, d3.loss_iou_aux1: 0.2333, d4.loss_cls_aux1: 0.0301, d4.loss_bbox_aux1: 0.0429, d4.loss_iou_aux1: 0.2333, loss: 28.4721, grad_norm: 180.2456
2024-03-18 18:38:14,361 - mmdet - INFO - Epoch [2][250/463]	lr: 1.000e-05, eta: 4:49:47, time: 2.643, data_time: 0.010, memory: 18193, enc_loss_cls: 0.2471, enc_loss_bbox: 0.0878, enc_loss_iou: 0.4217, loss_cls: 0.1311, loss_bbox: 0.0771, loss_iou: 0.3860, d0.loss_cls: 0.3484, d0.loss_bbox: 0.0815, d0.loss_iou: 0.3924, d1.loss_cls: 0.1685, d1.loss_bbox: 0.0764, d1.loss_iou: 0.3886, d2.loss_cls: 0.1420, d2.loss_bbox: 0.0737, d2.loss_iou: 0.3822, d3.loss_cls: 0.1314, d3.loss_bbox: 0.0767, d3.loss_iou: 0.3845, d4.loss_cls: 0.1299, d4.loss_bbox: 0.0772, d4.loss_iou: 0.3863, dn_loss_cls: 0.0304, dn_loss_bbox: 0.0393, dn_loss_iou: 0.2197, d0.dn_loss_cls: 0.1040, d0.dn_loss_bbox: 0.0547, d0.dn_loss_iou: 0.2990, d1.dn_loss_cls: 0.0431, d1.dn_loss_bbox: 0.0400, d1.dn_loss_iou: 0.2234, d2.dn_loss_cls: 0.0308, d2.dn_loss_bbox: 0.0392, d2.dn_loss_iou: 0.2197, d3.dn_loss_cls: 0.0292, d3.dn_loss_bbox: 0.0393, d3.dn_loss_iou: 0.2198, d4.dn_loss_cls: 0.0289, d4.dn_loss_bbox: 0.0393, d4.dn_loss_iou: 0.2197, loss_rpn_cls: 0.0496, loss_rpn_bbox: 0.1418, loss_cls0: 2.4534, acc0: 91.7031, loss_bbox0: 3.4784, loss_cls1: 1.9965, loss_bbox1: 4.1315, loss_centerness1: 7.1583, loss_cls_aux0: 0.0479, loss_bbox_aux0: 0.0189, loss_iou_aux0: 0.1006, d0.loss_cls_aux0: 0.0489, d0.loss_bbox_aux0: 0.0460, d0.loss_iou_aux0: 0.2560, d1.loss_cls_aux0: 0.0537, d1.loss_bbox_aux0: 0.0237, d1.loss_iou_aux0: 0.1293, d2.loss_cls_aux0: 0.0506, d2.loss_bbox_aux0: 0.0195, d2.loss_iou_aux0: 0.1044, d3.loss_cls_aux0: 0.0457, d3.loss_bbox_aux0: 0.0188, d3.loss_iou_aux0: 0.0999, d4.loss_cls_aux0: 0.0462, d4.loss_bbox_aux0: 0.0188, d4.loss_iou_aux0: 0.1002, loss_cls_aux1: 0.0445, loss_bbox_aux1: 0.0442, loss_iou_aux1: 0.2415, d0.loss_cls_aux1: 0.0492, d0.loss_bbox_aux1: 0.0537, d0.loss_iou_aux1: 0.2903, d1.loss_cls_aux1: 0.0500, d1.loss_bbox_aux1: 0.0451, d1.loss_iou_aux1: 0.2469, d2.loss_cls_aux1: 0.0451, d2.loss_bbox_aux1: 0.0442, d2.loss_iou_aux1: 0.2418, d3.loss_cls_aux1: 0.0432, d3.loss_bbox_aux1: 0.0441, d3.loss_iou_aux1: 0.2414, d4.loss_cls_aux1: 0.0427, d4.loss_bbox_aux1: 0.0441, d4.loss_iou_aux1: 0.2414, loss: 29.2021, grad_norm: 176.7265
2024-03-18 18:40:27,722 - mmdet - INFO - Epoch [2][300/463]	lr: 1.000e-05, eta: 4:48:07, time: 2.667, data_time: 0.008, memory: 18193, enc_loss_cls: 0.2274, enc_loss_bbox: 0.0785, enc_loss_iou: 0.3776, loss_cls: 0.1351, loss_bbox: 0.0731, loss_iou: 0.3555, d0.loss_cls: 0.3045, d0.loss_bbox: 0.0773, d0.loss_iou: 0.3585, d1.loss_cls: 0.1591, d1.loss_bbox: 0.0721, d1.loss_iou: 0.3555, d2.loss_cls: 0.1352, d2.loss_bbox: 0.0710, d2.loss_iou: 0.3529, d3.loss_cls: 0.1301, d3.loss_bbox: 0.0718, d3.loss_iou: 0.3558, d4.loss_cls: 0.1336, d4.loss_bbox: 0.0731, d4.loss_iou: 0.3553, dn_loss_cls: 0.0335, dn_loss_bbox: 0.0375, dn_loss_iou: 0.2155, d0.dn_loss_cls: 0.0729, d0.dn_loss_bbox: 0.0517, d0.dn_loss_iou: 0.2885, d1.dn_loss_cls: 0.0327, d1.dn_loss_bbox: 0.0381, d1.dn_loss_iou: 0.2180, d2.dn_loss_cls: 0.0277, d2.dn_loss_bbox: 0.0374, d2.dn_loss_iou: 0.2150, d3.dn_loss_cls: 0.0293, d3.dn_loss_bbox: 0.0375, d3.dn_loss_iou: 0.2152, d4.dn_loss_cls: 0.0325, d4.dn_loss_bbox: 0.0375, d4.dn_loss_iou: 0.2153, loss_rpn_cls: 0.0285, loss_rpn_bbox: 0.1700, loss_cls0: 2.3248, acc0: 91.9312, loss_bbox0: 3.5495, loss_cls1: 1.8965, loss_bbox1: 3.8597, loss_centerness1: 7.1326, loss_cls_aux0: 0.0312, loss_bbox_aux0: 0.0203, loss_iou_aux0: 0.1110, d0.loss_cls_aux0: 0.0277, d0.loss_bbox_aux0: 0.0480, d0.loss_iou_aux0: 0.2600, d1.loss_cls_aux0: 0.0309, d1.loss_bbox_aux0: 0.0242, d1.loss_iou_aux0: 0.1330, d2.loss_cls_aux0: 0.0312, d2.loss_bbox_aux0: 0.0211, d2.loss_iou_aux0: 0.1141, d3.loss_cls_aux0: 0.0311, d3.loss_bbox_aux0: 0.0201, d3.loss_iou_aux0: 0.1089, d4.loss_cls_aux0: 0.0306, d4.loss_bbox_aux0: 0.0202, d4.loss_iou_aux0: 0.1099, loss_cls_aux1: 0.0268, loss_bbox_aux1: 0.0427, loss_iou_aux1: 0.2317, d0.loss_cls_aux1: 0.0243, d0.loss_bbox_aux1: 0.0536, d0.loss_iou_aux1: 0.2864, d1.loss_cls_aux1: 0.0247, d1.loss_bbox_aux1: 0.0439, d1.loss_iou_aux1: 0.2368, d2.loss_cls_aux1: 0.0256, d2.loss_bbox_aux1: 0.0426, d2.loss_iou_aux1: 0.2311, d3.loss_cls_aux1: 0.0263, d3.loss_bbox_aux1: 0.0426, d3.loss_iou_aux1: 0.2312, d4.loss_cls_aux1: 0.0258, d4.loss_bbox_aux1: 0.0427, d4.loss_iou_aux1: 0.2314, loss: 28.0941, grad_norm: 192.6991
2024-03-18 18:42:29,910 - mmdet - INFO - Epoch [2][350/463]	lr: 1.000e-05, eta: 4:44:53, time: 2.444, data_time: 0.009, memory: 18193, enc_loss_cls: 0.2364, enc_loss_bbox: 0.0731, enc_loss_iou: 0.3742, loss_cls: 0.1314, loss_bbox: 0.0665, loss_iou: 0.3490, d0.loss_cls: 0.3085, d0.loss_bbox: 0.0672, d0.loss_iou: 0.3496, d1.loss_cls: 0.1478, d1.loss_bbox: 0.0672, d1.loss_iou: 0.3524, d2.loss_cls: 0.1339, d2.loss_bbox: 0.0669, d2.loss_iou: 0.3495, d3.loss_cls: 0.1319, d3.loss_bbox: 0.0667, d3.loss_iou: 0.3499, d4.loss_cls: 0.1317, d4.loss_bbox: 0.0664, d4.loss_iou: 0.3489, dn_loss_cls: 0.0137, dn_loss_bbox: 0.0359, dn_loss_iou: 0.2124, d0.dn_loss_cls: 0.0662, d0.dn_loss_bbox: 0.0492, d0.dn_loss_iou: 0.2851, d1.dn_loss_cls: 0.0211, d1.dn_loss_bbox: 0.0364, d1.dn_loss_iou: 0.2153, d2.dn_loss_cls: 0.0147, d2.dn_loss_bbox: 0.0358, d2.dn_loss_iou: 0.2119, d3.dn_loss_cls: 0.0140, d3.dn_loss_bbox: 0.0358, d3.dn_loss_iou: 0.2121, d4.dn_loss_cls: 0.0131, d4.dn_loss_bbox: 0.0358, d4.dn_loss_iou: 0.2122, loss_rpn_cls: 0.0486, loss_rpn_bbox: 0.1690, loss_cls0: 2.5199, acc0: 91.1830, loss_bbox0: 3.7167, loss_cls1: 1.8509, loss_bbox1: 3.9009, loss_centerness1: 7.1489, loss_cls_aux0: 0.0259, loss_bbox_aux0: 0.0198, loss_iou_aux0: 0.1092, d0.loss_cls_aux0: 0.0264, d0.loss_bbox_aux0: 0.0456, d0.loss_iou_aux0: 0.2533, d1.loss_cls_aux0: 0.0241, d1.loss_bbox_aux0: 0.0242, d1.loss_iou_aux0: 0.1350, d2.loss_cls_aux0: 0.0249, d2.loss_bbox_aux0: 0.0206, d2.loss_iou_aux0: 0.1136, d3.loss_cls_aux0: 0.0241, d3.loss_bbox_aux0: 0.0196, d3.loss_iou_aux0: 0.1072, d4.loss_cls_aux0: 0.0242, d4.loss_bbox_aux0: 0.0197, d4.loss_iou_aux0: 0.1083, loss_cls_aux1: 0.0194, loss_bbox_aux1: 0.0414, loss_iou_aux1: 0.2285, d0.loss_cls_aux1: 0.0244, d0.loss_bbox_aux1: 0.0523, d0.loss_iou_aux1: 0.2845, d1.loss_cls_aux1: 0.0201, d1.loss_bbox_aux1: 0.0428, d1.loss_iou_aux1: 0.2358, d2.loss_cls_aux1: 0.0200, d2.loss_bbox_aux1: 0.0413, d2.loss_iou_aux1: 0.2280, d3.loss_cls_aux1: 0.0186, d3.loss_bbox_aux1: 0.0413, d3.loss_iou_aux1: 0.2283, d4.loss_cls_aux1: 0.0182, d4.loss_bbox_aux1: 0.0413, d4.loss_iou_aux1: 0.2284, loss: 28.1849, grad_norm: 185.0374
2024-03-18 18:44:43,145 - mmdet - INFO - Epoch [2][400/463]	lr: 1.000e-05, eta: 4:43:11, time: 2.665, data_time: 0.008, memory: 18193, enc_loss_cls: 0.2120, enc_loss_bbox: 0.0830, enc_loss_iou: 0.3939, loss_cls: 0.1203, loss_bbox: 0.0793, loss_iou: 0.3683, d0.loss_cls: 0.2890, d0.loss_bbox: 0.0805, d0.loss_iou: 0.3677, d1.loss_cls: 0.1464, d1.loss_bbox: 0.0726, d1.loss_iou: 0.3643, d2.loss_cls: 0.1246, d2.loss_bbox: 0.0783, d2.loss_iou: 0.3665, d3.loss_cls: 0.1208, d3.loss_bbox: 0.0787, d3.loss_iou: 0.3679, d4.loss_cls: 0.1190, d4.loss_bbox: 0.0789, d4.loss_iou: 0.3683, dn_loss_cls: 0.0193, dn_loss_bbox: 0.0371, dn_loss_iou: 0.2122, d0.dn_loss_cls: 0.0643, d0.dn_loss_bbox: 0.0505, d0.dn_loss_iou: 0.2831, d1.dn_loss_cls: 0.0227, d1.dn_loss_bbox: 0.0377, d1.dn_loss_iou: 0.2154, d2.dn_loss_cls: 0.0174, d2.dn_loss_bbox: 0.0371, d2.dn_loss_iou: 0.2123, d3.dn_loss_cls: 0.0170, d3.dn_loss_bbox: 0.0371, d3.dn_loss_iou: 0.2122, d4.dn_loss_cls: 0.0178, d4.dn_loss_bbox: 0.0371, d4.dn_loss_iou: 0.2122, loss_rpn_cls: 0.0341, loss_rpn_bbox: 0.1663, loss_cls0: 2.4197, acc0: 91.6115, loss_bbox0: 3.6792, loss_cls1: 1.9056, loss_bbox1: 3.9087, loss_centerness1: 7.1439, loss_cls_aux0: 0.0292, loss_bbox_aux0: 0.0190, loss_iou_aux0: 0.1001, d0.loss_cls_aux0: 0.0269, d0.loss_bbox_aux0: 0.0462, d0.loss_iou_aux0: 0.2497, d1.loss_cls_aux0: 0.0282, d1.loss_bbox_aux0: 0.0232, d1.loss_iou_aux0: 0.1228, d2.loss_cls_aux0: 0.0282, d2.loss_bbox_aux0: 0.0194, d2.loss_iou_aux0: 0.1022, d3.loss_cls_aux0: 0.0275, d3.loss_bbox_aux0: 0.0189, d3.loss_iou_aux0: 0.0989, d4.loss_cls_aux0: 0.0281, d4.loss_bbox_aux0: 0.0189, d4.loss_iou_aux0: 0.0993, loss_cls_aux1: 0.0208, loss_bbox_aux1: 0.0424, loss_iou_aux1: 0.2254, d0.loss_cls_aux1: 0.0211, d0.loss_bbox_aux1: 0.0516, d0.loss_iou_aux1: 0.2717, d1.loss_cls_aux1: 0.0221, d1.loss_bbox_aux1: 0.0436, d1.loss_iou_aux1: 0.2306, d2.loss_cls_aux1: 0.0203, d2.loss_bbox_aux1: 0.0424, d2.loss_iou_aux1: 0.2252, d3.loss_cls_aux1: 0.0193, d3.loss_bbox_aux1: 0.0424, d3.loss_iou_aux1: 0.2252, d4.loss_cls_aux1: 0.0203, d4.loss_bbox_aux1: 0.0424, d4.loss_iou_aux1: 0.2253, loss: 28.1591, grad_norm: 174.8578
2024-03-18 18:46:58,039 - mmdet - INFO - Epoch [2][450/463]	lr: 1.000e-05, eta: 4:41:38, time: 2.698, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1853, enc_loss_bbox: 0.0757, enc_loss_iou: 0.3889, loss_cls: 0.1051, loss_bbox: 0.0676, loss_iou: 0.3556, d0.loss_cls: 0.2617, d0.loss_bbox: 0.0708, d0.loss_iou: 0.3612, d1.loss_cls: 0.1287, d1.loss_bbox: 0.0699, d1.loss_iou: 0.3598, d2.loss_cls: 0.1091, d2.loss_bbox: 0.0681, d2.loss_iou: 0.3576, d3.loss_cls: 0.1074, d3.loss_bbox: 0.0675, d3.loss_iou: 0.3559, d4.loss_cls: 0.1038, d4.loss_bbox: 0.0677, d4.loss_iou: 0.3559, dn_loss_cls: 0.0154, dn_loss_bbox: 0.0376, dn_loss_iou: 0.2122, d0.dn_loss_cls: 0.0683, d0.dn_loss_bbox: 0.0531, d0.dn_loss_iou: 0.2891, d1.dn_loss_cls: 0.0215, d1.dn_loss_bbox: 0.0387, d1.dn_loss_iou: 0.2168, d2.dn_loss_cls: 0.0158, d2.dn_loss_bbox: 0.0376, d2.dn_loss_iou: 0.2120, d3.dn_loss_cls: 0.0148, d3.dn_loss_bbox: 0.0376, d3.dn_loss_iou: 0.2120, d4.dn_loss_cls: 0.0150, d4.dn_loss_bbox: 0.0376, d4.dn_loss_iou: 0.2121, loss_rpn_cls: 0.0464, loss_rpn_bbox: 0.1749, loss_cls0: 2.4931, acc0: 91.3944, loss_bbox0: 3.7013, loss_cls1: 1.7964, loss_bbox1: 3.9965, loss_centerness1: 7.1393, loss_cls_aux0: 0.0230, loss_bbox_aux0: 0.0206, loss_iou_aux0: 0.1095, d0.loss_cls_aux0: 0.0255, d0.loss_bbox_aux0: 0.0460, d0.loss_iou_aux0: 0.2505, d1.loss_cls_aux0: 0.0241, d1.loss_bbox_aux0: 0.0245, d1.loss_iou_aux0: 0.1308, d2.loss_cls_aux0: 0.0232, d2.loss_bbox_aux0: 0.0212, d2.loss_iou_aux0: 0.1127, d3.loss_cls_aux0: 0.0232, d3.loss_bbox_aux0: 0.0204, d3.loss_iou_aux0: 0.1075, d4.loss_cls_aux0: 0.0224, d4.loss_bbox_aux0: 0.0205, d4.loss_iou_aux0: 0.1084, loss_cls_aux1: 0.0169, loss_bbox_aux1: 0.0407, loss_iou_aux1: 0.2278, d0.loss_cls_aux1: 0.0200, d0.loss_bbox_aux1: 0.0522, d0.loss_iou_aux1: 0.2839, d1.loss_cls_aux1: 0.0192, d1.loss_bbox_aux1: 0.0422, d1.loss_iou_aux1: 0.2347, d2.loss_cls_aux1: 0.0171, d2.loss_bbox_aux1: 0.0406, d2.loss_iou_aux1: 0.2276, d3.loss_cls_aux1: 0.0162, d3.loss_bbox_aux1: 0.0406, d3.loss_iou_aux1: 0.2272, d4.loss_cls_aux1: 0.0163, d4.loss_bbox_aux1: 0.0406, d4.loss_iou_aux1: 0.2275, loss: 28.0236, grad_norm: 159.2863
2024-03-18 18:47:30,189 - mmdet - INFO - Saving checkpoint at 2 epochs
2024-03-18 18:49:00,426 - mmdet - INFO - Evaluating bbox...
2024-03-18 18:49:16,818 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.593
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.872
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.721
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.566
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.798
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.721
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.724
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.724
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.669
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.719
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.848

2024-03-18 18:49:16,818 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.643 | Thatch   | 0.546 |
+----------+-------+----------+-------+
2024-03-18 18:49:17,474 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_004/best_bbox_mAP_epoch_1.pth was removed
2024-03-18 18:49:23,917 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_2.pth.
2024-03-18 18:49:23,918 - mmdet - INFO - Best bbox_mAP is 0.5930 at 2 epoch.
2024-03-18 18:49:23,918 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 18:49:23,918 - mmdet - INFO - Epoch(val) [2][154]	bbox_mAP: 0.5930, bbox_mAP_50: 0.8720, bbox_mAP_75: 0.7210, bbox_mAP_s: 0.4680, bbox_mAP_m: 0.5660, bbox_mAP_l: 0.7980, bbox_mAP_copypaste: 0.593 0.872 0.721 0.468 0.566 0.798
2024-03-18 18:51:36,329 - mmdet - INFO - Epoch [3][50/463]	lr: 1.000e-05, eta: 4:35:26, time: 2.648, data_time: 0.057, memory: 18193, enc_loss_cls: 0.1974, enc_loss_bbox: 0.0831, enc_loss_iou: 0.4172, loss_cls: 0.1132, loss_bbox: 0.0724, loss_iou: 0.3724, d0.loss_cls: 0.2473, d0.loss_bbox: 0.0749, d0.loss_iou: 0.3803, d1.loss_cls: 0.1357, d1.loss_bbox: 0.0748, d1.loss_iou: 0.3773, d2.loss_cls: 0.1151, d2.loss_bbox: 0.0727, d2.loss_iou: 0.3739, d3.loss_cls: 0.1168, d3.loss_bbox: 0.0720, d3.loss_iou: 0.3713, d4.loss_cls: 0.1118, d4.loss_bbox: 0.0724, d4.loss_iou: 0.3724, dn_loss_cls: 0.0240, dn_loss_bbox: 0.0376, dn_loss_iou: 0.2181, d0.dn_loss_cls: 0.0679, d0.dn_loss_bbox: 0.0548, d0.dn_loss_iou: 0.3040, d1.dn_loss_cls: 0.0290, d1.dn_loss_bbox: 0.0384, d1.dn_loss_iou: 0.2220, d2.dn_loss_cls: 0.0230, d2.dn_loss_bbox: 0.0375, d2.dn_loss_iou: 0.2177, d3.dn_loss_cls: 0.0214, d3.dn_loss_bbox: 0.0375, d3.dn_loss_iou: 0.2177, d4.dn_loss_cls: 0.0218, d4.dn_loss_bbox: 0.0375, d4.dn_loss_iou: 0.2178, loss_rpn_cls: 0.0272, loss_rpn_bbox: 0.1564, loss_cls0: 2.4552, acc0: 91.3754, loss_bbox0: 3.6947, loss_cls1: 1.8937, loss_bbox1: 4.1567, loss_centerness1: 7.1414, loss_cls_aux0: 0.0348, loss_bbox_aux0: 0.0184, loss_iou_aux0: 0.1025, d0.loss_cls_aux0: 0.0261, d0.loss_bbox_aux0: 0.0459, d0.loss_iou_aux0: 0.2526, d1.loss_cls_aux0: 0.0307, d1.loss_bbox_aux0: 0.0233, d1.loss_iou_aux0: 0.1304, d2.loss_cls_aux0: 0.0290, d2.loss_bbox_aux0: 0.0197, d2.loss_iou_aux0: 0.1086, d3.loss_cls_aux0: 0.0308, d3.loss_bbox_aux0: 0.0183, d3.loss_iou_aux0: 0.1011, d4.loss_cls_aux0: 0.0298, d4.loss_bbox_aux0: 0.0184, d4.loss_iou_aux0: 0.1018, loss_cls_aux1: 0.0201, loss_bbox_aux1: 0.0421, loss_iou_aux1: 0.2360, d0.loss_cls_aux1: 0.0179, d0.loss_bbox_aux1: 0.0541, d0.loss_iou_aux1: 0.2916, d1.loss_cls_aux1: 0.0201, d1.loss_bbox_aux1: 0.0441, d1.loss_iou_aux1: 0.2449, d2.loss_cls_aux1: 0.0193, d2.loss_bbox_aux1: 0.0420, d2.loss_iou_aux1: 0.2362, d3.loss_cls_aux1: 0.0188, d3.loss_bbox_aux1: 0.0420, d3.loss_iou_aux1: 0.2356, d4.loss_cls_aux1: 0.0180, d4.loss_bbox_aux1: 0.0420, d4.loss_iou_aux1: 0.2359, loss: 28.5604, grad_norm: 151.8630
2024-03-18 18:53:42,236 - mmdet - INFO - Epoch [3][100/463]	lr: 1.000e-05, eta: 4:33:02, time: 2.518, data_time: 0.009, memory: 18193, enc_loss_cls: 0.2119, enc_loss_bbox: 0.0677, enc_loss_iou: 0.3728, loss_cls: 0.1099, loss_bbox: 0.0637, loss_iou: 0.3529, d0.loss_cls: 0.2570, d0.loss_bbox: 0.0632, d0.loss_iou: 0.3535, d1.loss_cls: 0.1403, d1.loss_bbox: 0.0639, d1.loss_iou: 0.3529, d2.loss_cls: 0.1143, d2.loss_bbox: 0.0634, d2.loss_iou: 0.3517, d3.loss_cls: 0.1094, d3.loss_bbox: 0.0636, d3.loss_iou: 0.3520, d4.loss_cls: 0.1109, d4.loss_bbox: 0.0636, d4.loss_iou: 0.3526, dn_loss_cls: 0.0293, dn_loss_bbox: 0.0348, dn_loss_iou: 0.2079, d0.dn_loss_cls: 0.0579, d0.dn_loss_bbox: 0.0482, d0.dn_loss_iou: 0.2800, d1.dn_loss_cls: 0.0261, d1.dn_loss_bbox: 0.0355, d1.dn_loss_iou: 0.2114, d2.dn_loss_cls: 0.0262, d2.dn_loss_bbox: 0.0348, d2.dn_loss_iou: 0.2077, d3.dn_loss_cls: 0.0263, d3.dn_loss_bbox: 0.0348, d3.dn_loss_iou: 0.2077, d4.dn_loss_cls: 0.0279, d4.dn_loss_bbox: 0.0348, d4.dn_loss_iou: 0.2077, loss_rpn_cls: 0.0287, loss_rpn_bbox: 0.1531, loss_cls0: 2.2084, acc0: 92.3470, loss_bbox0: 3.3771, loss_cls1: 1.7314, loss_bbox1: 3.8074, loss_centerness1: 7.1477, loss_cls_aux0: 0.0289, loss_bbox_aux0: 0.0172, loss_iou_aux0: 0.0979, d0.loss_cls_aux0: 0.0272, d0.loss_bbox_aux0: 0.0432, d0.loss_iou_aux0: 0.2486, d1.loss_cls_aux0: 0.0297, d1.loss_bbox_aux0: 0.0224, d1.loss_iou_aux0: 0.1274, d2.loss_cls_aux0: 0.0297, d2.loss_bbox_aux0: 0.0182, d2.loss_iou_aux0: 0.1036, d3.loss_cls_aux0: 0.0299, d3.loss_bbox_aux0: 0.0170, d3.loss_iou_aux0: 0.0964, d4.loss_cls_aux0: 0.0284, d4.loss_bbox_aux0: 0.0171, d4.loss_iou_aux0: 0.0971, loss_cls_aux1: 0.0259, loss_bbox_aux1: 0.0389, loss_iou_aux1: 0.2321, d0.loss_cls_aux1: 0.0265, d0.loss_bbox_aux1: 0.0491, d0.loss_iou_aux1: 0.2847, d1.loss_cls_aux1: 0.0261, d1.loss_bbox_aux1: 0.0405, d1.loss_iou_aux1: 0.2396, d2.loss_cls_aux1: 0.0270, d2.loss_bbox_aux1: 0.0389, d2.loss_iou_aux1: 0.2323, d3.loss_cls_aux1: 0.0259, d3.loss_bbox_aux1: 0.0389, d3.loss_iou_aux1: 0.2320, d4.loss_cls_aux1: 0.0255, d4.loss_bbox_aux1: 0.0389, d4.loss_iou_aux1: 0.2321, loss: 27.1191, grad_norm: 176.9295
2024-03-18 18:55:53,083 - mmdet - INFO - Epoch [3][150/463]	lr: 1.000e-05, eta: 4:31:08, time: 2.617, data_time: 0.009, memory: 18193, enc_loss_cls: 0.1985, enc_loss_bbox: 0.0779, enc_loss_iou: 0.3848, loss_cls: 0.1104, loss_bbox: 0.0717, loss_iou: 0.3603, d0.loss_cls: 0.2772, d0.loss_bbox: 0.0718, d0.loss_iou: 0.3593, d1.loss_cls: 0.1327, d1.loss_bbox: 0.0720, d1.loss_iou: 0.3616, d2.loss_cls: 0.1176, d2.loss_bbox: 0.0719, d2.loss_iou: 0.3611, d3.loss_cls: 0.1116, d3.loss_bbox: 0.0715, d3.loss_iou: 0.3592, d4.loss_cls: 0.1096, d4.loss_bbox: 0.0717, d4.loss_iou: 0.3602, dn_loss_cls: 0.0177, dn_loss_bbox: 0.0373, dn_loss_iou: 0.2129, d0.dn_loss_cls: 0.0628, d0.dn_loss_bbox: 0.0525, d0.dn_loss_iou: 0.2878, d1.dn_loss_cls: 0.0239, d1.dn_loss_bbox: 0.0382, d1.dn_loss_iou: 0.2163, d2.dn_loss_cls: 0.0186, d2.dn_loss_bbox: 0.0373, d2.dn_loss_iou: 0.2123, d3.dn_loss_cls: 0.0173, d3.dn_loss_bbox: 0.0373, d3.dn_loss_iou: 0.2127, d4.dn_loss_cls: 0.0172, d4.dn_loss_bbox: 0.0373, d4.dn_loss_iou: 0.2128, loss_rpn_cls: 0.0382, loss_rpn_bbox: 0.1535, loss_cls0: 2.3739, acc0: 91.9190, loss_bbox0: 3.5590, loss_cls1: 1.7885, loss_bbox1: 3.8318, loss_centerness1: 7.1489, loss_cls_aux0: 0.0304, loss_bbox_aux0: 0.0176, loss_iou_aux0: 0.0971, d0.loss_cls_aux0: 0.0305, d0.loss_bbox_aux0: 0.0461, d0.loss_iou_aux0: 0.2521, d1.loss_cls_aux0: 0.0314, d1.loss_bbox_aux0: 0.0223, d1.loss_iou_aux0: 0.1232, d2.loss_cls_aux0: 0.0315, d2.loss_bbox_aux0: 0.0189, d2.loss_iou_aux0: 0.1036, d3.loss_cls_aux0: 0.0290, d3.loss_bbox_aux0: 0.0175, d3.loss_iou_aux0: 0.0960, d4.loss_cls_aux0: 0.0306, d4.loss_bbox_aux0: 0.0175, d4.loss_iou_aux0: 0.0965, loss_cls_aux1: 0.0258, loss_bbox_aux1: 0.0425, loss_iou_aux1: 0.2314, d0.loss_cls_aux1: 0.0280, d0.loss_bbox_aux1: 0.0523, d0.loss_iou_aux1: 0.2789, d1.loss_cls_aux1: 0.0280, d1.loss_bbox_aux1: 0.0433, d1.loss_iou_aux1: 0.2365, d2.loss_cls_aux1: 0.0245, d2.loss_bbox_aux1: 0.0424, d2.loss_iou_aux1: 0.2316, d3.loss_cls_aux1: 0.0236, d3.loss_bbox_aux1: 0.0424, d3.loss_iou_aux1: 0.2311, d4.loss_cls_aux1: 0.0256, d4.loss_bbox_aux1: 0.0424, d4.loss_iou_aux1: 0.2313, loss: 27.7118, grad_norm: 159.7281
2024-03-18 18:58:04,139 - mmdet - INFO - Epoch [3][200/463]	lr: 1.000e-05, eta: 4:29:14, time: 2.621, data_time: 0.010, memory: 18193, enc_loss_cls: 0.2056, enc_loss_bbox: 0.0813, enc_loss_iou: 0.3908, loss_cls: 0.1214, loss_bbox: 0.0741, loss_iou: 0.3564, d0.loss_cls: 0.2549, d0.loss_bbox: 0.0773, d0.loss_iou: 0.3688, d1.loss_cls: 0.1457, d1.loss_bbox: 0.0754, d1.loss_iou: 0.3643, d2.loss_cls: 0.1307, d2.loss_bbox: 0.0719, d2.loss_iou: 0.3549, d3.loss_cls: 0.1251, d3.loss_bbox: 0.0726, d3.loss_iou: 0.3577, d4.loss_cls: 0.1220, d4.loss_bbox: 0.0740, d4.loss_iou: 0.3562, dn_loss_cls: 0.0190, dn_loss_bbox: 0.0367, dn_loss_iou: 0.2077, d0.dn_loss_cls: 0.0576, d0.dn_loss_bbox: 0.0519, d0.dn_loss_iou: 0.2856, d1.dn_loss_cls: 0.0210, d1.dn_loss_bbox: 0.0376, d1.dn_loss_iou: 0.2119, d2.dn_loss_cls: 0.0178, d2.dn_loss_bbox: 0.0367, d2.dn_loss_iou: 0.2074, d3.dn_loss_cls: 0.0186, d3.dn_loss_bbox: 0.0367, d3.dn_loss_iou: 0.2076, d4.dn_loss_cls: 0.0188, d4.dn_loss_bbox: 0.0367, d4.dn_loss_iou: 0.2077, loss_rpn_cls: 0.0452, loss_rpn_bbox: 0.1803, loss_cls0: 2.4666, acc0: 91.4779, loss_bbox0: 3.6171, loss_cls1: 1.8573, loss_bbox1: 3.8353, loss_centerness1: 7.1413, loss_cls_aux0: 0.0287, loss_bbox_aux0: 0.0220, loss_iou_aux0: 0.1105, d0.loss_cls_aux0: 0.0305, d0.loss_bbox_aux0: 0.0474, d0.loss_iou_aux0: 0.2527, d1.loss_cls_aux0: 0.0317, d1.loss_bbox_aux0: 0.0273, d1.loss_iou_aux0: 0.1384, d2.loss_cls_aux0: 0.0291, d2.loss_bbox_aux0: 0.0230, d2.loss_iou_aux0: 0.1157, d3.loss_cls_aux0: 0.0281, d3.loss_bbox_aux0: 0.0219, d3.loss_iou_aux0: 0.1092, d4.loss_cls_aux0: 0.0280, d4.loss_bbox_aux0: 0.0219, d4.loss_iou_aux0: 0.1097, loss_cls_aux1: 0.0246, loss_bbox_aux1: 0.0407, loss_iou_aux1: 0.2184, d0.loss_cls_aux1: 0.0259, d0.loss_bbox_aux1: 0.0527, d0.loss_iou_aux1: 0.2810, d1.loss_cls_aux1: 0.0264, d1.loss_bbox_aux1: 0.0422, d1.loss_iou_aux1: 0.2254, d2.loss_cls_aux1: 0.0240, d2.loss_bbox_aux1: 0.0407, d2.loss_iou_aux1: 0.2182, d3.loss_cls_aux1: 0.0245, d3.loss_bbox_aux1: 0.0406, d3.loss_iou_aux1: 0.2181, d4.loss_cls_aux1: 0.0239, d4.loss_bbox_aux1: 0.0406, d4.loss_iou_aux1: 0.2182, loss: 28.0029, grad_norm: 148.7575
2024-03-18 19:00:14,269 - mmdet - INFO - Epoch [3][250/463]	lr: 1.000e-05, eta: 4:27:14, time: 2.602, data_time: 0.009, memory: 18193, enc_loss_cls: 0.1950, enc_loss_bbox: 0.0722, enc_loss_iou: 0.3538, loss_cls: 0.1192, loss_bbox: 0.0661, loss_iou: 0.3272, d0.loss_cls: 0.2497, d0.loss_bbox: 0.0667, d0.loss_iou: 0.3293, d1.loss_cls: 0.1306, d1.loss_bbox: 0.0682, d1.loss_iou: 0.3289, d2.loss_cls: 0.1160, d2.loss_bbox: 0.0658, d2.loss_iou: 0.3261, d3.loss_cls: 0.1154, d3.loss_bbox: 0.0667, d3.loss_iou: 0.3272, d4.loss_cls: 0.1169, d4.loss_bbox: 0.0661, d4.loss_iou: 0.3274, dn_loss_cls: 0.0186, dn_loss_bbox: 0.0371, dn_loss_iou: 0.2076, d0.dn_loss_cls: 0.0496, d0.dn_loss_bbox: 0.0519, d0.dn_loss_iou: 0.2813, d1.dn_loss_cls: 0.0197, d1.dn_loss_bbox: 0.0382, d1.dn_loss_iou: 0.2120, d2.dn_loss_cls: 0.0180, d2.dn_loss_bbox: 0.0373, d2.dn_loss_iou: 0.2073, d3.dn_loss_cls: 0.0187, d3.dn_loss_bbox: 0.0371, d3.dn_loss_iou: 0.2068, d4.dn_loss_cls: 0.0184, d4.dn_loss_bbox: 0.0371, d4.dn_loss_iou: 0.2069, loss_rpn_cls: 0.0339, loss_rpn_bbox: 0.1563, loss_cls0: 2.2825, acc0: 92.1692, loss_bbox0: 3.3746, loss_cls1: 1.7691, loss_bbox1: 3.5546, loss_centerness1: 7.1252, loss_cls_aux0: 0.0273, loss_bbox_aux0: 0.0174, loss_iou_aux0: 0.0941, d0.loss_cls_aux0: 0.0279, d0.loss_bbox_aux0: 0.0444, d0.loss_iou_aux0: 0.2396, d1.loss_cls_aux0: 0.0286, d1.loss_bbox_aux0: 0.0219, d1.loss_iou_aux0: 0.1187, d2.loss_cls_aux0: 0.0282, d2.loss_bbox_aux0: 0.0185, d2.loss_iou_aux0: 0.0997, d3.loss_cls_aux0: 0.0259, d3.loss_bbox_aux0: 0.0173, d3.loss_iou_aux0: 0.0929, d4.loss_cls_aux0: 0.0270, d4.loss_bbox_aux0: 0.0173, d4.loss_iou_aux0: 0.0934, loss_cls_aux1: 0.0230, loss_bbox_aux1: 0.0397, loss_iou_aux1: 0.2064, d0.loss_cls_aux1: 0.0237, d0.loss_bbox_aux1: 0.0506, d0.loss_iou_aux1: 0.2556, d1.loss_cls_aux1: 0.0243, d1.loss_bbox_aux1: 0.0413, d1.loss_iou_aux1: 0.2139, d2.loss_cls_aux1: 0.0239, d2.loss_bbox_aux1: 0.0397, d2.loss_iou_aux1: 0.2063, d3.loss_cls_aux1: 0.0216, d3.loss_bbox_aux1: 0.0396, d3.loss_iou_aux1: 0.2061, d4.loss_cls_aux1: 0.0229, d4.loss_bbox_aux1: 0.0397, d4.loss_iou_aux1: 0.2063, loss: 26.5590, grad_norm: 149.5521
2024-03-18 19:02:27,261 - mmdet - INFO - Epoch [3][300/463]	lr: 1.000e-05, eta: 4:25:27, time: 2.660, data_time: 0.009, memory: 18193, enc_loss_cls: 0.2018, enc_loss_bbox: 0.0728, enc_loss_iou: 0.3890, loss_cls: 0.1278, loss_bbox: 0.0687, loss_iou: 0.3657, d0.loss_cls: 0.2522, d0.loss_bbox: 0.0678, d0.loss_iou: 0.3654, d1.loss_cls: 0.1396, d1.loss_bbox: 0.0684, d1.loss_iou: 0.3650, d2.loss_cls: 0.1270, d2.loss_bbox: 0.0686, d2.loss_iou: 0.3640, d3.loss_cls: 0.1232, d3.loss_bbox: 0.0686, d3.loss_iou: 0.3645, d4.loss_cls: 0.1238, d4.loss_bbox: 0.0686, d4.loss_iou: 0.3643, dn_loss_cls: 0.0255, dn_loss_bbox: 0.0360, dn_loss_iou: 0.2140, d0.dn_loss_cls: 0.0592, d0.dn_loss_bbox: 0.0521, d0.dn_loss_iou: 0.2970, d1.dn_loss_cls: 0.0266, d1.dn_loss_bbox: 0.0370, d1.dn_loss_iou: 0.2183, d2.dn_loss_cls: 0.0237, d2.dn_loss_bbox: 0.0360, d2.dn_loss_iou: 0.2135, d3.dn_loss_cls: 0.0237, d3.dn_loss_bbox: 0.0360, d3.dn_loss_iou: 0.2136, d4.dn_loss_cls: 0.0248, d4.dn_loss_bbox: 0.0360, d4.dn_loss_iou: 0.2137, loss_rpn_cls: 0.0319, loss_rpn_bbox: 0.1574, loss_cls0: 2.3611, acc0: 91.8803, loss_bbox0: 3.5327, loss_cls1: 1.9153, loss_bbox1: 3.9809, loss_centerness1: 7.1739, loss_cls_aux0: 0.0434, loss_bbox_aux0: 0.0174, loss_iou_aux0: 0.1007, d0.loss_cls_aux0: 0.0339, d0.loss_bbox_aux0: 0.0458, d0.loss_iou_aux0: 0.2602, d1.loss_cls_aux0: 0.0418, d1.loss_bbox_aux0: 0.0219, d1.loss_iou_aux0: 0.1263, d2.loss_cls_aux0: 0.0391, d2.loss_bbox_aux0: 0.0185, d2.loss_iou_aux0: 0.1065, d3.loss_cls_aux0: 0.0412, d3.loss_bbox_aux0: 0.0173, d3.loss_iou_aux0: 0.0994, d4.loss_cls_aux0: 0.0432, d4.loss_bbox_aux0: 0.0174, d4.loss_iou_aux0: 0.1001, loss_cls_aux1: 0.0330, loss_bbox_aux1: 0.0404, loss_iou_aux1: 0.2312, d0.loss_cls_aux1: 0.0302, d0.loss_bbox_aux1: 0.0514, d0.loss_iou_aux1: 0.2913, d1.loss_cls_aux1: 0.0341, d1.loss_bbox_aux1: 0.0417, d1.loss_iou_aux1: 0.2381, d2.loss_cls_aux1: 0.0333, d2.loss_bbox_aux1: 0.0406, d2.loss_iou_aux1: 0.2318, d3.loss_cls_aux1: 0.0323, d3.loss_bbox_aux1: 0.0404, d3.loss_iou_aux1: 0.2311, d4.loss_cls_aux1: 0.0327, d4.loss_bbox_aux1: 0.0404, d4.loss_iou_aux1: 0.2311, loss: 28.1761, grad_norm: 152.2762
2024-03-18 19:04:29,933 - mmdet - INFO - Epoch [3][350/463]	lr: 1.000e-05, eta: 4:22:49, time: 2.453, data_time: 0.010, memory: 18193, enc_loss_cls: 0.2089, enc_loss_bbox: 0.0715, enc_loss_iou: 0.3683, loss_cls: 0.1235, loss_bbox: 0.0651, loss_iou: 0.3418, d0.loss_cls: 0.2434, d0.loss_bbox: 0.0667, d0.loss_iou: 0.3451, d1.loss_cls: 0.1422, d1.loss_bbox: 0.0669, d1.loss_iou: 0.3438, d2.loss_cls: 0.1251, d2.loss_bbox: 0.0657, d2.loss_iou: 0.3441, d3.loss_cls: 0.1215, d3.loss_bbox: 0.0659, d3.loss_iou: 0.3427, d4.loss_cls: 0.1227, d4.loss_bbox: 0.0650, d4.loss_iou: 0.3416, dn_loss_cls: 0.0154, dn_loss_bbox: 0.0348, dn_loss_iou: 0.2066, d0.dn_loss_cls: 0.0572, d0.dn_loss_bbox: 0.0488, d0.dn_loss_iou: 0.2834, d1.dn_loss_cls: 0.0205, d1.dn_loss_bbox: 0.0354, d1.dn_loss_iou: 0.2105, d2.dn_loss_cls: 0.0156, d2.dn_loss_bbox: 0.0348, d2.dn_loss_iou: 0.2064, d3.dn_loss_cls: 0.0154, d3.dn_loss_bbox: 0.0348, d3.dn_loss_iou: 0.2064, d4.dn_loss_cls: 0.0151, d4.dn_loss_bbox: 0.0348, d4.dn_loss_iou: 0.2065, loss_rpn_cls: 0.0451, loss_rpn_bbox: 0.1481, loss_cls0: 2.6027, acc0: 91.1098, loss_bbox0: 3.5678, loss_cls1: 1.8929, loss_bbox1: 3.7856, loss_centerness1: 7.1522, loss_cls_aux0: 0.0328, loss_bbox_aux0: 0.0164, loss_iou_aux0: 0.0941, d0.loss_cls_aux0: 0.0324, d0.loss_bbox_aux0: 0.0411, d0.loss_iou_aux0: 0.2395, d1.loss_cls_aux0: 0.0329, d1.loss_bbox_aux0: 0.0207, d1.loss_iou_aux0: 0.1194, d2.loss_cls_aux0: 0.0313, d2.loss_bbox_aux0: 0.0173, d2.loss_iou_aux0: 0.0990, d3.loss_cls_aux0: 0.0324, d3.loss_bbox_aux0: 0.0163, d3.loss_iou_aux0: 0.0925, d4.loss_cls_aux0: 0.0313, d4.loss_bbox_aux0: 0.0163, d4.loss_iou_aux0: 0.0931, loss_cls_aux1: 0.0249, loss_bbox_aux1: 0.0395, loss_iou_aux1: 0.2235, d0.loss_cls_aux1: 0.0271, d0.loss_bbox_aux1: 0.0498, d0.loss_iou_aux1: 0.2780, d1.loss_cls_aux1: 0.0263, d1.loss_bbox_aux1: 0.0408, d1.loss_iou_aux1: 0.2303, d2.loss_cls_aux1: 0.0251, d2.loss_bbox_aux1: 0.0396, d2.loss_iou_aux1: 0.2238, d3.loss_cls_aux1: 0.0254, d3.loss_bbox_aux1: 0.0395, d3.loss_iou_aux1: 0.2233, d4.loss_cls_aux1: 0.0242, d4.loss_bbox_aux1: 0.0395, d4.loss_iou_aux1: 0.2235, loss: 27.7209, grad_norm: 164.8833
2024-03-18 19:06:43,043 - mmdet - INFO - Epoch [3][400/463]	lr: 1.000e-05, eta: 4:21:01, time: 2.662, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1990, enc_loss_bbox: 0.0757, enc_loss_iou: 0.3805, loss_cls: 0.1158, loss_bbox: 0.0706, loss_iou: 0.3504, d0.loss_cls: 0.2329, d0.loss_bbox: 0.0704, d0.loss_iou: 0.3536, d1.loss_cls: 0.1271, d1.loss_bbox: 0.0716, d1.loss_iou: 0.3554, d2.loss_cls: 0.1180, d2.loss_bbox: 0.0700, d2.loss_iou: 0.3498, d3.loss_cls: 0.1145, d3.loss_bbox: 0.0707, d3.loss_iou: 0.3501, d4.loss_cls: 0.1157, d4.loss_bbox: 0.0710, d4.loss_iou: 0.3504, dn_loss_cls: 0.0165, dn_loss_bbox: 0.0376, dn_loss_iou: 0.2062, d0.dn_loss_cls: 0.0503, d0.dn_loss_bbox: 0.0532, d0.dn_loss_iou: 0.2824, d1.dn_loss_cls: 0.0204, d1.dn_loss_bbox: 0.0386, d1.dn_loss_iou: 0.2102, d2.dn_loss_cls: 0.0169, d2.dn_loss_bbox: 0.0376, d2.dn_loss_iou: 0.2059, d3.dn_loss_cls: 0.0159, d3.dn_loss_bbox: 0.0376, d3.dn_loss_iou: 0.2059, d4.dn_loss_cls: 0.0162, d4.dn_loss_bbox: 0.0376, d4.dn_loss_iou: 0.2061, loss_rpn_cls: 0.0328, loss_rpn_bbox: 0.1674, loss_cls0: 2.4203, acc0: 91.5496, loss_bbox0: 3.5351, loss_cls1: 1.8580, loss_bbox1: 3.9603, loss_centerness1: 7.1030, loss_cls_aux0: 0.0332, loss_bbox_aux0: 0.0163, loss_iou_aux0: 0.0891, d0.loss_cls_aux0: 0.0305, d0.loss_bbox_aux0: 0.0448, d0.loss_iou_aux0: 0.2395, d1.loss_cls_aux0: 0.0320, d1.loss_bbox_aux0: 0.0209, d1.loss_iou_aux0: 0.1131, d2.loss_cls_aux0: 0.0326, d2.loss_bbox_aux0: 0.0178, d2.loss_iou_aux0: 0.0949, d3.loss_cls_aux0: 0.0308, d3.loss_bbox_aux0: 0.0161, d3.loss_iou_aux0: 0.0864, d4.loss_cls_aux0: 0.0320, d4.loss_bbox_aux0: 0.0162, d4.loss_iou_aux0: 0.0876, loss_cls_aux1: 0.0248, loss_bbox_aux1: 0.0432, loss_iou_aux1: 0.2304, d0.loss_cls_aux1: 0.0244, d0.loss_bbox_aux1: 0.0548, d0.loss_iou_aux1: 0.2836, d1.loss_cls_aux1: 0.0260, d1.loss_bbox_aux1: 0.0448, d1.loss_iou_aux1: 0.2368, d2.loss_cls_aux1: 0.0268, d2.loss_bbox_aux1: 0.0429, d2.loss_iou_aux1: 0.2295, d3.loss_cls_aux1: 0.0249, d3.loss_bbox_aux1: 0.0430, d3.loss_iou_aux1: 0.2296, d4.loss_cls_aux1: 0.0241, d4.loss_bbox_aux1: 0.0431, d4.loss_iou_aux1: 0.2300, loss: 27.6822, grad_norm: 186.5849
2024-03-18 19:08:57,775 - mmdet - INFO - Epoch [3][450/463]	lr: 1.000e-05, eta: 4:19:18, time: 2.695, data_time: 0.011, memory: 18193, enc_loss_cls: 0.1777, enc_loss_bbox: 0.0737, enc_loss_iou: 0.3828, loss_cls: 0.1129, loss_bbox: 0.0684, loss_iou: 0.3515, d0.loss_cls: 0.2231, d0.loss_bbox: 0.0690, d0.loss_iou: 0.3532, d1.loss_cls: 0.1259, d1.loss_bbox: 0.0694, d1.loss_iou: 0.3540, d2.loss_cls: 0.1166, d2.loss_bbox: 0.0685, d2.loss_iou: 0.3517, d3.loss_cls: 0.1118, d3.loss_bbox: 0.0686, d3.loss_iou: 0.3518, d4.loss_cls: 0.1119, d4.loss_bbox: 0.0684, d4.loss_iou: 0.3518, dn_loss_cls: 0.0162, dn_loss_bbox: 0.0364, dn_loss_iou: 0.2100, d0.dn_loss_cls: 0.0494, d0.dn_loss_bbox: 0.0505, d0.dn_loss_iou: 0.2849, d1.dn_loss_cls: 0.0210, d1.dn_loss_bbox: 0.0366, d1.dn_loss_iou: 0.2126, d2.dn_loss_cls: 0.0172, d2.dn_loss_bbox: 0.0360, d2.dn_loss_iou: 0.2090, d3.dn_loss_cls: 0.0167, d3.dn_loss_bbox: 0.0363, d3.dn_loss_iou: 0.2097, d4.dn_loss_cls: 0.0161, d4.dn_loss_bbox: 0.0364, d4.dn_loss_iou: 0.2098, loss_rpn_cls: 0.0351, loss_rpn_bbox: 0.1593, loss_cls0: 2.4261, acc0: 91.5514, loss_bbox0: 3.6540, loss_cls1: 1.7726, loss_bbox1: 3.8515, loss_centerness1: 7.1564, loss_cls_aux0: 0.0335, loss_bbox_aux0: 0.0188, loss_iou_aux0: 0.1051, d0.loss_cls_aux0: 0.0319, d0.loss_bbox_aux0: 0.0441, d0.loss_iou_aux0: 0.2484, d1.loss_cls_aux0: 0.0330, d1.loss_bbox_aux0: 0.0231, d1.loss_iou_aux0: 0.1300, d2.loss_cls_aux0: 0.0340, d2.loss_bbox_aux0: 0.0199, d2.loss_iou_aux0: 0.1106, d3.loss_cls_aux0: 0.0334, d3.loss_bbox_aux0: 0.0187, d3.loss_iou_aux0: 0.1039, d4.loss_cls_aux0: 0.0332, d4.loss_bbox_aux0: 0.0187, d4.loss_iou_aux0: 0.1044, loss_cls_aux1: 0.0310, loss_bbox_aux1: 0.0394, loss_iou_aux1: 0.2209, d0.loss_cls_aux1: 0.0307, d0.loss_bbox_aux1: 0.0497, d0.loss_iou_aux1: 0.2749, d1.loss_cls_aux1: 0.0312, d1.loss_bbox_aux1: 0.0406, d1.loss_iou_aux1: 0.2271, d2.loss_cls_aux1: 0.0314, d2.loss_bbox_aux1: 0.0393, d2.loss_iou_aux1: 0.2203, d3.loss_cls_aux1: 0.0302, d3.loss_bbox_aux1: 0.0394, d3.loss_iou_aux1: 0.2205, d4.loss_cls_aux1: 0.0302, d4.loss_bbox_aux1: 0.0394, d4.loss_iou_aux1: 0.2207, loss: 27.6840, grad_norm: 148.5241
2024-03-18 19:09:30,106 - mmdet - INFO - Saving checkpoint at 3 epochs
2024-03-18 19:10:58,929 - mmdet - INFO - Evaluating bbox...
2024-03-18 19:11:14,794 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.596
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.869
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.724
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.563
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.804
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.724
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.727
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.727
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.685
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.715
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.854

2024-03-18 19:11:14,794 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.641 | Thatch   | 0.554 |
+----------+-------+----------+-------+
2024-03-18 19:11:15,429 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_004/best_bbox_mAP_epoch_2.pth was removed
2024-03-18 19:11:21,625 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_3.pth.
2024-03-18 19:11:21,625 - mmdet - INFO - Best bbox_mAP is 0.5960 at 3 epoch.
2024-03-18 19:11:21,625 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 19:11:21,626 - mmdet - INFO - Epoch(val) [3][154]	bbox_mAP: 0.5960, bbox_mAP_50: 0.8690, bbox_mAP_75: 0.7240, bbox_mAP_s: 0.4700, bbox_mAP_m: 0.5630, bbox_mAP_l: 0.8040, bbox_mAP_copypaste: 0.596 0.869 0.724 0.470 0.563 0.804
2024-03-18 19:13:34,199 - mmdet - INFO - Epoch [4][50/463]	lr: 1.000e-05, eta: 4:14:32, time: 2.651, data_time: 0.056, memory: 18193, enc_loss_cls: 0.2036, enc_loss_bbox: 0.0699, enc_loss_iou: 0.3640, loss_cls: 0.1352, loss_bbox: 0.0635, loss_iou: 0.3368, d0.loss_cls: 0.2467, d0.loss_bbox: 0.0638, d0.loss_iou: 0.3402, d1.loss_cls: 0.1360, d1.loss_bbox: 0.0657, d1.loss_iou: 0.3432, d2.loss_cls: 0.1307, d2.loss_bbox: 0.0633, d2.loss_iou: 0.3369, d3.loss_cls: 0.1310, d3.loss_bbox: 0.0631, d3.loss_iou: 0.3359, d4.loss_cls: 0.1326, d4.loss_bbox: 0.0633, d4.loss_iou: 0.3362, dn_loss_cls: 0.0258, dn_loss_bbox: 0.0357, dn_loss_iou: 0.2024, d0.dn_loss_cls: 0.0608, d0.dn_loss_bbox: 0.0503, d0.dn_loss_iou: 0.2789, d1.dn_loss_cls: 0.0273, d1.dn_loss_bbox: 0.0363, d1.dn_loss_iou: 0.2056, d2.dn_loss_cls: 0.0249, d2.dn_loss_bbox: 0.0357, d2.dn_loss_iou: 0.2023, d3.dn_loss_cls: 0.0244, d3.dn_loss_bbox: 0.0357, d3.dn_loss_iou: 0.2022, d4.dn_loss_cls: 0.0250, d4.dn_loss_bbox: 0.0357, d4.dn_loss_iou: 0.2022, loss_rpn_cls: 0.0302, loss_rpn_bbox: 0.1592, loss_cls0: 2.3233, acc0: 92.0104, loss_bbox0: 3.3298, loss_cls1: 1.8454, loss_bbox1: 3.7301, loss_centerness1: 7.1514, loss_cls_aux0: 0.0534, loss_bbox_aux0: 0.0177, loss_iou_aux0: 0.0988, d0.loss_cls_aux0: 0.0436, d0.loss_bbox_aux0: 0.0446, d0.loss_iou_aux0: 0.2465, d1.loss_cls_aux0: 0.0513, d1.loss_bbox_aux0: 0.0225, d1.loss_iou_aux0: 0.1242, d2.loss_cls_aux0: 0.0540, d2.loss_bbox_aux0: 0.0188, d2.loss_iou_aux0: 0.1027, d3.loss_cls_aux0: 0.0548, d3.loss_bbox_aux0: 0.0175, d3.loss_iou_aux0: 0.0965, d4.loss_cls_aux0: 0.0546, d4.loss_bbox_aux0: 0.0176, d4.loss_iou_aux0: 0.0975, loss_cls_aux1: 0.0357, loss_bbox_aux1: 0.0391, loss_iou_aux1: 0.2186, d0.loss_cls_aux1: 0.0338, d0.loss_bbox_aux1: 0.0515, d0.loss_iou_aux1: 0.2787, d1.loss_cls_aux1: 0.0351, d1.loss_bbox_aux1: 0.0406, d1.loss_iou_aux1: 0.2260, d2.loss_cls_aux1: 0.0336, d2.loss_bbox_aux1: 0.0390, d2.loss_iou_aux1: 0.2179, d3.loss_cls_aux1: 0.0347, d3.loss_bbox_aux1: 0.0390, d3.loss_iou_aux1: 0.2179, d4.loss_cls_aux1: 0.0357, d4.loss_bbox_aux1: 0.0390, d4.loss_iou_aux1: 0.2183, loss: 27.2931, grad_norm: 197.7641
2024-03-18 19:15:39,980 - mmdet - INFO - Epoch [4][100/463]	lr: 1.000e-05, eta: 4:12:15, time: 2.516, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1838, enc_loss_bbox: 0.0682, enc_loss_iou: 0.3702, loss_cls: 0.1116, loss_bbox: 0.0633, loss_iou: 0.3471, d0.loss_cls: 0.2272, d0.loss_bbox: 0.0641, d0.loss_iou: 0.3499, d1.loss_cls: 0.1240, d1.loss_bbox: 0.0640, d1.loss_iou: 0.3480, d2.loss_cls: 0.1135, d2.loss_bbox: 0.0631, d2.loss_iou: 0.3455, d3.loss_cls: 0.1126, d3.loss_bbox: 0.0634, d3.loss_iou: 0.3470, d4.loss_cls: 0.1109, d4.loss_bbox: 0.0632, d4.loss_iou: 0.3470, dn_loss_cls: 0.0188, dn_loss_bbox: 0.0349, dn_loss_iou: 0.2120, d0.dn_loss_cls: 0.0518, d0.dn_loss_bbox: 0.0500, d0.dn_loss_iou: 0.2932, d1.dn_loss_cls: 0.0218, d1.dn_loss_bbox: 0.0358, d1.dn_loss_iou: 0.2167, d2.dn_loss_cls: 0.0192, d2.dn_loss_bbox: 0.0349, d2.dn_loss_iou: 0.2121, d3.dn_loss_cls: 0.0181, d3.dn_loss_bbox: 0.0349, d3.dn_loss_iou: 0.2121, d4.dn_loss_cls: 0.0180, d4.dn_loss_bbox: 0.0349, d4.dn_loss_iou: 0.2120, loss_rpn_cls: 0.0360, loss_rpn_bbox: 0.1667, loss_cls0: 2.4032, acc0: 91.5573, loss_bbox0: 3.5286, loss_cls1: 1.8097, loss_bbox1: 3.8359, loss_centerness1: 7.1504, loss_cls_aux0: 0.0292, loss_bbox_aux0: 0.0185, loss_iou_aux0: 0.1015, d0.loss_cls_aux0: 0.0256, d0.loss_bbox_aux0: 0.0433, d0.loss_iou_aux0: 0.2488, d1.loss_cls_aux0: 0.0283, d1.loss_bbox_aux0: 0.0220, d1.loss_iou_aux0: 0.1233, d2.loss_cls_aux0: 0.0291, d2.loss_bbox_aux0: 0.0193, d2.loss_iou_aux0: 0.1059, d3.loss_cls_aux0: 0.0279, d3.loss_bbox_aux0: 0.0184, d3.loss_iou_aux0: 0.1003, d4.loss_cls_aux0: 0.0284, d4.loss_bbox_aux0: 0.0185, d4.loss_iou_aux0: 0.1008, loss_cls_aux1: 0.0222, loss_bbox_aux1: 0.0393, loss_iou_aux1: 0.2242, d0.loss_cls_aux1: 0.0216, d0.loss_bbox_aux1: 0.0494, d0.loss_iou_aux1: 0.2778, d1.loss_cls_aux1: 0.0226, d1.loss_bbox_aux1: 0.0408, d1.loss_iou_aux1: 0.2317, d2.loss_cls_aux1: 0.0222, d2.loss_bbox_aux1: 0.0392, d2.loss_iou_aux1: 0.2239, d3.loss_cls_aux1: 0.0228, d3.loss_bbox_aux1: 0.0392, d3.loss_iou_aux1: 0.2241, d4.loss_cls_aux1: 0.0225, d4.loss_bbox_aux1: 0.0392, d4.loss_iou_aux1: 0.2241, loss: 27.4252, grad_norm: 159.8442
2024-03-18 19:17:50,857 - mmdet - INFO - Epoch [4][150/463]	lr: 1.000e-05, eta: 4:10:19, time: 2.618, data_time: 0.009, memory: 18193, enc_loss_cls: 0.1850, enc_loss_bbox: 0.0715, enc_loss_iou: 0.3655, loss_cls: 0.0975, loss_bbox: 0.0648, loss_iou: 0.3379, d0.loss_cls: 0.2150, d0.loss_bbox: 0.0684, d0.loss_iou: 0.3448, d1.loss_cls: 0.1104, d1.loss_bbox: 0.0659, d1.loss_iou: 0.3400, d2.loss_cls: 0.1031, d2.loss_bbox: 0.0648, d2.loss_iou: 0.3340, d3.loss_cls: 0.1008, d3.loss_bbox: 0.0647, d3.loss_iou: 0.3358, d4.loss_cls: 0.0980, d4.loss_bbox: 0.0645, d4.loss_iou: 0.3363, dn_loss_cls: 0.0235, dn_loss_bbox: 0.0366, dn_loss_iou: 0.2084, d0.dn_loss_cls: 0.0554, d0.dn_loss_bbox: 0.0522, d0.dn_loss_iou: 0.2874, d1.dn_loss_cls: 0.0262, d1.dn_loss_bbox: 0.0374, d1.dn_loss_iou: 0.2121, d2.dn_loss_cls: 0.0239, d2.dn_loss_bbox: 0.0366, d2.dn_loss_iou: 0.2080, d3.dn_loss_cls: 0.0229, d3.dn_loss_bbox: 0.0366, d3.dn_loss_iou: 0.2081, d4.dn_loss_cls: 0.0230, d4.dn_loss_bbox: 0.0366, d4.dn_loss_iou: 0.2083, loss_rpn_cls: 0.0301, loss_rpn_bbox: 0.1499, loss_cls0: 2.2766, acc0: 92.1705, loss_bbox0: 3.4812, loss_cls1: 1.6642, loss_bbox1: 3.7493, loss_centerness1: 7.1341, loss_cls_aux0: 0.0317, loss_bbox_aux0: 0.0167, loss_iou_aux0: 0.0889, d0.loss_cls_aux0: 0.0270, d0.loss_bbox_aux0: 0.0449, d0.loss_iou_aux0: 0.2447, d1.loss_cls_aux0: 0.0318, d1.loss_bbox_aux0: 0.0227, d1.loss_iou_aux0: 0.1211, d2.loss_cls_aux0: 0.0322, d2.loss_bbox_aux0: 0.0178, d2.loss_iou_aux0: 0.0950, d3.loss_cls_aux0: 0.0311, d3.loss_bbox_aux0: 0.0166, d3.loss_iou_aux0: 0.0877, d4.loss_cls_aux0: 0.0312, d4.loss_bbox_aux0: 0.0166, d4.loss_iou_aux0: 0.0883, loss_cls_aux1: 0.0253, loss_bbox_aux1: 0.0402, loss_iou_aux1: 0.2161, d0.loss_cls_aux1: 0.0223, d0.loss_bbox_aux1: 0.0513, d0.loss_iou_aux1: 0.2713, d1.loss_cls_aux1: 0.0255, d1.loss_bbox_aux1: 0.0411, d1.loss_iou_aux1: 0.2207, d2.loss_cls_aux1: 0.0248, d2.loss_bbox_aux1: 0.0403, d2.loss_iou_aux1: 0.2166, d3.loss_cls_aux1: 0.0248, d3.loss_bbox_aux1: 0.0401, d3.loss_iou_aux1: 0.2158, d4.loss_cls_aux1: 0.0248, d4.loss_bbox_aux1: 0.0401, d4.loss_iou_aux1: 0.2159, loss: 26.8004, grad_norm: 164.3909
2024-03-18 19:20:02,257 - mmdet - INFO - Epoch [4][200/463]	lr: 1.000e-05, eta: 4:08:23, time: 2.628, data_time: 0.009, memory: 18193, enc_loss_cls: 0.1638, enc_loss_bbox: 0.0688, enc_loss_iou: 0.3696, loss_cls: 0.1091, loss_bbox: 0.0632, loss_iou: 0.3457, d0.loss_cls: 0.2068, d0.loss_bbox: 0.0641, d0.loss_iou: 0.3483, d1.loss_cls: 0.1129, d1.loss_bbox: 0.0643, d1.loss_iou: 0.3501, d2.loss_cls: 0.1055, d2.loss_bbox: 0.0636, d2.loss_iou: 0.3472, d3.loss_cls: 0.1053, d3.loss_bbox: 0.0633, d3.loss_iou: 0.3459, d4.loss_cls: 0.1065, d4.loss_bbox: 0.0632, d4.loss_iou: 0.3456, dn_loss_cls: 0.0150, dn_loss_bbox: 0.0359, dn_loss_iou: 0.2041, d0.dn_loss_cls: 0.0469, d0.dn_loss_bbox: 0.0504, d0.dn_loss_iou: 0.2788, d1.dn_loss_cls: 0.0170, d1.dn_loss_bbox: 0.0367, d1.dn_loss_iou: 0.2090, d2.dn_loss_cls: 0.0149, d2.dn_loss_bbox: 0.0359, d2.dn_loss_iou: 0.2040, d3.dn_loss_cls: 0.0149, d3.dn_loss_bbox: 0.0358, d3.dn_loss_iou: 0.2039, d4.dn_loss_cls: 0.0144, d4.dn_loss_bbox: 0.0358, d4.dn_loss_iou: 0.2039, loss_rpn_cls: 0.0489, loss_rpn_bbox: 0.1489, loss_cls0: 2.4377, acc0: 91.4629, loss_bbox0: 3.5872, loss_cls1: 1.7364, loss_bbox1: 3.8819, loss_centerness1: 7.1407, loss_cls_aux0: 0.0364, loss_bbox_aux0: 0.0171, loss_iou_aux0: 0.0973, d0.loss_cls_aux0: 0.0311, d0.loss_bbox_aux0: 0.0433, d0.loss_iou_aux0: 0.2452, d1.loss_cls_aux0: 0.0350, d1.loss_bbox_aux0: 0.0223, d1.loss_iou_aux0: 0.1247, d2.loss_cls_aux0: 0.0347, d2.loss_bbox_aux0: 0.0180, d2.loss_iou_aux0: 0.1021, d3.loss_cls_aux0: 0.0351, d3.loss_bbox_aux0: 0.0170, d3.loss_iou_aux0: 0.0962, d4.loss_cls_aux0: 0.0349, d4.loss_bbox_aux0: 0.0170, d4.loss_iou_aux0: 0.0967, loss_cls_aux1: 0.0240, loss_bbox_aux1: 0.0391, loss_iou_aux1: 0.2238, d0.loss_cls_aux1: 0.0243, d0.loss_bbox_aux1: 0.0487, d0.loss_iou_aux1: 0.2743, d1.loss_cls_aux1: 0.0229, d1.loss_bbox_aux1: 0.0404, d1.loss_iou_aux1: 0.2315, d2.loss_cls_aux1: 0.0226, d2.loss_bbox_aux1: 0.0390, d2.loss_iou_aux1: 0.2235, d3.loss_cls_aux1: 0.0225, d3.loss_bbox_aux1: 0.0390, d3.loss_iou_aux1: 0.2236, d4.loss_cls_aux1: 0.0231, d4.loss_bbox_aux1: 0.0391, d4.loss_iou_aux1: 0.2237, loss: 27.3411, grad_norm: 149.9499
2024-03-18 19:22:12,575 - mmdet - INFO - Epoch [4][250/463]	lr: 1.000e-05, eta: 4:06:23, time: 2.606, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1843, enc_loss_bbox: 0.0728, enc_loss_iou: 0.3658, loss_cls: 0.1137, loss_bbox: 0.0651, loss_iou: 0.3380, d0.loss_cls: 0.2289, d0.loss_bbox: 0.0664, d0.loss_iou: 0.3405, d1.loss_cls: 0.1256, d1.loss_bbox: 0.0675, d1.loss_iou: 0.3412, d2.loss_cls: 0.1149, d2.loss_bbox: 0.0641, d2.loss_iou: 0.3366, d3.loss_cls: 0.1133, d3.loss_bbox: 0.0651, d3.loss_iou: 0.3379, d4.loss_cls: 0.1127, d4.loss_bbox: 0.0653, d4.loss_iou: 0.3385, dn_loss_cls: 0.0148, dn_loss_bbox: 0.0347, dn_loss_iou: 0.2034, d0.dn_loss_cls: 0.0472, d0.dn_loss_bbox: 0.0484, d0.dn_loss_iou: 0.2765, d1.dn_loss_cls: 0.0178, d1.dn_loss_bbox: 0.0355, d1.dn_loss_iou: 0.2073, d2.dn_loss_cls: 0.0142, d2.dn_loss_bbox: 0.0347, d2.dn_loss_iou: 0.2033, d3.dn_loss_cls: 0.0141, d3.dn_loss_bbox: 0.0347, d3.dn_loss_iou: 0.2031, d4.dn_loss_cls: 0.0141, d4.dn_loss_bbox: 0.0347, d4.dn_loss_iou: 0.2032, loss_rpn_cls: 0.0441, loss_rpn_bbox: 0.1684, loss_cls0: 2.3890, acc0: 91.7351, loss_bbox0: 3.3879, loss_cls1: 1.7946, loss_bbox1: 3.6840, loss_centerness1: 7.1453, loss_cls_aux0: 0.0275, loss_bbox_aux0: 0.0186, loss_iou_aux0: 0.1018, d0.loss_cls_aux0: 0.0248, d0.loss_bbox_aux0: 0.0434, d0.loss_iou_aux0: 0.2416, d1.loss_cls_aux0: 0.0259, d1.loss_bbox_aux0: 0.0227, d1.loss_iou_aux0: 0.1255, d2.loss_cls_aux0: 0.0262, d2.loss_bbox_aux0: 0.0195, d2.loss_iou_aux0: 0.1061, d3.loss_cls_aux0: 0.0254, d3.loss_bbox_aux0: 0.0185, d3.loss_iou_aux0: 0.1001, d4.loss_cls_aux0: 0.0264, d4.loss_bbox_aux0: 0.0185, d4.loss_iou_aux0: 0.1008, loss_cls_aux1: 0.0221, loss_bbox_aux1: 0.0401, loss_iou_aux1: 0.2210, d0.loss_cls_aux1: 0.0230, d0.loss_bbox_aux1: 0.0497, d0.loss_iou_aux1: 0.2708, d1.loss_cls_aux1: 0.0223, d1.loss_bbox_aux1: 0.0411, d1.loss_iou_aux1: 0.2260, d2.loss_cls_aux1: 0.0214, d2.loss_bbox_aux1: 0.0400, d2.loss_iou_aux1: 0.2209, d3.loss_cls_aux1: 0.0213, d3.loss_bbox_aux1: 0.0400, d3.loss_iou_aux1: 0.2206, d4.loss_cls_aux1: 0.0217, d4.loss_bbox_aux1: 0.0400, d4.loss_iou_aux1: 0.2207, loss: 26.9496, grad_norm: 168.9476
2024-03-18 19:24:25,808 - mmdet - INFO - Epoch [4][300/463]	lr: 1.000e-05, eta: 4:04:32, time: 2.665, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1783, enc_loss_bbox: 0.0758, enc_loss_iou: 0.3789, loss_cls: 0.1028, loss_bbox: 0.0693, loss_iou: 0.3553, d0.loss_cls: 0.2208, d0.loss_bbox: 0.0719, d0.loss_iou: 0.3609, d1.loss_cls: 0.1218, d1.loss_bbox: 0.0708, d1.loss_iou: 0.3576, d2.loss_cls: 0.1072, d2.loss_bbox: 0.0695, d2.loss_iou: 0.3550, d3.loss_cls: 0.1031, d3.loss_bbox: 0.0693, d3.loss_iou: 0.3553, d4.loss_cls: 0.1023, d4.loss_bbox: 0.0692, d4.loss_iou: 0.3553, dn_loss_cls: 0.0226, dn_loss_bbox: 0.0371, dn_loss_iou: 0.2101, d0.dn_loss_cls: 0.0560, d0.dn_loss_bbox: 0.0528, d0.dn_loss_iou: 0.2874, d1.dn_loss_cls: 0.0245, d1.dn_loss_bbox: 0.0376, d1.dn_loss_iou: 0.2114, d2.dn_loss_cls: 0.0224, d2.dn_loss_bbox: 0.0370, d2.dn_loss_iou: 0.2088, d3.dn_loss_cls: 0.0213, d3.dn_loss_bbox: 0.0371, d3.dn_loss_iou: 0.2097, d4.dn_loss_cls: 0.0219, d4.dn_loss_bbox: 0.0371, d4.dn_loss_iou: 0.2099, loss_rpn_cls: 0.0241, loss_rpn_bbox: 0.1575, loss_cls0: 2.4668, acc0: 91.5356, loss_bbox0: 3.5562, loss_cls1: 1.7626, loss_bbox1: 3.9216, loss_centerness1: 7.1348, loss_cls_aux0: 0.0319, loss_bbox_aux0: 0.0190, loss_iou_aux0: 0.1042, d0.loss_cls_aux0: 0.0327, d0.loss_bbox_aux0: 0.0454, d0.loss_iou_aux0: 0.2451, d1.loss_cls_aux0: 0.0357, d1.loss_bbox_aux0: 0.0234, d1.loss_iou_aux0: 0.1266, d2.loss_cls_aux0: 0.0356, d2.loss_bbox_aux0: 0.0198, d2.loss_iou_aux0: 0.1072, d3.loss_cls_aux0: 0.0329, d3.loss_bbox_aux0: 0.0189, d3.loss_iou_aux0: 0.1025, d4.loss_cls_aux0: 0.0316, d4.loss_bbox_aux0: 0.0189, d4.loss_iou_aux0: 0.1033, loss_cls_aux1: 0.0214, loss_bbox_aux1: 0.0419, loss_iou_aux1: 0.2287, d0.loss_cls_aux1: 0.0250, d0.loss_bbox_aux1: 0.0526, d0.loss_iou_aux1: 0.2843, d1.loss_cls_aux1: 0.0244, d1.loss_bbox_aux1: 0.0435, d1.loss_iou_aux1: 0.2379, d2.loss_cls_aux1: 0.0240, d2.loss_bbox_aux1: 0.0418, d2.loss_iou_aux1: 0.2284, d3.loss_cls_aux1: 0.0222, d3.loss_bbox_aux1: 0.0418, d3.loss_iou_aux1: 0.2285, d4.loss_cls_aux1: 0.0215, d4.loss_bbox_aux1: 0.0419, d4.loss_iou_aux1: 0.2286, loss: 27.6920, grad_norm: 175.7019
2024-03-18 19:26:28,313 - mmdet - INFO - Epoch [4][350/463]	lr: 1.000e-05, eta: 4:02:05, time: 2.450, data_time: 0.009, memory: 18193, enc_loss_cls: 0.1776, enc_loss_bbox: 0.0633, enc_loss_iou: 0.3452, loss_cls: 0.1186, loss_bbox: 0.0573, loss_iou: 0.3238, d0.loss_cls: 0.2214, d0.loss_bbox: 0.0577, d0.loss_iou: 0.3261, d1.loss_cls: 0.1183, d1.loss_bbox: 0.0577, d1.loss_iou: 0.3267, d2.loss_cls: 0.1149, d2.loss_bbox: 0.0569, d2.loss_iou: 0.3240, d3.loss_cls: 0.1142, d3.loss_bbox: 0.0570, d3.loss_iou: 0.3243, d4.loss_cls: 0.1156, d4.loss_bbox: 0.0573, d4.loss_iou: 0.3238, dn_loss_cls: 0.0122, dn_loss_bbox: 0.0349, dn_loss_iou: 0.2041, d0.dn_loss_cls: 0.0409, d0.dn_loss_bbox: 0.0489, d0.dn_loss_iou: 0.2813, d1.dn_loss_cls: 0.0152, d1.dn_loss_bbox: 0.0355, d1.dn_loss_iou: 0.2070, d2.dn_loss_cls: 0.0119, d2.dn_loss_bbox: 0.0348, d2.dn_loss_iou: 0.2039, d3.dn_loss_cls: 0.0116, d3.dn_loss_bbox: 0.0348, d3.dn_loss_iou: 0.2039, d4.dn_loss_cls: 0.0120, d4.dn_loss_bbox: 0.0348, d4.dn_loss_iou: 0.2040, loss_rpn_cls: 0.0295, loss_rpn_bbox: 0.1500, loss_cls0: 2.2414, acc0: 92.2893, loss_bbox0: 3.4043, loss_cls1: 1.6294, loss_bbox1: 3.6176, loss_centerness1: 7.1369, loss_cls_aux0: 0.0190, loss_bbox_aux0: 0.0165, loss_iou_aux0: 0.0960, d0.loss_cls_aux0: 0.0198, d0.loss_bbox_aux0: 0.0412, d0.loss_iou_aux0: 0.2362, d1.loss_cls_aux0: 0.0215, d1.loss_bbox_aux0: 0.0214, d1.loss_iou_aux0: 0.1224, d2.loss_cls_aux0: 0.0194, d2.loss_bbox_aux0: 0.0176, d2.loss_iou_aux0: 0.1021, d3.loss_cls_aux0: 0.0183, d3.loss_bbox_aux0: 0.0164, d3.loss_iou_aux0: 0.0950, d4.loss_cls_aux0: 0.0188, d4.loss_bbox_aux0: 0.0164, d4.loss_iou_aux0: 0.0954, loss_cls_aux1: 0.0144, loss_bbox_aux1: 0.0376, loss_iou_aux1: 0.2167, d0.loss_cls_aux1: 0.0161, d0.loss_bbox_aux1: 0.0477, d0.loss_iou_aux1: 0.2652, d1.loss_cls_aux1: 0.0160, d1.loss_bbox_aux1: 0.0386, d1.loss_iou_aux1: 0.2221, d2.loss_cls_aux1: 0.0151, d2.loss_bbox_aux1: 0.0376, d2.loss_iou_aux1: 0.2167, d3.loss_cls_aux1: 0.0143, d3.loss_bbox_aux1: 0.0376, d3.loss_iou_aux1: 0.2165, d4.loss_cls_aux1: 0.0143, d4.loss_bbox_aux1: 0.0376, d4.loss_iou_aux1: 0.2166, loss: 26.1967, grad_norm: 151.8022
2024-03-18 19:28:41,774 - mmdet - INFO - Epoch [4][400/463]	lr: 1.000e-05, eta: 4:00:14, time: 2.669, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1704, enc_loss_bbox: 0.0769, enc_loss_iou: 0.3969, loss_cls: 0.1045, loss_bbox: 0.0712, loss_iou: 0.3731, d0.loss_cls: 0.2181, d0.loss_bbox: 0.0710, d0.loss_iou: 0.3737, d1.loss_cls: 0.1123, d1.loss_bbox: 0.0713, d1.loss_iou: 0.3743, d2.loss_cls: 0.1022, d2.loss_bbox: 0.0718, d2.loss_iou: 0.3744, d3.loss_cls: 0.1035, d3.loss_bbox: 0.0710, d3.loss_iou: 0.3727, d4.loss_cls: 0.1034, d4.loss_bbox: 0.0711, d4.loss_iou: 0.3730, dn_loss_cls: 0.0117, dn_loss_bbox: 0.0362, dn_loss_iou: 0.2118, d0.dn_loss_cls: 0.0445, d0.dn_loss_bbox: 0.0528, d0.dn_loss_iou: 0.2966, d1.dn_loss_cls: 0.0144, d1.dn_loss_bbox: 0.0372, d1.dn_loss_iou: 0.2167, d2.dn_loss_cls: 0.0116, d2.dn_loss_bbox: 0.0361, d2.dn_loss_iou: 0.2117, d3.dn_loss_cls: 0.0114, d3.dn_loss_bbox: 0.0361, d3.dn_loss_iou: 0.2116, d4.dn_loss_cls: 0.0113, d4.dn_loss_bbox: 0.0361, d4.dn_loss_iou: 0.2117, loss_rpn_cls: 0.0380, loss_rpn_bbox: 0.1802, loss_cls0: 2.5648, acc0: 90.9701, loss_bbox0: 3.8274, loss_cls1: 1.8606, loss_bbox1: 4.0839, loss_centerness1: 7.1331, loss_cls_aux0: 0.0261, loss_bbox_aux0: 0.0184, loss_iou_aux0: 0.1047, d0.loss_cls_aux0: 0.0245, d0.loss_bbox_aux0: 0.0456, d0.loss_iou_aux0: 0.2602, d1.loss_cls_aux0: 0.0280, d1.loss_bbox_aux0: 0.0232, d1.loss_iou_aux0: 0.1312, d2.loss_cls_aux0: 0.0277, d2.loss_bbox_aux0: 0.0194, d2.loss_iou_aux0: 0.1096, d3.loss_cls_aux0: 0.0256, d3.loss_bbox_aux0: 0.0183, d3.loss_iou_aux0: 0.1036, d4.loss_cls_aux0: 0.0251, d4.loss_bbox_aux0: 0.0184, d4.loss_iou_aux0: 0.1040, loss_cls_aux1: 0.0188, loss_bbox_aux1: 0.0395, loss_iou_aux1: 0.2241, d0.loss_cls_aux1: 0.0206, d0.loss_bbox_aux1: 0.0510, d0.loss_iou_aux1: 0.2828, d1.loss_cls_aux1: 0.0199, d1.loss_bbox_aux1: 0.0404, d1.loss_iou_aux1: 0.2281, d2.loss_cls_aux1: 0.0199, d2.loss_bbox_aux1: 0.0395, d2.loss_iou_aux1: 0.2248, d3.loss_cls_aux1: 0.0182, d3.loss_bbox_aux1: 0.0394, d3.loss_iou_aux1: 0.2239, d4.loss_cls_aux1: 0.0183, d4.loss_bbox_aux1: 0.0394, d4.loss_iou_aux1: 0.2241, loss: 28.3308, grad_norm: 174.4729
2024-03-18 19:30:56,463 - mmdet - INFO - Epoch [4][450/463]	lr: 1.000e-05, eta: 3:58:25, time: 2.694, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1750, enc_loss_bbox: 0.0700, enc_loss_iou: 0.3519, loss_cls: 0.1085, loss_bbox: 0.0647, loss_iou: 0.3288, d0.loss_cls: 0.2077, d0.loss_bbox: 0.0648, d0.loss_iou: 0.3318, d1.loss_cls: 0.1185, d1.loss_bbox: 0.0652, d1.loss_iou: 0.3295, d2.loss_cls: 0.1090, d2.loss_bbox: 0.0643, d2.loss_iou: 0.3271, d3.loss_cls: 0.1065, d3.loss_bbox: 0.0645, d3.loss_iou: 0.3283, d4.loss_cls: 0.1053, d4.loss_bbox: 0.0650, d4.loss_iou: 0.3290, dn_loss_cls: 0.0094, dn_loss_bbox: 0.0338, dn_loss_iou: 0.1989, d0.dn_loss_cls: 0.0385, d0.dn_loss_bbox: 0.0478, d0.dn_loss_iou: 0.2736, d1.dn_loss_cls: 0.0123, d1.dn_loss_bbox: 0.0346, d1.dn_loss_iou: 0.2025, d2.dn_loss_cls: 0.0092, d2.dn_loss_bbox: 0.0338, d2.dn_loss_iou: 0.1987, d3.dn_loss_cls: 0.0090, d3.dn_loss_bbox: 0.0338, d3.dn_loss_iou: 0.1987, d4.dn_loss_cls: 0.0093, d4.dn_loss_bbox: 0.0338, d4.dn_loss_iou: 0.1988, loss_rpn_cls: 0.0160, loss_rpn_bbox: 0.1293, loss_cls0: 2.2989, acc0: 91.8982, loss_bbox0: 3.3643, loss_cls1: 1.6911, loss_bbox1: 3.6982, loss_centerness1: 7.1270, loss_cls_aux0: 0.0168, loss_bbox_aux0: 0.0176, loss_iou_aux0: 0.0932, d0.loss_cls_aux0: 0.0184, d0.loss_bbox_aux0: 0.0421, d0.loss_iou_aux0: 0.2320, d1.loss_cls_aux0: 0.0198, d1.loss_bbox_aux0: 0.0215, d1.loss_iou_aux0: 0.1156, d2.loss_cls_aux0: 0.0169, d2.loss_bbox_aux0: 0.0183, d2.loss_iou_aux0: 0.0961, d3.loss_cls_aux0: 0.0174, d3.loss_bbox_aux0: 0.0175, d3.loss_iou_aux0: 0.0909, d4.loss_cls_aux0: 0.0167, d4.loss_bbox_aux0: 0.0175, d4.loss_iou_aux0: 0.0920, loss_cls_aux1: 0.0154, loss_bbox_aux1: 0.0391, loss_iou_aux1: 0.2135, d0.loss_cls_aux1: 0.0176, d0.loss_bbox_aux1: 0.0483, d0.loss_iou_aux1: 0.2574, d1.loss_cls_aux1: 0.0174, d1.loss_bbox_aux1: 0.0403, d1.loss_iou_aux1: 0.2184, d2.loss_cls_aux1: 0.0155, d2.loss_bbox_aux1: 0.0389, d2.loss_iou_aux1: 0.2128, d3.loss_cls_aux1: 0.0157, d3.loss_bbox_aux1: 0.0391, d3.loss_iou_aux1: 0.2131, d4.loss_cls_aux1: 0.0152, d4.loss_bbox_aux1: 0.0391, d4.loss_iou_aux1: 0.2133, loss: 26.2475, grad_norm: 167.8104
2024-03-18 19:31:28,687 - mmdet - INFO - Saving checkpoint at 4 epochs
2024-03-18 19:32:57,428 - mmdet - INFO - Evaluating bbox...
2024-03-18 19:33:14,142 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.606
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.887
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.733
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.583
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.795
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.727
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.730
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.726
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.848

2024-03-18 19:33:14,142 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.652 | Thatch   | 0.563 |
+----------+-------+----------+-------+
2024-03-18 19:33:14,800 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_004/best_bbox_mAP_epoch_3.pth was removed
2024-03-18 19:33:21,159 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_4.pth.
2024-03-18 19:33:21,160 - mmdet - INFO - Best bbox_mAP is 0.6060 at 4 epoch.
2024-03-18 19:33:21,160 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 19:33:21,160 - mmdet - INFO - Epoch(val) [4][154]	bbox_mAP: 0.6060, bbox_mAP_50: 0.8870, bbox_mAP_75: 0.7330, bbox_mAP_s: 0.4840, bbox_mAP_m: 0.5830, bbox_mAP_l: 0.7950, bbox_mAP_copypaste: 0.606 0.887 0.733 0.484 0.583 0.795
2024-03-18 19:35:34,059 - mmdet - INFO - Epoch [5][50/463]	lr: 1.000e-05, eta: 3:54:20, time: 2.658, data_time: 0.057, memory: 18193, enc_loss_cls: 0.1725, enc_loss_bbox: 0.0709, enc_loss_iou: 0.3535, loss_cls: 0.1110, loss_bbox: 0.0637, loss_iou: 0.3209, d0.loss_cls: 0.2079, d0.loss_bbox: 0.0645, d0.loss_iou: 0.3266, d1.loss_cls: 0.1195, d1.loss_bbox: 0.0634, d1.loss_iou: 0.3241, d2.loss_cls: 0.1085, d2.loss_bbox: 0.0619, d2.loss_iou: 0.3220, d3.loss_cls: 0.1081, d3.loss_bbox: 0.0634, d3.loss_iou: 0.3216, d4.loss_cls: 0.1086, d4.loss_bbox: 0.0636, d4.loss_iou: 0.3215, dn_loss_cls: 0.0127, dn_loss_bbox: 0.0361, dn_loss_iou: 0.2045, d0.dn_loss_cls: 0.0434, d0.dn_loss_bbox: 0.0506, d0.dn_loss_iou: 0.2782, d1.dn_loss_cls: 0.0159, d1.dn_loss_bbox: 0.0369, d1.dn_loss_iou: 0.2075, d2.dn_loss_cls: 0.0130, d2.dn_loss_bbox: 0.0360, d2.dn_loss_iou: 0.2033, d3.dn_loss_cls: 0.0125, d3.dn_loss_bbox: 0.0361, d3.dn_loss_iou: 0.2042, d4.dn_loss_cls: 0.0128, d4.dn_loss_bbox: 0.0361, d4.dn_loss_iou: 0.2040, loss_rpn_cls: 0.0124, loss_rpn_bbox: 0.1270, loss_cls0: 2.1862, acc0: 92.4391, loss_bbox0: 3.2376, loss_cls1: 1.6411, loss_bbox1: 3.5687, loss_centerness1: 7.1034, loss_cls_aux0: 0.0251, loss_bbox_aux0: 0.0156, loss_iou_aux0: 0.0861, d0.loss_cls_aux0: 0.0234, d0.loss_bbox_aux0: 0.0425, d0.loss_iou_aux0: 0.2304, d1.loss_cls_aux0: 0.0244, d1.loss_bbox_aux0: 0.0202, d1.loss_iou_aux0: 0.1092, d2.loss_cls_aux0: 0.0244, d2.loss_bbox_aux0: 0.0165, d2.loss_iou_aux0: 0.0898, d3.loss_cls_aux0: 0.0239, d3.loss_bbox_aux0: 0.0154, d3.loss_iou_aux0: 0.0842, d4.loss_cls_aux0: 0.0239, d4.loss_bbox_aux0: 0.0155, d4.loss_iou_aux0: 0.0850, loss_cls_aux1: 0.0197, loss_bbox_aux1: 0.0392, loss_iou_aux1: 0.2086, d0.loss_cls_aux1: 0.0192, d0.loss_bbox_aux1: 0.0499, d0.loss_iou_aux1: 0.2596, d1.loss_cls_aux1: 0.0199, d1.loss_bbox_aux1: 0.0403, d1.loss_iou_aux1: 0.2137, d2.loss_cls_aux1: 0.0198, d2.loss_bbox_aux1: 0.0391, d2.loss_iou_aux1: 0.2082, d3.loss_cls_aux1: 0.0196, d3.loss_bbox_aux1: 0.0391, d3.loss_iou_aux1: 0.2083, d4.loss_cls_aux1: 0.0196, d4.loss_bbox_aux1: 0.0392, d4.loss_iou_aux1: 0.2084, loss: 25.8244, grad_norm: 157.7944
2024-03-18 19:37:39,964 - mmdet - INFO - Epoch [5][100/463]	lr: 1.000e-05, eta: 3:52:07, time: 2.518, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1681, enc_loss_bbox: 0.0668, enc_loss_iou: 0.3446, loss_cls: 0.1040, loss_bbox: 0.0609, loss_iou: 0.3178, d0.loss_cls: 0.2002, d0.loss_bbox: 0.0630, d0.loss_iou: 0.3225, d1.loss_cls: 0.1146, d1.loss_bbox: 0.0636, d1.loss_iou: 0.3216, d2.loss_cls: 0.1048, d2.loss_bbox: 0.0607, d2.loss_iou: 0.3182, d3.loss_cls: 0.1033, d3.loss_bbox: 0.0613, d3.loss_iou: 0.3180, d4.loss_cls: 0.1013, d4.loss_bbox: 0.0615, d4.loss_iou: 0.3190, dn_loss_cls: 0.0102, dn_loss_bbox: 0.0349, dn_loss_iou: 0.2053, d0.dn_loss_cls: 0.0366, d0.dn_loss_bbox: 0.0485, d0.dn_loss_iou: 0.2781, d1.dn_loss_cls: 0.0135, d1.dn_loss_bbox: 0.0357, d1.dn_loss_iou: 0.2090, d2.dn_loss_cls: 0.0115, d2.dn_loss_bbox: 0.0349, d2.dn_loss_iou: 0.2046, d3.dn_loss_cls: 0.0108, d3.dn_loss_bbox: 0.0349, d3.dn_loss_iou: 0.2048, d4.dn_loss_cls: 0.0104, d4.dn_loss_bbox: 0.0349, d4.dn_loss_iou: 0.2051, loss_rpn_cls: 0.0260, loss_rpn_bbox: 0.1419, loss_cls0: 2.2154, acc0: 92.2733, loss_bbox0: 3.2639, loss_cls1: 1.6532, loss_bbox1: 3.5090, loss_centerness1: 7.1083, loss_cls_aux0: 0.0194, loss_bbox_aux0: 0.0158, loss_iou_aux0: 0.0890, d0.loss_cls_aux0: 0.0180, d0.loss_bbox_aux0: 0.0413, d0.loss_iou_aux0: 0.2367, d1.loss_cls_aux0: 0.0192, d1.loss_bbox_aux0: 0.0192, d1.loss_iou_aux0: 0.1095, d2.loss_cls_aux0: 0.0192, d2.loss_bbox_aux0: 0.0166, d2.loss_iou_aux0: 0.0927, d3.loss_cls_aux0: 0.0192, d3.loss_bbox_aux0: 0.0157, d3.loss_iou_aux0: 0.0877, d4.loss_cls_aux0: 0.0190, d4.loss_bbox_aux0: 0.0157, d4.loss_iou_aux0: 0.0883, loss_cls_aux1: 0.0122, loss_bbox_aux1: 0.0387, loss_iou_aux1: 0.2096, d0.loss_cls_aux1: 0.0142, d0.loss_bbox_aux1: 0.0486, d0.loss_iou_aux1: 0.2605, d1.loss_cls_aux1: 0.0125, d1.loss_bbox_aux1: 0.0398, d1.loss_iou_aux1: 0.2159, d2.loss_cls_aux1: 0.0117, d2.loss_bbox_aux1: 0.0386, d2.loss_iou_aux1: 0.2097, d3.loss_cls_aux1: 0.0117, d3.loss_bbox_aux1: 0.0386, d3.loss_iou_aux1: 0.2094, d4.loss_cls_aux1: 0.0120, d4.loss_bbox_aux1: 0.0386, d4.loss_iou_aux1: 0.2095, loss: 25.7109, grad_norm: 176.0627
2024-03-18 19:39:51,254 - mmdet - INFO - Epoch [5][150/463]	lr: 1.000e-05, eta: 3:50:09, time: 2.626, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1797, enc_loss_bbox: 0.0808, enc_loss_iou: 0.4041, loss_cls: 0.1033, loss_bbox: 0.0771, loss_iou: 0.3886, d0.loss_cls: 0.2054, d0.loss_bbox: 0.0775, d0.loss_iou: 0.3899, d1.loss_cls: 0.1160, d1.loss_bbox: 0.0790, d1.loss_iou: 0.3932, d2.loss_cls: 0.1088, d2.loss_bbox: 0.0766, d2.loss_iou: 0.3875, d3.loss_cls: 0.1036, d3.loss_bbox: 0.0772, d3.loss_iou: 0.3885, d4.loss_cls: 0.1038, d4.loss_bbox: 0.0771, d4.loss_iou: 0.3885, dn_loss_cls: 0.0163, dn_loss_bbox: 0.0377, dn_loss_iou: 0.2073, d0.dn_loss_cls: 0.0460, d0.dn_loss_bbox: 0.0552, d0.dn_loss_iou: 0.2926, d1.dn_loss_cls: 0.0185, d1.dn_loss_bbox: 0.0387, d1.dn_loss_iou: 0.2119, d2.dn_loss_cls: 0.0156, d2.dn_loss_bbox: 0.0377, d2.dn_loss_iou: 0.2076, d3.dn_loss_cls: 0.0152, d3.dn_loss_bbox: 0.0377, d3.dn_loss_iou: 0.2073, d4.dn_loss_cls: 0.0156, d4.dn_loss_bbox: 0.0377, d4.dn_loss_iou: 0.2073, loss_rpn_cls: 0.0356, loss_rpn_bbox: 0.1508, loss_cls0: 2.4330, acc0: 91.4382, loss_bbox0: 3.6782, loss_cls1: 1.8756, loss_bbox1: 4.2667, loss_centerness1: 7.1639, loss_cls_aux0: 0.0361, loss_bbox_aux0: 0.0168, loss_iou_aux0: 0.0918, d0.loss_cls_aux0: 0.0274, d0.loss_bbox_aux0: 0.0491, d0.loss_iou_aux0: 0.2683, d1.loss_cls_aux0: 0.0338, d1.loss_bbox_aux0: 0.0222, d1.loss_iou_aux0: 0.1221, d2.loss_cls_aux0: 0.0333, d2.loss_bbox_aux0: 0.0183, d2.loss_iou_aux0: 0.0996, d3.loss_cls_aux0: 0.0338, d3.loss_bbox_aux0: 0.0167, d3.loss_iou_aux0: 0.0905, d4.loss_cls_aux0: 0.0350, d4.loss_bbox_aux0: 0.0167, d4.loss_iou_aux0: 0.0910, loss_cls_aux1: 0.0234, loss_bbox_aux1: 0.0425, loss_iou_aux1: 0.2346, d0.loss_cls_aux1: 0.0223, d0.loss_bbox_aux1: 0.0555, d0.loss_iou_aux1: 0.3027, d1.loss_cls_aux1: 0.0239, d1.loss_bbox_aux1: 0.0445, d1.loss_iou_aux1: 0.2451, d2.loss_cls_aux1: 0.0239, d2.loss_bbox_aux1: 0.0426, d2.loss_iou_aux1: 0.2348, d3.loss_cls_aux1: 0.0229, d3.loss_bbox_aux1: 0.0424, d3.loss_iou_aux1: 0.2344, d4.loss_cls_aux1: 0.0228, d4.loss_bbox_aux1: 0.0424, d4.loss_iou_aux1: 0.2345, loss: 28.5139, grad_norm: 151.5842
2024-03-18 19:42:02,776 - mmdet - INFO - Epoch [5][200/463]	lr: 1.000e-05, eta: 3:48:11, time: 2.630, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1786, enc_loss_bbox: 0.0722, enc_loss_iou: 0.3746, loss_cls: 0.1089, loss_bbox: 0.0674, loss_iou: 0.3568, d0.loss_cls: 0.2112, d0.loss_bbox: 0.0683, d0.loss_iou: 0.3566, d1.loss_cls: 0.1206, d1.loss_bbox: 0.0679, d1.loss_iou: 0.3570, d2.loss_cls: 0.1104, d2.loss_bbox: 0.0676, d2.loss_iou: 0.3571, d3.loss_cls: 0.1079, d3.loss_bbox: 0.0677, d3.loss_iou: 0.3575, d4.loss_cls: 0.1075, d4.loss_bbox: 0.0676, d4.loss_iou: 0.3575, dn_loss_cls: 0.0167, dn_loss_bbox: 0.0363, dn_loss_iou: 0.2114, d0.dn_loss_cls: 0.0477, d0.dn_loss_bbox: 0.0524, d0.dn_loss_iou: 0.2943, d1.dn_loss_cls: 0.0207, d1.dn_loss_bbox: 0.0373, d1.dn_loss_iou: 0.2161, d2.dn_loss_cls: 0.0168, d2.dn_loss_bbox: 0.0363, d2.dn_loss_iou: 0.2114, d3.dn_loss_cls: 0.0157, d3.dn_loss_bbox: 0.0363, d3.dn_loss_iou: 0.2116, d4.dn_loss_cls: 0.0159, d4.dn_loss_bbox: 0.0363, d4.dn_loss_iou: 0.2114, loss_rpn_cls: 0.0293, loss_rpn_bbox: 0.1790, loss_cls0: 2.5088, acc0: 91.3216, loss_bbox0: 3.7300, loss_cls1: 1.7720, loss_bbox1: 3.9025, loss_centerness1: 7.1524, loss_cls_aux0: 0.0314, loss_bbox_aux0: 0.0190, loss_iou_aux0: 0.1063, d0.loss_cls_aux0: 0.0273, d0.loss_bbox_aux0: 0.0455, d0.loss_iou_aux0: 0.2520, d1.loss_cls_aux0: 0.0288, d1.loss_bbox_aux0: 0.0242, d1.loss_iou_aux0: 0.1332, d2.loss_cls_aux0: 0.0278, d2.loss_bbox_aux0: 0.0204, d2.loss_iou_aux0: 0.1136, d3.loss_cls_aux0: 0.0294, d3.loss_bbox_aux0: 0.0189, d3.loss_iou_aux0: 0.1049, d4.loss_cls_aux0: 0.0309, d4.loss_bbox_aux0: 0.0189, d4.loss_iou_aux0: 0.1055, loss_cls_aux1: 0.0222, loss_bbox_aux1: 0.0418, loss_iou_aux1: 0.2295, d0.loss_cls_aux1: 0.0210, d0.loss_bbox_aux1: 0.0522, d0.loss_iou_aux1: 0.2816, d1.loss_cls_aux1: 0.0197, d1.loss_bbox_aux1: 0.0429, d1.loss_iou_aux1: 0.2340, d2.loss_cls_aux1: 0.0198, d2.loss_bbox_aux1: 0.0418, d2.loss_iou_aux1: 0.2295, d3.loss_cls_aux1: 0.0205, d3.loss_bbox_aux1: 0.0417, d3.loss_iou_aux1: 0.2292, d4.loss_cls_aux1: 0.0216, d4.loss_bbox_aux1: 0.0417, d4.loss_iou_aux1: 0.2293, loss: 27.8981, grad_norm: 145.0698
2024-03-18 19:44:13,740 - mmdet - INFO - Epoch [5][250/463]	lr: 1.000e-05, eta: 3:46:11, time: 2.619, data_time: 0.009, memory: 18193, enc_loss_cls: 0.1658, enc_loss_bbox: 0.0724, enc_loss_iou: 0.3710, loss_cls: 0.1019, loss_bbox: 0.0667, loss_iou: 0.3472, d0.loss_cls: 0.2056, d0.loss_bbox: 0.0662, d0.loss_iou: 0.3478, d1.loss_cls: 0.1086, d1.loss_bbox: 0.0661, d1.loss_iou: 0.3477, d2.loss_cls: 0.1012, d2.loss_bbox: 0.0663, d2.loss_iou: 0.3472, d3.loss_cls: 0.0994, d3.loss_bbox: 0.0666, d3.loss_iou: 0.3467, d4.loss_cls: 0.1002, d4.loss_bbox: 0.0667, d4.loss_iou: 0.3470, dn_loss_cls: 0.0204, dn_loss_bbox: 0.0361, dn_loss_iou: 0.2074, d0.dn_loss_cls: 0.0481, d0.dn_loss_bbox: 0.0505, d0.dn_loss_iou: 0.2817, d1.dn_loss_cls: 0.0220, d1.dn_loss_bbox: 0.0367, d1.dn_loss_iou: 0.2108, d2.dn_loss_cls: 0.0199, d2.dn_loss_bbox: 0.0361, d2.dn_loss_iou: 0.2071, d3.dn_loss_cls: 0.0198, d3.dn_loss_bbox: 0.0360, d3.dn_loss_iou: 0.2072, d4.dn_loss_cls: 0.0196, d4.dn_loss_bbox: 0.0361, d4.dn_loss_iou: 0.2073, loss_rpn_cls: 0.0229, loss_rpn_bbox: 0.1587, loss_cls0: 2.4099, acc0: 91.5492, loss_bbox0: 3.6249, loss_cls1: 1.6886, loss_bbox1: 3.8092, loss_centerness1: 7.1434, loss_cls_aux0: 0.0331, loss_bbox_aux0: 0.0177, loss_iou_aux0: 0.0956, d0.loss_cls_aux0: 0.0279, d0.loss_bbox_aux0: 0.0447, d0.loss_iou_aux0: 0.2420, d1.loss_cls_aux0: 0.0321, d1.loss_bbox_aux0: 0.0220, d1.loss_iou_aux0: 0.1195, d2.loss_cls_aux0: 0.0323, d2.loss_bbox_aux0: 0.0185, d2.loss_iou_aux0: 0.1005, d3.loss_cls_aux0: 0.0307, d3.loss_bbox_aux0: 0.0176, d3.loss_iou_aux0: 0.0946, d4.loss_cls_aux0: 0.0311, d4.loss_bbox_aux0: 0.0177, d4.loss_iou_aux0: 0.0950, loss_cls_aux1: 0.0284, loss_bbox_aux1: 0.0399, loss_iou_aux1: 0.2199, d0.loss_cls_aux1: 0.0268, d0.loss_bbox_aux1: 0.0513, d0.loss_iou_aux1: 0.2758, d1.loss_cls_aux1: 0.0281, d1.loss_bbox_aux1: 0.0412, d1.loss_iou_aux1: 0.2254, d2.loss_cls_aux1: 0.0282, d2.loss_bbox_aux1: 0.0398, d2.loss_iou_aux1: 0.2197, d3.loss_cls_aux1: 0.0275, d3.loss_bbox_aux1: 0.0399, d3.loss_iou_aux1: 0.2197, d4.loss_cls_aux1: 0.0275, d4.loss_bbox_aux1: 0.0399, d4.loss_iou_aux1: 0.2198, loss: 27.2395, grad_norm: 147.9121
2024-03-18 19:46:27,762 - mmdet - INFO - Epoch [5][300/463]	lr: 1.000e-05, eta: 3:44:19, time: 2.680, data_time: 0.009, memory: 18193, enc_loss_cls: 0.1692, enc_loss_bbox: 0.0661, enc_loss_iou: 0.3547, loss_cls: 0.1092, loss_bbox: 0.0604, loss_iou: 0.3290, d0.loss_cls: 0.2147, d0.loss_bbox: 0.0605, d0.loss_iou: 0.3327, d1.loss_cls: 0.1236, d1.loss_bbox: 0.0604, d1.loss_iou: 0.3299, d2.loss_cls: 0.1079, d2.loss_bbox: 0.0605, d2.loss_iou: 0.3292, d3.loss_cls: 0.1060, d3.loss_bbox: 0.0606, d3.loss_iou: 0.3287, d4.loss_cls: 0.1081, d4.loss_bbox: 0.0605, d4.loss_iou: 0.3291, dn_loss_cls: 0.0277, dn_loss_bbox: 0.0354, dn_loss_iou: 0.2078, d0.dn_loss_cls: 0.0557, d0.dn_loss_bbox: 0.0506, d0.dn_loss_iou: 0.2897, d1.dn_loss_cls: 0.0287, d1.dn_loss_bbox: 0.0361, d1.dn_loss_iou: 0.2110, d2.dn_loss_cls: 0.0255, d2.dn_loss_bbox: 0.0353, d2.dn_loss_iou: 0.2073, d3.dn_loss_cls: 0.0252, d3.dn_loss_bbox: 0.0353, d3.dn_loss_iou: 0.2075, d4.dn_loss_cls: 0.0261, d4.dn_loss_bbox: 0.0353, d4.dn_loss_iou: 0.2077, loss_rpn_cls: 0.0370, loss_rpn_bbox: 0.1274, loss_cls0: 2.1264, acc0: 92.7245, loss_bbox0: 3.2673, loss_cls1: 1.6959, loss_bbox1: 3.6354, loss_centerness1: 7.1307, loss_cls_aux0: 0.0338, loss_bbox_aux0: 0.0147, loss_iou_aux0: 0.0831, d0.loss_cls_aux0: 0.0293, d0.loss_bbox_aux0: 0.0421, d0.loss_iou_aux0: 0.2449, d1.loss_cls_aux0: 0.0356, d1.loss_bbox_aux0: 0.0191, d1.loss_iou_aux0: 0.1084, d2.loss_cls_aux0: 0.0340, d2.loss_bbox_aux0: 0.0155, d2.loss_iou_aux0: 0.0872, d3.loss_cls_aux0: 0.0340, d3.loss_bbox_aux0: 0.0145, d3.loss_iou_aux0: 0.0816, d4.loss_cls_aux0: 0.0346, d4.loss_bbox_aux0: 0.0146, d4.loss_iou_aux0: 0.0823, loss_cls_aux1: 0.0241, loss_bbox_aux1: 0.0394, loss_iou_aux1: 0.2219, d0.loss_cls_aux1: 0.0236, d0.loss_bbox_aux1: 0.0495, d0.loss_iou_aux1: 0.2759, d1.loss_cls_aux1: 0.0254, d1.loss_bbox_aux1: 0.0404, d1.loss_iou_aux1: 0.2265, d2.loss_cls_aux1: 0.0233, d2.loss_bbox_aux1: 0.0395, d2.loss_iou_aux1: 0.2229, d3.loss_cls_aux1: 0.0236, d3.loss_bbox_aux1: 0.0394, d3.loss_iou_aux1: 0.2218, d4.loss_cls_aux1: 0.0241, d4.loss_bbox_aux1: 0.0394, d4.loss_iou_aux1: 0.2219, loss: 26.2608, grad_norm: 138.9143
2024-03-18 19:48:30,941 - mmdet - INFO - Epoch [5][350/463]	lr: 1.000e-05, eta: 3:41:59, time: 2.464, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1671, enc_loss_bbox: 0.0653, enc_loss_iou: 0.3479, loss_cls: 0.1123, loss_bbox: 0.0581, loss_iou: 0.3200, d0.loss_cls: 0.2228, d0.loss_bbox: 0.0594, d0.loss_iou: 0.3241, d1.loss_cls: 0.1306, d1.loss_bbox: 0.0586, d1.loss_iou: 0.3214, d2.loss_cls: 0.1145, d2.loss_bbox: 0.0581, d2.loss_iou: 0.3202, d3.loss_cls: 0.1113, d3.loss_bbox: 0.0580, d3.loss_iou: 0.3199, d4.loss_cls: 0.1112, d4.loss_bbox: 0.0581, d4.loss_iou: 0.3199, dn_loss_cls: 0.0237, dn_loss_bbox: 0.0334, dn_loss_iou: 0.2042, d0.dn_loss_cls: 0.0450, d0.dn_loss_bbox: 0.0465, d0.dn_loss_iou: 0.2782, d1.dn_loss_cls: 0.0233, d1.dn_loss_bbox: 0.0340, d1.dn_loss_iou: 0.2073, d2.dn_loss_cls: 0.0232, d2.dn_loss_bbox: 0.0333, d2.dn_loss_iou: 0.2039, d3.dn_loss_cls: 0.0235, d3.dn_loss_bbox: 0.0333, d3.dn_loss_iou: 0.2038, d4.dn_loss_cls: 0.0226, d4.dn_loss_bbox: 0.0333, d4.dn_loss_iou: 0.2041, loss_rpn_cls: 0.0408, loss_rpn_bbox: 0.1876, loss_cls0: 2.2442, acc0: 92.1881, loss_bbox0: 3.3832, loss_cls1: 1.6487, loss_bbox1: 3.6053, loss_centerness1: 7.1302, loss_cls_aux0: 0.0293, loss_bbox_aux0: 0.0193, loss_iou_aux0: 0.1055, d0.loss_cls_aux0: 0.0258, d0.loss_bbox_aux0: 0.0430, d0.loss_iou_aux0: 0.2470, d1.loss_cls_aux0: 0.0296, d1.loss_bbox_aux0: 0.0234, d1.loss_iou_aux0: 0.1288, d2.loss_cls_aux0: 0.0287, d2.loss_bbox_aux0: 0.0201, d2.loss_iou_aux0: 0.1100, d3.loss_cls_aux0: 0.0276, d3.loss_bbox_aux0: 0.0191, d3.loss_iou_aux0: 0.1042, d4.loss_cls_aux0: 0.0280, d4.loss_bbox_aux0: 0.0192, d4.loss_iou_aux0: 0.1047, loss_cls_aux1: 0.0243, loss_bbox_aux1: 0.0387, loss_iou_aux1: 0.2193, d0.loss_cls_aux1: 0.0233, d0.loss_bbox_aux1: 0.0496, d0.loss_iou_aux1: 0.2727, d1.loss_cls_aux1: 0.0247, d1.loss_bbox_aux1: 0.0401, d1.loss_iou_aux1: 0.2250, d2.loss_cls_aux1: 0.0225, d2.loss_bbox_aux1: 0.0387, d2.loss_iou_aux1: 0.2194, d3.loss_cls_aux1: 0.0225, d3.loss_bbox_aux1: 0.0387, d3.loss_iou_aux1: 0.2192, d4.loss_cls_aux1: 0.0232, d4.loss_bbox_aux1: 0.0387, d4.loss_iou_aux1: 0.2192, loss: 26.4484, grad_norm: 161.5476
2024-03-18 19:50:44,440 - mmdet - INFO - Epoch [5][400/463]	lr: 1.000e-05, eta: 3:40:04, time: 2.670, data_time: 0.010, memory: 18193, enc_loss_cls: 0.1568, enc_loss_bbox: 0.0707, enc_loss_iou: 0.3709, loss_cls: 0.0994, loss_bbox: 0.0654, loss_iou: 0.3506, d0.loss_cls: 0.1992, d0.loss_bbox: 0.0658, d0.loss_iou: 0.3517, d1.loss_cls: 0.1136, d1.loss_bbox: 0.0656, d1.loss_iou: 0.3516, d2.loss_cls: 0.1039, d2.loss_bbox: 0.0657, d2.loss_iou: 0.3488, d3.loss_cls: 0.1007, d3.loss_bbox: 0.0655, d3.loss_iou: 0.3501, d4.loss_cls: 0.0991, d4.loss_bbox: 0.0654, d4.loss_iou: 0.3506, dn_loss_cls: 0.0078, dn_loss_bbox: 0.0349, dn_loss_iou: 0.2039, d0.dn_loss_cls: 0.0348, d0.dn_loss_bbox: 0.0497, d0.dn_loss_iou: 0.2814, d1.dn_loss_cls: 0.0108, d1.dn_loss_bbox: 0.0358, d1.dn_loss_iou: 0.2083, d2.dn_loss_cls: 0.0080, d2.dn_loss_bbox: 0.0349, d2.dn_loss_iou: 0.2039, d3.dn_loss_cls: 0.0079, d3.dn_loss_bbox: 0.0349, d3.dn_loss_iou: 0.2038, d4.dn_loss_cls: 0.0078, d4.dn_loss_bbox: 0.0349, d4.dn_loss_iou: 0.2038, loss_rpn_cls: 0.0247, loss_rpn_bbox: 0.1386, loss_cls0: 2.2854, acc0: 91.9532, loss_bbox0: 3.3332, loss_cls1: 1.7229, loss_bbox1: 3.8550, loss_centerness1: 7.1053, loss_cls_aux0: 0.0133, loss_bbox_aux0: 0.0167, loss_iou_aux0: 0.0955, d0.loss_cls_aux0: 0.0142, d0.loss_bbox_aux0: 0.0426, d0.loss_iou_aux0: 0.2414, d1.loss_cls_aux0: 0.0138, d1.loss_bbox_aux0: 0.0210, d1.loss_iou_aux0: 0.1185, d2.loss_cls_aux0: 0.0122, d2.loss_bbox_aux0: 0.0177, d2.loss_iou_aux0: 0.0998, d3.loss_cls_aux0: 0.0126, d3.loss_bbox_aux0: 0.0166, d3.loss_iou_aux0: 0.0937, d4.loss_cls_aux0: 0.0126, d4.loss_bbox_aux0: 0.0167, d4.loss_iou_aux0: 0.0945, loss_cls_aux1: 0.0109, loss_bbox_aux1: 0.0392, loss_iou_aux1: 0.2190, d0.loss_cls_aux1: 0.0126, d0.loss_bbox_aux1: 0.0501, d0.loss_iou_aux1: 0.2734, d1.loss_cls_aux1: 0.0121, d1.loss_bbox_aux1: 0.0403, d1.loss_iou_aux1: 0.2254, d2.loss_cls_aux1: 0.0102, d2.loss_bbox_aux1: 0.0390, d2.loss_iou_aux1: 0.2185, d3.loss_cls_aux1: 0.0103, d3.loss_bbox_aux1: 0.0391, d3.loss_iou_aux1: 0.2187, d4.loss_cls_aux1: 0.0107, d4.loss_bbox_aux1: 0.0391, d4.loss_iou_aux1: 0.2188, loss: 26.5244, grad_norm: 169.1604
2024-03-18 19:53:00,136 - mmdet - INFO - Epoch [5][450/463]	lr: 1.000e-05, eta: 3:38:13, time: 2.714, data_time: 0.009, memory: 18193, enc_loss_cls: 0.1751, enc_loss_bbox: 0.0708, enc_loss_iou: 0.3538, loss_cls: 0.1095, loss_bbox: 0.0688, loss_iou: 0.3408, d0.loss_cls: 0.1993, d0.loss_bbox: 0.0692, d0.loss_iou: 0.3444, d1.loss_cls: 0.1199, d1.loss_bbox: 0.0691, d1.loss_iou: 0.3403, d2.loss_cls: 0.1075, d2.loss_bbox: 0.0689, d2.loss_iou: 0.3409, d3.loss_cls: 0.1125, d3.loss_bbox: 0.0680, d3.loss_iou: 0.3397, d4.loss_cls: 0.1091, d4.loss_bbox: 0.0688, d4.loss_iou: 0.3405, dn_loss_cls: 0.0137, dn_loss_bbox: 0.0363, dn_loss_iou: 0.2054, d0.dn_loss_cls: 0.0405, d0.dn_loss_bbox: 0.0522, d0.dn_loss_iou: 0.2837, d1.dn_loss_cls: 0.0160, d1.dn_loss_bbox: 0.0372, d1.dn_loss_iou: 0.2084, d2.dn_loss_cls: 0.0134, d2.dn_loss_bbox: 0.0363, d2.dn_loss_iou: 0.2045, d3.dn_loss_cls: 0.0133, d3.dn_loss_bbox: 0.0362, d3.dn_loss_iou: 0.2045, d4.dn_loss_cls: 0.0132, d4.dn_loss_bbox: 0.0362, d4.dn_loss_iou: 0.2052, loss_rpn_cls: 0.0243, loss_rpn_bbox: 0.1642, loss_cls0: 2.3116, acc0: 92.1406, loss_bbox0: 3.5578, loss_cls1: 1.8082, loss_bbox1: 3.7549, loss_centerness1: 7.1394, loss_cls_aux0: 0.0265, loss_bbox_aux0: 0.0183, loss_iou_aux0: 0.1010, d0.loss_cls_aux0: 0.0226, d0.loss_bbox_aux0: 0.0457, d0.loss_iou_aux0: 0.2458, d1.loss_cls_aux0: 0.0247, d1.loss_bbox_aux0: 0.0230, d1.loss_iou_aux0: 0.1256, d2.loss_cls_aux0: 0.0250, d2.loss_bbox_aux0: 0.0192, d2.loss_iou_aux0: 0.1048, d3.loss_cls_aux0: 0.0257, d3.loss_bbox_aux0: 0.0181, d3.loss_iou_aux0: 0.0989, d4.loss_cls_aux0: 0.0258, d4.loss_bbox_aux0: 0.0182, d4.loss_iou_aux0: 0.0999, loss_cls_aux1: 0.0289, loss_bbox_aux1: 0.0404, loss_iou_aux1: 0.2184, d0.loss_cls_aux1: 0.0248, d0.loss_bbox_aux1: 0.0514, d0.loss_iou_aux1: 0.2730, d1.loss_cls_aux1: 0.0272, d1.loss_bbox_aux1: 0.0417, d1.loss_iou_aux1: 0.2241, d2.loss_cls_aux1: 0.0265, d2.loss_bbox_aux1: 0.0406, d2.loss_iou_aux1: 0.2191, d3.loss_cls_aux1: 0.0292, d3.loss_bbox_aux1: 0.0404, d3.loss_iou_aux1: 0.2182, d4.loss_cls_aux1: 0.0286, d4.loss_bbox_aux1: 0.0404, d4.loss_iou_aux1: 0.2183, loss: 27.0931, grad_norm: 128.8980
2024-03-18 19:53:32,646 - mmdet - INFO - Saving checkpoint at 5 epochs
2024-03-18 19:55:02,599 - mmdet - INFO - Evaluating bbox...
2024-03-18 19:55:18,342 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.603
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.877
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.732
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.485
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.576
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.803
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.731
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.734
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.734
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.729
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.849

2024-03-18 19:55:18,343 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.648 | Thatch   | 0.561 |
+----------+-------+----------+-------+
2024-03-18 19:55:18,494 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 19:55:18,494 - mmdet - INFO - Epoch(val) [5][154]	bbox_mAP: 0.6030, bbox_mAP_50: 0.8770, bbox_mAP_75: 0.7320, bbox_mAP_s: 0.4850, bbox_mAP_m: 0.5760, bbox_mAP_l: 0.8030, bbox_mAP_copypaste: 0.603 0.877 0.732 0.485 0.576 0.803
2024-03-18 19:57:31,637 - mmdet - INFO - Epoch [6][50/463]	lr: 1.000e-05, eta: 3:34:31, time: 2.662, data_time: 0.058, memory: 18193, enc_loss_cls: 0.1771, enc_loss_bbox: 0.0651, enc_loss_iou: 0.3501, loss_cls: 0.1078, loss_bbox: 0.0615, loss_iou: 0.3346, d0.loss_cls: 0.2157, d0.loss_bbox: 0.0617, d0.loss_iou: 0.3366, d1.loss_cls: 0.1249, d1.loss_bbox: 0.0622, d1.loss_iou: 0.3353, d2.loss_cls: 0.1138, d2.loss_bbox: 0.0614, d2.loss_iou: 0.3337, d3.loss_cls: 0.1089, d3.loss_bbox: 0.0616, d3.loss_iou: 0.3336, d4.loss_cls: 0.1092, d4.loss_bbox: 0.0614, d4.loss_iou: 0.3344, dn_loss_cls: 0.0136, dn_loss_bbox: 0.0349, dn_loss_iou: 0.2084, d0.dn_loss_cls: 0.0457, d0.dn_loss_bbox: 0.0489, d0.dn_loss_iou: 0.2803, d1.dn_loss_cls: 0.0197, d1.dn_loss_bbox: 0.0355, d1.dn_loss_iou: 0.2097, d2.dn_loss_cls: 0.0154, d2.dn_loss_bbox: 0.0349, d2.dn_loss_iou: 0.2067, d3.dn_loss_cls: 0.0137, d3.dn_loss_bbox: 0.0349, d3.dn_loss_iou: 0.2066, d4.dn_loss_cls: 0.0136, d4.dn_loss_bbox: 0.0349, d4.dn_loss_iou: 0.2082, loss_rpn_cls: 0.0133, loss_rpn_bbox: 0.1296, loss_cls0: 2.0942, acc0: 92.7303, loss_bbox0: 3.2090, loss_cls1: 1.6650, loss_bbox1: 3.7432, loss_centerness1: 7.1546, loss_cls_aux0: 0.0206, loss_bbox_aux0: 0.0139, loss_iou_aux0: 0.0805, d0.loss_cls_aux0: 0.0232, d0.loss_bbox_aux0: 0.0415, d0.loss_iou_aux0: 0.2342, d1.loss_cls_aux0: 0.0233, d1.loss_bbox_aux0: 0.0188, d1.loss_iou_aux0: 0.1064, d2.loss_cls_aux0: 0.0215, d2.loss_bbox_aux0: 0.0148, d2.loss_iou_aux0: 0.0847, d3.loss_cls_aux0: 0.0211, d3.loss_bbox_aux0: 0.0137, d3.loss_iou_aux0: 0.0783, d4.loss_cls_aux0: 0.0206, d4.loss_bbox_aux0: 0.0138, d4.loss_iou_aux0: 0.0793, loss_cls_aux1: 0.0208, loss_bbox_aux1: 0.0409, loss_iou_aux1: 0.2290, d0.loss_cls_aux1: 0.0227, d0.loss_bbox_aux1: 0.0501, d0.loss_iou_aux1: 0.2759, d1.loss_cls_aux1: 0.0256, d1.loss_bbox_aux1: 0.0422, d1.loss_iou_aux1: 0.2351, d2.loss_cls_aux1: 0.0216, d2.loss_bbox_aux1: 0.0408, d2.loss_iou_aux1: 0.2289, d3.loss_cls_aux1: 0.0206, d3.loss_bbox_aux1: 0.0408, d3.loss_iou_aux1: 0.2284, d4.loss_cls_aux1: 0.0210, d4.loss_bbox_aux1: 0.0409, d4.loss_iou_aux1: 0.2287, loss: 26.1496, grad_norm: 132.0071
2024-03-18 19:59:37,857 - mmdet - INFO - Epoch [6][100/463]	lr: 1.000e-05, eta: 3:32:20, time: 2.524, data_time: 0.012, memory: 18193, enc_loss_cls: 0.1857, enc_loss_bbox: 0.0648, enc_loss_iou: 0.3442, loss_cls: 0.1168, loss_bbox: 0.0595, loss_iou: 0.3205, d0.loss_cls: 0.2251, d0.loss_bbox: 0.0597, d0.loss_iou: 0.3211, d1.loss_cls: 0.1299, d1.loss_bbox: 0.0590, d1.loss_iou: 0.3191, d2.loss_cls: 0.1210, d2.loss_bbox: 0.0591, d2.loss_iou: 0.3189, d3.loss_cls: 0.1164, d3.loss_bbox: 0.0598, d3.loss_iou: 0.3196, d4.loss_cls: 0.1166, d4.loss_bbox: 0.0598, d4.loss_iou: 0.3206, dn_loss_cls: 0.0140, dn_loss_bbox: 0.0362, dn_loss_iou: 0.2015, d0.dn_loss_cls: 0.0377, d0.dn_loss_bbox: 0.0499, d0.dn_loss_iou: 0.2717, d1.dn_loss_cls: 0.0159, d1.dn_loss_bbox: 0.0368, d1.dn_loss_iou: 0.2043, d2.dn_loss_cls: 0.0141, d2.dn_loss_bbox: 0.0362, d2.dn_loss_iou: 0.2016, d3.dn_loss_cls: 0.0139, d3.dn_loss_bbox: 0.0361, d3.dn_loss_iou: 0.2015, d4.dn_loss_cls: 0.0139, d4.dn_loss_bbox: 0.0361, d4.dn_loss_iou: 0.2015, loss_rpn_cls: 0.0325, loss_rpn_bbox: 0.1538, loss_cls0: 2.2698, acc0: 92.1279, loss_bbox0: 3.2934, loss_cls1: 1.7094, loss_bbox1: 3.5538, loss_centerness1: 7.1383, loss_cls_aux0: 0.0201, loss_bbox_aux0: 0.0175, loss_iou_aux0: 0.0973, d0.loss_cls_aux0: 0.0199, d0.loss_bbox_aux0: 0.0436, d0.loss_iou_aux0: 0.2360, d1.loss_cls_aux0: 0.0209, d1.loss_bbox_aux0: 0.0214, d1.loss_iou_aux0: 0.1185, d2.loss_cls_aux0: 0.0208, d2.loss_bbox_aux0: 0.0182, d2.loss_iou_aux0: 0.1000, d3.loss_cls_aux0: 0.0195, d3.loss_bbox_aux0: 0.0173, d3.loss_iou_aux0: 0.0956, d4.loss_cls_aux0: 0.0199, d4.loss_bbox_aux0: 0.0174, d4.loss_iou_aux0: 0.0963, loss_cls_aux1: 0.0227, loss_bbox_aux1: 0.0379, loss_iou_aux1: 0.2116, d0.loss_cls_aux1: 0.0229, d0.loss_bbox_aux1: 0.0479, d0.loss_iou_aux1: 0.2622, d1.loss_cls_aux1: 0.0239, d1.loss_bbox_aux1: 0.0387, d1.loss_iou_aux1: 0.2173, d2.loss_cls_aux1: 0.0243, d2.loss_bbox_aux1: 0.0379, d2.loss_iou_aux1: 0.2120, d3.loss_cls_aux1: 0.0233, d3.loss_bbox_aux1: 0.0378, d3.loss_iou_aux1: 0.2115, d4.loss_cls_aux1: 0.0226, d4.loss_bbox_aux1: 0.0379, d4.loss_iou_aux1: 0.2115, loss: 26.1752, grad_norm: 149.4741
2024-03-18 20:01:50,073 - mmdet - INFO - Epoch [6][150/463]	lr: 1.000e-05, eta: 3:30:22, time: 2.644, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1534, enc_loss_bbox: 0.0679, enc_loss_iou: 0.3521, loss_cls: 0.0956, loss_bbox: 0.0652, loss_iou: 0.3380, d0.loss_cls: 0.1881, d0.loss_bbox: 0.0655, d0.loss_iou: 0.3415, d1.loss_cls: 0.1070, d1.loss_bbox: 0.0655, d1.loss_iou: 0.3390, d2.loss_cls: 0.0963, d2.loss_bbox: 0.0653, d2.loss_iou: 0.3388, d3.loss_cls: 0.0967, d3.loss_bbox: 0.0652, d3.loss_iou: 0.3367, d4.loss_cls: 0.0969, d4.loss_bbox: 0.0651, d4.loss_iou: 0.3366, dn_loss_cls: 0.0193, dn_loss_bbox: 0.0353, dn_loss_iou: 0.2044, d0.dn_loss_cls: 0.0491, d0.dn_loss_bbox: 0.0508, d0.dn_loss_iou: 0.2840, d1.dn_loss_cls: 0.0227, d1.dn_loss_bbox: 0.0361, d1.dn_loss_iou: 0.2085, d2.dn_loss_cls: 0.0232, d2.dn_loss_bbox: 0.0353, d2.dn_loss_iou: 0.2043, d3.dn_loss_cls: 0.0198, d3.dn_loss_bbox: 0.0353, d3.dn_loss_iou: 0.2043, d4.dn_loss_cls: 0.0180, d4.dn_loss_bbox: 0.0353, d4.dn_loss_iou: 0.2043, loss_rpn_cls: 0.0331, loss_rpn_bbox: 0.1587, loss_cls0: 2.2686, acc0: 92.1270, loss_bbox0: 3.5249, loss_cls1: 1.6628, loss_bbox1: 3.7364, loss_centerness1: 7.1317, loss_cls_aux0: 0.0300, loss_bbox_aux0: 0.0175, loss_iou_aux0: 0.0924, d0.loss_cls_aux0: 0.0278, d0.loss_bbox_aux0: 0.0448, d0.loss_iou_aux0: 0.2429, d1.loss_cls_aux0: 0.0329, d1.loss_bbox_aux0: 0.0230, d1.loss_iou_aux0: 0.1212, d2.loss_cls_aux0: 0.0318, d2.loss_bbox_aux0: 0.0187, d2.loss_iou_aux0: 0.0987, d3.loss_cls_aux0: 0.0299, d3.loss_bbox_aux0: 0.0174, d3.loss_iou_aux0: 0.0916, d4.loss_cls_aux0: 0.0300, d4.loss_bbox_aux0: 0.0175, d4.loss_iou_aux0: 0.0919, loss_cls_aux1: 0.0255, loss_bbox_aux1: 0.0408, loss_iou_aux1: 0.2185, d0.loss_cls_aux1: 0.0253, d0.loss_bbox_aux1: 0.0513, d0.loss_iou_aux1: 0.2706, d1.loss_cls_aux1: 0.0293, d1.loss_bbox_aux1: 0.0420, d1.loss_iou_aux1: 0.2250, d2.loss_cls_aux1: 0.0265, d2.loss_bbox_aux1: 0.0409, d2.loss_iou_aux1: 0.2192, d3.loss_cls_aux1: 0.0251, d3.loss_bbox_aux1: 0.0408, d3.loss_iou_aux1: 0.2183, d4.loss_cls_aux1: 0.0251, d4.loss_bbox_aux1: 0.0408, d4.loss_iou_aux1: 0.2184, loss: 26.7260, grad_norm: 143.3151
2024-03-18 20:04:01,172 - mmdet - INFO - Epoch [6][200/463]	lr: 1.000e-05, eta: 3:28:21, time: 2.622, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1755, enc_loss_bbox: 0.0675, enc_loss_iou: 0.3617, loss_cls: 0.1233, loss_bbox: 0.0603, loss_iou: 0.3324, d0.loss_cls: 0.2182, d0.loss_bbox: 0.0611, d0.loss_iou: 0.3360, d1.loss_cls: 0.1331, d1.loss_bbox: 0.0609, d1.loss_iou: 0.3329, d2.loss_cls: 0.1264, d2.loss_bbox: 0.0605, d2.loss_iou: 0.3322, d3.loss_cls: 0.1219, d3.loss_bbox: 0.0603, d3.loss_iou: 0.3322, d4.loss_cls: 0.1234, d4.loss_bbox: 0.0602, d4.loss_iou: 0.3315, dn_loss_cls: 0.0141, dn_loss_bbox: 0.0358, dn_loss_iou: 0.2084, d0.dn_loss_cls: 0.0405, d0.dn_loss_bbox: 0.0500, d0.dn_loss_iou: 0.2825, d1.dn_loss_cls: 0.0167, d1.dn_loss_bbox: 0.0365, d1.dn_loss_iou: 0.2118, d2.dn_loss_cls: 0.0137, d2.dn_loss_bbox: 0.0358, d2.dn_loss_iou: 0.2084, d3.dn_loss_cls: 0.0134, d3.dn_loss_bbox: 0.0357, d3.dn_loss_iou: 0.2082, d4.dn_loss_cls: 0.0143, d4.dn_loss_bbox: 0.0358, d4.dn_loss_iou: 0.2083, loss_rpn_cls: 0.0199, loss_rpn_bbox: 0.1495, loss_cls0: 2.2545, acc0: 92.0966, loss_bbox0: 3.4658, loss_cls1: 1.7537, loss_bbox1: 3.7055, loss_centerness1: 7.1562, loss_cls_aux0: 0.0278, loss_bbox_aux0: 0.0158, loss_iou_aux0: 0.0918, d0.loss_cls_aux0: 0.0252, d0.loss_bbox_aux0: 0.0412, d0.loss_iou_aux0: 0.2394, d1.loss_cls_aux0: 0.0269, d1.loss_bbox_aux0: 0.0202, d1.loss_iou_aux0: 0.1170, d2.loss_cls_aux0: 0.0261, d2.loss_bbox_aux0: 0.0167, d2.loss_iou_aux0: 0.0966, d3.loss_cls_aux0: 0.0272, d3.loss_bbox_aux0: 0.0157, d3.loss_iou_aux0: 0.0909, d4.loss_cls_aux0: 0.0275, d4.loss_bbox_aux0: 0.0158, d4.loss_iou_aux0: 0.0912, loss_cls_aux1: 0.0237, loss_bbox_aux1: 0.0382, loss_iou_aux1: 0.2188, d0.loss_cls_aux1: 0.0221, d0.loss_bbox_aux1: 0.0481, d0.loss_iou_aux1: 0.2697, d1.loss_cls_aux1: 0.0236, d1.loss_bbox_aux1: 0.0393, d1.loss_iou_aux1: 0.2240, d2.loss_cls_aux1: 0.0213, d2.loss_bbox_aux1: 0.0382, d2.loss_iou_aux1: 0.2189, d3.loss_cls_aux1: 0.0221, d3.loss_bbox_aux1: 0.0382, d3.loss_iou_aux1: 0.2185, d4.loss_cls_aux1: 0.0229, d4.loss_bbox_aux1: 0.0382, d4.loss_iou_aux1: 0.2186, loss: 26.7440, grad_norm: 175.3719
2024-03-18 20:06:11,983 - mmdet - INFO - Epoch [6][250/463]	lr: 1.000e-05, eta: 3:26:19, time: 2.616, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1462, enc_loss_bbox: 0.0707, enc_loss_iou: 0.3533, loss_cls: 0.0973, loss_bbox: 0.0669, loss_iou: 0.3351, d0.loss_cls: 0.1766, d0.loss_bbox: 0.0680, d0.loss_iou: 0.3409, d1.loss_cls: 0.1084, d1.loss_bbox: 0.0670, d1.loss_iou: 0.3368, d2.loss_cls: 0.0946, d2.loss_bbox: 0.0676, d2.loss_iou: 0.3377, d3.loss_cls: 0.0938, d3.loss_bbox: 0.0670, d3.loss_iou: 0.3361, d4.loss_cls: 0.0963, d4.loss_bbox: 0.0669, d4.loss_iou: 0.3351, dn_loss_cls: 0.0116, dn_loss_bbox: 0.0355, dn_loss_iou: 0.1996, d0.dn_loss_cls: 0.0327, d0.dn_loss_bbox: 0.0511, d0.dn_loss_iou: 0.2769, d1.dn_loss_cls: 0.0119, d1.dn_loss_bbox: 0.0364, d1.dn_loss_iou: 0.2037, d2.dn_loss_cls: 0.0110, d2.dn_loss_bbox: 0.0354, d2.dn_loss_iou: 0.1994, d3.dn_loss_cls: 0.0110, d3.dn_loss_bbox: 0.0355, d3.dn_loss_iou: 0.1994, d4.dn_loss_cls: 0.0117, d4.dn_loss_bbox: 0.0355, d4.dn_loss_iou: 0.1995, loss_rpn_cls: 0.0250, loss_rpn_bbox: 0.1416, loss_cls0: 2.0846, acc0: 92.6296, loss_bbox0: 3.3418, loss_cls1: 1.6033, loss_bbox1: 3.7127, loss_centerness1: 7.1411, loss_cls_aux0: 0.0224, loss_bbox_aux0: 0.0170, loss_iou_aux0: 0.0912, d0.loss_cls_aux0: 0.0166, d0.loss_bbox_aux0: 0.0445, d0.loss_iou_aux0: 0.2331, d1.loss_cls_aux0: 0.0192, d1.loss_bbox_aux0: 0.0221, d1.loss_iou_aux0: 0.1169, d2.loss_cls_aux0: 0.0200, d2.loss_bbox_aux0: 0.0179, d2.loss_iou_aux0: 0.0957, d3.loss_cls_aux0: 0.0201, d3.loss_bbox_aux0: 0.0168, d3.loss_iou_aux0: 0.0901, d4.loss_cls_aux0: 0.0226, d4.loss_bbox_aux0: 0.0169, d4.loss_iou_aux0: 0.0906, loss_cls_aux1: 0.0162, loss_bbox_aux1: 0.0396, loss_iou_aux1: 0.2119, d0.loss_cls_aux1: 0.0134, d0.loss_bbox_aux1: 0.0497, d0.loss_iou_aux1: 0.2618, d1.loss_cls_aux1: 0.0133, d1.loss_bbox_aux1: 0.0404, d1.loss_iou_aux1: 0.2162, d2.loss_cls_aux1: 0.0139, d2.loss_bbox_aux1: 0.0396, d2.loss_iou_aux1: 0.2119, d3.loss_cls_aux1: 0.0144, d3.loss_bbox_aux1: 0.0396, d3.loss_iou_aux1: 0.2117, d4.loss_cls_aux1: 0.0159, d4.loss_bbox_aux1: 0.0396, d4.loss_iou_aux1: 0.2118, loss: 25.9446, grad_norm: 139.5988
2024-03-18 20:08:25,704 - mmdet - INFO - Epoch [6][300/463]	lr: 1.000e-05, eta: 3:24:22, time: 2.674, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1791, enc_loss_bbox: 0.0762, enc_loss_iou: 0.3688, loss_cls: 0.1235, loss_bbox: 0.0661, loss_iou: 0.3276, d0.loss_cls: 0.2175, d0.loss_bbox: 0.0663, d0.loss_iou: 0.3275, d1.loss_cls: 0.1369, d1.loss_bbox: 0.0655, d1.loss_iou: 0.3257, d2.loss_cls: 0.1236, d2.loss_bbox: 0.0653, d2.loss_iou: 0.3254, d3.loss_cls: 0.1222, d3.loss_bbox: 0.0659, d3.loss_iou: 0.3258, d4.loss_cls: 0.1224, d4.loss_bbox: 0.0661, d4.loss_iou: 0.3275, dn_loss_cls: 0.0222, dn_loss_bbox: 0.0371, dn_loss_iou: 0.2047, d0.dn_loss_cls: 0.0477, d0.dn_loss_bbox: 0.0513, d0.dn_loss_iou: 0.2766, d1.dn_loss_cls: 0.0240, d1.dn_loss_bbox: 0.0377, d1.dn_loss_iou: 0.2079, d2.dn_loss_cls: 0.0208, d2.dn_loss_bbox: 0.0370, d2.dn_loss_iou: 0.2044, d3.dn_loss_cls: 0.0216, d3.dn_loss_bbox: 0.0370, d3.dn_loss_iou: 0.2045, d4.dn_loss_cls: 0.0219, d4.dn_loss_bbox: 0.0370, d4.dn_loss_iou: 0.2045, loss_rpn_cls: 0.0721, loss_rpn_bbox: 0.1718, loss_cls0: 2.2901, acc0: 92.2546, loss_bbox0: 3.4652, loss_cls1: 1.7345, loss_bbox1: 3.6430, loss_centerness1: 7.1266, loss_cls_aux0: 0.0398, loss_bbox_aux0: 0.0186, loss_iou_aux0: 0.0965, d0.loss_cls_aux0: 0.0345, d0.loss_bbox_aux0: 0.0445, d0.loss_iou_aux0: 0.2349, d1.loss_cls_aux0: 0.0418, d1.loss_bbox_aux0: 0.0236, d1.loss_iou_aux0: 0.1235, d2.loss_cls_aux0: 0.0388, d2.loss_bbox_aux0: 0.0198, d2.loss_iou_aux0: 0.1022, d3.loss_cls_aux0: 0.0401, d3.loss_bbox_aux0: 0.0185, d3.loss_iou_aux0: 0.0952, d4.loss_cls_aux0: 0.0388, d4.loss_bbox_aux0: 0.0186, d4.loss_iou_aux0: 0.0957, loss_cls_aux1: 0.0284, loss_bbox_aux1: 0.0408, loss_iou_aux1: 0.2122, d0.loss_cls_aux1: 0.0275, d0.loss_bbox_aux1: 0.0516, d0.loss_iou_aux1: 0.2639, d1.loss_cls_aux1: 0.0284, d1.loss_bbox_aux1: 0.0421, d1.loss_iou_aux1: 0.2175, d2.loss_cls_aux1: 0.0274, d2.loss_bbox_aux1: 0.0409, d2.loss_iou_aux1: 0.2126, d3.loss_cls_aux1: 0.0282, d3.loss_bbox_aux1: 0.0408, d3.loss_iou_aux1: 0.2119, d4.loss_cls_aux1: 0.0285, d4.loss_bbox_aux1: 0.0408, d4.loss_iou_aux1: 0.2120, loss: 26.9068, grad_norm: 153.6978
2024-03-18 20:10:28,611 - mmdet - INFO - Epoch [6][350/463]	lr: 1.000e-05, eta: 3:22:05, time: 2.458, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1749, enc_loss_bbox: 0.0679, enc_loss_iou: 0.3660, loss_cls: 0.1166, loss_bbox: 0.0650, loss_iou: 0.3492, d0.loss_cls: 0.2055, d0.loss_bbox: 0.0637, d0.loss_iou: 0.3474, d1.loss_cls: 0.1322, d1.loss_bbox: 0.0634, d1.loss_iou: 0.3424, d2.loss_cls: 0.1219, d2.loss_bbox: 0.0638, d2.loss_iou: 0.3472, d3.loss_cls: 0.1151, d3.loss_bbox: 0.0640, d3.loss_iou: 0.3491, d4.loss_cls: 0.1163, d4.loss_bbox: 0.0640, d4.loss_iou: 0.3490, dn_loss_cls: 0.0317, dn_loss_bbox: 0.0340, dn_loss_iou: 0.2091, d0.dn_loss_cls: 0.0593, d0.dn_loss_bbox: 0.0481, d0.dn_loss_iou: 0.2844, d1.dn_loss_cls: 0.0317, d1.dn_loss_bbox: 0.0347, d1.dn_loss_iou: 0.2116, d2.dn_loss_cls: 0.0300, d2.dn_loss_bbox: 0.0340, d2.dn_loss_iou: 0.2077, d3.dn_loss_cls: 0.0308, d3.dn_loss_bbox: 0.0340, d3.dn_loss_iou: 0.2081, d4.dn_loss_cls: 0.0315, d4.dn_loss_bbox: 0.0340, d4.dn_loss_iou: 0.2083, loss_rpn_cls: 0.0310, loss_rpn_bbox: 0.1484, loss_cls0: 2.2385, acc0: 92.3724, loss_bbox0: 3.3570, loss_cls1: 1.7720, loss_bbox1: 3.7963, loss_centerness1: 7.1370, loss_cls_aux0: 0.0566, loss_bbox_aux0: 0.0153, loss_iou_aux0: 0.0872, d0.loss_cls_aux0: 0.0447, d0.loss_bbox_aux0: 0.0418, d0.loss_iou_aux0: 0.2397, d1.loss_cls_aux0: 0.0535, d1.loss_bbox_aux0: 0.0196, d1.loss_iou_aux0: 0.1118, d2.loss_cls_aux0: 0.0558, d2.loss_bbox_aux0: 0.0163, d2.loss_iou_aux0: 0.0924, d3.loss_cls_aux0: 0.0553, d3.loss_bbox_aux0: 0.0152, d3.loss_iou_aux0: 0.0860, d4.loss_cls_aux0: 0.0564, d4.loss_bbox_aux0: 0.0152, d4.loss_iou_aux0: 0.0864, loss_cls_aux1: 0.0435, loss_bbox_aux1: 0.0393, loss_iou_aux1: 0.2243, d0.loss_cls_aux1: 0.0378, d0.loss_bbox_aux1: 0.0480, d0.loss_iou_aux1: 0.2705, d1.loss_cls_aux1: 0.0433, d1.loss_bbox_aux1: 0.0403, d1.loss_iou_aux1: 0.2304, d2.loss_cls_aux1: 0.0425, d2.loss_bbox_aux1: 0.0392, d2.loss_iou_aux1: 0.2241, d3.loss_cls_aux1: 0.0409, d3.loss_bbox_aux1: 0.0392, d3.loss_iou_aux1: 0.2241, d4.loss_cls_aux1: 0.0427, d4.loss_bbox_aux1: 0.0393, d4.loss_iou_aux1: 0.2242, loss: 27.1709, grad_norm: 172.2797
2024-03-18 20:12:42,694 - mmdet - INFO - Epoch [6][400/463]	lr: 1.000e-05, eta: 3:20:08, time: 2.682, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1809, enc_loss_bbox: 0.0716, enc_loss_iou: 0.3773, loss_cls: 0.1333, loss_bbox: 0.0671, loss_iou: 0.3574, d0.loss_cls: 0.2088, d0.loss_bbox: 0.0674, d0.loss_iou: 0.3602, d1.loss_cls: 0.1389, d1.loss_bbox: 0.0665, d1.loss_iou: 0.3561, d2.loss_cls: 0.1315, d2.loss_bbox: 0.0667, d2.loss_iou: 0.3558, d3.loss_cls: 0.1311, d3.loss_bbox: 0.0670, d3.loss_iou: 0.3566, d4.loss_cls: 0.1331, d4.loss_bbox: 0.0670, d4.loss_iou: 0.3566, dn_loss_cls: 0.0223, dn_loss_bbox: 0.0355, dn_loss_iou: 0.2095, d0.dn_loss_cls: 0.0492, d0.dn_loss_bbox: 0.0517, d0.dn_loss_iou: 0.2918, d1.dn_loss_cls: 0.0235, d1.dn_loss_bbox: 0.0362, d1.dn_loss_iou: 0.2128, d2.dn_loss_cls: 0.0212, d2.dn_loss_bbox: 0.0355, d2.dn_loss_iou: 0.2091, d3.dn_loss_cls: 0.0215, d3.dn_loss_bbox: 0.0355, d3.dn_loss_iou: 0.2093, d4.dn_loss_cls: 0.0224, d4.dn_loss_bbox: 0.0355, d4.dn_loss_iou: 0.2092, loss_rpn_cls: 0.0355, loss_rpn_bbox: 0.1901, loss_cls0: 2.4645, acc0: 91.5594, loss_bbox0: 3.6659, loss_cls1: 1.9296, loss_bbox1: 3.9413, loss_centerness1: 7.1477, loss_cls_aux0: 0.0356, loss_bbox_aux0: 0.0193, loss_iou_aux0: 0.1039, d0.loss_cls_aux0: 0.0304, d0.loss_bbox_aux0: 0.0459, d0.loss_iou_aux0: 0.2533, d1.loss_cls_aux0: 0.0358, d1.loss_bbox_aux0: 0.0234, d1.loss_iou_aux0: 0.1278, d2.loss_cls_aux0: 0.0353, d2.loss_bbox_aux0: 0.0206, d2.loss_iou_aux0: 0.1102, d3.loss_cls_aux0: 0.0355, d3.loss_bbox_aux0: 0.0192, d3.loss_iou_aux0: 0.1024, d4.loss_cls_aux0: 0.0349, d4.loss_bbox_aux0: 0.0193, d4.loss_iou_aux0: 0.1031, loss_cls_aux1: 0.0307, loss_bbox_aux1: 0.0408, loss_iou_aux1: 0.2289, d0.loss_cls_aux1: 0.0294, d0.loss_bbox_aux1: 0.0520, d0.loss_iou_aux1: 0.2851, d1.loss_cls_aux1: 0.0332, d1.loss_bbox_aux1: 0.0418, d1.loss_iou_aux1: 0.2343, d2.loss_cls_aux1: 0.0309, d2.loss_bbox_aux1: 0.0407, d2.loss_iou_aux1: 0.2284, d3.loss_cls_aux1: 0.0309, d3.loss_bbox_aux1: 0.0408, d3.loss_iou_aux1: 0.2287, d4.loss_cls_aux1: 0.0310, d4.loss_bbox_aux1: 0.0408, d4.loss_iou_aux1: 0.2287, loss: 28.1899, grad_norm: 196.3683
2024-03-18 20:14:58,203 - mmdet - INFO - Epoch [6][450/463]	lr: 1.000e-05, eta: 3:18:13, time: 2.710, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1635, enc_loss_bbox: 0.0678, enc_loss_iou: 0.3547, loss_cls: 0.0981, loss_bbox: 0.0636, loss_iou: 0.3365, d0.loss_cls: 0.1928, d0.loss_bbox: 0.0639, d0.loss_iou: 0.3398, d1.loss_cls: 0.1086, d1.loss_bbox: 0.0633, d1.loss_iou: 0.3369, d2.loss_cls: 0.1009, d2.loss_bbox: 0.0635, d2.loss_iou: 0.3361, d3.loss_cls: 0.0997, d3.loss_bbox: 0.0634, d3.loss_iou: 0.3357, d4.loss_cls: 0.0967, d4.loss_bbox: 0.0636, d4.loss_iou: 0.3372, dn_loss_cls: 0.0127, dn_loss_bbox: 0.0344, dn_loss_iou: 0.2036, d0.dn_loss_cls: 0.0403, d0.dn_loss_bbox: 0.0491, d0.dn_loss_iou: 0.2826, d1.dn_loss_cls: 0.0146, d1.dn_loss_bbox: 0.0354, d1.dn_loss_iou: 0.2083, d2.dn_loss_cls: 0.0122, d2.dn_loss_bbox: 0.0344, d2.dn_loss_iou: 0.2034, d3.dn_loss_cls: 0.0124, d3.dn_loss_bbox: 0.0344, d3.dn_loss_iou: 0.2034, d4.dn_loss_cls: 0.0123, d4.dn_loss_bbox: 0.0344, d4.dn_loss_iou: 0.2035, loss_rpn_cls: 0.0197, loss_rpn_bbox: 0.1580, loss_cls0: 2.3614, acc0: 91.7666, loss_bbox0: 3.5450, loss_cls1: 1.6400, loss_bbox1: 3.7385, loss_centerness1: 7.1083, loss_cls_aux0: 0.0283, loss_bbox_aux0: 0.0177, loss_iou_aux0: 0.0997, d0.loss_cls_aux0: 0.0252, d0.loss_bbox_aux0: 0.0431, d0.loss_iou_aux0: 0.2417, d1.loss_cls_aux0: 0.0292, d1.loss_bbox_aux0: 0.0217, d1.loss_iou_aux0: 0.1229, d2.loss_cls_aux0: 0.0288, d2.loss_bbox_aux0: 0.0184, d2.loss_iou_aux0: 0.1034, d3.loss_cls_aux0: 0.0277, d3.loss_bbox_aux0: 0.0175, d3.loss_iou_aux0: 0.0984, d4.loss_cls_aux0: 0.0274, d4.loss_bbox_aux0: 0.0176, d4.loss_iou_aux0: 0.0990, loss_cls_aux1: 0.0184, loss_bbox_aux1: 0.0382, loss_iou_aux1: 0.2119, d0.loss_cls_aux1: 0.0202, d0.loss_bbox_aux1: 0.0484, d0.loss_iou_aux1: 0.2658, d1.loss_cls_aux1: 0.0188, d1.loss_bbox_aux1: 0.0393, d1.loss_iou_aux1: 0.2179, d2.loss_cls_aux1: 0.0184, d2.loss_bbox_aux1: 0.0382, d2.loss_iou_aux1: 0.2117, d3.loss_cls_aux1: 0.0181, d3.loss_bbox_aux1: 0.0382, d3.loss_iou_aux1: 0.2118, d4.loss_cls_aux1: 0.0177, d4.loss_bbox_aux1: 0.0382, d4.loss_iou_aux1: 0.2119, loss: 26.6393, grad_norm: 133.8824
2024-03-18 20:15:30,586 - mmdet - INFO - Saving checkpoint at 6 epochs
2024-03-18 20:17:01,610 - mmdet - INFO - Evaluating bbox...
2024-03-18 20:17:18,049 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.610
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.884
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.736
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.489
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.580
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.809
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.735
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.739
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.739
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.704
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.727
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.854

2024-03-18 20:17:18,050 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.653 | Thatch   | 0.570 |
+----------+-------+----------+-------+
2024-03-18 20:17:18,731 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_004/best_bbox_mAP_epoch_4.pth was removed
2024-03-18 20:17:25,057 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_6.pth.
2024-03-18 20:17:25,057 - mmdet - INFO - Best bbox_mAP is 0.6100 at 6 epoch.
2024-03-18 20:17:25,058 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 20:17:25,058 - mmdet - INFO - Epoch(val) [6][154]	bbox_mAP: 0.6100, bbox_mAP_50: 0.8840, bbox_mAP_75: 0.7360, bbox_mAP_s: 0.4890, bbox_mAP_m: 0.5800, bbox_mAP_l: 0.8090, bbox_mAP_copypaste: 0.610 0.884 0.736 0.489 0.580 0.809
2024-03-18 20:19:37,991 - mmdet - INFO - Epoch [7][50/463]	lr: 1.000e-05, eta: 3:14:45, time: 2.658, data_time: 0.056, memory: 19333, enc_loss_cls: 0.1568, enc_loss_bbox: 0.0676, enc_loss_iou: 0.3549, loss_cls: 0.1072, loss_bbox: 0.0610, loss_iou: 0.3212, d0.loss_cls: 0.1831, d0.loss_bbox: 0.0617, d0.loss_iou: 0.3257, d1.loss_cls: 0.1163, d1.loss_bbox: 0.0608, d1.loss_iou: 0.3213, d2.loss_cls: 0.1076, d2.loss_bbox: 0.0608, d2.loss_iou: 0.3208, d3.loss_cls: 0.1057, d3.loss_bbox: 0.0607, d3.loss_iou: 0.3211, d4.loss_cls: 0.1059, d4.loss_bbox: 0.0611, d4.loss_iou: 0.3212, dn_loss_cls: 0.0217, dn_loss_bbox: 0.0356, dn_loss_iou: 0.1999, d0.dn_loss_cls: 0.0449, d0.dn_loss_bbox: 0.0494, d0.dn_loss_iou: 0.2701, d1.dn_loss_cls: 0.0226, d1.dn_loss_bbox: 0.0363, d1.dn_loss_iou: 0.2029, d2.dn_loss_cls: 0.0199, d2.dn_loss_bbox: 0.0356, d2.dn_loss_iou: 0.1993, d3.dn_loss_cls: 0.0191, d3.dn_loss_bbox: 0.0356, d3.dn_loss_iou: 0.1993, d4.dn_loss_cls: 0.0208, d4.dn_loss_bbox: 0.0356, d4.dn_loss_iou: 0.1995, loss_rpn_cls: 0.0290, loss_rpn_bbox: 0.1364, loss_cls0: 2.1239, acc0: 92.6790, loss_bbox0: 3.2194, loss_cls1: 1.6570, loss_bbox1: 3.5927, loss_centerness1: 7.1337, loss_cls_aux0: 0.0312, loss_bbox_aux0: 0.0151, loss_iou_aux0: 0.0850, d0.loss_cls_aux0: 0.0271, d0.loss_bbox_aux0: 0.0423, d0.loss_iou_aux0: 0.2350, d1.loss_cls_aux0: 0.0318, d1.loss_bbox_aux0: 0.0198, d1.loss_iou_aux0: 0.1108, d2.loss_cls_aux0: 0.0325, d2.loss_bbox_aux0: 0.0159, d2.loss_iou_aux0: 0.0881, d3.loss_cls_aux0: 0.0303, d3.loss_bbox_aux0: 0.0149, d3.loss_iou_aux0: 0.0831, d4.loss_cls_aux0: 0.0306, d4.loss_bbox_aux0: 0.0150, d4.loss_iou_aux0: 0.0839, loss_cls_aux1: 0.0194, loss_bbox_aux1: 0.0398, loss_iou_aux1: 0.2169, d0.loss_cls_aux1: 0.0208, d0.loss_bbox_aux1: 0.0481, d0.loss_iou_aux1: 0.2613, d1.loss_cls_aux1: 0.0202, d1.loss_bbox_aux1: 0.0405, d1.loss_iou_aux1: 0.2205, d2.loss_cls_aux1: 0.0191, d2.loss_bbox_aux1: 0.0397, d2.loss_iou_aux1: 0.2165, d3.loss_cls_aux1: 0.0186, d3.loss_bbox_aux1: 0.0398, d3.loss_iou_aux1: 0.2166, d4.loss_cls_aux1: 0.0189, d4.loss_bbox_aux1: 0.0398, d4.loss_iou_aux1: 0.2167, loss: 25.8485, grad_norm: 145.9493
2024-03-18 20:21:44,641 - mmdet - INFO - Epoch [7][100/463]	lr: 1.000e-05, eta: 3:12:36, time: 2.533, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1542, enc_loss_bbox: 0.0632, enc_loss_iou: 0.3250, loss_cls: 0.0967, loss_bbox: 0.0585, loss_iou: 0.3109, d0.loss_cls: 0.1942, d0.loss_bbox: 0.0589, d0.loss_iou: 0.3121, d1.loss_cls: 0.1133, d1.loss_bbox: 0.0585, d1.loss_iou: 0.3117, d2.loss_cls: 0.0967, d2.loss_bbox: 0.0585, d2.loss_iou: 0.3113, d3.loss_cls: 0.0954, d3.loss_bbox: 0.0585, d3.loss_iou: 0.3115, d4.loss_cls: 0.0962, d4.loss_bbox: 0.0585, d4.loss_iou: 0.3109, dn_loss_cls: 0.0073, dn_loss_bbox: 0.0342, dn_loss_iou: 0.1955, d0.dn_loss_cls: 0.0356, d0.dn_loss_bbox: 0.0480, d0.dn_loss_iou: 0.2667, d1.dn_loss_cls: 0.0104, d1.dn_loss_bbox: 0.0352, d1.dn_loss_iou: 0.1992, d2.dn_loss_cls: 0.0078, d2.dn_loss_bbox: 0.0342, d2.dn_loss_iou: 0.1944, d3.dn_loss_cls: 0.0073, d3.dn_loss_bbox: 0.0342, d3.dn_loss_iou: 0.1950, d4.dn_loss_cls: 0.0072, d4.dn_loss_bbox: 0.0342, d4.dn_loss_iou: 0.1954, loss_rpn_cls: 0.0247, loss_rpn_bbox: 0.1692, loss_cls0: 2.2172, acc0: 92.1652, loss_bbox0: 3.3443, loss_cls1: 1.6007, loss_bbox1: 3.4615, loss_centerness1: 7.1146, loss_cls_aux0: 0.0122, loss_bbox_aux0: 0.0167, loss_iou_aux0: 0.0952, d0.loss_cls_aux0: 0.0145, d0.loss_bbox_aux0: 0.0417, d0.loss_iou_aux0: 0.2354, d1.loss_cls_aux0: 0.0144, d1.loss_bbox_aux0: 0.0210, d1.loss_iou_aux0: 0.1175, d2.loss_cls_aux0: 0.0137, d2.loss_bbox_aux0: 0.0176, d2.loss_iou_aux0: 0.0998, d3.loss_cls_aux0: 0.0124, d3.loss_bbox_aux0: 0.0166, d3.loss_iou_aux0: 0.0942, d4.loss_cls_aux0: 0.0114, d4.loss_bbox_aux0: 0.0167, d4.loss_iou_aux0: 0.0946, loss_cls_aux1: 0.0128, loss_bbox_aux1: 0.0369, loss_iou_aux1: 0.2050, d0.loss_cls_aux1: 0.0147, d0.loss_bbox_aux1: 0.0466, d0.loss_iou_aux1: 0.2554, d1.loss_cls_aux1: 0.0143, d1.loss_bbox_aux1: 0.0385, d1.loss_iou_aux1: 0.2139, d2.loss_cls_aux1: 0.0129, d2.loss_bbox_aux1: 0.0369, d2.loss_iou_aux1: 0.2051, d3.loss_cls_aux1: 0.0131, d3.loss_bbox_aux1: 0.0369, d3.loss_iou_aux1: 0.2048, d4.loss_cls_aux1: 0.0126, d4.loss_bbox_aux1: 0.0369, d4.loss_iou_aux1: 0.2049, loss: 25.4770, grad_norm: 136.4209
2024-03-18 20:23:55,889 - mmdet - INFO - Epoch [7][150/463]	lr: 1.000e-05, eta: 3:10:34, time: 2.625, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1494, enc_loss_bbox: 0.0662, enc_loss_iou: 0.3495, loss_cls: 0.0949, loss_bbox: 0.0638, loss_iou: 0.3345, d0.loss_cls: 0.1923, d0.loss_bbox: 0.0639, d0.loss_iou: 0.3364, d1.loss_cls: 0.1081, d1.loss_bbox: 0.0641, d1.loss_iou: 0.3375, d2.loss_cls: 0.0974, d2.loss_bbox: 0.0638, d2.loss_iou: 0.3352, d3.loss_cls: 0.0966, d3.loss_bbox: 0.0637, d3.loss_iou: 0.3338, d4.loss_cls: 0.0947, d4.loss_bbox: 0.0638, d4.loss_iou: 0.3344, dn_loss_cls: 0.0140, dn_loss_bbox: 0.0350, dn_loss_iou: 0.2012, d0.dn_loss_cls: 0.0410, d0.dn_loss_bbox: 0.0496, d0.dn_loss_iou: 0.2779, d1.dn_loss_cls: 0.0151, d1.dn_loss_bbox: 0.0359, d1.dn_loss_iou: 0.2056, d2.dn_loss_cls: 0.0129, d2.dn_loss_bbox: 0.0349, d2.dn_loss_iou: 0.2011, d3.dn_loss_cls: 0.0129, d3.dn_loss_bbox: 0.0349, d3.dn_loss_iou: 0.2010, d4.dn_loss_cls: 0.0136, d4.dn_loss_bbox: 0.0349, d4.dn_loss_iou: 0.2011, loss_rpn_cls: 0.0527, loss_rpn_bbox: 0.1631, loss_cls0: 2.2015, acc0: 92.3460, loss_bbox0: 3.4442, loss_cls1: 1.6827, loss_bbox1: 3.6930, loss_centerness1: 7.1029, loss_cls_aux0: 0.0313, loss_bbox_aux0: 0.0167, loss_iou_aux0: 0.0949, d0.loss_cls_aux0: 0.0280, d0.loss_bbox_aux0: 0.0428, d0.loss_iou_aux0: 0.2399, d1.loss_cls_aux0: 0.0279, d1.loss_bbox_aux0: 0.0214, d1.loss_iou_aux0: 0.1200, d2.loss_cls_aux0: 0.0288, d2.loss_bbox_aux0: 0.0173, d2.loss_iou_aux0: 0.0980, d3.loss_cls_aux0: 0.0308, d3.loss_bbox_aux0: 0.0165, d3.loss_iou_aux0: 0.0935, d4.loss_cls_aux0: 0.0308, d4.loss_bbox_aux0: 0.0166, d4.loss_iou_aux0: 0.0941, loss_cls_aux1: 0.0201, loss_bbox_aux1: 0.0396, loss_iou_aux1: 0.2194, d0.loss_cls_aux1: 0.0216, d0.loss_bbox_aux1: 0.0494, d0.loss_iou_aux1: 0.2672, d1.loss_cls_aux1: 0.0201, d1.loss_bbox_aux1: 0.0406, d1.loss_iou_aux1: 0.2239, d2.loss_cls_aux1: 0.0186, d2.loss_bbox_aux1: 0.0396, d2.loss_iou_aux1: 0.2198, d3.loss_cls_aux1: 0.0190, d3.loss_bbox_aux1: 0.0395, d3.loss_iou_aux1: 0.2192, d4.loss_cls_aux1: 0.0196, d4.loss_bbox_aux1: 0.0395, d4.loss_iou_aux1: 0.2193, loss: 26.3924, grad_norm: 167.5344
2024-03-18 20:26:06,785 - mmdet - INFO - Epoch [7][200/463]	lr: 1.000e-05, eta: 3:08:32, time: 2.618, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1320, enc_loss_bbox: 0.0745, enc_loss_iou: 0.3624, loss_cls: 0.0812, loss_bbox: 0.0710, loss_iou: 0.3435, d0.loss_cls: 0.1698, d0.loss_bbox: 0.0719, d0.loss_iou: 0.3469, d1.loss_cls: 0.0933, d1.loss_bbox: 0.0723, d1.loss_iou: 0.3461, d2.loss_cls: 0.0814, d2.loss_bbox: 0.0710, d2.loss_iou: 0.3428, d3.loss_cls: 0.0802, d3.loss_bbox: 0.0708, d3.loss_iou: 0.3429, d4.loss_cls: 0.0801, d4.loss_bbox: 0.0709, d4.loss_iou: 0.3432, dn_loss_cls: 0.0153, dn_loss_bbox: 0.0379, dn_loss_iou: 0.2048, d0.dn_loss_cls: 0.0433, d0.dn_loss_bbox: 0.0558, d0.dn_loss_iou: 0.2897, d1.dn_loss_cls: 0.0169, d1.dn_loss_bbox: 0.0392, d1.dn_loss_iou: 0.2099, d2.dn_loss_cls: 0.0137, d2.dn_loss_bbox: 0.0379, d2.dn_loss_iou: 0.2047, d3.dn_loss_cls: 0.0156, d3.dn_loss_bbox: 0.0379, d3.dn_loss_iou: 0.2045, d4.dn_loss_cls: 0.0148, d4.dn_loss_bbox: 0.0379, d4.dn_loss_iou: 0.2047, loss_rpn_cls: 0.0266, loss_rpn_bbox: 0.1792, loss_cls0: 2.4058, acc0: 91.6570, loss_bbox0: 3.6704, loss_cls1: 1.6939, loss_bbox1: 3.8186, loss_centerness1: 7.1498, loss_cls_aux0: 0.0209, loss_bbox_aux0: 0.0195, loss_iou_aux0: 0.0994, d0.loss_cls_aux0: 0.0182, d0.loss_bbox_aux0: 0.0481, d0.loss_iou_aux0: 0.2481, d1.loss_cls_aux0: 0.0213, d1.loss_bbox_aux0: 0.0242, d1.loss_iou_aux0: 0.1240, d2.loss_cls_aux0: 0.0181, d2.loss_bbox_aux0: 0.0205, d2.loss_iou_aux0: 0.1038, d3.loss_cls_aux0: 0.0199, d3.loss_bbox_aux0: 0.0193, d3.loss_iou_aux0: 0.0976, d4.loss_cls_aux0: 0.0201, d4.loss_bbox_aux0: 0.0194, d4.loss_iou_aux0: 0.0984, loss_cls_aux1: 0.0125, loss_bbox_aux1: 0.0419, loss_iou_aux1: 0.2170, d0.loss_cls_aux1: 0.0141, d0.loss_bbox_aux1: 0.0525, d0.loss_iou_aux1: 0.2677, d1.loss_cls_aux1: 0.0136, d1.loss_bbox_aux1: 0.0428, d1.loss_iou_aux1: 0.2213, d2.loss_cls_aux1: 0.0132, d2.loss_bbox_aux1: 0.0419, d2.loss_iou_aux1: 0.2171, d3.loss_cls_aux1: 0.0128, d3.loss_bbox_aux1: 0.0419, d3.loss_iou_aux1: 0.2168, d4.loss_cls_aux1: 0.0124, d4.loss_bbox_aux1: 0.0419, d4.loss_iou_aux1: 0.2169, loss: 27.0162, grad_norm: 148.2359
2024-03-18 20:28:17,024 - mmdet - INFO - Epoch [7][250/463]	lr: 1.000e-05, eta: 3:06:28, time: 2.605, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1655, enc_loss_bbox: 0.0663, enc_loss_iou: 0.3485, loss_cls: 0.1115, loss_bbox: 0.0594, loss_iou: 0.3182, d0.loss_cls: 0.2066, d0.loss_bbox: 0.0601, d0.loss_iou: 0.3228, d1.loss_cls: 0.1257, d1.loss_bbox: 0.0598, d1.loss_iou: 0.3222, d2.loss_cls: 0.1114, d2.loss_bbox: 0.0596, d2.loss_iou: 0.3186, d3.loss_cls: 0.1116, d3.loss_bbox: 0.0591, d3.loss_iou: 0.3180, d4.loss_cls: 0.1114, d4.loss_bbox: 0.0594, d4.loss_iou: 0.3182, dn_loss_cls: 0.0186, dn_loss_bbox: 0.0339, dn_loss_iou: 0.2028, d0.dn_loss_cls: 0.0469, d0.dn_loss_bbox: 0.0480, d0.dn_loss_iou: 0.2761, d1.dn_loss_cls: 0.0214, d1.dn_loss_bbox: 0.0347, d1.dn_loss_iou: 0.2062, d2.dn_loss_cls: 0.0184, d2.dn_loss_bbox: 0.0339, d2.dn_loss_iou: 0.2025, d3.dn_loss_cls: 0.0184, d3.dn_loss_bbox: 0.0339, d3.dn_loss_iou: 0.2025, d4.dn_loss_cls: 0.0186, d4.dn_loss_bbox: 0.0339, d4.dn_loss_iou: 0.2027, loss_rpn_cls: 0.0260, loss_rpn_bbox: 0.1539, loss_cls0: 2.3296, acc0: 91.7973, loss_bbox0: 3.4144, loss_cls1: 1.7337, loss_bbox1: 3.6353, loss_centerness1: 7.1248, loss_cls_aux0: 0.0436, loss_bbox_aux0: 0.0186, loss_iou_aux0: 0.1025, d0.loss_cls_aux0: 0.0356, d0.loss_bbox_aux0: 0.0418, d0.loss_iou_aux0: 0.2396, d1.loss_cls_aux0: 0.0412, d1.loss_bbox_aux0: 0.0227, d1.loss_iou_aux0: 0.1267, d2.loss_cls_aux0: 0.0395, d2.loss_bbox_aux0: 0.0198, d2.loss_iou_aux0: 0.1085, d3.loss_cls_aux0: 0.0389, d3.loss_bbox_aux0: 0.0185, d3.loss_iou_aux0: 0.1014, d4.loss_cls_aux0: 0.0420, d4.loss_bbox_aux0: 0.0185, d4.loss_iou_aux0: 0.1019, loss_cls_aux1: 0.0280, loss_bbox_aux1: 0.0377, loss_iou_aux1: 0.2138, d0.loss_cls_aux1: 0.0252, d0.loss_bbox_aux1: 0.0470, d0.loss_iou_aux1: 0.2624, d1.loss_cls_aux1: 0.0271, d1.loss_bbox_aux1: 0.0387, d1.loss_iou_aux1: 0.2192, d2.loss_cls_aux1: 0.0254, d2.loss_bbox_aux1: 0.0376, d2.loss_iou_aux1: 0.2135, d3.loss_cls_aux1: 0.0256, d3.loss_bbox_aux1: 0.0376, d3.loss_iou_aux1: 0.2136, d4.loss_cls_aux1: 0.0272, d4.loss_bbox_aux1: 0.0377, d4.loss_iou_aux1: 0.2137, loss: 26.5975, grad_norm: 143.9878
2024-03-18 20:30:29,826 - mmdet - INFO - Epoch [7][300/463]	lr: 1.000e-05, eta: 3:04:27, time: 2.656, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1605, enc_loss_bbox: 0.0622, enc_loss_iou: 0.3314, loss_cls: 0.1062, loss_bbox: 0.0594, loss_iou: 0.3183, d0.loss_cls: 0.1986, d0.loss_bbox: 0.0596, d0.loss_iou: 0.3208, d1.loss_cls: 0.1120, d1.loss_bbox: 0.0592, d1.loss_iou: 0.3177, d2.loss_cls: 0.1049, d2.loss_bbox: 0.0592, d2.loss_iou: 0.3174, d3.loss_cls: 0.1058, d3.loss_bbox: 0.0594, d3.loss_iou: 0.3181, d4.loss_cls: 0.1054, d4.loss_bbox: 0.0594, d4.loss_iou: 0.3182, dn_loss_cls: 0.0181, dn_loss_bbox: 0.0342, dn_loss_iou: 0.1971, d0.dn_loss_cls: 0.0437, d0.dn_loss_bbox: 0.0484, d0.dn_loss_iou: 0.2726, d1.dn_loss_cls: 0.0193, d1.dn_loss_bbox: 0.0350, d1.dn_loss_iou: 0.2010, d2.dn_loss_cls: 0.0181, d2.dn_loss_bbox: 0.0342, d2.dn_loss_iou: 0.1968, d3.dn_loss_cls: 0.0176, d3.dn_loss_bbox: 0.0342, d3.dn_loss_iou: 0.1968, d4.dn_loss_cls: 0.0184, d4.dn_loss_bbox: 0.0342, d4.dn_loss_iou: 0.1969, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.1384, loss_cls0: 2.2699, acc0: 92.2721, loss_bbox0: 3.3335, loss_cls1: 1.6127, loss_bbox1: 3.5371, loss_centerness1: 7.1323, loss_cls_aux0: 0.0343, loss_bbox_aux0: 0.0177, loss_iou_aux0: 0.0933, d0.loss_cls_aux0: 0.0336, d0.loss_bbox_aux0: 0.0413, d0.loss_iou_aux0: 0.2311, d1.loss_cls_aux0: 0.0372, d1.loss_bbox_aux0: 0.0218, d1.loss_iou_aux0: 0.1165, d2.loss_cls_aux0: 0.0355, d2.loss_bbox_aux0: 0.0186, d2.loss_iou_aux0: 0.0978, d3.loss_cls_aux0: 0.0348, d3.loss_bbox_aux0: 0.0177, d3.loss_iou_aux0: 0.0923, d4.loss_cls_aux0: 0.0342, d4.loss_bbox_aux0: 0.0177, d4.loss_iou_aux0: 0.0927, loss_cls_aux1: 0.0301, loss_bbox_aux1: 0.0385, loss_iou_aux1: 0.2128, d0.loss_cls_aux1: 0.0302, d0.loss_bbox_aux1: 0.0470, d0.loss_iou_aux1: 0.2580, d1.loss_cls_aux1: 0.0304, d1.loss_bbox_aux1: 0.0395, d1.loss_iou_aux1: 0.2177, d2.loss_cls_aux1: 0.0302, d2.loss_bbox_aux1: 0.0385, d2.loss_iou_aux1: 0.2131, d3.loss_cls_aux1: 0.0305, d3.loss_bbox_aux1: 0.0385, d3.loss_iou_aux1: 0.2127, d4.loss_cls_aux1: 0.0293, d4.loss_bbox_aux1: 0.0385, d4.loss_iou_aux1: 0.2128, loss: 26.0276, grad_norm: 129.3902
2024-03-18 20:32:32,276 - mmdet - INFO - Epoch [7][350/463]	lr: 1.000e-05, eta: 3:02:12, time: 2.449, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1478, enc_loss_bbox: 0.0643, enc_loss_iou: 0.3666, loss_cls: 0.0914, loss_bbox: 0.0611, loss_iou: 0.3477, d0.loss_cls: 0.1774, d0.loss_bbox: 0.0614, d0.loss_iou: 0.3488, d1.loss_cls: 0.0975, d1.loss_bbox: 0.0617, d1.loss_iou: 0.3490, d2.loss_cls: 0.0917, d2.loss_bbox: 0.0611, d2.loss_iou: 0.3478, d3.loss_cls: 0.0916, d3.loss_bbox: 0.0611, d3.loss_iou: 0.3479, d4.loss_cls: 0.0913, d4.loss_bbox: 0.0611, d4.loss_iou: 0.3477, dn_loss_cls: 0.0190, dn_loss_bbox: 0.0338, dn_loss_iou: 0.2069, d0.dn_loss_cls: 0.0451, d0.dn_loss_bbox: 0.0475, d0.dn_loss_iou: 0.2853, d1.dn_loss_cls: 0.0183, d1.dn_loss_bbox: 0.0344, d1.dn_loss_iou: 0.2100, d2.dn_loss_cls: 0.0184, d2.dn_loss_bbox: 0.0338, d2.dn_loss_iou: 0.2068, d3.dn_loss_cls: 0.0189, d3.dn_loss_bbox: 0.0338, d3.dn_loss_iou: 0.2068, d4.dn_loss_cls: 0.0186, d4.dn_loss_bbox: 0.0338, d4.dn_loss_iou: 0.2068, loss_rpn_cls: 0.0306, loss_rpn_bbox: 0.1533, loss_cls0: 2.3545, acc0: 91.8276, loss_bbox0: 3.6909, loss_cls1: 1.6554, loss_bbox1: 3.8769, loss_centerness1: 7.1535, loss_cls_aux0: 0.0335, loss_bbox_aux0: 0.0172, loss_iou_aux0: 0.1014, d0.loss_cls_aux0: 0.0243, d0.loss_bbox_aux0: 0.0417, d0.loss_iou_aux0: 0.2474, d1.loss_cls_aux0: 0.0291, d1.loss_bbox_aux0: 0.0210, d1.loss_iou_aux0: 0.1234, d2.loss_cls_aux0: 0.0316, d2.loss_bbox_aux0: 0.0179, d2.loss_iou_aux0: 0.1055, d3.loss_cls_aux0: 0.0328, d3.loss_bbox_aux0: 0.0171, d3.loss_iou_aux0: 0.1003, d4.loss_cls_aux0: 0.0341, d4.loss_bbox_aux0: 0.0171, d4.loss_iou_aux0: 0.1007, loss_cls_aux1: 0.0274, loss_bbox_aux1: 0.0377, loss_iou_aux1: 0.2232, d0.loss_cls_aux1: 0.0229, d0.loss_bbox_aux1: 0.0469, d0.loss_iou_aux1: 0.2747, d1.loss_cls_aux1: 0.0233, d1.loss_bbox_aux1: 0.0385, d1.loss_iou_aux1: 0.2284, d2.loss_cls_aux1: 0.0250, d2.loss_bbox_aux1: 0.0378, d2.loss_iou_aux1: 0.2240, d3.loss_cls_aux1: 0.0262, d3.loss_bbox_aux1: 0.0377, d3.loss_iou_aux1: 0.2230, d4.loss_cls_aux1: 0.0273, d4.loss_bbox_aux1: 0.0377, d4.loss_iou_aux1: 0.2232, loss: 27.1502, grad_norm: 133.7407
2024-03-18 20:34:44,995 - mmdet - INFO - Epoch [7][400/463]	lr: 1.000e-05, eta: 3:00:11, time: 2.654, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1642, enc_loss_bbox: 0.0635, enc_loss_iou: 0.3485, loss_cls: 0.1131, loss_bbox: 0.0594, loss_iou: 0.3258, d0.loss_cls: 0.1942, d0.loss_bbox: 0.0597, d0.loss_iou: 0.3295, d1.loss_cls: 0.1191, d1.loss_bbox: 0.0599, d1.loss_iou: 0.3273, d2.loss_cls: 0.1148, d2.loss_bbox: 0.0596, d2.loss_iou: 0.3257, d3.loss_cls: 0.1119, d3.loss_bbox: 0.0594, d3.loss_iou: 0.3254, d4.loss_cls: 0.1128, d4.loss_bbox: 0.0594, d4.loss_iou: 0.3253, dn_loss_cls: 0.0178, dn_loss_bbox: 0.0337, dn_loss_iou: 0.2020, d0.dn_loss_cls: 0.0412, d0.dn_loss_bbox: 0.0474, d0.dn_loss_iou: 0.2750, d1.dn_loss_cls: 0.0200, d1.dn_loss_bbox: 0.0344, d1.dn_loss_iou: 0.2050, d2.dn_loss_cls: 0.0163, d2.dn_loss_bbox: 0.0337, d2.dn_loss_iou: 0.2017, d3.dn_loss_cls: 0.0161, d3.dn_loss_bbox: 0.0336, d3.dn_loss_iou: 0.2017, d4.dn_loss_cls: 0.0173, d4.dn_loss_bbox: 0.0336, d4.dn_loss_iou: 0.2018, loss_rpn_cls: 0.0251, loss_rpn_bbox: 0.1318, loss_cls0: 2.2891, acc0: 92.2025, loss_bbox0: 3.3335, loss_cls1: 1.7091, loss_bbox1: 3.6701, loss_centerness1: 7.1175, loss_cls_aux0: 0.0296, loss_bbox_aux0: 0.0161, loss_iou_aux0: 0.0923, d0.loss_cls_aux0: 0.0297, d0.loss_bbox_aux0: 0.0403, d0.loss_iou_aux0: 0.2331, d1.loss_cls_aux0: 0.0308, d1.loss_bbox_aux0: 0.0202, d1.loss_iou_aux0: 0.1141, d2.loss_cls_aux0: 0.0301, d2.loss_bbox_aux0: 0.0167, d2.loss_iou_aux0: 0.0938, d3.loss_cls_aux0: 0.0292, d3.loss_bbox_aux0: 0.0159, d3.loss_iou_aux0: 0.0895, d4.loss_cls_aux0: 0.0293, d4.loss_bbox_aux0: 0.0160, d4.loss_iou_aux0: 0.0907, loss_cls_aux1: 0.0213, loss_bbox_aux1: 0.0367, loss_iou_aux1: 0.2129, d0.loss_cls_aux1: 0.0241, d0.loss_bbox_aux1: 0.0463, d0.loss_iou_aux1: 0.2646, d1.loss_cls_aux1: 0.0229, d1.loss_bbox_aux1: 0.0379, d1.loss_iou_aux1: 0.2189, d2.loss_cls_aux1: 0.0224, d2.loss_bbox_aux1: 0.0367, d2.loss_iou_aux1: 0.2132, d3.loss_cls_aux1: 0.0211, d3.loss_bbox_aux1: 0.0366, d3.loss_iou_aux1: 0.2124, d4.loss_cls_aux1: 0.0210, d4.loss_bbox_aux1: 0.0366, d4.loss_iou_aux1: 0.2127, loss: 26.2823, grad_norm: 209.4860
2024-03-18 20:36:59,629 - mmdet - INFO - Epoch [7][450/463]	lr: 1.000e-05, eta: 2:58:12, time: 2.693, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1375, enc_loss_bbox: 0.0746, enc_loss_iou: 0.3718, loss_cls: 0.0962, loss_bbox: 0.0704, loss_iou: 0.3501, d0.loss_cls: 0.1739, d0.loss_bbox: 0.0704, d0.loss_iou: 0.3515, d1.loss_cls: 0.1015, d1.loss_bbox: 0.0709, d1.loss_iou: 0.3538, d2.loss_cls: 0.0938, d2.loss_bbox: 0.0700, d2.loss_iou: 0.3500, d3.loss_cls: 0.0958, d3.loss_bbox: 0.0702, d3.loss_iou: 0.3498, d4.loss_cls: 0.0959, d4.loss_bbox: 0.0703, d4.loss_iou: 0.3497, dn_loss_cls: 0.0099, dn_loss_bbox: 0.0362, dn_loss_iou: 0.2055, d0.dn_loss_cls: 0.0330, d0.dn_loss_bbox: 0.0524, d0.dn_loss_iou: 0.2854, d1.dn_loss_cls: 0.0113, d1.dn_loss_bbox: 0.0370, d1.dn_loss_iou: 0.2090, d2.dn_loss_cls: 0.0095, d2.dn_loss_bbox: 0.0362, d2.dn_loss_iou: 0.2055, d3.dn_loss_cls: 0.0094, d3.dn_loss_bbox: 0.0362, d3.dn_loss_iou: 0.2054, d4.dn_loss_cls: 0.0096, d4.dn_loss_bbox: 0.0362, d4.dn_loss_iou: 0.2055, loss_rpn_cls: 0.0274, loss_rpn_bbox: 0.1585, loss_cls0: 2.2654, acc0: 92.2031, loss_bbox0: 3.5754, loss_cls1: 1.7899, loss_bbox1: 3.8818, loss_centerness1: 7.1371, loss_cls_aux0: 0.0138, loss_bbox_aux0: 0.0178, loss_iou_aux0: 0.0962, d0.loss_cls_aux0: 0.0134, d0.loss_bbox_aux0: 0.0441, d0.loss_iou_aux0: 0.2405, d1.loss_cls_aux0: 0.0131, d1.loss_bbox_aux0: 0.0219, d1.loss_iou_aux0: 0.1168, d2.loss_cls_aux0: 0.0125, d2.loss_bbox_aux0: 0.0187, d2.loss_iou_aux0: 0.0991, d3.loss_cls_aux0: 0.0118, d3.loss_bbox_aux0: 0.0177, d3.loss_iou_aux0: 0.0947, d4.loss_cls_aux0: 0.0129, d4.loss_bbox_aux0: 0.0178, d4.loss_iou_aux0: 0.0953, loss_cls_aux1: 0.0117, loss_bbox_aux1: 0.0407, loss_iou_aux1: 0.2200, d0.loss_cls_aux1: 0.0129, d0.loss_bbox_aux1: 0.0503, d0.loss_iou_aux1: 0.2635, d1.loss_cls_aux1: 0.0121, d1.loss_bbox_aux1: 0.0417, d1.loss_iou_aux1: 0.2245, d2.loss_cls_aux1: 0.0109, d2.loss_bbox_aux1: 0.0406, d2.loss_iou_aux1: 0.2201, d3.loss_cls_aux1: 0.0114, d3.loss_bbox_aux1: 0.0406, d3.loss_iou_aux1: 0.2199, d4.loss_cls_aux1: 0.0115, d4.loss_bbox_aux1: 0.0407, d4.loss_iou_aux1: 0.2199, loss: 26.8879, grad_norm: 158.8133
2024-03-18 20:37:31,890 - mmdet - INFO - Saving checkpoint at 7 epochs
2024-03-18 20:38:57,749 - mmdet - INFO - Evaluating bbox...
2024-03-18 20:39:14,288 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.608
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.885
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.742
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.492
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.583
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.800
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.695
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.727
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.851

2024-03-18 20:39:14,289 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.651 | Thatch   | 0.568 |
+----------+-------+----------+-------+
2024-03-18 20:39:14,431 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 20:39:14,432 - mmdet - INFO - Epoch(val) [7][154]	bbox_mAP: 0.6080, bbox_mAP_50: 0.8850, bbox_mAP_75: 0.7420, bbox_mAP_s: 0.4920, bbox_mAP_m: 0.5830, bbox_mAP_l: 0.8000, bbox_mAP_copypaste: 0.608 0.885 0.742 0.492 0.583 0.800
2024-03-18 20:41:26,838 - mmdet - INFO - Epoch [8][50/463]	lr: 1.000e-05, eta: 2:54:55, time: 2.648, data_time: 0.057, memory: 19333, enc_loss_cls: 0.1550, enc_loss_bbox: 0.0655, enc_loss_iou: 0.3508, loss_cls: 0.1070, loss_bbox: 0.0630, loss_iou: 0.3357, d0.loss_cls: 0.1825, d0.loss_bbox: 0.0642, d0.loss_iou: 0.3439, d1.loss_cls: 0.1171, d1.loss_bbox: 0.0633, d1.loss_iou: 0.3389, d2.loss_cls: 0.1066, d2.loss_bbox: 0.0629, d2.loss_iou: 0.3362, d3.loss_cls: 0.1053, d3.loss_bbox: 0.0630, d3.loss_iou: 0.3362, d4.loss_cls: 0.1071, d4.loss_bbox: 0.0629, d4.loss_iou: 0.3356, dn_loss_cls: 0.0149, dn_loss_bbox: 0.0338, dn_loss_iou: 0.1991, d0.dn_loss_cls: 0.0406, d0.dn_loss_bbox: 0.0487, d0.dn_loss_iou: 0.2785, d1.dn_loss_cls: 0.0166, d1.dn_loss_bbox: 0.0347, d1.dn_loss_iou: 0.2033, d2.dn_loss_cls: 0.0149, d2.dn_loss_bbox: 0.0338, d2.dn_loss_iou: 0.1988, d3.dn_loss_cls: 0.0148, d3.dn_loss_bbox: 0.0338, d3.dn_loss_iou: 0.1988, d4.dn_loss_cls: 0.0149, d4.dn_loss_bbox: 0.0338, d4.dn_loss_iou: 0.1990, loss_rpn_cls: 0.0361, loss_rpn_bbox: 0.1442, loss_cls0: 2.2983, acc0: 92.0453, loss_bbox0: 3.4472, loss_cls1: 1.6857, loss_bbox1: 3.7763, loss_centerness1: 7.1653, loss_cls_aux0: 0.0322, loss_bbox_aux0: 0.0156, loss_iou_aux0: 0.0891, d0.loss_cls_aux0: 0.0297, d0.loss_bbox_aux0: 0.0413, d0.loss_iou_aux0: 0.2365, d1.loss_cls_aux0: 0.0323, d1.loss_bbox_aux0: 0.0196, d1.loss_iou_aux0: 0.1127, d2.loss_cls_aux0: 0.0316, d2.loss_bbox_aux0: 0.0169, d2.loss_iou_aux0: 0.0961, d3.loss_cls_aux0: 0.0308, d3.loss_bbox_aux0: 0.0155, d3.loss_iou_aux0: 0.0881, d4.loss_cls_aux0: 0.0311, d4.loss_bbox_aux0: 0.0155, d4.loss_iou_aux0: 0.0885, loss_cls_aux1: 0.0194, loss_bbox_aux1: 0.0389, loss_iou_aux1: 0.2208, d0.loss_cls_aux1: 0.0212, d0.loss_bbox_aux1: 0.0497, d0.loss_iou_aux1: 0.2750, d1.loss_cls_aux1: 0.0214, d1.loss_bbox_aux1: 0.0405, d1.loss_iou_aux1: 0.2289, d2.loss_cls_aux1: 0.0204, d2.loss_bbox_aux1: 0.0390, d2.loss_iou_aux1: 0.2214, d3.loss_cls_aux1: 0.0198, d3.loss_bbox_aux1: 0.0389, d3.loss_iou_aux1: 0.2206, d4.loss_cls_aux1: 0.0194, d4.loss_bbox_aux1: 0.0389, d4.loss_iou_aux1: 0.2207, loss: 26.6464, grad_norm: 158.9901
2024-03-18 20:43:32,554 - mmdet - INFO - Epoch [8][100/463]	lr: 1.000e-05, eta: 2:52:45, time: 2.514, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1431, enc_loss_bbox: 0.0682, enc_loss_iou: 0.3562, loss_cls: 0.0957, loss_bbox: 0.0650, loss_iou: 0.3460, d0.loss_cls: 0.1745, d0.loss_bbox: 0.0663, d0.loss_iou: 0.3504, d1.loss_cls: 0.1036, d1.loss_bbox: 0.0655, d1.loss_iou: 0.3477, d2.loss_cls: 0.0970, d2.loss_bbox: 0.0648, d2.loss_iou: 0.3452, d3.loss_cls: 0.0923, d3.loss_bbox: 0.0651, d3.loss_iou: 0.3466, d4.loss_cls: 0.0932, d4.loss_bbox: 0.0649, d4.loss_iou: 0.3459, dn_loss_cls: 0.0116, dn_loss_bbox: 0.0342, dn_loss_iou: 0.2010, d0.dn_loss_cls: 0.0383, d0.dn_loss_bbox: 0.0497, d0.dn_loss_iou: 0.2811, d1.dn_loss_cls: 0.0141, d1.dn_loss_bbox: 0.0349, d1.dn_loss_iou: 0.2044, d2.dn_loss_cls: 0.0117, d2.dn_loss_bbox: 0.0342, d2.dn_loss_iou: 0.2008, d3.dn_loss_cls: 0.0109, d3.dn_loss_bbox: 0.0341, d3.dn_loss_iou: 0.2007, d4.dn_loss_cls: 0.0111, d4.dn_loss_bbox: 0.0342, d4.dn_loss_iou: 0.2009, loss_rpn_cls: 0.0350, loss_rpn_bbox: 0.1356, loss_cls0: 2.2125, acc0: 92.3090, loss_bbox0: 3.4604, loss_cls1: 1.6284, loss_bbox1: 3.8033, loss_centerness1: 7.1274, loss_cls_aux0: 0.0232, loss_bbox_aux0: 0.0148, loss_iou_aux0: 0.0823, d0.loss_cls_aux0: 0.0225, d0.loss_bbox_aux0: 0.0412, d0.loss_iou_aux0: 0.2325, d1.loss_cls_aux0: 0.0248, d1.loss_bbox_aux0: 0.0192, d1.loss_iou_aux0: 0.1079, d2.loss_cls_aux0: 0.0236, d2.loss_bbox_aux0: 0.0158, d2.loss_iou_aux0: 0.0883, d3.loss_cls_aux0: 0.0216, d3.loss_bbox_aux0: 0.0147, d3.loss_iou_aux0: 0.0814, d4.loss_cls_aux0: 0.0219, d4.loss_bbox_aux0: 0.0148, d4.loss_iou_aux0: 0.0818, loss_cls_aux1: 0.0145, loss_bbox_aux1: 0.0393, loss_iou_aux1: 0.2185, d0.loss_cls_aux1: 0.0171, d0.loss_bbox_aux1: 0.0494, d0.loss_iou_aux1: 0.2703, d1.loss_cls_aux1: 0.0169, d1.loss_bbox_aux1: 0.0400, d1.loss_iou_aux1: 0.2219, d2.loss_cls_aux1: 0.0162, d2.loss_bbox_aux1: 0.0393, d2.loss_iou_aux1: 0.2186, d3.loss_cls_aux1: 0.0145, d3.loss_bbox_aux1: 0.0393, d3.loss_iou_aux1: 0.2183, d4.loss_cls_aux1: 0.0142, d4.loss_bbox_aux1: 0.0393, d4.loss_iou_aux1: 0.2184, loss: 26.3460, grad_norm: 172.4041
2024-03-18 20:45:43,206 - mmdet - INFO - Epoch [8][150/463]	lr: 1.000e-05, eta: 2:50:42, time: 2.613, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1545, enc_loss_bbox: 0.0760, enc_loss_iou: 0.3789, loss_cls: 0.0993, loss_bbox: 0.0705, loss_iou: 0.3542, d0.loss_cls: 0.1919, d0.loss_bbox: 0.0716, d0.loss_iou: 0.3591, d1.loss_cls: 0.1138, d1.loss_bbox: 0.0727, d1.loss_iou: 0.3578, d2.loss_cls: 0.1018, d2.loss_bbox: 0.0705, d2.loss_iou: 0.3539, d3.loss_cls: 0.0989, d3.loss_bbox: 0.0705, d3.loss_iou: 0.3542, d4.loss_cls: 0.0985, d4.loss_bbox: 0.0705, d4.loss_iou: 0.3542, dn_loss_cls: 0.0094, dn_loss_bbox: 0.0365, dn_loss_iou: 0.2045, d0.dn_loss_cls: 0.0361, d0.dn_loss_bbox: 0.0520, d0.dn_loss_iou: 0.2826, d1.dn_loss_cls: 0.0125, d1.dn_loss_bbox: 0.0372, d1.dn_loss_iou: 0.2081, d2.dn_loss_cls: 0.0096, d2.dn_loss_bbox: 0.0365, d2.dn_loss_iou: 0.2043, d3.dn_loss_cls: 0.0093, d3.dn_loss_bbox: 0.0365, d3.dn_loss_iou: 0.2043, d4.dn_loss_cls: 0.0094, d4.dn_loss_bbox: 0.0365, d4.dn_loss_iou: 0.2045, loss_rpn_cls: 0.0266, loss_rpn_bbox: 0.1499, loss_cls0: 2.1315, acc0: 92.4500, loss_bbox0: 3.3454, loss_cls1: 1.7081, loss_bbox1: 3.8969, loss_centerness1: 7.1443, loss_cls_aux0: 0.0175, loss_bbox_aux0: 0.0177, loss_iou_aux0: 0.0955, d0.loss_cls_aux0: 0.0171, d0.loss_bbox_aux0: 0.0439, d0.loss_iou_aux0: 0.2390, d1.loss_cls_aux0: 0.0171, d1.loss_bbox_aux0: 0.0228, d1.loss_iou_aux0: 0.1237, d2.loss_cls_aux0: 0.0168, d2.loss_bbox_aux0: 0.0185, d2.loss_iou_aux0: 0.0991, d3.loss_cls_aux0: 0.0165, d3.loss_bbox_aux0: 0.0175, d3.loss_iou_aux0: 0.0938, d4.loss_cls_aux0: 0.0173, d4.loss_bbox_aux0: 0.0176, d4.loss_iou_aux0: 0.0945, loss_cls_aux1: 0.0235, loss_bbox_aux1: 0.0412, loss_iou_aux1: 0.2227, d0.loss_cls_aux1: 0.0227, d0.loss_bbox_aux1: 0.0526, d0.loss_iou_aux1: 0.2766, d1.loss_cls_aux1: 0.0229, d1.loss_bbox_aux1: 0.0426, d1.loss_iou_aux1: 0.2297, d2.loss_cls_aux1: 0.0241, d2.loss_bbox_aux1: 0.0413, d2.loss_iou_aux1: 0.2233, d3.loss_cls_aux1: 0.0232, d3.loss_bbox_aux1: 0.0411, d3.loss_iou_aux1: 0.2223, d4.loss_cls_aux1: 0.0230, d4.loss_bbox_aux1: 0.0412, d4.loss_iou_aux1: 0.2225, loss: 26.6881, grad_norm: 136.7929
2024-03-18 20:47:53,945 - mmdet - INFO - Epoch [8][200/463]	lr: 1.000e-05, eta: 2:48:38, time: 2.615, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1528, enc_loss_bbox: 0.0717, enc_loss_iou: 0.3449, loss_cls: 0.1093, loss_bbox: 0.0673, loss_iou: 0.3242, d0.loss_cls: 0.1931, d0.loss_bbox: 0.0673, d0.loss_iou: 0.3282, d1.loss_cls: 0.1131, d1.loss_bbox: 0.0680, d1.loss_iou: 0.3258, d2.loss_cls: 0.1096, d2.loss_bbox: 0.0671, d2.loss_iou: 0.3239, d3.loss_cls: 0.1075, d3.loss_bbox: 0.0672, d3.loss_iou: 0.3239, d4.loss_cls: 0.1088, d4.loss_bbox: 0.0674, d4.loss_iou: 0.3239, dn_loss_cls: 0.0134, dn_loss_bbox: 0.0361, dn_loss_iou: 0.2004, d0.dn_loss_cls: 0.0390, d0.dn_loss_bbox: 0.0511, d0.dn_loss_iou: 0.2771, d1.dn_loss_cls: 0.0152, d1.dn_loss_bbox: 0.0370, d1.dn_loss_iou: 0.2045, d2.dn_loss_cls: 0.0132, d2.dn_loss_bbox: 0.0360, d2.dn_loss_iou: 0.1999, d3.dn_loss_cls: 0.0127, d3.dn_loss_bbox: 0.0361, d3.dn_loss_iou: 0.2000, d4.dn_loss_cls: 0.0131, d4.dn_loss_bbox: 0.0361, d4.dn_loss_iou: 0.2001, loss_rpn_cls: 0.0260, loss_rpn_bbox: 0.1490, loss_cls0: 2.1637, acc0: 92.4038, loss_bbox0: 3.3533, loss_cls1: 1.6932, loss_bbox1: 3.6687, loss_centerness1: 7.1328, loss_cls_aux0: 0.0217, loss_bbox_aux0: 0.0175, loss_iou_aux0: 0.0925, d0.loss_cls_aux0: 0.0239, d0.loss_bbox_aux0: 0.0438, d0.loss_iou_aux0: 0.2353, d1.loss_cls_aux0: 0.0254, d1.loss_bbox_aux0: 0.0224, d1.loss_iou_aux0: 0.1173, d2.loss_cls_aux0: 0.0247, d2.loss_bbox_aux0: 0.0184, d2.loss_iou_aux0: 0.0956, d3.loss_cls_aux0: 0.0227, d3.loss_bbox_aux0: 0.0173, d3.loss_iou_aux0: 0.0899, d4.loss_cls_aux0: 0.0214, d4.loss_bbox_aux0: 0.0174, d4.loss_iou_aux0: 0.0911, loss_cls_aux1: 0.0168, loss_bbox_aux1: 0.0436, loss_iou_aux1: 0.2243, d0.loss_cls_aux1: 0.0187, d0.loss_bbox_aux1: 0.0525, d0.loss_iou_aux1: 0.2675, d1.loss_cls_aux1: 0.0183, d1.loss_bbox_aux1: 0.0446, d1.loss_iou_aux1: 0.2287, d2.loss_cls_aux1: 0.0164, d2.loss_bbox_aux1: 0.0434, d2.loss_iou_aux1: 0.2237, d3.loss_cls_aux1: 0.0158, d3.loss_bbox_aux1: 0.0434, d3.loss_iou_aux1: 0.2239, d4.loss_cls_aux1: 0.0161, d4.loss_bbox_aux1: 0.0435, d4.loss_iou_aux1: 0.2241, loss: 26.2363, grad_norm: 135.3291
2024-03-18 20:50:04,083 - mmdet - INFO - Epoch [8][250/463]	lr: 1.000e-05, eta: 2:46:33, time: 2.603, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1563, enc_loss_bbox: 0.0688, enc_loss_iou: 0.3545, loss_cls: 0.1057, loss_bbox: 0.0629, loss_iou: 0.3302, d0.loss_cls: 0.1837, d0.loss_bbox: 0.0647, d0.loss_iou: 0.3351, d1.loss_cls: 0.1112, d1.loss_bbox: 0.0643, d1.loss_iou: 0.3350, d2.loss_cls: 0.1058, d2.loss_bbox: 0.0634, d2.loss_iou: 0.3314, d3.loss_cls: 0.1068, d3.loss_bbox: 0.0631, d3.loss_iou: 0.3311, d4.loss_cls: 0.1060, d4.loss_bbox: 0.0631, d4.loss_iou: 0.3306, dn_loss_cls: 0.0115, dn_loss_bbox: 0.0352, dn_loss_iou: 0.2006, d0.dn_loss_cls: 0.0370, d0.dn_loss_bbox: 0.0505, d0.dn_loss_iou: 0.2784, d1.dn_loss_cls: 0.0129, d1.dn_loss_bbox: 0.0360, d1.dn_loss_iou: 0.2049, d2.dn_loss_cls: 0.0117, d2.dn_loss_bbox: 0.0352, d2.dn_loss_iou: 0.2007, d3.dn_loss_cls: 0.0115, d3.dn_loss_bbox: 0.0352, d3.dn_loss_iou: 0.2006, d4.dn_loss_cls: 0.0113, d4.dn_loss_bbox: 0.0352, d4.dn_loss_iou: 0.2006, loss_rpn_cls: 0.0331, loss_rpn_bbox: 0.1454, loss_cls0: 2.1862, acc0: 92.3983, loss_bbox0: 3.4291, loss_cls1: 1.6948, loss_bbox1: 3.7058, loss_centerness1: 7.1457, loss_cls_aux0: 0.0202, loss_bbox_aux0: 0.0176, loss_iou_aux0: 0.0960, d0.loss_cls_aux0: 0.0173, d0.loss_bbox_aux0: 0.0428, d0.loss_iou_aux0: 0.2316, d1.loss_cls_aux0: 0.0182, d1.loss_bbox_aux0: 0.0217, d1.loss_iou_aux0: 0.1187, d2.loss_cls_aux0: 0.0205, d2.loss_bbox_aux0: 0.0186, d2.loss_iou_aux0: 0.1010, d3.loss_cls_aux0: 0.0191, d3.loss_bbox_aux0: 0.0175, d3.loss_iou_aux0: 0.0943, d4.loss_cls_aux0: 0.0197, d4.loss_bbox_aux0: 0.0175, d4.loss_iou_aux0: 0.0951, loss_cls_aux1: 0.0231, loss_bbox_aux1: 0.0399, loss_iou_aux1: 0.2120, d0.loss_cls_aux1: 0.0201, d0.loss_bbox_aux1: 0.0508, d0.loss_iou_aux1: 0.2654, d1.loss_cls_aux1: 0.0201, d1.loss_bbox_aux1: 0.0412, d1.loss_iou_aux1: 0.2185, d2.loss_cls_aux1: 0.0224, d2.loss_bbox_aux1: 0.0399, d2.loss_iou_aux1: 0.2121, d3.loss_cls_aux1: 0.0224, d3.loss_bbox_aux1: 0.0398, d3.loss_iou_aux1: 0.2118, d4.loss_cls_aux1: 0.0226, d4.loss_bbox_aux1: 0.0399, d4.loss_iou_aux1: 0.2119, loss: 26.3234, grad_norm: 123.1361
2024-03-18 20:52:17,301 - mmdet - INFO - Epoch [8][300/463]	lr: 1.000e-05, eta: 2:44:32, time: 2.664, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1602, enc_loss_bbox: 0.0614, enc_loss_iou: 0.3492, loss_cls: 0.1046, loss_bbox: 0.0574, loss_iou: 0.3283, d0.loss_cls: 0.1964, d0.loss_bbox: 0.0570, d0.loss_iou: 0.3273, d1.loss_cls: 0.1158, d1.loss_bbox: 0.0575, d1.loss_iou: 0.3288, d2.loss_cls: 0.1062, d2.loss_bbox: 0.0572, d2.loss_iou: 0.3280, d3.loss_cls: 0.1041, d3.loss_bbox: 0.0570, d3.loss_iou: 0.3278, d4.loss_cls: 0.1039, d4.loss_bbox: 0.0576, d4.loss_iou: 0.3283, dn_loss_cls: 0.0186, dn_loss_bbox: 0.0341, dn_loss_iou: 0.2031, d0.dn_loss_cls: 0.0471, d0.dn_loss_bbox: 0.0485, d0.dn_loss_iou: 0.2825, d1.dn_loss_cls: 0.0213, d1.dn_loss_bbox: 0.0349, d1.dn_loss_iou: 0.2073, d2.dn_loss_cls: 0.0185, d2.dn_loss_bbox: 0.0340, d2.dn_loss_iou: 0.2030, d3.dn_loss_cls: 0.0182, d3.dn_loss_bbox: 0.0340, d3.dn_loss_iou: 0.2028, d4.dn_loss_cls: 0.0183, d4.dn_loss_bbox: 0.0340, d4.dn_loss_iou: 0.2028, loss_rpn_cls: 0.0273, loss_rpn_bbox: 0.1576, loss_cls0: 2.1199, acc0: 92.6698, loss_bbox0: 3.2181, loss_cls1: 1.6303, loss_bbox1: 3.6151, loss_centerness1: 7.1379, loss_cls_aux0: 0.0295, loss_bbox_aux0: 0.0168, loss_iou_aux0: 0.0979, d0.loss_cls_aux0: 0.0269, d0.loss_bbox_aux0: 0.0404, d0.loss_iou_aux0: 0.2348, d1.loss_cls_aux0: 0.0284, d1.loss_bbox_aux0: 0.0203, d1.loss_iou_aux0: 0.1185, d2.loss_cls_aux0: 0.0269, d2.loss_bbox_aux0: 0.0176, d2.loss_iou_aux0: 0.1015, d3.loss_cls_aux0: 0.0297, d3.loss_bbox_aux0: 0.0166, d3.loss_iou_aux0: 0.0963, d4.loss_cls_aux0: 0.0290, d4.loss_bbox_aux0: 0.0167, d4.loss_iou_aux0: 0.0970, loss_cls_aux1: 0.0187, loss_bbox_aux1: 0.0368, loss_iou_aux1: 0.2163, d0.loss_cls_aux1: 0.0181, d0.loss_bbox_aux1: 0.0466, d0.loss_iou_aux1: 0.2712, d1.loss_cls_aux1: 0.0183, d1.loss_bbox_aux1: 0.0377, d1.loss_iou_aux1: 0.2220, d2.loss_cls_aux1: 0.0182, d2.loss_bbox_aux1: 0.0368, d2.loss_iou_aux1: 0.2162, d3.loss_cls_aux1: 0.0176, d3.loss_bbox_aux1: 0.0367, d3.loss_iou_aux1: 0.2161, d4.loss_cls_aux1: 0.0182, d4.loss_bbox_aux1: 0.0368, d4.loss_iou_aux1: 0.2162, loss: 25.9267, grad_norm: 142.0031
2024-03-18 20:54:19,355 - mmdet - INFO - Epoch [8][350/463]	lr: 1.000e-05, eta: 2:42:18, time: 2.441, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1408, enc_loss_bbox: 0.0685, enc_loss_iou: 0.3487, loss_cls: 0.0888, loss_bbox: 0.0658, loss_iou: 0.3337, d0.loss_cls: 0.1754, d0.loss_bbox: 0.0657, d0.loss_iou: 0.3354, d1.loss_cls: 0.1000, d1.loss_bbox: 0.0657, d1.loss_iou: 0.3326, d2.loss_cls: 0.0917, d2.loss_bbox: 0.0657, d2.loss_iou: 0.3340, d3.loss_cls: 0.0887, d3.loss_bbox: 0.0657, d3.loss_iou: 0.3334, d4.loss_cls: 0.0890, d4.loss_bbox: 0.0658, d4.loss_iou: 0.3336, dn_loss_cls: 0.0096, dn_loss_bbox: 0.0353, dn_loss_iou: 0.2031, d0.dn_loss_cls: 0.0333, d0.dn_loss_bbox: 0.0496, d0.dn_loss_iou: 0.2769, d1.dn_loss_cls: 0.0117, d1.dn_loss_bbox: 0.0361, d1.dn_loss_iou: 0.2069, d2.dn_loss_cls: 0.0098, d2.dn_loss_bbox: 0.0352, d2.dn_loss_iou: 0.2026, d3.dn_loss_cls: 0.0097, d3.dn_loss_bbox: 0.0352, d3.dn_loss_iou: 0.2025, d4.dn_loss_cls: 0.0097, d4.dn_loss_bbox: 0.0353, d4.dn_loss_iou: 0.2029, loss_rpn_cls: 0.0300, loss_rpn_bbox: 0.1953, loss_cls0: 2.3491, acc0: 91.7644, loss_bbox0: 3.6901, loss_cls1: 1.6431, loss_bbox1: 3.7135, loss_centerness1: 7.1297, loss_cls_aux0: 0.0151, loss_bbox_aux0: 0.0198, loss_iou_aux0: 0.1082, d0.loss_cls_aux0: 0.0158, d0.loss_bbox_aux0: 0.0438, d0.loss_iou_aux0: 0.2456, d1.loss_cls_aux0: 0.0154, d1.loss_bbox_aux0: 0.0237, d1.loss_iou_aux0: 0.1298, d2.loss_cls_aux0: 0.0164, d2.loss_bbox_aux0: 0.0207, d2.loss_iou_aux0: 0.1120, d3.loss_cls_aux0: 0.0154, d3.loss_bbox_aux0: 0.0197, d3.loss_iou_aux0: 0.1069, d4.loss_cls_aux0: 0.0152, d4.loss_bbox_aux0: 0.0198, d4.loss_iou_aux0: 0.1075, loss_cls_aux1: 0.0119, loss_bbox_aux1: 0.0398, loss_iou_aux1: 0.2169, d0.loss_cls_aux1: 0.0138, d0.loss_bbox_aux1: 0.0499, d0.loss_iou_aux1: 0.2673, d1.loss_cls_aux1: 0.0133, d1.loss_bbox_aux1: 0.0408, d1.loss_iou_aux1: 0.2228, d2.loss_cls_aux1: 0.0128, d2.loss_bbox_aux1: 0.0398, d2.loss_iou_aux1: 0.2167, d3.loss_cls_aux1: 0.0121, d3.loss_bbox_aux1: 0.0398, d3.loss_iou_aux1: 0.2166, d4.loss_cls_aux1: 0.0120, d4.loss_bbox_aux1: 0.0398, d4.loss_iou_aux1: 0.2167, loss: 26.6788, grad_norm: 122.5115
2024-03-18 20:56:32,535 - mmdet - INFO - Epoch [8][400/463]	lr: 1.000e-05, eta: 2:40:16, time: 2.664, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1374, enc_loss_bbox: 0.0645, enc_loss_iou: 0.3495, loss_cls: 0.0876, loss_bbox: 0.0629, loss_iou: 0.3367, d0.loss_cls: 0.1779, d0.loss_bbox: 0.0628, d0.loss_iou: 0.3374, d1.loss_cls: 0.0969, d1.loss_bbox: 0.0628, d1.loss_iou: 0.3380, d2.loss_cls: 0.0891, d2.loss_bbox: 0.0626, d2.loss_iou: 0.3364, d3.loss_cls: 0.0880, d3.loss_bbox: 0.0627, d3.loss_iou: 0.3363, d4.loss_cls: 0.0871, d4.loss_bbox: 0.0630, d4.loss_iou: 0.3372, dn_loss_cls: 0.0292, dn_loss_bbox: 0.0339, dn_loss_iou: 0.2034, d0.dn_loss_cls: 0.0493, d0.dn_loss_bbox: 0.0480, d0.dn_loss_iou: 0.2793, d1.dn_loss_cls: 0.0249, d1.dn_loss_bbox: 0.0346, d1.dn_loss_iou: 0.2070, d2.dn_loss_cls: 0.0272, d2.dn_loss_bbox: 0.0339, d2.dn_loss_iou: 0.2036, d3.dn_loss_cls: 0.0287, d3.dn_loss_bbox: 0.0339, d3.dn_loss_iou: 0.2035, d4.dn_loss_cls: 0.0276, d4.dn_loss_bbox: 0.0339, d4.dn_loss_iou: 0.2034, loss_rpn_cls: 0.0235, loss_rpn_bbox: 0.1715, loss_cls0: 2.2799, acc0: 92.0548, loss_bbox0: 3.5404, loss_cls1: 1.6091, loss_bbox1: 3.7580, loss_centerness1: 7.1385, loss_cls_aux0: 0.0282, loss_bbox_aux0: 0.0176, loss_iou_aux0: 0.1009, d0.loss_cls_aux0: 0.0212, d0.loss_bbox_aux0: 0.0427, d0.loss_iou_aux0: 0.2456, d1.loss_cls_aux0: 0.0240, d1.loss_bbox_aux0: 0.0215, d1.loss_iou_aux0: 0.1223, d2.loss_cls_aux0: 0.0253, d2.loss_bbox_aux0: 0.0180, d2.loss_iou_aux0: 0.1018, d3.loss_cls_aux0: 0.0271, d3.loss_bbox_aux0: 0.0174, d3.loss_iou_aux0: 0.0988, d4.loss_cls_aux0: 0.0269, d4.loss_bbox_aux0: 0.0175, d4.loss_iou_aux0: 0.0997, loss_cls_aux1: 0.0140, loss_bbox_aux1: 0.0385, loss_iou_aux1: 0.2184, d0.loss_cls_aux1: 0.0130, d0.loss_bbox_aux1: 0.0479, d0.loss_iou_aux1: 0.2681, d1.loss_cls_aux1: 0.0126, d1.loss_bbox_aux1: 0.0396, d1.loss_iou_aux1: 0.2236, d2.loss_cls_aux1: 0.0127, d2.loss_bbox_aux1: 0.0384, d2.loss_iou_aux1: 0.2177, d3.loss_cls_aux1: 0.0132, d3.loss_bbox_aux1: 0.0385, d3.loss_iou_aux1: 0.2182, d4.loss_cls_aux1: 0.0132, d4.loss_bbox_aux1: 0.0385, d4.loss_iou_aux1: 0.2183, loss: 26.5441, grad_norm: 147.3192
2024-03-18 20:58:47,193 - mmdet - INFO - Epoch [8][450/463]	lr: 1.000e-05, eta: 2:38:16, time: 2.693, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1617, enc_loss_bbox: 0.0621, enc_loss_iou: 0.3471, loss_cls: 0.1090, loss_bbox: 0.0589, loss_iou: 0.3311, d0.loss_cls: 0.1879, d0.loss_bbox: 0.0594, d0.loss_iou: 0.3331, d1.loss_cls: 0.1183, d1.loss_bbox: 0.0594, d1.loss_iou: 0.3315, d2.loss_cls: 0.1104, d2.loss_bbox: 0.0591, d2.loss_iou: 0.3326, d3.loss_cls: 0.1070, d3.loss_bbox: 0.0590, d3.loss_iou: 0.3317, d4.loss_cls: 0.1072, d4.loss_bbox: 0.0589, d4.loss_iou: 0.3314, dn_loss_cls: 0.0186, dn_loss_bbox: 0.0334, dn_loss_iou: 0.2011, d0.dn_loss_cls: 0.0449, d0.dn_loss_bbox: 0.0460, d0.dn_loss_iou: 0.2706, d1.dn_loss_cls: 0.0210, d1.dn_loss_bbox: 0.0339, d1.dn_loss_iou: 0.2038, d2.dn_loss_cls: 0.0183, d2.dn_loss_bbox: 0.0334, d2.dn_loss_iou: 0.2008, d3.dn_loss_cls: 0.0182, d3.dn_loss_bbox: 0.0334, d3.dn_loss_iou: 0.2007, d4.dn_loss_cls: 0.0186, d4.dn_loss_bbox: 0.0334, d4.dn_loss_iou: 0.2009, loss_rpn_cls: 0.0394, loss_rpn_bbox: 0.1448, loss_cls0: 2.2338, acc0: 92.2909, loss_bbox0: 3.2425, loss_cls1: 1.7114, loss_bbox1: 3.6651, loss_centerness1: 7.1462, loss_cls_aux0: 0.0408, loss_bbox_aux0: 0.0162, loss_iou_aux0: 0.0931, d0.loss_cls_aux0: 0.0339, d0.loss_bbox_aux0: 0.0407, d0.loss_iou_aux0: 0.2369, d1.loss_cls_aux0: 0.0368, d1.loss_bbox_aux0: 0.0200, d1.loss_iou_aux0: 0.1168, d2.loss_cls_aux0: 0.0376, d2.loss_bbox_aux0: 0.0171, d2.loss_iou_aux0: 0.0978, d3.loss_cls_aux0: 0.0396, d3.loss_bbox_aux0: 0.0161, d3.loss_iou_aux0: 0.0920, d4.loss_cls_aux0: 0.0391, d4.loss_bbox_aux0: 0.0161, d4.loss_iou_aux0: 0.0924, loss_cls_aux1: 0.0292, loss_bbox_aux1: 0.0379, loss_iou_aux1: 0.2179, d0.loss_cls_aux1: 0.0295, d0.loss_bbox_aux1: 0.0468, d0.loss_iou_aux1: 0.2675, d1.loss_cls_aux1: 0.0295, d1.loss_bbox_aux1: 0.0392, d1.loss_iou_aux1: 0.2245, d2.loss_cls_aux1: 0.0284, d2.loss_bbox_aux1: 0.0379, d2.loss_iou_aux1: 0.2182, d3.loss_cls_aux1: 0.0276, d3.loss_bbox_aux1: 0.0379, d3.loss_iou_aux1: 0.2177, d4.loss_cls_aux1: 0.0285, d4.loss_bbox_aux1: 0.0379, d4.loss_iou_aux1: 0.2178, loss: 26.3279, grad_norm: 139.2133
2024-03-18 20:59:19,365 - mmdet - INFO - Saving checkpoint at 8 epochs
2024-03-18 21:00:46,483 - mmdet - INFO - Evaluating bbox...
2024-03-18 21:01:03,337 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.607
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.883
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.732
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.486
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.577
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.797
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.724
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.727
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.727
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.720
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.839

2024-03-18 21:01:03,337 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.648 | Thatch   | 0.567 |
+----------+-------+----------+-------+
2024-03-18 21:01:03,466 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 21:01:03,466 - mmdet - INFO - Epoch(val) [8][154]	bbox_mAP: 0.6070, bbox_mAP_50: 0.8830, bbox_mAP_75: 0.7320, bbox_mAP_s: 0.4860, bbox_mAP_m: 0.5770, bbox_mAP_l: 0.7970, bbox_mAP_copypaste: 0.607 0.883 0.732 0.486 0.577 0.797
2024-03-18 21:03:15,773 - mmdet - INFO - Epoch [9][50/463]	lr: 1.000e-06, eta: 2:35:07, time: 2.646, data_time: 0.056, memory: 19333, enc_loss_cls: 0.1467, enc_loss_bbox: 0.0664, enc_loss_iou: 0.3376, loss_cls: 0.0924, loss_bbox: 0.0646, loss_iou: 0.3256, d0.loss_cls: 0.1765, d0.loss_bbox: 0.0641, d0.loss_iou: 0.3253, d1.loss_cls: 0.1014, d1.loss_bbox: 0.0637, d1.loss_iou: 0.3241, d2.loss_cls: 0.0917, d2.loss_bbox: 0.0648, d2.loss_iou: 0.3277, d3.loss_cls: 0.0918, d3.loss_bbox: 0.0645, d3.loss_iou: 0.3255, d4.loss_cls: 0.0920, d4.loss_bbox: 0.0647, d4.loss_iou: 0.3257, dn_loss_cls: 0.0187, dn_loss_bbox: 0.0366, dn_loss_iou: 0.2015, d0.dn_loss_cls: 0.0459, d0.dn_loss_bbox: 0.0528, d0.dn_loss_iou: 0.2780, d1.dn_loss_cls: 0.0203, d1.dn_loss_bbox: 0.0378, d1.dn_loss_iou: 0.2068, d2.dn_loss_cls: 0.0195, d2.dn_loss_bbox: 0.0367, d2.dn_loss_iou: 0.2018, d3.dn_loss_cls: 0.0182, d3.dn_loss_bbox: 0.0366, d3.dn_loss_iou: 0.2015, d4.dn_loss_cls: 0.0187, d4.dn_loss_bbox: 0.0366, d4.dn_loss_iou: 0.2015, loss_rpn_cls: 0.0177, loss_rpn_bbox: 0.1361, loss_cls0: 1.9894, acc0: 93.1266, loss_bbox0: 3.2101, loss_cls1: 1.6355, loss_bbox1: 3.5748, loss_centerness1: 7.1106, loss_cls_aux0: 0.0264, loss_bbox_aux0: 0.0160, loss_iou_aux0: 0.0846, d0.loss_cls_aux0: 0.0257, d0.loss_bbox_aux0: 0.0428, d0.loss_iou_aux0: 0.2263, d1.loss_cls_aux0: 0.0281, d1.loss_bbox_aux0: 0.0201, d1.loss_iou_aux0: 0.1053, d2.loss_cls_aux0: 0.0278, d2.loss_bbox_aux0: 0.0165, d2.loss_iou_aux0: 0.0868, d3.loss_cls_aux0: 0.0252, d3.loss_bbox_aux0: 0.0159, d3.loss_iou_aux0: 0.0837, d4.loss_cls_aux0: 0.0262, d4.loss_bbox_aux0: 0.0159, d4.loss_iou_aux0: 0.0840, loss_cls_aux1: 0.0149, loss_bbox_aux1: 0.0399, loss_iou_aux1: 0.2108, d0.loss_cls_aux1: 0.0172, d0.loss_bbox_aux1: 0.0485, d0.loss_iou_aux1: 0.2530, d1.loss_cls_aux1: 0.0168, d1.loss_bbox_aux1: 0.0415, d1.loss_iou_aux1: 0.2188, d2.loss_cls_aux1: 0.0156, d2.loss_bbox_aux1: 0.0399, d2.loss_iou_aux1: 0.2107, d3.loss_cls_aux1: 0.0150, d3.loss_bbox_aux1: 0.0399, d3.loss_iou_aux1: 0.2107, d4.loss_cls_aux1: 0.0148, d4.loss_bbox_aux1: 0.0399, d4.loss_iou_aux1: 0.2107, loss: 25.4960, grad_norm: 116.2614
2024-03-18 21:05:21,736 - mmdet - INFO - Epoch [9][100/463]	lr: 1.000e-06, eta: 2:32:58, time: 2.519, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1329, enc_loss_bbox: 0.0653, enc_loss_iou: 0.3389, loss_cls: 0.0838, loss_bbox: 0.0629, loss_iou: 0.3284, d0.loss_cls: 0.1626, d0.loss_bbox: 0.0632, d0.loss_iou: 0.3302, d1.loss_cls: 0.0915, d1.loss_bbox: 0.0638, d1.loss_iou: 0.3308, d2.loss_cls: 0.0856, d2.loss_bbox: 0.0630, d2.loss_iou: 0.3285, d3.loss_cls: 0.0832, d3.loss_bbox: 0.0629, d3.loss_iou: 0.3284, d4.loss_cls: 0.0831, d4.loss_bbox: 0.0630, d4.loss_iou: 0.3287, dn_loss_cls: 0.0102, dn_loss_bbox: 0.0349, dn_loss_iou: 0.2003, d0.dn_loss_cls: 0.0359, d0.dn_loss_bbox: 0.0495, d0.dn_loss_iou: 0.2750, d1.dn_loss_cls: 0.0135, d1.dn_loss_bbox: 0.0357, d1.dn_loss_iou: 0.2042, d2.dn_loss_cls: 0.0108, d2.dn_loss_bbox: 0.0349, d2.dn_loss_iou: 0.2005, d3.dn_loss_cls: 0.0103, d3.dn_loss_bbox: 0.0349, d3.dn_loss_iou: 0.2003, d4.dn_loss_cls: 0.0103, d4.dn_loss_bbox: 0.0349, d4.dn_loss_iou: 0.2003, loss_rpn_cls: 0.0243, loss_rpn_bbox: 0.1636, loss_cls0: 2.0861, acc0: 92.7132, loss_bbox0: 3.3321, loss_cls1: 1.5595, loss_bbox1: 3.6755, loss_centerness1: 7.1100, loss_cls_aux0: 0.0166, loss_bbox_aux0: 0.0175, loss_iou_aux0: 0.0918, d0.loss_cls_aux0: 0.0155, d0.loss_bbox_aux0: 0.0416, d0.loss_iou_aux0: 0.2301, d1.loss_cls_aux0: 0.0175, d1.loss_bbox_aux0: 0.0212, d1.loss_iou_aux0: 0.1123, d2.loss_cls_aux0: 0.0154, d2.loss_bbox_aux0: 0.0184, d2.loss_iou_aux0: 0.0968, d3.loss_cls_aux0: 0.0168, d3.loss_bbox_aux0: 0.0176, d3.loss_iou_aux0: 0.0918, d4.loss_cls_aux0: 0.0164, d4.loss_bbox_aux0: 0.0175, d4.loss_iou_aux0: 0.0917, loss_cls_aux1: 0.0131, loss_bbox_aux1: 0.0392, loss_iou_aux1: 0.2150, d0.loss_cls_aux1: 0.0147, d0.loss_bbox_aux1: 0.0481, d0.loss_iou_aux1: 0.2563, d1.loss_cls_aux1: 0.0135, d1.loss_bbox_aux1: 0.0404, d1.loss_iou_aux1: 0.2218, d2.loss_cls_aux1: 0.0128, d2.loss_bbox_aux1: 0.0392, d2.loss_iou_aux1: 0.2152, d3.loss_cls_aux1: 0.0133, d3.loss_bbox_aux1: 0.0392, d3.loss_iou_aux1: 0.2151, d4.loss_cls_aux1: 0.0131, d4.loss_bbox_aux1: 0.0392, d4.loss_iou_aux1: 0.2150, loss: 25.6388, grad_norm: 100.7189
2024-03-18 21:07:32,485 - mmdet - INFO - Epoch [9][150/463]	lr: 1.000e-06, eta: 2:30:54, time: 2.615, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1439, enc_loss_bbox: 0.0593, enc_loss_iou: 0.3363, loss_cls: 0.0895, loss_bbox: 0.0584, loss_iou: 0.3278, d0.loss_cls: 0.1812, d0.loss_bbox: 0.0570, d0.loss_iou: 0.3243, d1.loss_cls: 0.1020, d1.loss_bbox: 0.0581, d1.loss_iou: 0.3260, d2.loss_cls: 0.0907, d2.loss_bbox: 0.0586, d2.loss_iou: 0.3282, d3.loss_cls: 0.0897, d3.loss_bbox: 0.0584, d3.loss_iou: 0.3275, d4.loss_cls: 0.0893, d4.loss_bbox: 0.0586, d4.loss_iou: 0.3277, dn_loss_cls: 0.0088, dn_loss_bbox: 0.0336, dn_loss_iou: 0.1980, d0.dn_loss_cls: 0.0304, d0.dn_loss_bbox: 0.0461, d0.dn_loss_iou: 0.2661, d1.dn_loss_cls: 0.0108, d1.dn_loss_bbox: 0.0342, d1.dn_loss_iou: 0.2013, d2.dn_loss_cls: 0.0089, d2.dn_loss_bbox: 0.0336, d2.dn_loss_iou: 0.1981, d3.dn_loss_cls: 0.0084, d3.dn_loss_bbox: 0.0336, d3.dn_loss_iou: 0.1981, d4.dn_loss_cls: 0.0087, d4.dn_loss_bbox: 0.0336, d4.dn_loss_iou: 0.1980, loss_rpn_cls: 0.0240, loss_rpn_bbox: 0.1654, loss_cls0: 1.9518, acc0: 93.1894, loss_bbox0: 3.2330, loss_cls1: 1.5786, loss_bbox1: 3.5749, loss_centerness1: 7.1532, loss_cls_aux0: 0.0108, loss_bbox_aux0: 0.0171, loss_iou_aux0: 0.0957, d0.loss_cls_aux0: 0.0115, d0.loss_bbox_aux0: 0.0396, d0.loss_iou_aux0: 0.2277, d1.loss_cls_aux0: 0.0106, d1.loss_bbox_aux0: 0.0205, d1.loss_iou_aux0: 0.1147, d2.loss_cls_aux0: 0.0107, d2.loss_bbox_aux0: 0.0177, d2.loss_iou_aux0: 0.1001, d3.loss_cls_aux0: 0.0107, d3.loss_bbox_aux0: 0.0171, d3.loss_iou_aux0: 0.0957, d4.loss_cls_aux0: 0.0106, d4.loss_bbox_aux0: 0.0171, d4.loss_iou_aux0: 0.0957, loss_cls_aux1: 0.0106, loss_bbox_aux1: 0.0362, loss_iou_aux1: 0.2111, d0.loss_cls_aux1: 0.0114, d0.loss_bbox_aux1: 0.0431, d0.loss_iou_aux1: 0.2517, d1.loss_cls_aux1: 0.0116, d1.loss_bbox_aux1: 0.0372, d1.loss_iou_aux1: 0.2177, d2.loss_cls_aux1: 0.0107, d2.loss_bbox_aux1: 0.0363, d2.loss_iou_aux1: 0.2117, d3.loss_cls_aux1: 0.0102, d3.loss_bbox_aux1: 0.0362, d3.loss_iou_aux1: 0.2111, d4.loss_cls_aux1: 0.0104, d4.loss_bbox_aux1: 0.0362, d4.loss_iou_aux1: 0.2111, loss: 25.2520, grad_norm: 111.9528
2024-03-18 21:09:43,330 - mmdet - INFO - Epoch [9][200/463]	lr: 1.000e-06, eta: 2:28:50, time: 2.617, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1228, enc_loss_bbox: 0.0646, enc_loss_iou: 0.3516, loss_cls: 0.0777, loss_bbox: 0.0624, loss_iou: 0.3409, d0.loss_cls: 0.1535, d0.loss_bbox: 0.0628, d0.loss_iou: 0.3426, d1.loss_cls: 0.0872, d1.loss_bbox: 0.0629, d1.loss_iou: 0.3412, d2.loss_cls: 0.0787, d2.loss_bbox: 0.0627, d2.loss_iou: 0.3422, d3.loss_cls: 0.0768, d3.loss_bbox: 0.0624, d3.loss_iou: 0.3412, d4.loss_cls: 0.0776, d4.loss_bbox: 0.0625, d4.loss_iou: 0.3411, dn_loss_cls: 0.0090, dn_loss_bbox: 0.0333, dn_loss_iou: 0.1991, d0.dn_loss_cls: 0.0326, d0.dn_loss_bbox: 0.0480, d0.dn_loss_iou: 0.2771, d1.dn_loss_cls: 0.0118, d1.dn_loss_bbox: 0.0342, d1.dn_loss_iou: 0.2033, d2.dn_loss_cls: 0.0094, d2.dn_loss_bbox: 0.0334, d2.dn_loss_iou: 0.1990, d3.dn_loss_cls: 0.0089, d3.dn_loss_bbox: 0.0333, d3.dn_loss_iou: 0.1991, d4.dn_loss_cls: 0.0089, d4.dn_loss_bbox: 0.0333, d4.dn_loss_iou: 0.1992, loss_rpn_cls: 0.0270, loss_rpn_bbox: 0.1733, loss_cls0: 2.1769, acc0: 92.3380, loss_bbox0: 3.5448, loss_cls1: 1.5799, loss_bbox1: 3.7731, loss_centerness1: 7.1227, loss_cls_aux0: 0.0205, loss_bbox_aux0: 0.0165, loss_iou_aux0: 0.0922, d0.loss_cls_aux0: 0.0204, d0.loss_bbox_aux0: 0.0400, d0.loss_iou_aux0: 0.2279, d1.loss_cls_aux0: 0.0223, d1.loss_bbox_aux0: 0.0200, d1.loss_iou_aux0: 0.1123, d2.loss_cls_aux0: 0.0214, d2.loss_bbox_aux0: 0.0173, d2.loss_iou_aux0: 0.0970, d3.loss_cls_aux0: 0.0195, d3.loss_bbox_aux0: 0.0165, d3.loss_iou_aux0: 0.0921, d4.loss_cls_aux0: 0.0200, d4.loss_bbox_aux0: 0.0165, d4.loss_iou_aux0: 0.0921, loss_cls_aux1: 0.0172, loss_bbox_aux1: 0.0385, loss_iou_aux1: 0.2172, d0.loss_cls_aux1: 0.0192, d0.loss_bbox_aux1: 0.0465, d0.loss_iou_aux1: 0.2586, d1.loss_cls_aux1: 0.0183, d1.loss_bbox_aux1: 0.0397, d1.loss_iou_aux1: 0.2233, d2.loss_cls_aux1: 0.0177, d2.loss_bbox_aux1: 0.0387, d2.loss_iou_aux1: 0.2180, d3.loss_cls_aux1: 0.0165, d3.loss_bbox_aux1: 0.0385, d3.loss_iou_aux1: 0.2172, d4.loss_cls_aux1: 0.0167, d4.loss_bbox_aux1: 0.0385, d4.loss_iou_aux1: 0.2172, loss: 26.1485, grad_norm: 114.7643
2024-03-18 21:11:53,653 - mmdet - INFO - Epoch [9][250/463]	lr: 1.000e-06, eta: 2:26:45, time: 2.606, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1320, enc_loss_bbox: 0.0604, enc_loss_iou: 0.3234, loss_cls: 0.0825, loss_bbox: 0.0602, loss_iou: 0.3167, d0.loss_cls: 0.1613, d0.loss_bbox: 0.0599, d0.loss_iou: 0.3173, d1.loss_cls: 0.0901, d1.loss_bbox: 0.0602, d1.loss_iou: 0.3158, d2.loss_cls: 0.0833, d2.loss_bbox: 0.0603, d2.loss_iou: 0.3170, d3.loss_cls: 0.0822, d3.loss_bbox: 0.0602, d3.loss_iou: 0.3166, d4.loss_cls: 0.0824, d4.loss_bbox: 0.0602, d4.loss_iou: 0.3167, dn_loss_cls: 0.0066, dn_loss_bbox: 0.0343, dn_loss_iou: 0.1925, d0.dn_loss_cls: 0.0274, d0.dn_loss_bbox: 0.0486, d0.dn_loss_iou: 0.2643, d1.dn_loss_cls: 0.0082, d1.dn_loss_bbox: 0.0351, d1.dn_loss_iou: 0.1964, d2.dn_loss_cls: 0.0067, d2.dn_loss_bbox: 0.0343, d2.dn_loss_iou: 0.1927, d3.dn_loss_cls: 0.0066, d3.dn_loss_bbox: 0.0343, d3.dn_loss_iou: 0.1925, d4.dn_loss_cls: 0.0068, d4.dn_loss_bbox: 0.0343, d4.dn_loss_iou: 0.1925, loss_rpn_cls: 0.0392, loss_rpn_bbox: 0.1556, loss_cls0: 1.9972, acc0: 92.9651, loss_bbox0: 3.2641, loss_cls1: 1.5594, loss_bbox1: 3.4985, loss_centerness1: 7.1053, loss_cls_aux0: 0.0118, loss_bbox_aux0: 0.0156, loss_iou_aux0: 0.0874, d0.loss_cls_aux0: 0.0114, d0.loss_bbox_aux0: 0.0409, d0.loss_iou_aux0: 0.2252, d1.loss_cls_aux0: 0.0131, d1.loss_bbox_aux0: 0.0191, d1.loss_iou_aux0: 0.1069, d2.loss_cls_aux0: 0.0115, d2.loss_bbox_aux0: 0.0164, d2.loss_iou_aux0: 0.0919, d3.loss_cls_aux0: 0.0118, d3.loss_bbox_aux0: 0.0156, d3.loss_iou_aux0: 0.0874, d4.loss_cls_aux0: 0.0120, d4.loss_bbox_aux0: 0.0156, d4.loss_iou_aux0: 0.0873, loss_cls_aux1: 0.0117, loss_bbox_aux1: 0.0358, loss_iou_aux1: 0.2009, d0.loss_cls_aux1: 0.0122, d0.loss_bbox_aux1: 0.0430, d0.loss_iou_aux1: 0.2386, d1.loss_cls_aux1: 0.0125, d1.loss_bbox_aux1: 0.0368, d1.loss_iou_aux1: 0.2054, d2.loss_cls_aux1: 0.0115, d2.loss_bbox_aux1: 0.0360, d2.loss_iou_aux1: 0.2019, d3.loss_cls_aux1: 0.0117, d3.loss_bbox_aux1: 0.0358, d3.loss_iou_aux1: 0.2009, d4.loss_cls_aux1: 0.0118, d4.loss_bbox_aux1: 0.0358, d4.loss_iou_aux1: 0.2009, loss: 24.9166, grad_norm: 115.7433
2024-03-18 21:14:06,736 - mmdet - INFO - Epoch [9][300/463]	lr: 1.000e-06, eta: 2:24:42, time: 2.662, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1477, enc_loss_bbox: 0.0637, enc_loss_iou: 0.3378, loss_cls: 0.0983, loss_bbox: 0.0627, loss_iou: 0.3303, d0.loss_cls: 0.1730, d0.loss_bbox: 0.0617, d0.loss_iou: 0.3294, d1.loss_cls: 0.1059, d1.loss_bbox: 0.0621, d1.loss_iou: 0.3274, d2.loss_cls: 0.0988, d2.loss_bbox: 0.0623, d2.loss_iou: 0.3312, d3.loss_cls: 0.0984, d3.loss_bbox: 0.0620, d3.loss_iou: 0.3294, d4.loss_cls: 0.0982, d4.loss_bbox: 0.0627, d4.loss_iou: 0.3301, dn_loss_cls: 0.0098, dn_loss_bbox: 0.0345, dn_loss_iou: 0.1963, d0.dn_loss_cls: 0.0332, d0.dn_loss_bbox: 0.0479, d0.dn_loss_iou: 0.2665, d1.dn_loss_cls: 0.0113, d1.dn_loss_bbox: 0.0351, d1.dn_loss_iou: 0.1989, d2.dn_loss_cls: 0.0098, d2.dn_loss_bbox: 0.0345, d2.dn_loss_iou: 0.1961, d3.dn_loss_cls: 0.0097, d3.dn_loss_bbox: 0.0345, d3.dn_loss_iou: 0.1960, d4.dn_loss_cls: 0.0096, d4.dn_loss_bbox: 0.0345, d4.dn_loss_iou: 0.1961, loss_rpn_cls: 0.0361, loss_rpn_bbox: 0.1396, loss_cls0: 2.0244, acc0: 93.1946, loss_bbox0: 3.2408, loss_cls1: 1.6250, loss_bbox1: 3.6298, loss_centerness1: 7.1495, loss_cls_aux0: 0.0193, loss_bbox_aux0: 0.0141, loss_iou_aux0: 0.0748, d0.loss_cls_aux0: 0.0164, d0.loss_bbox_aux0: 0.0400, d0.loss_iou_aux0: 0.2168, d1.loss_cls_aux0: 0.0191, d1.loss_bbox_aux0: 0.0176, d1.loss_iou_aux0: 0.0931, d2.loss_cls_aux0: 0.0192, d2.loss_bbox_aux0: 0.0150, d2.loss_iou_aux0: 0.0796, d3.loss_cls_aux0: 0.0189, d3.loss_bbox_aux0: 0.0141, d3.loss_iou_aux0: 0.0747, d4.loss_cls_aux0: 0.0187, d4.loss_bbox_aux0: 0.0141, d4.loss_iou_aux0: 0.0746, loss_cls_aux1: 0.0183, loss_bbox_aux1: 0.0388, loss_iou_aux1: 0.2150, d0.loss_cls_aux1: 0.0173, d0.loss_bbox_aux1: 0.0454, d0.loss_iou_aux1: 0.2501, d1.loss_cls_aux1: 0.0170, d1.loss_bbox_aux1: 0.0397, d1.loss_iou_aux1: 0.2197, d2.loss_cls_aux1: 0.0172, d2.loss_bbox_aux1: 0.0388, d2.loss_iou_aux1: 0.2154, d3.loss_cls_aux1: 0.0178, d3.loss_bbox_aux1: 0.0388, d3.loss_iou_aux1: 0.2150, d4.loss_cls_aux1: 0.0177, d4.loss_bbox_aux1: 0.0388, d4.loss_iou_aux1: 0.2150, loss: 25.4880, grad_norm: 126.7591
2024-03-18 21:16:08,908 - mmdet - INFO - Epoch [9][350/463]	lr: 1.000e-06, eta: 2:22:30, time: 2.443, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1316, enc_loss_bbox: 0.0683, enc_loss_iou: 0.3397, loss_cls: 0.0814, loss_bbox: 0.0682, loss_iou: 0.3332, d0.loss_cls: 0.1638, d0.loss_bbox: 0.0669, d0.loss_iou: 0.3325, d1.loss_cls: 0.0918, d1.loss_bbox: 0.0673, d1.loss_iou: 0.3306, d2.loss_cls: 0.0816, d2.loss_bbox: 0.0681, d2.loss_iou: 0.3338, d3.loss_cls: 0.0807, d3.loss_bbox: 0.0682, d3.loss_iou: 0.3333, d4.loss_cls: 0.0815, d4.loss_bbox: 0.0682, d4.loss_iou: 0.3332, dn_loss_cls: 0.0062, dn_loss_bbox: 0.0338, dn_loss_iou: 0.1956, d0.dn_loss_cls: 0.0298, d0.dn_loss_bbox: 0.0476, d0.dn_loss_iou: 0.2663, d1.dn_loss_cls: 0.0091, d1.dn_loss_bbox: 0.0343, d1.dn_loss_iou: 0.1982, d2.dn_loss_cls: 0.0069, d2.dn_loss_bbox: 0.0338, d2.dn_loss_iou: 0.1953, d3.dn_loss_cls: 0.0063, d3.dn_loss_bbox: 0.0338, d3.dn_loss_iou: 0.1952, d4.dn_loss_cls: 0.0063, d4.dn_loss_bbox: 0.0338, d4.dn_loss_iou: 0.1954, loss_rpn_cls: 0.0228, loss_rpn_bbox: 0.1343, loss_cls0: 1.9609, acc0: 93.0801, loss_bbox0: 3.2364, loss_cls1: 1.5920, loss_bbox1: 3.6810, loss_centerness1: 7.1299, loss_cls_aux0: 0.0167, loss_bbox_aux0: 0.0145, loss_iou_aux0: 0.0750, d0.loss_cls_aux0: 0.0145, d0.loss_bbox_aux0: 0.0400, d0.loss_iou_aux0: 0.2162, d1.loss_cls_aux0: 0.0154, d1.loss_bbox_aux0: 0.0179, d1.loss_iou_aux0: 0.0936, d2.loss_cls_aux0: 0.0150, d2.loss_bbox_aux0: 0.0152, d2.loss_iou_aux0: 0.0790, d3.loss_cls_aux0: 0.0146, d3.loss_bbox_aux0: 0.0145, d3.loss_iou_aux0: 0.0749, d4.loss_cls_aux0: 0.0159, d4.loss_bbox_aux0: 0.0145, d4.loss_iou_aux0: 0.0749, loss_cls_aux1: 0.0141, loss_bbox_aux1: 0.0397, loss_iou_aux1: 0.2124, d0.loss_cls_aux1: 0.0136, d0.loss_bbox_aux1: 0.0472, d0.loss_iou_aux1: 0.2466, d1.loss_cls_aux1: 0.0129, d1.loss_bbox_aux1: 0.0408, d1.loss_iou_aux1: 0.2166, d2.loss_cls_aux1: 0.0107, d2.loss_bbox_aux1: 0.0398, d2.loss_iou_aux1: 0.2128, d3.loss_cls_aux1: 0.0108, d3.loss_bbox_aux1: 0.0397, d3.loss_iou_aux1: 0.2124, d4.loss_cls_aux1: 0.0128, d4.loss_bbox_aux1: 0.0397, d4.loss_iou_aux1: 0.2124, loss: 25.2662, grad_norm: 118.2361
2024-03-18 21:18:21,774 - mmdet - INFO - Epoch [9][400/463]	lr: 1.000e-06, eta: 2:20:27, time: 2.657, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1565, enc_loss_bbox: 0.0576, enc_loss_iou: 0.3187, loss_cls: 0.0972, loss_bbox: 0.0571, loss_iou: 0.3110, d0.loss_cls: 0.1900, d0.loss_bbox: 0.0574, d0.loss_iou: 0.3124, d1.loss_cls: 0.1078, d1.loss_bbox: 0.0571, d1.loss_iou: 0.3116, d2.loss_cls: 0.0999, d2.loss_bbox: 0.0574, d2.loss_iou: 0.3108, d3.loss_cls: 0.0974, d3.loss_bbox: 0.0574, d3.loss_iou: 0.3111, d4.loss_cls: 0.0968, d4.loss_bbox: 0.0571, d4.loss_iou: 0.3110, dn_loss_cls: 0.0131, dn_loss_bbox: 0.0322, dn_loss_iou: 0.1934, d0.dn_loss_cls: 0.0381, d0.dn_loss_bbox: 0.0444, d0.dn_loss_iou: 0.2607, d1.dn_loss_cls: 0.0158, d1.dn_loss_bbox: 0.0329, d1.dn_loss_iou: 0.1969, d2.dn_loss_cls: 0.0137, d2.dn_loss_bbox: 0.0321, d2.dn_loss_iou: 0.1933, d3.dn_loss_cls: 0.0128, d3.dn_loss_bbox: 0.0322, d3.dn_loss_iou: 0.1933, d4.dn_loss_cls: 0.0130, d4.dn_loss_bbox: 0.0322, d4.dn_loss_iou: 0.1932, loss_rpn_cls: 0.0278, loss_rpn_bbox: 0.1587, loss_cls0: 2.0920, acc0: 92.9176, loss_bbox0: 3.2855, loss_cls1: 1.5626, loss_bbox1: 3.4711, loss_centerness1: 7.1088, loss_cls_aux0: 0.0278, loss_bbox_aux0: 0.0138, loss_iou_aux0: 0.0759, d0.loss_cls_aux0: 0.0287, d0.loss_bbox_aux0: 0.0379, d0.loss_iou_aux0: 0.2169, d1.loss_cls_aux0: 0.0338, d1.loss_bbox_aux0: 0.0169, d1.loss_iou_aux0: 0.0938, d2.loss_cls_aux0: 0.0302, d2.loss_bbox_aux0: 0.0145, d2.loss_iou_aux0: 0.0804, d3.loss_cls_aux0: 0.0279, d3.loss_bbox_aux0: 0.0138, d3.loss_iou_aux0: 0.0758, d4.loss_cls_aux0: 0.0268, d4.loss_bbox_aux0: 0.0138, d4.loss_iou_aux0: 0.0758, loss_cls_aux1: 0.0227, loss_bbox_aux1: 0.0358, loss_iou_aux1: 0.2050, d0.loss_cls_aux1: 0.0228, d0.loss_bbox_aux1: 0.0431, d0.loss_iou_aux1: 0.2438, d1.loss_cls_aux1: 0.0257, d1.loss_bbox_aux1: 0.0369, d1.loss_iou_aux1: 0.2111, d2.loss_cls_aux1: 0.0232, d2.loss_bbox_aux1: 0.0358, d2.loss_iou_aux1: 0.2051, d3.loss_cls_aux1: 0.0225, d3.loss_bbox_aux1: 0.0358, d3.loss_iou_aux1: 0.2050, d4.loss_cls_aux1: 0.0222, d4.loss_bbox_aux1: 0.0358, d4.loss_iou_aux1: 0.2050, loss: 25.2244, grad_norm: 122.6028
2024-03-18 21:20:36,265 - mmdet - INFO - Epoch [9][450/463]	lr: 1.000e-06, eta: 2:18:25, time: 2.690, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1512, enc_loss_bbox: 0.0651, enc_loss_iou: 0.3513, loss_cls: 0.0997, loss_bbox: 0.0665, loss_iou: 0.3462, d0.loss_cls: 0.1914, d0.loss_bbox: 0.0635, d0.loss_iou: 0.3419, d1.loss_cls: 0.1083, d1.loss_bbox: 0.0642, d1.loss_iou: 0.3423, d2.loss_cls: 0.1055, d2.loss_bbox: 0.0668, d2.loss_iou: 0.3464, d3.loss_cls: 0.1003, d3.loss_bbox: 0.0628, d3.loss_iou: 0.3398, d4.loss_cls: 0.0999, d4.loss_bbox: 0.0628, d4.loss_iou: 0.3404, dn_loss_cls: 0.0092, dn_loss_bbox: 0.0335, dn_loss_iou: 0.1982, d0.dn_loss_cls: 0.0332, d0.dn_loss_bbox: 0.0481, d0.dn_loss_iou: 0.2733, d1.dn_loss_cls: 0.0114, d1.dn_loss_bbox: 0.0342, d1.dn_loss_iou: 0.2016, d2.dn_loss_cls: 0.0095, d2.dn_loss_bbox: 0.0335, d2.dn_loss_iou: 0.1984, d3.dn_loss_cls: 0.0091, d3.dn_loss_bbox: 0.0335, d3.dn_loss_iou: 0.1982, d4.dn_loss_cls: 0.0094, d4.dn_loss_bbox: 0.0335, d4.dn_loss_iou: 0.1982, loss_rpn_cls: 0.0221, loss_rpn_bbox: 0.1246, loss_cls0: 1.9740, acc0: 93.1410, loss_bbox0: 3.2255, loss_cls1: 1.6802, loss_bbox1: 3.7470, loss_centerness1: 7.1347, loss_cls_aux0: 0.0139, loss_bbox_aux0: 0.0138, loss_iou_aux0: 0.0784, d0.loss_cls_aux0: 0.0137, d0.loss_bbox_aux0: 0.0378, d0.loss_iou_aux0: 0.2191, d1.loss_cls_aux0: 0.0143, d1.loss_bbox_aux0: 0.0173, d1.loss_iou_aux0: 0.0995, d2.loss_cls_aux0: 0.0152, d2.loss_bbox_aux0: 0.0145, d2.loss_iou_aux0: 0.0827, d3.loss_cls_aux0: 0.0142, d3.loss_bbox_aux0: 0.0138, d3.loss_iou_aux0: 0.0782, d4.loss_cls_aux0: 0.0140, d4.loss_bbox_aux0: 0.0138, d4.loss_iou_aux0: 0.0783, loss_cls_aux1: 0.0174, loss_bbox_aux1: 0.0377, loss_iou_aux1: 0.2166, d0.loss_cls_aux1: 0.0200, d0.loss_bbox_aux1: 0.0446, d0.loss_iou_aux1: 0.2527, d1.loss_cls_aux1: 0.0184, d1.loss_bbox_aux1: 0.0388, d1.loss_iou_aux1: 0.2223, d2.loss_cls_aux1: 0.0192, d2.loss_bbox_aux1: 0.0377, d2.loss_iou_aux1: 0.2170, d3.loss_cls_aux1: 0.0174, d3.loss_bbox_aux1: 0.0377, d3.loss_iou_aux1: 0.2167, d4.loss_cls_aux1: 0.0172, d4.loss_bbox_aux1: 0.0377, d4.loss_iou_aux1: 0.2166, loss: 25.7089, grad_norm: 134.4791
2024-03-18 21:21:08,544 - mmdet - INFO - Saving checkpoint at 9 epochs
2024-03-18 21:22:37,524 - mmdet - INFO - Evaluating bbox...
2024-03-18 21:22:54,067 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.615
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.890
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.743
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.497
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.586
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.812
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.735
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.735
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.727
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.853

2024-03-18 21:22:54,067 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.655 | Thatch   | 0.578 |
+----------+-------+----------+-------+
2024-03-18 21:22:54,780 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_004/best_bbox_mAP_epoch_6.pth was removed
2024-03-18 21:23:00,815 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_9.pth.
2024-03-18 21:23:00,815 - mmdet - INFO - Best bbox_mAP is 0.6150 at 9 epoch.
2024-03-18 21:23:00,816 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 21:23:00,816 - mmdet - INFO - Epoch(val) [9][154]	bbox_mAP: 0.6150, bbox_mAP_50: 0.8900, bbox_mAP_75: 0.7430, bbox_mAP_s: 0.4970, bbox_mAP_m: 0.5860, bbox_mAP_l: 0.8120, bbox_mAP_copypaste: 0.615 0.890 0.743 0.497 0.586 0.812
2024-03-18 21:25:13,034 - mmdet - INFO - Epoch [10][50/463]	lr: 1.000e-06, eta: 2:15:23, time: 2.644, data_time: 0.056, memory: 19333, enc_loss_cls: 0.1347, enc_loss_bbox: 0.0592, enc_loss_iou: 0.3177, loss_cls: 0.0891, loss_bbox: 0.0573, loss_iou: 0.3088, d0.loss_cls: 0.1610, d0.loss_bbox: 0.0572, d0.loss_iou: 0.3104, d1.loss_cls: 0.0948, d1.loss_bbox: 0.0570, d1.loss_iou: 0.3081, d2.loss_cls: 0.0887, d2.loss_bbox: 0.0575, d2.loss_iou: 0.3095, d3.loss_cls: 0.0893, d3.loss_bbox: 0.0577, d3.loss_iou: 0.3097, d4.loss_cls: 0.0886, d4.loss_bbox: 0.0573, d4.loss_iou: 0.3088, dn_loss_cls: 0.0101, dn_loss_bbox: 0.0336, dn_loss_iou: 0.1952, d0.dn_loss_cls: 0.0352, d0.dn_loss_bbox: 0.0472, d0.dn_loss_iou: 0.2646, d1.dn_loss_cls: 0.0129, d1.dn_loss_bbox: 0.0342, d1.dn_loss_iou: 0.1983, d2.dn_loss_cls: 0.0102, d2.dn_loss_bbox: 0.0336, d2.dn_loss_iou: 0.1954, d3.dn_loss_cls: 0.0099, d3.dn_loss_bbox: 0.0336, d3.dn_loss_iou: 0.1952, d4.dn_loss_cls: 0.0101, d4.dn_loss_bbox: 0.0336, d4.dn_loss_iou: 0.1953, loss_rpn_cls: 0.0198, loss_rpn_bbox: 0.1403, loss_cls0: 2.0349, acc0: 92.9095, loss_bbox0: 3.1665, loss_cls1: 1.5213, loss_bbox1: 3.4239, loss_centerness1: 7.1087, loss_cls_aux0: 0.0229, loss_bbox_aux0: 0.0148, loss_iou_aux0: 0.0825, d0.loss_cls_aux0: 0.0197, d0.loss_bbox_aux0: 0.0384, d0.loss_iou_aux0: 0.2127, d1.loss_cls_aux0: 0.0228, d1.loss_bbox_aux0: 0.0178, d1.loss_iou_aux0: 0.0994, d2.loss_cls_aux0: 0.0207, d2.loss_bbox_aux0: 0.0155, d2.loss_iou_aux0: 0.0865, d3.loss_cls_aux0: 0.0214, d3.loss_bbox_aux0: 0.0148, d3.loss_iou_aux0: 0.0824, d4.loss_cls_aux0: 0.0217, d4.loss_bbox_aux0: 0.0148, d4.loss_iou_aux0: 0.0824, loss_cls_aux1: 0.0141, loss_bbox_aux1: 0.0359, loss_iou_aux1: 0.2014, d0.loss_cls_aux1: 0.0160, d0.loss_bbox_aux1: 0.0425, d0.loss_iou_aux1: 0.2340, d1.loss_cls_aux1: 0.0149, d1.loss_bbox_aux1: 0.0368, d1.loss_iou_aux1: 0.2054, d2.loss_cls_aux1: 0.0144, d2.loss_bbox_aux1: 0.0360, d2.loss_iou_aux1: 0.2016, d3.loss_cls_aux1: 0.0138, d3.loss_bbox_aux1: 0.0359, d3.loss_iou_aux1: 0.2014, d4.loss_cls_aux1: 0.0138, d4.loss_bbox_aux1: 0.0359, d4.loss_iou_aux1: 0.2014, loss: 24.7329, grad_norm: 109.2965
2024-03-18 21:27:18,609 - mmdet - INFO - Epoch [10][100/463]	lr: 1.000e-06, eta: 2:13:14, time: 2.511, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1390, enc_loss_bbox: 0.0651, enc_loss_iou: 0.3377, loss_cls: 0.0850, loss_bbox: 0.0650, loss_iou: 0.3355, d0.loss_cls: 0.1638, d0.loss_bbox: 0.0652, d0.loss_iou: 0.3355, d1.loss_cls: 0.0943, d1.loss_bbox: 0.0646, d1.loss_iou: 0.3342, d2.loss_cls: 0.0879, d2.loss_bbox: 0.0649, d2.loss_iou: 0.3351, d3.loss_cls: 0.0862, d3.loss_bbox: 0.0648, d3.loss_iou: 0.3353, d4.loss_cls: 0.0849, d4.loss_bbox: 0.0648, d4.loss_iou: 0.3355, dn_loss_cls: 0.0126, dn_loss_bbox: 0.0356, dn_loss_iou: 0.1964, d0.dn_loss_cls: 0.0405, d0.dn_loss_bbox: 0.0510, d0.dn_loss_iou: 0.2713, d1.dn_loss_cls: 0.0163, d1.dn_loss_bbox: 0.0363, d1.dn_loss_iou: 0.1993, d2.dn_loss_cls: 0.0136, d2.dn_loss_bbox: 0.0356, d2.dn_loss_iou: 0.1964, d3.dn_loss_cls: 0.0129, d3.dn_loss_bbox: 0.0356, d3.dn_loss_iou: 0.1964, d4.dn_loss_cls: 0.0128, d4.dn_loss_bbox: 0.0356, d4.dn_loss_iou: 0.1964, loss_rpn_cls: 0.0290, loss_rpn_bbox: 0.1697, loss_cls0: 2.1998, acc0: 92.4394, loss_bbox0: 3.4574, loss_cls1: 1.6162, loss_bbox1: 3.6983, loss_centerness1: 7.1259, loss_cls_aux0: 0.0247, loss_bbox_aux0: 0.0174, loss_iou_aux0: 0.0897, d0.loss_cls_aux0: 0.0245, d0.loss_bbox_aux0: 0.0427, d0.loss_iou_aux0: 0.2251, d1.loss_cls_aux0: 0.0283, d1.loss_bbox_aux0: 0.0206, d1.loss_iou_aux0: 0.1070, d2.loss_cls_aux0: 0.0267, d2.loss_bbox_aux0: 0.0181, d2.loss_iou_aux0: 0.0933, d3.loss_cls_aux0: 0.0249, d3.loss_bbox_aux0: 0.0174, d3.loss_iou_aux0: 0.0896, d4.loss_cls_aux0: 0.0238, d4.loss_bbox_aux0: 0.0174, d4.loss_iou_aux0: 0.0896, loss_cls_aux1: 0.0201, loss_bbox_aux1: 0.0394, loss_iou_aux1: 0.2116, d0.loss_cls_aux1: 0.0215, d0.loss_bbox_aux1: 0.0470, d0.loss_iou_aux1: 0.2494, d1.loss_cls_aux1: 0.0200, d1.loss_bbox_aux1: 0.0405, d1.loss_iou_aux1: 0.2176, d2.loss_cls_aux1: 0.0199, d2.loss_bbox_aux1: 0.0394, d2.loss_iou_aux1: 0.2116, d3.loss_cls_aux1: 0.0198, d3.loss_bbox_aux1: 0.0394, d3.loss_iou_aux1: 0.2116, d4.loss_cls_aux1: 0.0199, d4.loss_bbox_aux1: 0.0394, d4.loss_iou_aux1: 0.2116, loss: 26.0958, grad_norm: 98.8510
2024-03-18 21:29:29,399 - mmdet - INFO - Epoch [10][150/463]	lr: 1.000e-06, eta: 2:11:09, time: 2.616, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1462, enc_loss_bbox: 0.0562, enc_loss_iou: 0.3204, loss_cls: 0.0949, loss_bbox: 0.0553, loss_iou: 0.3151, d0.loss_cls: 0.1817, d0.loss_bbox: 0.0542, d0.loss_iou: 0.3107, d1.loss_cls: 0.1044, d1.loss_bbox: 0.0546, d1.loss_iou: 0.3134, d2.loss_cls: 0.0955, d2.loss_bbox: 0.0550, d2.loss_iou: 0.3155, d3.loss_cls: 0.0955, d3.loss_bbox: 0.0551, d3.loss_iou: 0.3140, d4.loss_cls: 0.0945, d4.loss_bbox: 0.0554, d4.loss_iou: 0.3150, dn_loss_cls: 0.0099, dn_loss_bbox: 0.0329, dn_loss_iou: 0.2019, d0.dn_loss_cls: 0.0333, d0.dn_loss_bbox: 0.0459, d0.dn_loss_iou: 0.2720, d1.dn_loss_cls: 0.0126, d1.dn_loss_bbox: 0.0335, d1.dn_loss_iou: 0.2050, d2.dn_loss_cls: 0.0103, d2.dn_loss_bbox: 0.0329, d2.dn_loss_iou: 0.2012, d3.dn_loss_cls: 0.0100, d3.dn_loss_bbox: 0.0329, d3.dn_loss_iou: 0.2011, d4.dn_loss_cls: 0.0099, d4.dn_loss_bbox: 0.0329, d4.dn_loss_iou: 0.2011, loss_rpn_cls: 0.0161, loss_rpn_bbox: 0.1409, loss_cls0: 1.9822, acc0: 92.9075, loss_bbox0: 3.1354, loss_cls1: 1.5423, loss_bbox1: 3.4186, loss_centerness1: 7.1248, loss_cls_aux0: 0.0176, loss_bbox_aux0: 0.0128, loss_iou_aux0: 0.0749, d0.loss_cls_aux0: 0.0170, d0.loss_bbox_aux0: 0.0364, d0.loss_iou_aux0: 0.2128, d1.loss_cls_aux0: 0.0187, d1.loss_bbox_aux0: 0.0159, d1.loss_iou_aux0: 0.0924, d2.loss_cls_aux0: 0.0177, d2.loss_bbox_aux0: 0.0137, d2.loss_iou_aux0: 0.0795, d3.loss_cls_aux0: 0.0168, d3.loss_bbox_aux0: 0.0128, d3.loss_iou_aux0: 0.0748, d4.loss_cls_aux0: 0.0171, d4.loss_bbox_aux0: 0.0128, d4.loss_iou_aux0: 0.0748, loss_cls_aux1: 0.0161, loss_bbox_aux1: 0.0348, loss_iou_aux1: 0.2031, d0.loss_cls_aux1: 0.0166, d0.loss_bbox_aux1: 0.0399, d0.loss_iou_aux1: 0.2310, d1.loss_cls_aux1: 0.0155, d1.loss_bbox_aux1: 0.0354, d1.loss_iou_aux1: 0.2069, d2.loss_cls_aux1: 0.0150, d2.loss_bbox_aux1: 0.0347, d2.loss_iou_aux1: 0.2028, d3.loss_cls_aux1: 0.0153, d3.loss_bbox_aux1: 0.0348, d3.loss_iou_aux1: 0.2031, d4.loss_cls_aux1: 0.0155, d4.loss_bbox_aux1: 0.0348, d4.loss_iou_aux1: 0.2031, loss: 24.7188, grad_norm: 113.9698
2024-03-18 21:31:40,289 - mmdet - INFO - Epoch [10][200/463]	lr: 1.000e-06, eta: 2:09:05, time: 2.618, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1489, enc_loss_bbox: 0.0610, enc_loss_iou: 0.3145, loss_cls: 0.0865, loss_bbox: 0.0612, loss_iou: 0.3137, d0.loss_cls: 0.1701, d0.loss_bbox: 0.0608, d0.loss_iou: 0.3124, d1.loss_cls: 0.0948, d1.loss_bbox: 0.0619, d1.loss_iou: 0.3151, d2.loss_cls: 0.0877, d2.loss_bbox: 0.0613, d2.loss_iou: 0.3133, d3.loss_cls: 0.0875, d3.loss_bbox: 0.0611, d3.loss_iou: 0.3132, d4.loss_cls: 0.0871, d4.loss_bbox: 0.0610, d4.loss_iou: 0.3134, dn_loss_cls: 0.0077, dn_loss_bbox: 0.0337, dn_loss_iou: 0.1899, d0.dn_loss_cls: 0.0285, d0.dn_loss_bbox: 0.0471, d0.dn_loss_iou: 0.2589, d1.dn_loss_cls: 0.0094, d1.dn_loss_bbox: 0.0344, d1.dn_loss_iou: 0.1932, d2.dn_loss_cls: 0.0084, d2.dn_loss_bbox: 0.0337, d2.dn_loss_iou: 0.1900, d3.dn_loss_cls: 0.0079, d3.dn_loss_bbox: 0.0337, d3.dn_loss_iou: 0.1899, d4.dn_loss_cls: 0.0076, d4.dn_loss_bbox: 0.0337, d4.dn_loss_iou: 0.1899, loss_rpn_cls: 0.0267, loss_rpn_bbox: 0.1518, loss_cls0: 1.9392, acc0: 93.2581, loss_bbox0: 3.2212, loss_cls1: 1.5382, loss_bbox1: 3.4571, loss_centerness1: 7.1095, loss_cls_aux0: 0.0128, loss_bbox_aux0: 0.0135, loss_iou_aux0: 0.0737, d0.loss_cls_aux0: 0.0126, d0.loss_bbox_aux0: 0.0386, d0.loss_iou_aux0: 0.2080, d1.loss_cls_aux0: 0.0130, d1.loss_bbox_aux0: 0.0166, d1.loss_iou_aux0: 0.0906, d2.loss_cls_aux0: 0.0134, d2.loss_bbox_aux0: 0.0143, d2.loss_iou_aux0: 0.0785, d3.loss_cls_aux0: 0.0125, d3.loss_bbox_aux0: 0.0135, d3.loss_iou_aux0: 0.0737, d4.loss_cls_aux0: 0.0127, d4.loss_bbox_aux0: 0.0135, d4.loss_iou_aux0: 0.0736, loss_cls_aux1: 0.0120, loss_bbox_aux1: 0.0362, loss_iou_aux1: 0.1952, d0.loss_cls_aux1: 0.0131, d0.loss_bbox_aux1: 0.0438, d0.loss_iou_aux1: 0.2334, d1.loss_cls_aux1: 0.0133, d1.loss_bbox_aux1: 0.0372, d1.loss_iou_aux1: 0.1997, d2.loss_cls_aux1: 0.0141, d2.loss_bbox_aux1: 0.0363, d2.loss_iou_aux1: 0.1959, d3.loss_cls_aux1: 0.0126, d3.loss_bbox_aux1: 0.0362, d3.loss_iou_aux1: 0.1952, d4.loss_cls_aux1: 0.0123, d4.loss_bbox_aux1: 0.0362, d4.loss_iou_aux1: 0.1952, loss: 24.6307, grad_norm: 110.3492
2024-03-18 21:33:50,324 - mmdet - INFO - Epoch [10][250/463]	lr: 1.000e-06, eta: 2:06:59, time: 2.601, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1328, enc_loss_bbox: 0.0610, enc_loss_iou: 0.3276, loss_cls: 0.0803, loss_bbox: 0.0597, loss_iou: 0.3210, d0.loss_cls: 0.1568, d0.loss_bbox: 0.0603, d0.loss_iou: 0.3218, d1.loss_cls: 0.0851, d1.loss_bbox: 0.0596, d1.loss_iou: 0.3213, d2.loss_cls: 0.0817, d2.loss_bbox: 0.0599, d2.loss_iou: 0.3218, d3.loss_cls: 0.0806, d3.loss_bbox: 0.0597, d3.loss_iou: 0.3209, d4.loss_cls: 0.0805, d4.loss_bbox: 0.0597, d4.loss_iou: 0.3210, dn_loss_cls: 0.0068, dn_loss_bbox: 0.0337, dn_loss_iou: 0.1950, d0.dn_loss_cls: 0.0277, d0.dn_loss_bbox: 0.0479, d0.dn_loss_iou: 0.2680, d1.dn_loss_cls: 0.0084, d1.dn_loss_bbox: 0.0345, d1.dn_loss_iou: 0.1985, d2.dn_loss_cls: 0.0069, d2.dn_loss_bbox: 0.0337, d2.dn_loss_iou: 0.1950, d3.dn_loss_cls: 0.0066, d3.dn_loss_bbox: 0.0337, d3.dn_loss_iou: 0.1950, d4.dn_loss_cls: 0.0068, d4.dn_loss_bbox: 0.0337, d4.dn_loss_iou: 0.1949, loss_rpn_cls: 0.0232, loss_rpn_bbox: 0.1429, loss_cls0: 2.0181, acc0: 92.9203, loss_bbox0: 3.3305, loss_cls1: 1.5144, loss_bbox1: 3.5599, loss_centerness1: 7.1341, loss_cls_aux0: 0.0128, loss_bbox_aux0: 0.0151, loss_iou_aux0: 0.0818, d0.loss_cls_aux0: 0.0134, d0.loss_bbox_aux0: 0.0395, d0.loss_iou_aux0: 0.2176, d1.loss_cls_aux0: 0.0133, d1.loss_bbox_aux0: 0.0183, d1.loss_iou_aux0: 0.0996, d2.loss_cls_aux0: 0.0139, d2.loss_bbox_aux0: 0.0159, d2.loss_iou_aux0: 0.0860, d3.loss_cls_aux0: 0.0128, d3.loss_bbox_aux0: 0.0151, d3.loss_iou_aux0: 0.0817, d4.loss_cls_aux0: 0.0122, d4.loss_bbox_aux0: 0.0151, d4.loss_iou_aux0: 0.0817, loss_cls_aux1: 0.0106, loss_bbox_aux1: 0.0368, loss_iou_aux1: 0.2023, d0.loss_cls_aux1: 0.0120, d0.loss_bbox_aux1: 0.0441, d0.loss_iou_aux1: 0.2388, d1.loss_cls_aux1: 0.0116, d1.loss_bbox_aux1: 0.0379, d1.loss_iou_aux1: 0.2076, d2.loss_cls_aux1: 0.0109, d2.loss_bbox_aux1: 0.0369, d2.loss_iou_aux1: 0.2029, d3.loss_cls_aux1: 0.0105, d3.loss_bbox_aux1: 0.0368, d3.loss_iou_aux1: 0.2023, d4.loss_cls_aux1: 0.0103, d4.loss_bbox_aux1: 0.0368, d4.loss_iou_aux1: 0.2023, loss: 25.0202, grad_norm: 107.8023
2024-03-18 21:36:03,401 - mmdet - INFO - Epoch [10][300/463]	lr: 1.000e-06, eta: 2:04:55, time: 2.662, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1513, enc_loss_bbox: 0.0658, enc_loss_iou: 0.3432, loss_cls: 0.0820, loss_bbox: 0.0675, loss_iou: 0.3448, d0.loss_cls: 0.1710, d0.loss_bbox: 0.0670, d0.loss_iou: 0.3425, d1.loss_cls: 0.0960, d1.loss_bbox: 0.0671, d1.loss_iou: 0.3438, d2.loss_cls: 0.0843, d2.loss_bbox: 0.0677, d2.loss_iou: 0.3445, d3.loss_cls: 0.0823, d3.loss_bbox: 0.0675, d3.loss_iou: 0.3450, d4.loss_cls: 0.0832, d4.loss_bbox: 0.0674, d4.loss_iou: 0.3446, dn_loss_cls: 0.0104, dn_loss_bbox: 0.0332, dn_loss_iou: 0.1984, d0.dn_loss_cls: 0.0347, d0.dn_loss_bbox: 0.0471, d0.dn_loss_iou: 0.2706, d1.dn_loss_cls: 0.0130, d1.dn_loss_bbox: 0.0340, d1.dn_loss_iou: 0.2016, d2.dn_loss_cls: 0.0108, d2.dn_loss_bbox: 0.0332, d2.dn_loss_iou: 0.1981, d3.dn_loss_cls: 0.0102, d3.dn_loss_bbox: 0.0332, d3.dn_loss_iou: 0.1977, d4.dn_loss_cls: 0.0103, d4.dn_loss_bbox: 0.0332, d4.dn_loss_iou: 0.1975, loss_rpn_cls: 0.0342, loss_rpn_bbox: 0.1538, loss_cls0: 1.9536, acc0: 93.3349, loss_bbox0: 3.1654, loss_cls1: 1.6596, loss_bbox1: 3.7190, loss_centerness1: 7.1244, loss_cls_aux0: 0.0232, loss_bbox_aux0: 0.0156, loss_iou_aux0: 0.0817, d0.loss_cls_aux0: 0.0232, d0.loss_bbox_aux0: 0.0404, d0.loss_iou_aux0: 0.2244, d1.loss_cls_aux0: 0.0254, d1.loss_bbox_aux0: 0.0183, d1.loss_iou_aux0: 0.0997, d2.loss_cls_aux0: 0.0241, d2.loss_bbox_aux0: 0.0163, d2.loss_iou_aux0: 0.0860, d3.loss_cls_aux0: 0.0240, d3.loss_bbox_aux0: 0.0156, d3.loss_iou_aux0: 0.0815, d4.loss_cls_aux0: 0.0225, d4.loss_bbox_aux0: 0.0156, d4.loss_iou_aux0: 0.0815, loss_cls_aux1: 0.0150, loss_bbox_aux1: 0.0390, loss_iou_aux1: 0.2115, d0.loss_cls_aux1: 0.0181, d0.loss_bbox_aux1: 0.0476, d0.loss_iou_aux1: 0.2540, d1.loss_cls_aux1: 0.0169, d1.loss_bbox_aux1: 0.0402, d1.loss_iou_aux1: 0.2177, d2.loss_cls_aux1: 0.0153, d2.loss_bbox_aux1: 0.0390, d2.loss_iou_aux1: 0.2117, d3.loss_cls_aux1: 0.0150, d3.loss_bbox_aux1: 0.0390, d3.loss_iou_aux1: 0.2115, d4.loss_cls_aux1: 0.0145, d4.loss_bbox_aux1: 0.0390, d4.loss_iou_aux1: 0.2115, loss: 25.5809, grad_norm: 138.3232
2024-03-18 21:38:05,487 - mmdet - INFO - Epoch [10][350/463]	lr: 1.000e-06, eta: 2:02:45, time: 2.442, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1533, enc_loss_bbox: 0.0600, enc_loss_iou: 0.3258, loss_cls: 0.0940, loss_bbox: 0.0605, loss_iou: 0.3204, d0.loss_cls: 0.1788, d0.loss_bbox: 0.0587, d0.loss_iou: 0.3187, d1.loss_cls: 0.0982, d1.loss_bbox: 0.0609, d1.loss_iou: 0.3227, d2.loss_cls: 0.0945, d2.loss_bbox: 0.0608, d2.loss_iou: 0.3210, d3.loss_cls: 0.0937, d3.loss_bbox: 0.0604, d3.loss_iou: 0.3205, d4.loss_cls: 0.0932, d4.loss_bbox: 0.0605, d4.loss_iou: 0.3200, dn_loss_cls: 0.0086, dn_loss_bbox: 0.0331, dn_loss_iou: 0.1945, d0.dn_loss_cls: 0.0317, d0.dn_loss_bbox: 0.0470, d0.dn_loss_iou: 0.2683, d1.dn_loss_cls: 0.0100, d1.dn_loss_bbox: 0.0340, d1.dn_loss_iou: 0.1986, d2.dn_loss_cls: 0.0088, d2.dn_loss_bbox: 0.0332, d2.dn_loss_iou: 0.1946, d3.dn_loss_cls: 0.0086, d3.dn_loss_bbox: 0.0331, d3.dn_loss_iou: 0.1945, d4.dn_loss_cls: 0.0085, d4.dn_loss_bbox: 0.0331, d4.dn_loss_iou: 0.1945, loss_rpn_cls: 0.0205, loss_rpn_bbox: 0.1229, loss_cls0: 2.0592, acc0: 92.7392, loss_bbox0: 3.2612, loss_cls1: 1.5600, loss_bbox1: 3.5309, loss_centerness1: 7.1071, loss_cls_aux0: 0.0163, loss_bbox_aux0: 0.0122, loss_iou_aux0: 0.0686, d0.loss_cls_aux0: 0.0167, d0.loss_bbox_aux0: 0.0369, d0.loss_iou_aux0: 0.2101, d1.loss_cls_aux0: 0.0175, d1.loss_bbox_aux0: 0.0153, d1.loss_iou_aux0: 0.0867, d2.loss_cls_aux0: 0.0173, d2.loss_bbox_aux0: 0.0129, d2.loss_iou_aux0: 0.0730, d3.loss_cls_aux0: 0.0162, d3.loss_bbox_aux0: 0.0122, d3.loss_iou_aux0: 0.0685, d4.loss_cls_aux0: 0.0155, d4.loss_bbox_aux0: 0.0122, d4.loss_iou_aux0: 0.0685, loss_cls_aux1: 0.0109, loss_bbox_aux1: 0.0367, loss_iou_aux1: 0.2098, d0.loss_cls_aux1: 0.0123, d0.loss_bbox_aux1: 0.0434, d0.loss_iou_aux1: 0.2427, d1.loss_cls_aux1: 0.0112, d1.loss_bbox_aux1: 0.0376, d1.loss_iou_aux1: 0.2147, d2.loss_cls_aux1: 0.0109, d2.loss_bbox_aux1: 0.0368, d2.loss_iou_aux1: 0.2102, d3.loss_cls_aux1: 0.0112, d3.loss_bbox_aux1: 0.0367, d3.loss_iou_aux1: 0.2098, d4.loss_cls_aux1: 0.0107, d4.loss_bbox_aux1: 0.0367, d4.loss_iou_aux1: 0.2098, loss: 25.0417, grad_norm: 115.9983
2024-03-18 21:40:18,055 - mmdet - INFO - Epoch [10][400/463]	lr: 1.000e-06, eta: 2:00:40, time: 2.651, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1408, enc_loss_bbox: 0.0658, enc_loss_iou: 0.3378, loss_cls: 0.0909, loss_bbox: 0.0656, loss_iou: 0.3340, d0.loss_cls: 0.1643, d0.loss_bbox: 0.0652, d0.loss_iou: 0.3340, d1.loss_cls: 0.0999, d1.loss_bbox: 0.0650, d1.loss_iou: 0.3336, d2.loss_cls: 0.0922, d2.loss_bbox: 0.0654, d2.loss_iou: 0.3333, d3.loss_cls: 0.0904, d3.loss_bbox: 0.0654, d3.loss_iou: 0.3340, d4.loss_cls: 0.0916, d4.loss_bbox: 0.0655, d4.loss_iou: 0.3336, dn_loss_cls: 0.0157, dn_loss_bbox: 0.0354, dn_loss_iou: 0.1940, d0.dn_loss_cls: 0.0459, d0.dn_loss_bbox: 0.0507, d0.dn_loss_iou: 0.2688, d1.dn_loss_cls: 0.0201, d1.dn_loss_bbox: 0.0363, d1.dn_loss_iou: 0.1975, d2.dn_loss_cls: 0.0178, d2.dn_loss_bbox: 0.0354, d2.dn_loss_iou: 0.1941, d3.dn_loss_cls: 0.0153, d3.dn_loss_bbox: 0.0354, d3.dn_loss_iou: 0.1940, d4.dn_loss_cls: 0.0154, d4.dn_loss_bbox: 0.0354, d4.dn_loss_iou: 0.1940, loss_rpn_cls: 0.0196, loss_rpn_bbox: 0.1299, loss_cls0: 1.9943, acc0: 93.0284, loss_bbox0: 3.1808, loss_cls1: 1.6007, loss_bbox1: 3.6494, loss_centerness1: 7.1195, loss_cls_aux0: 0.0235, loss_bbox_aux0: 0.0154, loss_iou_aux0: 0.0808, d0.loss_cls_aux0: 0.0232, d0.loss_bbox_aux0: 0.0417, d0.loss_iou_aux0: 0.2196, d1.loss_cls_aux0: 0.0231, d1.loss_bbox_aux0: 0.0189, d1.loss_iou_aux0: 0.0989, d2.loss_cls_aux0: 0.0244, d2.loss_bbox_aux0: 0.0162, d2.loss_iou_aux0: 0.0851, d3.loss_cls_aux0: 0.0226, d3.loss_bbox_aux0: 0.0154, d3.loss_iou_aux0: 0.0808, d4.loss_cls_aux0: 0.0231, d4.loss_bbox_aux0: 0.0154, d4.loss_iou_aux0: 0.0808, loss_cls_aux1: 0.0154, loss_bbox_aux1: 0.0381, loss_iou_aux1: 0.2061, d0.loss_cls_aux1: 0.0180, d0.loss_bbox_aux1: 0.0456, d0.loss_iou_aux1: 0.2416, d1.loss_cls_aux1: 0.0150, d1.loss_bbox_aux1: 0.0393, d1.loss_iou_aux1: 0.2115, d2.loss_cls_aux1: 0.0157, d2.loss_bbox_aux1: 0.0381, d2.loss_iou_aux1: 0.2063, d3.loss_cls_aux1: 0.0147, d3.loss_bbox_aux1: 0.0381, d3.loss_iou_aux1: 0.2060, d4.loss_cls_aux1: 0.0150, d4.loss_bbox_aux1: 0.0381, d4.loss_iou_aux1: 0.2061, loss: 25.3819, grad_norm: 113.4137
2024-03-18 21:42:32,644 - mmdet - INFO - Epoch [10][450/463]	lr: 1.000e-06, eta: 1:58:37, time: 2.692, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1348, enc_loss_bbox: 0.0583, enc_loss_iou: 0.3347, loss_cls: 0.0798, loss_bbox: 0.0583, loss_iou: 0.3317, d0.loss_cls: 0.1578, d0.loss_bbox: 0.0587, d0.loss_iou: 0.3335, d1.loss_cls: 0.0847, d1.loss_bbox: 0.0583, d1.loss_iou: 0.3318, d2.loss_cls: 0.0816, d2.loss_bbox: 0.0583, d2.loss_iou: 0.3315, d3.loss_cls: 0.0815, d3.loss_bbox: 0.0582, d3.loss_iou: 0.3312, d4.loss_cls: 0.0802, d4.loss_bbox: 0.0582, d4.loss_iou: 0.3313, dn_loss_cls: 0.0119, dn_loss_bbox: 0.0311, dn_loss_iou: 0.1949, d0.dn_loss_cls: 0.0338, d0.dn_loss_bbox: 0.0436, d0.dn_loss_iou: 0.2654, d1.dn_loss_cls: 0.0126, d1.dn_loss_bbox: 0.0316, d1.dn_loss_iou: 0.1980, d2.dn_loss_cls: 0.0121, d2.dn_loss_bbox: 0.0311, d2.dn_loss_iou: 0.1949, d3.dn_loss_cls: 0.0118, d3.dn_loss_bbox: 0.0311, d3.dn_loss_iou: 0.1949, d4.dn_loss_cls: 0.0121, d4.dn_loss_bbox: 0.0311, d4.dn_loss_iou: 0.1948, loss_rpn_cls: 0.0335, loss_rpn_bbox: 0.1810, loss_cls0: 2.1335, acc0: 92.6352, loss_bbox0: 3.3815, loss_cls1: 1.5591, loss_bbox1: 3.6160, loss_centerness1: 7.1227, loss_cls_aux0: 0.0221, loss_bbox_aux0: 0.0150, loss_iou_aux0: 0.0877, d0.loss_cls_aux0: 0.0192, d0.loss_bbox_aux0: 0.0374, d0.loss_iou_aux0: 0.2249, d1.loss_cls_aux0: 0.0207, d1.loss_bbox_aux0: 0.0178, d1.loss_iou_aux0: 0.1049, d2.loss_cls_aux0: 0.0220, d2.loss_bbox_aux0: 0.0156, d2.loss_iou_aux0: 0.0918, d3.loss_cls_aux0: 0.0225, d3.loss_bbox_aux0: 0.0150, d3.loss_iou_aux0: 0.0876, d4.loss_cls_aux0: 0.0220, d4.loss_bbox_aux0: 0.0150, d4.loss_iou_aux0: 0.0876, loss_cls_aux1: 0.0207, loss_bbox_aux1: 0.0347, loss_iou_aux1: 0.2064, d0.loss_cls_aux1: 0.0203, d0.loss_bbox_aux1: 0.0416, d0.loss_iou_aux1: 0.2451, d1.loss_cls_aux1: 0.0197, d1.loss_bbox_aux1: 0.0354, d1.loss_iou_aux1: 0.2111, d2.loss_cls_aux1: 0.0213, d2.loss_bbox_aux1: 0.0347, d2.loss_iou_aux1: 0.2069, d3.loss_cls_aux1: 0.0211, d3.loss_bbox_aux1: 0.0347, d3.loss_iou_aux1: 0.2064, d4.loss_cls_aux1: 0.0204, d4.loss_bbox_aux1: 0.0347, d4.loss_iou_aux1: 0.2064, loss: 25.5487, grad_norm: 102.8464
2024-03-18 21:43:04,930 - mmdet - INFO - Saving checkpoint at 10 epochs
2024-03-18 21:44:31,789 - mmdet - INFO - Evaluating bbox...
2024-03-18 21:44:48,468 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.614
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.888
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.746
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.495
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.588
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.811
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.732
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.734
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.734
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.726
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.849

2024-03-18 21:44:48,469 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.655 | Thatch   | 0.576 |
+----------+-------+----------+-------+
2024-03-18 21:44:48,609 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 21:44:48,610 - mmdet - INFO - Epoch(val) [10][154]	bbox_mAP: 0.6140, bbox_mAP_50: 0.8880, bbox_mAP_75: 0.7460, bbox_mAP_s: 0.4950, bbox_mAP_m: 0.5880, bbox_mAP_l: 0.8110, bbox_mAP_copypaste: 0.614 0.888 0.746 0.495 0.588 0.811
2024-03-18 21:47:00,861 - mmdet - INFO - Epoch [11][50/463]	lr: 1.000e-06, eta: 1:55:40, time: 2.645, data_time: 0.058, memory: 19333, enc_loss_cls: 0.1329, enc_loss_bbox: 0.0643, enc_loss_iou: 0.3369, loss_cls: 0.0862, loss_bbox: 0.0628, loss_iou: 0.3314, d0.loss_cls: 0.1644, d0.loss_bbox: 0.0636, d0.loss_iou: 0.3336, d1.loss_cls: 0.0953, d1.loss_bbox: 0.0631, d1.loss_iou: 0.3325, d2.loss_cls: 0.0885, d2.loss_bbox: 0.0630, d2.loss_iou: 0.3319, d3.loss_cls: 0.0855, d3.loss_bbox: 0.0628, d3.loss_iou: 0.3316, d4.loss_cls: 0.0862, d4.loss_bbox: 0.0628, d4.loss_iou: 0.3314, dn_loss_cls: 0.0121, dn_loss_bbox: 0.0337, dn_loss_iou: 0.1938, d0.dn_loss_cls: 0.0368, d0.dn_loss_bbox: 0.0476, d0.dn_loss_iou: 0.2659, d1.dn_loss_cls: 0.0137, d1.dn_loss_bbox: 0.0343, d1.dn_loss_iou: 0.1969, d2.dn_loss_cls: 0.0124, d2.dn_loss_bbox: 0.0337, d2.dn_loss_iou: 0.1939, d3.dn_loss_cls: 0.0122, d3.dn_loss_bbox: 0.0337, d3.dn_loss_iou: 0.1938, d4.dn_loss_cls: 0.0118, d4.dn_loss_bbox: 0.0337, d4.dn_loss_iou: 0.1938, loss_rpn_cls: 0.0488, loss_rpn_bbox: 0.1536, loss_cls0: 2.0647, acc0: 92.7420, loss_bbox0: 3.3100, loss_cls1: 1.6043, loss_bbox1: 3.7025, loss_centerness1: 7.1296, loss_cls_aux0: 0.0203, loss_bbox_aux0: 0.0158, loss_iou_aux0: 0.0887, d0.loss_cls_aux0: 0.0186, d0.loss_bbox_aux0: 0.0396, d0.loss_iou_aux0: 0.2215, d1.loss_cls_aux0: 0.0184, d1.loss_bbox_aux0: 0.0188, d1.loss_iou_aux0: 0.1060, d2.loss_cls_aux0: 0.0195, d2.loss_bbox_aux0: 0.0166, d2.loss_iou_aux0: 0.0934, d3.loss_cls_aux0: 0.0198, d3.loss_bbox_aux0: 0.0158, d3.loss_iou_aux0: 0.0886, d4.loss_cls_aux0: 0.0197, d4.loss_bbox_aux0: 0.0158, d4.loss_iou_aux0: 0.0886, loss_cls_aux1: 0.0146, loss_bbox_aux1: 0.0387, loss_iou_aux1: 0.2152, d0.loss_cls_aux1: 0.0162, d0.loss_bbox_aux1: 0.0465, d0.loss_iou_aux1: 0.2534, d1.loss_cls_aux1: 0.0154, d1.loss_bbox_aux1: 0.0397, d1.loss_iou_aux1: 0.2203, d2.loss_cls_aux1: 0.0154, d2.loss_bbox_aux1: 0.0388, d2.loss_iou_aux1: 0.2154, d3.loss_cls_aux1: 0.0147, d3.loss_bbox_aux1: 0.0387, d3.loss_iou_aux1: 0.2152, d4.loss_cls_aux1: 0.0145, d4.loss_bbox_aux1: 0.0387, d4.loss_iou_aux1: 0.2152, loss: 25.6704, grad_norm: 104.4323
2024-03-18 21:49:06,502 - mmdet - INFO - Epoch [11][100/463]	lr: 1.000e-06, eta: 1:53:32, time: 2.513, data_time: 0.011, memory: 19333, enc_loss_cls: 0.1271, enc_loss_bbox: 0.0657, enc_loss_iou: 0.3454, loss_cls: 0.0816, loss_bbox: 0.0663, loss_iou: 0.3412, d0.loss_cls: 0.1559, d0.loss_bbox: 0.0652, d0.loss_iou: 0.3410, d1.loss_cls: 0.0866, d1.loss_bbox: 0.0661, d1.loss_iou: 0.3410, d2.loss_cls: 0.0826, d2.loss_bbox: 0.0664, d2.loss_iou: 0.3414, d3.loss_cls: 0.0812, d3.loss_bbox: 0.0664, d3.loss_iou: 0.3413, d4.loss_cls: 0.0812, d4.loss_bbox: 0.0664, d4.loss_iou: 0.3412, dn_loss_cls: 0.0099, dn_loss_bbox: 0.0349, dn_loss_iou: 0.2005, d0.dn_loss_cls: 0.0346, d0.dn_loss_bbox: 0.0494, d0.dn_loss_iou: 0.2727, d1.dn_loss_cls: 0.0128, d1.dn_loss_bbox: 0.0357, d1.dn_loss_iou: 0.2034, d2.dn_loss_cls: 0.0104, d2.dn_loss_bbox: 0.0349, d2.dn_loss_iou: 0.1991, d3.dn_loss_cls: 0.0096, d3.dn_loss_bbox: 0.0349, d3.dn_loss_iou: 0.1996, d4.dn_loss_cls: 0.0099, d4.dn_loss_bbox: 0.0349, d4.dn_loss_iou: 0.1991, loss_rpn_cls: 0.0281, loss_rpn_bbox: 0.1525, loss_cls0: 2.0664, acc0: 92.7610, loss_bbox0: 3.2728, loss_cls1: 1.6038, loss_bbox1: 3.7073, loss_centerness1: 7.1402, loss_cls_aux0: 0.0201, loss_bbox_aux0: 0.0162, loss_iou_aux0: 0.0874, d0.loss_cls_aux0: 0.0226, d0.loss_bbox_aux0: 0.0403, d0.loss_iou_aux0: 0.2193, d1.loss_cls_aux0: 0.0228, d1.loss_bbox_aux0: 0.0192, d1.loss_iou_aux0: 0.1037, d2.loss_cls_aux0: 0.0209, d2.loss_bbox_aux0: 0.0168, d2.loss_iou_aux0: 0.0911, d3.loss_cls_aux0: 0.0189, d3.loss_bbox_aux0: 0.0162, d3.loss_iou_aux0: 0.0874, d4.loss_cls_aux0: 0.0194, d4.loss_bbox_aux0: 0.0162, d4.loss_iou_aux0: 0.0873, loss_cls_aux1: 0.0146, loss_bbox_aux1: 0.0383, loss_iou_aux1: 0.2102, d0.loss_cls_aux1: 0.0170, d0.loss_bbox_aux1: 0.0458, d0.loss_iou_aux1: 0.2484, d1.loss_cls_aux1: 0.0163, d1.loss_bbox_aux1: 0.0390, d1.loss_iou_aux1: 0.2145, d2.loss_cls_aux1: 0.0155, d2.loss_bbox_aux1: 0.0382, d2.loss_iou_aux1: 0.2099, d3.loss_cls_aux1: 0.0146, d3.loss_bbox_aux1: 0.0383, d3.loss_iou_aux1: 0.2103, d4.loss_cls_aux1: 0.0143, d4.loss_bbox_aux1: 0.0383, d4.loss_iou_aux1: 0.2102, loss: 25.6683, grad_norm: 118.4916
2024-03-18 21:51:17,062 - mmdet - INFO - Epoch [11][150/463]	lr: 1.000e-06, eta: 1:51:27, time: 2.611, data_time: 0.011, memory: 19333, enc_loss_cls: 0.1316, enc_loss_bbox: 0.0613, enc_loss_iou: 0.3269, loss_cls: 0.0836, loss_bbox: 0.0597, loss_iou: 0.3178, d0.loss_cls: 0.1576, d0.loss_bbox: 0.0601, d0.loss_iou: 0.3197, d1.loss_cls: 0.0915, d1.loss_bbox: 0.0591, d1.loss_iou: 0.3186, d2.loss_cls: 0.0850, d2.loss_bbox: 0.0598, d2.loss_iou: 0.3183, d3.loss_cls: 0.0839, d3.loss_bbox: 0.0597, d3.loss_iou: 0.3174, d4.loss_cls: 0.0839, d4.loss_bbox: 0.0598, d4.loss_iou: 0.3176, dn_loss_cls: 0.0078, dn_loss_bbox: 0.0344, dn_loss_iou: 0.1963, d0.dn_loss_cls: 0.0291, d0.dn_loss_bbox: 0.0485, d0.dn_loss_iou: 0.2681, d1.dn_loss_cls: 0.0102, d1.dn_loss_bbox: 0.0351, d1.dn_loss_iou: 0.1991, d2.dn_loss_cls: 0.0085, d2.dn_loss_bbox: 0.0344, d2.dn_loss_iou: 0.1961, d3.dn_loss_cls: 0.0082, d3.dn_loss_bbox: 0.0344, d3.dn_loss_iou: 0.1960, d4.dn_loss_cls: 0.0081, d4.dn_loss_bbox: 0.0344, d4.dn_loss_iou: 0.1959, loss_rpn_cls: 0.0271, loss_rpn_bbox: 0.1439, loss_cls0: 1.8788, acc0: 93.3913, loss_bbox0: 3.1724, loss_cls1: 1.4848, loss_bbox1: 3.5354, loss_centerness1: 7.1297, loss_cls_aux0: 0.0135, loss_bbox_aux0: 0.0148, loss_iou_aux0: 0.0780, d0.loss_cls_aux0: 0.0140, d0.loss_bbox_aux0: 0.0396, d0.loss_iou_aux0: 0.2151, d1.loss_cls_aux0: 0.0164, d1.loss_bbox_aux0: 0.0178, d1.loss_iou_aux0: 0.0946, d2.loss_cls_aux0: 0.0144, d2.loss_bbox_aux0: 0.0156, d2.loss_iou_aux0: 0.0820, d3.loss_cls_aux0: 0.0135, d3.loss_bbox_aux0: 0.0148, d3.loss_iou_aux0: 0.0779, d4.loss_cls_aux0: 0.0134, d4.loss_bbox_aux0: 0.0148, d4.loss_iou_aux0: 0.0779, loss_cls_aux1: 0.0095, loss_bbox_aux1: 0.0381, loss_iou_aux1: 0.2088, d0.loss_cls_aux1: 0.0107, d0.loss_bbox_aux1: 0.0446, d0.loss_iou_aux1: 0.2424, d1.loss_cls_aux1: 0.0103, d1.loss_bbox_aux1: 0.0393, d1.loss_iou_aux1: 0.2156, d2.loss_cls_aux1: 0.0093, d2.loss_bbox_aux1: 0.0382, d2.loss_iou_aux1: 0.2091, d3.loss_cls_aux1: 0.0094, d3.loss_bbox_aux1: 0.0381, d3.loss_iou_aux1: 0.2087, d4.loss_cls_aux1: 0.0094, d4.loss_bbox_aux1: 0.0381, d4.loss_iou_aux1: 0.2087, loss: 24.7064, grad_norm: 95.9784
2024-03-18 21:53:27,800 - mmdet - INFO - Epoch [11][200/463]	lr: 1.000e-06, eta: 1:49:21, time: 2.615, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1342, enc_loss_bbox: 0.0580, enc_loss_iou: 0.3075, loss_cls: 0.0755, loss_bbox: 0.0573, loss_iou: 0.3053, d0.loss_cls: 0.1694, d0.loss_bbox: 0.0571, d0.loss_iou: 0.3037, d1.loss_cls: 0.0845, d1.loss_bbox: 0.0569, d1.loss_iou: 0.3044, d2.loss_cls: 0.0788, d2.loss_bbox: 0.0575, d2.loss_iou: 0.3054, d3.loss_cls: 0.0766, d3.loss_bbox: 0.0572, d3.loss_iou: 0.3050, d4.loss_cls: 0.0768, d4.loss_bbox: 0.0571, d4.loss_iou: 0.3049, dn_loss_cls: 0.0078, dn_loss_bbox: 0.0327, dn_loss_iou: 0.1887, d0.dn_loss_cls: 0.0292, d0.dn_loss_bbox: 0.0459, d0.dn_loss_iou: 0.2576, d1.dn_loss_cls: 0.0095, d1.dn_loss_bbox: 0.0334, d1.dn_loss_iou: 0.1919, d2.dn_loss_cls: 0.0080, d2.dn_loss_bbox: 0.0327, d2.dn_loss_iou: 0.1887, d3.dn_loss_cls: 0.0079, d3.dn_loss_bbox: 0.0327, d3.dn_loss_iou: 0.1886, d4.dn_loss_cls: 0.0079, d4.dn_loss_bbox: 0.0327, d4.dn_loss_iou: 0.1886, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.1364, loss_cls0: 1.8687, acc0: 93.3745, loss_bbox0: 3.0706, loss_cls1: 1.4567, loss_bbox1: 3.3736, loss_centerness1: 7.1134, loss_cls_aux0: 0.0135, loss_bbox_aux0: 0.0133, loss_iou_aux0: 0.0725, d0.loss_cls_aux0: 0.0140, d0.loss_bbox_aux0: 0.0373, d0.loss_iou_aux0: 0.2072, d1.loss_cls_aux0: 0.0143, d1.loss_bbox_aux0: 0.0163, d1.loss_iou_aux0: 0.0874, d2.loss_cls_aux0: 0.0135, d2.loss_bbox_aux0: 0.0141, d2.loss_iou_aux0: 0.0764, d3.loss_cls_aux0: 0.0133, d3.loss_bbox_aux0: 0.0133, d3.loss_iou_aux0: 0.0723, d4.loss_cls_aux0: 0.0133, d4.loss_bbox_aux0: 0.0133, d4.loss_iou_aux0: 0.0723, loss_cls_aux1: 0.0108, loss_bbox_aux1: 0.0359, loss_iou_aux1: 0.1990, d0.loss_cls_aux1: 0.0126, d0.loss_bbox_aux1: 0.0419, d0.loss_iou_aux1: 0.2285, d1.loss_cls_aux1: 0.0112, d1.loss_bbox_aux1: 0.0367, d1.loss_iou_aux1: 0.2030, d2.loss_cls_aux1: 0.0108, d2.loss_bbox_aux1: 0.0359, d2.loss_iou_aux1: 0.1992, d3.loss_cls_aux1: 0.0107, d3.loss_bbox_aux1: 0.0359, d3.loss_iou_aux1: 0.1989, d4.loss_cls_aux1: 0.0106, d4.loss_bbox_aux1: 0.0359, d4.loss_iou_aux1: 0.1990, loss: 24.0483, grad_norm: 111.7461
2024-03-18 21:55:37,745 - mmdet - INFO - Epoch [11][250/463]	lr: 1.000e-06, eta: 1:47:15, time: 2.599, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1268, enc_loss_bbox: 0.0609, enc_loss_iou: 0.3263, loss_cls: 0.0820, loss_bbox: 0.0607, loss_iou: 0.3238, d0.loss_cls: 0.1567, d0.loss_bbox: 0.0605, d0.loss_iou: 0.3219, d1.loss_cls: 0.0878, d1.loss_bbox: 0.0612, d1.loss_iou: 0.3238, d2.loss_cls: 0.0827, d2.loss_bbox: 0.0606, d2.loss_iou: 0.3240, d3.loss_cls: 0.0821, d3.loss_bbox: 0.0606, d3.loss_iou: 0.3236, d4.loss_cls: 0.0824, d4.loss_bbox: 0.0606, d4.loss_iou: 0.3236, dn_loss_cls: 0.0092, dn_loss_bbox: 0.0344, dn_loss_iou: 0.1928, d0.dn_loss_cls: 0.0298, d0.dn_loss_bbox: 0.0476, d0.dn_loss_iou: 0.2629, d1.dn_loss_cls: 0.0101, d1.dn_loss_bbox: 0.0350, d1.dn_loss_iou: 0.1960, d2.dn_loss_cls: 0.0092, d2.dn_loss_bbox: 0.0344, d2.dn_loss_iou: 0.1929, d3.dn_loss_cls: 0.0093, d3.dn_loss_bbox: 0.0344, d3.dn_loss_iou: 0.1928, d4.dn_loss_cls: 0.0092, d4.dn_loss_bbox: 0.0344, d4.dn_loss_iou: 0.1928, loss_rpn_cls: 0.0277, loss_rpn_bbox: 0.1542, loss_cls0: 2.0869, acc0: 92.8111, loss_bbox0: 3.3208, loss_cls1: 1.5154, loss_bbox1: 3.6110, loss_centerness1: 7.1168, loss_cls_aux0: 0.0180, loss_bbox_aux0: 0.0141, loss_iou_aux0: 0.0774, d0.loss_cls_aux0: 0.0166, d0.loss_bbox_aux0: 0.0392, d0.loss_iou_aux0: 0.2160, d1.loss_cls_aux0: 0.0179, d1.loss_bbox_aux0: 0.0172, d1.loss_iou_aux0: 0.0937, d2.loss_cls_aux0: 0.0167, d2.loss_bbox_aux0: 0.0148, d2.loss_iou_aux0: 0.0813, d3.loss_cls_aux0: 0.0170, d3.loss_bbox_aux0: 0.0141, d3.loss_iou_aux0: 0.0773, d4.loss_cls_aux0: 0.0177, d4.loss_bbox_aux0: 0.0141, d4.loss_iou_aux0: 0.0773, loss_cls_aux1: 0.0161, loss_bbox_aux1: 0.0384, loss_iou_aux1: 0.2131, d0.loss_cls_aux1: 0.0151, d0.loss_bbox_aux1: 0.0452, d0.loss_iou_aux1: 0.2475, d1.loss_cls_aux1: 0.0154, d1.loss_bbox_aux1: 0.0395, d1.loss_iou_aux1: 0.2184, d2.loss_cls_aux1: 0.0148, d2.loss_bbox_aux1: 0.0384, d2.loss_iou_aux1: 0.2134, d3.loss_cls_aux1: 0.0159, d3.loss_bbox_aux1: 0.0384, d3.loss_iou_aux1: 0.2130, d4.loss_cls_aux1: 0.0161, d4.loss_bbox_aux1: 0.0384, d4.loss_iou_aux1: 0.2131, loss: 25.2435, grad_norm: 119.2139
2024-03-18 21:57:50,675 - mmdet - INFO - Epoch [11][300/463]	lr: 1.000e-06, eta: 1:45:11, time: 2.659, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1515, enc_loss_bbox: 0.0672, enc_loss_iou: 0.3528, loss_cls: 0.0971, loss_bbox: 0.0663, loss_iou: 0.3484, d0.loss_cls: 0.1710, d0.loss_bbox: 0.0674, d0.loss_iou: 0.3494, d1.loss_cls: 0.1045, d1.loss_bbox: 0.0689, d1.loss_iou: 0.3509, d2.loss_cls: 0.0965, d2.loss_bbox: 0.0679, d2.loss_iou: 0.3508, d3.loss_cls: 0.0957, d3.loss_bbox: 0.0665, d3.loss_iou: 0.3487, d4.loss_cls: 0.0966, d4.loss_bbox: 0.0663, d4.loss_iou: 0.3482, dn_loss_cls: 0.0119, dn_loss_bbox: 0.0344, dn_loss_iou: 0.2032, d0.dn_loss_cls: 0.0393, d0.dn_loss_bbox: 0.0500, d0.dn_loss_iou: 0.2814, d1.dn_loss_cls: 0.0155, d1.dn_loss_bbox: 0.0352, d1.dn_loss_iou: 0.2059, d2.dn_loss_cls: 0.0129, d2.dn_loss_bbox: 0.0344, d2.dn_loss_iou: 0.2024, d3.dn_loss_cls: 0.0118, d3.dn_loss_bbox: 0.0344, d3.dn_loss_iou: 0.2025, d4.dn_loss_cls: 0.0118, d4.dn_loss_bbox: 0.0344, d4.dn_loss_iou: 0.2026, loss_rpn_cls: 0.0394, loss_rpn_bbox: 0.1478, loss_cls0: 2.0984, acc0: 92.7483, loss_bbox0: 3.3541, loss_cls1: 1.7166, loss_bbox1: 3.8392, loss_centerness1: 7.1523, loss_cls_aux0: 0.0205, loss_bbox_aux0: 0.0147, loss_iou_aux0: 0.0758, d0.loss_cls_aux0: 0.0229, d0.loss_bbox_aux0: 0.0401, d0.loss_iou_aux0: 0.2214, d1.loss_cls_aux0: 0.0254, d1.loss_bbox_aux0: 0.0179, d1.loss_iou_aux0: 0.0938, d2.loss_cls_aux0: 0.0213, d2.loss_bbox_aux0: 0.0154, d2.loss_iou_aux0: 0.0801, d3.loss_cls_aux0: 0.0197, d3.loss_bbox_aux0: 0.0146, d3.loss_iou_aux0: 0.0757, d4.loss_cls_aux0: 0.0191, d4.loss_bbox_aux0: 0.0146, d4.loss_iou_aux0: 0.0757, loss_cls_aux1: 0.0185, loss_bbox_aux1: 0.0388, loss_iou_aux1: 0.2148, d0.loss_cls_aux1: 0.0218, d0.loss_bbox_aux1: 0.0472, d0.loss_iou_aux1: 0.2544, d1.loss_cls_aux1: 0.0193, d1.loss_bbox_aux1: 0.0401, d1.loss_iou_aux1: 0.2202, d2.loss_cls_aux1: 0.0173, d2.loss_bbox_aux1: 0.0389, d2.loss_iou_aux1: 0.2154, d3.loss_cls_aux1: 0.0168, d3.loss_bbox_aux1: 0.0388, d3.loss_iou_aux1: 0.2148, d4.loss_cls_aux1: 0.0175, d4.loss_bbox_aux1: 0.0388, d4.loss_iou_aux1: 0.2148, loss: 26.2615, grad_norm: 130.7786
2024-03-18 21:59:52,953 - mmdet - INFO - Epoch [11][350/463]	lr: 1.000e-06, eta: 1:43:01, time: 2.445, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1309, enc_loss_bbox: 0.0611, enc_loss_iou: 0.3305, loss_cls: 0.0850, loss_bbox: 0.0599, loss_iou: 0.3225, d0.loss_cls: 0.1668, d0.loss_bbox: 0.0598, d0.loss_iou: 0.3227, d1.loss_cls: 0.0941, d1.loss_bbox: 0.0598, d1.loss_iou: 0.3222, d2.loss_cls: 0.0871, d2.loss_bbox: 0.0601, d2.loss_iou: 0.3230, d3.loss_cls: 0.0851, d3.loss_bbox: 0.0599, d3.loss_iou: 0.3226, d4.loss_cls: 0.0845, d4.loss_bbox: 0.0599, d4.loss_iou: 0.3225, dn_loss_cls: 0.0151, dn_loss_bbox: 0.0334, dn_loss_iou: 0.1952, d0.dn_loss_cls: 0.0438, d0.dn_loss_bbox: 0.0472, d0.dn_loss_iou: 0.2678, d1.dn_loss_cls: 0.0204, d1.dn_loss_bbox: 0.0341, d1.dn_loss_iou: 0.1988, d2.dn_loss_cls: 0.0189, d2.dn_loss_bbox: 0.0334, d2.dn_loss_iou: 0.1955, d3.dn_loss_cls: 0.0168, d3.dn_loss_bbox: 0.0334, d3.dn_loss_iou: 0.1952, d4.dn_loss_cls: 0.0152, d4.dn_loss_bbox: 0.0334, d4.dn_loss_iou: 0.1952, loss_rpn_cls: 0.0199, loss_rpn_bbox: 0.1739, loss_cls0: 1.9960, acc0: 93.0988, loss_bbox0: 3.2009, loss_cls1: 1.5345, loss_bbox1: 3.5921, loss_centerness1: 7.1590, loss_cls_aux0: 0.0201, loss_bbox_aux0: 0.0163, loss_iou_aux0: 0.0903, d0.loss_cls_aux0: 0.0185, d0.loss_bbox_aux0: 0.0390, d0.loss_iou_aux0: 0.2208, d1.loss_cls_aux0: 0.0220, d1.loss_bbox_aux0: 0.0194, d1.loss_iou_aux0: 0.1085, d2.loss_cls_aux0: 0.0215, d2.loss_bbox_aux0: 0.0168, d2.loss_iou_aux0: 0.0935, d3.loss_cls_aux0: 0.0199, d3.loss_bbox_aux0: 0.0163, d3.loss_iou_aux0: 0.0902, d4.loss_cls_aux0: 0.0202, d4.loss_bbox_aux0: 0.0163, d4.loss_iou_aux0: 0.0902, loss_cls_aux1: 0.0140, loss_bbox_aux1: 0.0373, loss_iou_aux1: 0.2114, d0.loss_cls_aux1: 0.0161, d0.loss_bbox_aux1: 0.0442, d0.loss_iou_aux1: 0.2473, d1.loss_cls_aux1: 0.0157, d1.loss_bbox_aux1: 0.0383, d1.loss_iou_aux1: 0.2167, d2.loss_cls_aux1: 0.0153, d2.loss_bbox_aux1: 0.0374, d2.loss_iou_aux1: 0.2121, d3.loss_cls_aux1: 0.0144, d3.loss_bbox_aux1: 0.0373, d3.loss_iou_aux1: 0.2114, d4.loss_cls_aux1: 0.0139, d4.loss_bbox_aux1: 0.0373, d4.loss_iou_aux1: 0.2114, loss: 25.2601, grad_norm: 124.5918
2024-03-18 22:02:05,760 - mmdet - INFO - Epoch [11][400/463]	lr: 1.000e-06, eta: 1:40:56, time: 2.656, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1412, enc_loss_bbox: 0.0604, enc_loss_iou: 0.3211, loss_cls: 0.0942, loss_bbox: 0.0597, loss_iou: 0.3154, d0.loss_cls: 0.1641, d0.loss_bbox: 0.0594, d0.loss_iou: 0.3142, d1.loss_cls: 0.0994, d1.loss_bbox: 0.0601, d1.loss_iou: 0.3164, d2.loss_cls: 0.0964, d2.loss_bbox: 0.0596, d2.loss_iou: 0.3144, d3.loss_cls: 0.0926, d3.loss_bbox: 0.0598, d3.loss_iou: 0.3157, d4.loss_cls: 0.0937, d4.loss_bbox: 0.0597, d4.loss_iou: 0.3155, dn_loss_cls: 0.0161, dn_loss_bbox: 0.0339, dn_loss_iou: 0.1917, d0.dn_loss_cls: 0.0356, d0.dn_loss_bbox: 0.0475, d0.dn_loss_iou: 0.2587, d1.dn_loss_cls: 0.0156, d1.dn_loss_bbox: 0.0347, d1.dn_loss_iou: 0.1952, d2.dn_loss_cls: 0.0149, d2.dn_loss_bbox: 0.0340, d2.dn_loss_iou: 0.1917, d3.dn_loss_cls: 0.0150, d3.dn_loss_bbox: 0.0339, d3.dn_loss_iou: 0.1917, d4.dn_loss_cls: 0.0157, d4.dn_loss_bbox: 0.0339, d4.dn_loss_iou: 0.1917, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.1321, loss_cls0: 2.0991, acc0: 92.6305, loss_bbox0: 3.3155, loss_cls1: 1.5897, loss_bbox1: 3.4739, loss_centerness1: 7.1161, loss_cls_aux0: 0.0260, loss_bbox_aux0: 0.0134, loss_iou_aux0: 0.0717, d0.loss_cls_aux0: 0.0200, d0.loss_bbox_aux0: 0.0378, d0.loss_iou_aux0: 0.2090, d1.loss_cls_aux0: 0.0240, d1.loss_bbox_aux0: 0.0164, d1.loss_iou_aux0: 0.0885, d2.loss_cls_aux0: 0.0231, d2.loss_bbox_aux0: 0.0142, d2.loss_iou_aux0: 0.0760, d3.loss_cls_aux0: 0.0253, d3.loss_bbox_aux0: 0.0134, d3.loss_iou_aux0: 0.0716, d4.loss_cls_aux0: 0.0255, d4.loss_bbox_aux0: 0.0134, d4.loss_iou_aux0: 0.0716, loss_cls_aux1: 0.0200, loss_bbox_aux1: 0.0370, loss_iou_aux1: 0.2039, d0.loss_cls_aux1: 0.0188, d0.loss_bbox_aux1: 0.0439, d0.loss_iou_aux1: 0.2353, d1.loss_cls_aux1: 0.0199, d1.loss_bbox_aux1: 0.0380, d1.loss_iou_aux1: 0.2089, d2.loss_cls_aux1: 0.0181, d2.loss_bbox_aux1: 0.0371, d2.loss_iou_aux1: 0.2043, d3.loss_cls_aux1: 0.0190, d3.loss_bbox_aux1: 0.0370, d3.loss_iou_aux1: 0.2039, d4.loss_cls_aux1: 0.0190, d4.loss_bbox_aux1: 0.0370, d4.loss_iou_aux1: 0.2039, loss: 25.1578, grad_norm: 115.1662
2024-03-18 22:04:20,361 - mmdet - INFO - Epoch [11][450/463]	lr: 1.000e-06, eta: 1:38:52, time: 2.692, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1270, enc_loss_bbox: 0.0619, enc_loss_iou: 0.3360, loss_cls: 0.0767, loss_bbox: 0.0608, loss_iou: 0.3281, d0.loss_cls: 0.1561, d0.loss_bbox: 0.0614, d0.loss_iou: 0.3306, d1.loss_cls: 0.0850, d1.loss_bbox: 0.0612, d1.loss_iou: 0.3290, d2.loss_cls: 0.0780, d2.loss_bbox: 0.0608, d2.loss_iou: 0.3283, d3.loss_cls: 0.0773, d3.loss_bbox: 0.0607, d3.loss_iou: 0.3280, d4.loss_cls: 0.0764, d4.loss_bbox: 0.0608, d4.loss_iou: 0.3280, dn_loss_cls: 0.0091, dn_loss_bbox: 0.0328, dn_loss_iou: 0.1985, d0.dn_loss_cls: 0.0327, d0.dn_loss_bbox: 0.0465, d0.dn_loss_iou: 0.2723, d1.dn_loss_cls: 0.0127, d1.dn_loss_bbox: 0.0335, d1.dn_loss_iou: 0.2023, d2.dn_loss_cls: 0.0104, d2.dn_loss_bbox: 0.0328, d2.dn_loss_iou: 0.1987, d3.dn_loss_cls: 0.0091, d3.dn_loss_bbox: 0.0328, d3.dn_loss_iou: 0.1985, d4.dn_loss_cls: 0.0093, d4.dn_loss_bbox: 0.0328, d4.dn_loss_iou: 0.1985, loss_rpn_cls: 0.0176, loss_rpn_bbox: 0.1533, loss_cls0: 2.0525, acc0: 92.8247, loss_bbox0: 3.4782, loss_cls1: 1.4954, loss_bbox1: 3.6061, loss_centerness1: 7.1305, loss_cls_aux0: 0.0141, loss_bbox_aux0: 0.0146, loss_iou_aux0: 0.0818, d0.loss_cls_aux0: 0.0137, d0.loss_bbox_aux0: 0.0383, d0.loss_iou_aux0: 0.2191, d1.loss_cls_aux0: 0.0142, d1.loss_bbox_aux0: 0.0174, d1.loss_iou_aux0: 0.0989, d2.loss_cls_aux0: 0.0129, d2.loss_bbox_aux0: 0.0153, d2.loss_iou_aux0: 0.0861, d3.loss_cls_aux0: 0.0123, d3.loss_bbox_aux0: 0.0146, d3.loss_iou_aux0: 0.0818, d4.loss_cls_aux0: 0.0133, d4.loss_bbox_aux0: 0.0146, d4.loss_iou_aux0: 0.0817, loss_cls_aux1: 0.0102, loss_bbox_aux1: 0.0364, loss_iou_aux1: 0.2071, d0.loss_cls_aux1: 0.0128, d0.loss_bbox_aux1: 0.0436, d0.loss_iou_aux1: 0.2437, d1.loss_cls_aux1: 0.0109, d1.loss_bbox_aux1: 0.0377, d1.loss_iou_aux1: 0.2137, d2.loss_cls_aux1: 0.0102, d2.loss_bbox_aux1: 0.0365, d2.loss_iou_aux1: 0.2074, d3.loss_cls_aux1: 0.0101, d3.loss_bbox_aux1: 0.0364, d3.loss_iou_aux1: 0.2071, d4.loss_cls_aux1: 0.0101, d4.loss_bbox_aux1: 0.0364, d4.loss_iou_aux1: 0.2071, loss: 25.3315, grad_norm: 113.1627
2024-03-18 22:04:52,541 - mmdet - INFO - Saving checkpoint at 11 epochs
2024-03-18 22:06:21,700 - mmdet - INFO - Evaluating bbox...
2024-03-18 22:06:38,076 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.890
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.748
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.589
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.813
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.735
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.737
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.737
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.696
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.728
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.857

2024-03-18 22:06:38,076 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.658 | Thatch   | 0.577 |
+----------+-------+----------+-------+
2024-03-18 22:06:38,776 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_004/best_bbox_mAP_epoch_9.pth was removed
2024-03-18 22:06:44,982 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_11.pth.
2024-03-18 22:06:44,983 - mmdet - INFO - Best bbox_mAP is 0.6160 at 11 epoch.
2024-03-18 22:06:44,983 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 22:06:44,983 - mmdet - INFO - Epoch(val) [11][154]	bbox_mAP: 0.6160, bbox_mAP_50: 0.8900, bbox_mAP_75: 0.7480, bbox_mAP_s: 0.4990, bbox_mAP_m: 0.5890, bbox_mAP_l: 0.8130, bbox_mAP_copypaste: 0.616 0.890 0.748 0.499 0.589 0.813
2024-03-18 22:08:57,026 - mmdet - INFO - Epoch [12][50/463]	lr: 1.000e-06, eta: 1:35:59, time: 2.641, data_time: 0.058, memory: 19333, enc_loss_cls: 0.1502, enc_loss_bbox: 0.0610, enc_loss_iou: 0.3361, loss_cls: 0.0926, loss_bbox: 0.0599, loss_iou: 0.3305, d0.loss_cls: 0.1715, d0.loss_bbox: 0.0593, d0.loss_iou: 0.3274, d1.loss_cls: 0.1013, d1.loss_bbox: 0.0598, d1.loss_iou: 0.3323, d2.loss_cls: 0.0956, d2.loss_bbox: 0.0586, d2.loss_iou: 0.3270, d3.loss_cls: 0.0908, d3.loss_bbox: 0.0597, d3.loss_iou: 0.3306, d4.loss_cls: 0.0928, d4.loss_bbox: 0.0596, d4.loss_iou: 0.3299, dn_loss_cls: 0.0082, dn_loss_bbox: 0.0318, dn_loss_iou: 0.1945, d0.dn_loss_cls: 0.0300, d0.dn_loss_bbox: 0.0449, d0.dn_loss_iou: 0.2657, d1.dn_loss_cls: 0.0103, d1.dn_loss_bbox: 0.0324, d1.dn_loss_iou: 0.1975, d2.dn_loss_cls: 0.0086, d2.dn_loss_bbox: 0.0318, d2.dn_loss_iou: 0.1942, d3.dn_loss_cls: 0.0081, d3.dn_loss_bbox: 0.0318, d3.dn_loss_iou: 0.1943, d4.dn_loss_cls: 0.0081, d4.dn_loss_bbox: 0.0318, d4.dn_loss_iou: 0.1942, loss_rpn_cls: 0.0207, loss_rpn_bbox: 0.1449, loss_cls0: 2.0135, acc0: 93.1092, loss_bbox0: 3.2806, loss_cls1: 1.6052, loss_bbox1: 3.5995, loss_centerness1: 7.1386, loss_cls_aux0: 0.0176, loss_bbox_aux0: 0.0133, loss_iou_aux0: 0.0778, d0.loss_cls_aux0: 0.0173, d0.loss_bbox_aux0: 0.0366, d0.loss_iou_aux0: 0.2143, d1.loss_cls_aux0: 0.0194, d1.loss_bbox_aux0: 0.0165, d1.loss_iou_aux0: 0.0974, d2.loss_cls_aux0: 0.0176, d2.loss_bbox_aux0: 0.0139, d2.loss_iou_aux0: 0.0814, d3.loss_cls_aux0: 0.0162, d3.loss_bbox_aux0: 0.0133, d3.loss_iou_aux0: 0.0777, d4.loss_cls_aux0: 0.0170, d4.loss_bbox_aux0: 0.0133, d4.loss_iou_aux0: 0.0777, loss_cls_aux1: 0.0173, loss_bbox_aux1: 0.0352, loss_iou_aux1: 0.2084, d0.loss_cls_aux1: 0.0190, d0.loss_bbox_aux1: 0.0423, d0.loss_iou_aux1: 0.2471, d1.loss_cls_aux1: 0.0186, d1.loss_bbox_aux1: 0.0362, d1.loss_iou_aux1: 0.2146, d2.loss_cls_aux1: 0.0187, d2.loss_bbox_aux1: 0.0352, d2.loss_iou_aux1: 0.2086, d3.loss_cls_aux1: 0.0179, d3.loss_bbox_aux1: 0.0352, d3.loss_iou_aux1: 0.2084, d4.loss_cls_aux1: 0.0173, d4.loss_bbox_aux1: 0.0352, d4.loss_iou_aux1: 0.2084, loss: 25.3098, grad_norm: 120.0474
2024-03-18 22:11:02,668 - mmdet - INFO - Epoch [12][100/463]	lr: 1.000e-06, eta: 1:33:51, time: 2.513, data_time: 0.012, memory: 19333, enc_loss_cls: 0.1435, enc_loss_bbox: 0.0635, enc_loss_iou: 0.3449, loss_cls: 0.0889, loss_bbox: 0.0632, loss_iou: 0.3398, d0.loss_cls: 0.1609, d0.loss_bbox: 0.0632, d0.loss_iou: 0.3414, d1.loss_cls: 0.0939, d1.loss_bbox: 0.0630, d1.loss_iou: 0.3411, d2.loss_cls: 0.0898, d2.loss_bbox: 0.0632, d2.loss_iou: 0.3409, d3.loss_cls: 0.0883, d3.loss_bbox: 0.0633, d3.loss_iou: 0.3403, d4.loss_cls: 0.0862, d4.loss_bbox: 0.0634, d4.loss_iou: 0.3409, dn_loss_cls: 0.0137, dn_loss_bbox: 0.0333, dn_loss_iou: 0.1968, d0.dn_loss_cls: 0.0436, d0.dn_loss_bbox: 0.0471, d0.dn_loss_iou: 0.2703, d1.dn_loss_cls: 0.0173, d1.dn_loss_bbox: 0.0339, d1.dn_loss_iou: 0.2000, d2.dn_loss_cls: 0.0160, d2.dn_loss_bbox: 0.0333, d2.dn_loss_iou: 0.1968, d3.dn_loss_cls: 0.0144, d3.dn_loss_bbox: 0.0333, d3.dn_loss_iou: 0.1966, d4.dn_loss_cls: 0.0136, d4.dn_loss_bbox: 0.0333, d4.dn_loss_iou: 0.1968, loss_rpn_cls: 0.0337, loss_rpn_bbox: 0.1463, loss_cls0: 2.0136, acc0: 92.9791, loss_bbox0: 3.2426, loss_cls1: 1.6081, loss_bbox1: 3.7210, loss_centerness1: 7.1536, loss_cls_aux0: 0.0280, loss_bbox_aux0: 0.0147, loss_iou_aux0: 0.0834, d0.loss_cls_aux0: 0.0269, d0.loss_bbox_aux0: 0.0390, d0.loss_iou_aux0: 0.2225, d1.loss_cls_aux0: 0.0322, d1.loss_bbox_aux0: 0.0174, d1.loss_iou_aux0: 0.0997, d2.loss_cls_aux0: 0.0292, d2.loss_bbox_aux0: 0.0154, d2.loss_iou_aux0: 0.0877, d3.loss_cls_aux0: 0.0263, d3.loss_bbox_aux0: 0.0147, d3.loss_iou_aux0: 0.0834, d4.loss_cls_aux0: 0.0270, d4.loss_bbox_aux0: 0.0147, d4.loss_iou_aux0: 0.0834, loss_cls_aux1: 0.0158, loss_bbox_aux1: 0.0374, loss_iou_aux1: 0.2133, d0.loss_cls_aux1: 0.0160, d0.loss_bbox_aux1: 0.0447, d0.loss_iou_aux1: 0.2497, d1.loss_cls_aux1: 0.0165, d1.loss_bbox_aux1: 0.0384, d1.loss_iou_aux1: 0.2178, d2.loss_cls_aux1: 0.0151, d2.loss_bbox_aux1: 0.0374, d2.loss_iou_aux1: 0.2135, d3.loss_cls_aux1: 0.0153, d3.loss_bbox_aux1: 0.0374, d3.loss_iou_aux1: 0.2133, d4.loss_cls_aux1: 0.0152, d4.loss_bbox_aux1: 0.0374, d4.loss_iou_aux1: 0.2133, loss: 25.6854, grad_norm: 104.7290
2024-03-18 22:13:13,230 - mmdet - INFO - Epoch [12][150/463]	lr: 1.000e-06, eta: 1:31:46, time: 2.611, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1414, enc_loss_bbox: 0.0584, enc_loss_iou: 0.3156, loss_cls: 0.0821, loss_bbox: 0.0577, loss_iou: 0.3122, d0.loss_cls: 0.1660, d0.loss_bbox: 0.0571, d0.loss_iou: 0.3106, d1.loss_cls: 0.0925, d1.loss_bbox: 0.0576, d1.loss_iou: 0.3115, d2.loss_cls: 0.0847, d2.loss_bbox: 0.0578, d2.loss_iou: 0.3120, d3.loss_cls: 0.0844, d3.loss_bbox: 0.0577, d3.loss_iou: 0.3115, d4.loss_cls: 0.0829, d4.loss_bbox: 0.0577, d4.loss_iou: 0.3117, dn_loss_cls: 0.0075, dn_loss_bbox: 0.0342, dn_loss_iou: 0.1946, d0.dn_loss_cls: 0.0285, d0.dn_loss_bbox: 0.0482, d0.dn_loss_iou: 0.2649, d1.dn_loss_cls: 0.0098, d1.dn_loss_bbox: 0.0350, d1.dn_loss_iou: 0.1974, d2.dn_loss_cls: 0.0085, d2.dn_loss_bbox: 0.0342, d2.dn_loss_iou: 0.1940, d3.dn_loss_cls: 0.0077, d3.dn_loss_bbox: 0.0341, d3.dn_loss_iou: 0.1940, d4.dn_loss_cls: 0.0076, d4.dn_loss_bbox: 0.0342, d4.dn_loss_iou: 0.1941, loss_rpn_cls: 0.0224, loss_rpn_bbox: 0.1318, loss_cls0: 1.8718, acc0: 93.4233, loss_bbox0: 3.1210, loss_cls1: 1.5037, loss_bbox1: 3.4485, loss_centerness1: 7.1241, loss_cls_aux0: 0.0110, loss_bbox_aux0: 0.0151, loss_iou_aux0: 0.0792, d0.loss_cls_aux0: 0.0099, d0.loss_bbox_aux0: 0.0385, d0.loss_iou_aux0: 0.2100, d1.loss_cls_aux0: 0.0109, d1.loss_bbox_aux0: 0.0180, d1.loss_iou_aux0: 0.0960, d2.loss_cls_aux0: 0.0108, d2.loss_bbox_aux0: 0.0157, d2.loss_iou_aux0: 0.0828, d3.loss_cls_aux0: 0.0114, d3.loss_bbox_aux0: 0.0151, d3.loss_iou_aux0: 0.0791, d4.loss_cls_aux0: 0.0110, d4.loss_bbox_aux0: 0.0151, d4.loss_iou_aux0: 0.0791, loss_cls_aux1: 0.0105, loss_bbox_aux1: 0.0362, loss_iou_aux1: 0.2002, d0.loss_cls_aux1: 0.0112, d0.loss_bbox_aux1: 0.0431, d0.loss_iou_aux1: 0.2337, d1.loss_cls_aux1: 0.0118, d1.loss_bbox_aux1: 0.0366, d1.loss_iou_aux1: 0.2031, d2.loss_cls_aux1: 0.0109, d2.loss_bbox_aux1: 0.0365, d2.loss_iou_aux1: 0.2012, d3.loss_cls_aux1: 0.0115, d3.loss_bbox_aux1: 0.0362, d3.loss_iou_aux1: 0.2002, d4.loss_cls_aux1: 0.0106, d4.loss_bbox_aux1: 0.0362, d4.loss_iou_aux1: 0.2002, loss: 24.4141, grad_norm: 117.8439
2024-03-18 22:15:23,867 - mmdet - INFO - Epoch [12][200/463]	lr: 1.000e-06, eta: 1:29:40, time: 2.613, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1431, enc_loss_bbox: 0.0650, enc_loss_iou: 0.3239, loss_cls: 0.0895, loss_bbox: 0.0635, loss_iou: 0.3204, d0.loss_cls: 0.1688, d0.loss_bbox: 0.0637, d0.loss_iou: 0.3197, d1.loss_cls: 0.0956, d1.loss_bbox: 0.0636, d1.loss_iou: 0.3210, d2.loss_cls: 0.0900, d2.loss_bbox: 0.0636, d2.loss_iou: 0.3211, d3.loss_cls: 0.0908, d3.loss_bbox: 0.0635, d3.loss_iou: 0.3203, d4.loss_cls: 0.0896, d4.loss_bbox: 0.0636, d4.loss_iou: 0.3204, dn_loss_cls: 0.0079, dn_loss_bbox: 0.0350, dn_loss_iou: 0.1943, d0.dn_loss_cls: 0.0317, d0.dn_loss_bbox: 0.0499, d0.dn_loss_iou: 0.2680, d1.dn_loss_cls: 0.0098, d1.dn_loss_bbox: 0.0357, d1.dn_loss_iou: 0.1975, d2.dn_loss_cls: 0.0083, d2.dn_loss_bbox: 0.0350, d2.dn_loss_iou: 0.1944, d3.dn_loss_cls: 0.0078, d3.dn_loss_bbox: 0.0350, d3.dn_loss_iou: 0.1943, d4.dn_loss_cls: 0.0078, d4.dn_loss_bbox: 0.0350, d4.dn_loss_iou: 0.1943, loss_rpn_cls: 0.0222, loss_rpn_bbox: 0.1684, loss_cls0: 2.1586, acc0: 92.5045, loss_bbox0: 3.4216, loss_cls1: 1.5645, loss_bbox1: 3.5801, loss_centerness1: 7.1213, loss_cls_aux0: 0.0170, loss_bbox_aux0: 0.0170, loss_iou_aux0: 0.0908, d0.loss_cls_aux0: 0.0187, d0.loss_bbox_aux0: 0.0420, d0.loss_iou_aux0: 0.2240, d1.loss_cls_aux0: 0.0198, d1.loss_bbox_aux0: 0.0203, d1.loss_iou_aux0: 0.1080, d2.loss_cls_aux0: 0.0176, d2.loss_bbox_aux0: 0.0176, d2.loss_iou_aux0: 0.0943, d3.loss_cls_aux0: 0.0183, d3.loss_bbox_aux0: 0.0169, d3.loss_iou_aux0: 0.0907, d4.loss_cls_aux0: 0.0175, d4.loss_bbox_aux0: 0.0169, d4.loss_iou_aux0: 0.0907, loss_cls_aux1: 0.0170, loss_bbox_aux1: 0.0402, loss_iou_aux1: 0.2141, d0.loss_cls_aux1: 0.0194, d0.loss_bbox_aux1: 0.0469, d0.loss_iou_aux1: 0.2452, d1.loss_cls_aux1: 0.0185, d1.loss_bbox_aux1: 0.0410, d1.loss_iou_aux1: 0.2190, d2.loss_cls_aux1: 0.0171, d2.loss_bbox_aux1: 0.0403, d2.loss_iou_aux1: 0.2144, d3.loss_cls_aux1: 0.0172, d3.loss_bbox_aux1: 0.0402, d3.loss_iou_aux1: 0.2141, d4.loss_cls_aux1: 0.0174, d4.loss_bbox_aux1: 0.0402, d4.loss_iou_aux1: 0.2141, loss: 25.6536, grad_norm: 101.5659
2024-03-18 22:17:34,082 - mmdet - INFO - Epoch [12][250/463]	lr: 1.000e-06, eta: 1:27:34, time: 2.604, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1333, enc_loss_bbox: 0.0613, enc_loss_iou: 0.3313, loss_cls: 0.0857, loss_bbox: 0.0611, loss_iou: 0.3303, d0.loss_cls: 0.1655, d0.loss_bbox: 0.0604, d0.loss_iou: 0.3282, d1.loss_cls: 0.0909, d1.loss_bbox: 0.0610, d1.loss_iou: 0.3299, d2.loss_cls: 0.0868, d2.loss_bbox: 0.0612, d2.loss_iou: 0.3312, d3.loss_cls: 0.0853, d3.loss_bbox: 0.0611, d3.loss_iou: 0.3305, d4.loss_cls: 0.0862, d4.loss_bbox: 0.0611, d4.loss_iou: 0.3303, dn_loss_cls: 0.0065, dn_loss_bbox: 0.0348, dn_loss_iou: 0.1961, d0.dn_loss_cls: 0.0312, d0.dn_loss_bbox: 0.0488, d0.dn_loss_iou: 0.2702, d1.dn_loss_cls: 0.0095, d1.dn_loss_bbox: 0.0355, d1.dn_loss_iou: 0.1998, d2.dn_loss_cls: 0.0070, d2.dn_loss_bbox: 0.0348, d2.dn_loss_iou: 0.1962, d3.dn_loss_cls: 0.0067, d3.dn_loss_bbox: 0.0348, d3.dn_loss_iou: 0.1961, d4.dn_loss_cls: 0.0067, d4.dn_loss_bbox: 0.0348, d4.dn_loss_iou: 0.1961, loss_rpn_cls: 0.0294, loss_rpn_bbox: 0.1601, loss_cls0: 2.1169, acc0: 92.6236, loss_bbox0: 3.3893, loss_cls1: 1.5534, loss_bbox1: 3.6162, loss_centerness1: 7.1612, loss_cls_aux0: 0.0134, loss_bbox_aux0: 0.0163, loss_iou_aux0: 0.0871, d0.loss_cls_aux0: 0.0172, d0.loss_bbox_aux0: 0.0403, d0.loss_iou_aux0: 0.2195, d1.loss_cls_aux0: 0.0171, d1.loss_bbox_aux0: 0.0193, d1.loss_iou_aux0: 0.1053, d2.loss_cls_aux0: 0.0149, d2.loss_bbox_aux0: 0.0170, d2.loss_iou_aux0: 0.0910, d3.loss_cls_aux0: 0.0131, d3.loss_bbox_aux0: 0.0163, d3.loss_iou_aux0: 0.0869, d4.loss_cls_aux0: 0.0127, d4.loss_bbox_aux0: 0.0163, d4.loss_iou_aux0: 0.0870, loss_cls_aux1: 0.0111, loss_bbox_aux1: 0.0380, loss_iou_aux1: 0.2096, d0.loss_cls_aux1: 0.0143, d0.loss_bbox_aux1: 0.0457, d0.loss_iou_aux1: 0.2481, d1.loss_cls_aux1: 0.0137, d1.loss_bbox_aux1: 0.0391, d1.loss_iou_aux1: 0.2159, d2.loss_cls_aux1: 0.0126, d2.loss_bbox_aux1: 0.0380, d2.loss_iou_aux1: 0.2096, d3.loss_cls_aux1: 0.0113, d3.loss_bbox_aux1: 0.0380, d3.loss_iou_aux1: 0.2096, d4.loss_cls_aux1: 0.0110, d4.loss_bbox_aux1: 0.0380, d4.loss_iou_aux1: 0.2096, loss: 25.5488, grad_norm: 129.2433
2024-03-18 22:19:47,170 - mmdet - INFO - Epoch [12][300/463]	lr: 1.000e-06, eta: 1:25:29, time: 2.662, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1386, enc_loss_bbox: 0.0632, enc_loss_iou: 0.3231, loss_cls: 0.0836, loss_bbox: 0.0611, loss_iou: 0.3143, d0.loss_cls: 0.1654, d0.loss_bbox: 0.0612, d0.loss_iou: 0.3153, d1.loss_cls: 0.0913, d1.loss_bbox: 0.0611, d1.loss_iou: 0.3139, d2.loss_cls: 0.0858, d2.loss_bbox: 0.0613, d2.loss_iou: 0.3143, d3.loss_cls: 0.0840, d3.loss_bbox: 0.0611, d3.loss_iou: 0.3143, d4.loss_cls: 0.0833, d4.loss_bbox: 0.0611, d4.loss_iou: 0.3143, dn_loss_cls: 0.0085, dn_loss_bbox: 0.0349, dn_loss_iou: 0.1978, d0.dn_loss_cls: 0.0324, d0.dn_loss_bbox: 0.0492, d0.dn_loss_iou: 0.2688, d1.dn_loss_cls: 0.0108, d1.dn_loss_bbox: 0.0355, d1.dn_loss_iou: 0.2010, d2.dn_loss_cls: 0.0089, d2.dn_loss_bbox: 0.0349, d2.dn_loss_iou: 0.1983, d3.dn_loss_cls: 0.0083, d3.dn_loss_bbox: 0.0349, d3.dn_loss_iou: 0.1982, d4.dn_loss_cls: 0.0085, d4.dn_loss_bbox: 0.0349, d4.dn_loss_iou: 0.1978, loss_rpn_cls: 0.0232, loss_rpn_bbox: 0.1490, loss_cls0: 1.9673, acc0: 93.0706, loss_bbox0: 3.2083, loss_cls1: 1.5160, loss_bbox1: 3.5115, loss_centerness1: 7.1287, loss_cls_aux0: 0.0155, loss_bbox_aux0: 0.0156, loss_iou_aux0: 0.0815, d0.loss_cls_aux0: 0.0172, d0.loss_bbox_aux0: 0.0406, d0.loss_iou_aux0: 0.2153, d1.loss_cls_aux0: 0.0177, d1.loss_bbox_aux0: 0.0187, d1.loss_iou_aux0: 0.0982, d2.loss_cls_aux0: 0.0164, d2.loss_bbox_aux0: 0.0164, d2.loss_iou_aux0: 0.0858, d3.loss_cls_aux0: 0.0146, d3.loss_bbox_aux0: 0.0156, d3.loss_iou_aux0: 0.0816, d4.loss_cls_aux0: 0.0147, d4.loss_bbox_aux0: 0.0156, d4.loss_iou_aux0: 0.0815, loss_cls_aux1: 0.0108, loss_bbox_aux1: 0.0379, loss_iou_aux1: 0.2041, d0.loss_cls_aux1: 0.0131, d0.loss_bbox_aux1: 0.0453, d0.loss_iou_aux1: 0.2372, d1.loss_cls_aux1: 0.0124, d1.loss_bbox_aux1: 0.0389, d1.loss_iou_aux1: 0.2088, d2.loss_cls_aux1: 0.0115, d2.loss_bbox_aux1: 0.0381, d2.loss_iou_aux1: 0.2047, d3.loss_cls_aux1: 0.0106, d3.loss_bbox_aux1: 0.0379, d3.loss_iou_aux1: 0.2041, d4.loss_cls_aux1: 0.0105, d4.loss_bbox_aux1: 0.0379, d4.loss_iou_aux1: 0.2040, loss: 24.8689, grad_norm: 111.4956
2024-03-18 22:21:49,362 - mmdet - INFO - Epoch [12][350/463]	lr: 1.000e-06, eta: 1:23:20, time: 2.444, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1319, enc_loss_bbox: 0.0623, enc_loss_iou: 0.3377, loss_cls: 0.0796, loss_bbox: 0.0616, loss_iou: 0.3346, d0.loss_cls: 0.1646, d0.loss_bbox: 0.0615, d0.loss_iou: 0.3323, d1.loss_cls: 0.0878, d1.loss_bbox: 0.0614, d1.loss_iou: 0.3341, d2.loss_cls: 0.0818, d2.loss_bbox: 0.0617, d2.loss_iou: 0.3352, d3.loss_cls: 0.0809, d3.loss_bbox: 0.0615, d3.loss_iou: 0.3345, d4.loss_cls: 0.0796, d4.loss_bbox: 0.0616, d4.loss_iou: 0.3346, dn_loss_cls: 0.0072, dn_loss_bbox: 0.0324, dn_loss_iou: 0.1925, d0.dn_loss_cls: 0.0307, d0.dn_loss_bbox: 0.0452, d0.dn_loss_iou: 0.2620, d1.dn_loss_cls: 0.0113, d1.dn_loss_bbox: 0.0329, d1.dn_loss_iou: 0.1954, d2.dn_loss_cls: 0.0085, d2.dn_loss_bbox: 0.0324, d2.dn_loss_iou: 0.1926, d3.dn_loss_cls: 0.0080, d3.dn_loss_bbox: 0.0324, d3.dn_loss_iou: 0.1925, d4.dn_loss_cls: 0.0078, d4.dn_loss_bbox: 0.0324, d4.dn_loss_iou: 0.1926, loss_rpn_cls: 0.0240, loss_rpn_bbox: 0.1657, loss_cls0: 2.0687, acc0: 92.7674, loss_bbox0: 3.4279, loss_cls1: 1.5697, loss_bbox1: 3.6425, loss_centerness1: 7.1286, loss_cls_aux0: 0.0118, loss_bbox_aux0: 0.0159, loss_iou_aux0: 0.0892, d0.loss_cls_aux0: 0.0141, d0.loss_bbox_aux0: 0.0387, d0.loss_iou_aux0: 0.2202, d1.loss_cls_aux0: 0.0162, d1.loss_bbox_aux0: 0.0190, d1.loss_iou_aux0: 0.1072, d2.loss_cls_aux0: 0.0139, d2.loss_bbox_aux0: 0.0166, d2.loss_iou_aux0: 0.0934, d3.loss_cls_aux0: 0.0146, d3.loss_bbox_aux0: 0.0159, d3.loss_iou_aux0: 0.0892, d4.loss_cls_aux0: 0.0125, d4.loss_bbox_aux0: 0.0159, d4.loss_iou_aux0: 0.0891, loss_cls_aux1: 0.0119, loss_bbox_aux1: 0.0368, loss_iou_aux1: 0.2093, d0.loss_cls_aux1: 0.0161, d0.loss_bbox_aux1: 0.0442, d0.loss_iou_aux1: 0.2486, d1.loss_cls_aux1: 0.0168, d1.loss_bbox_aux1: 0.0377, d1.loss_iou_aux1: 0.2147, d2.loss_cls_aux1: 0.0141, d2.loss_bbox_aux1: 0.0369, d2.loss_iou_aux1: 0.2096, d3.loss_cls_aux1: 0.0142, d3.loss_bbox_aux1: 0.0368, d3.loss_iou_aux1: 0.2093, d4.loss_cls_aux1: 0.0129, d4.loss_bbox_aux1: 0.0368, d4.loss_iou_aux1: 0.2093, loss: 25.5260, grad_norm: 108.4168
2024-03-18 22:24:01,981 - mmdet - INFO - Epoch [12][400/463]	lr: 1.000e-06, eta: 1:21:14, time: 2.652, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1240, enc_loss_bbox: 0.0672, enc_loss_iou: 0.3391, loss_cls: 0.0718, loss_bbox: 0.0670, loss_iou: 0.3346, d0.loss_cls: 0.1473, d0.loss_bbox: 0.0673, d0.loss_iou: 0.3369, d1.loss_cls: 0.0808, d1.loss_bbox: 0.0663, d1.loss_iou: 0.3347, d2.loss_cls: 0.0739, d2.loss_bbox: 0.0676, d2.loss_iou: 0.3358, d3.loss_cls: 0.0715, d3.loss_bbox: 0.0672, d3.loss_iou: 0.3350, d4.loss_cls: 0.0726, d4.loss_bbox: 0.0671, d4.loss_iou: 0.3343, dn_loss_cls: 0.0085, dn_loss_bbox: 0.0345, dn_loss_iou: 0.1971, d0.dn_loss_cls: 0.0314, d0.dn_loss_bbox: 0.0486, d0.dn_loss_iou: 0.2678, d1.dn_loss_cls: 0.0104, d1.dn_loss_bbox: 0.0352, d1.dn_loss_iou: 0.1994, d2.dn_loss_cls: 0.0086, d2.dn_loss_bbox: 0.0345, d2.dn_loss_iou: 0.1965, d3.dn_loss_cls: 0.0085, d3.dn_loss_bbox: 0.0345, d3.dn_loss_iou: 0.1962, d4.dn_loss_cls: 0.0084, d4.dn_loss_bbox: 0.0345, d4.dn_loss_iou: 0.1969, loss_rpn_cls: 0.0365, loss_rpn_bbox: 0.1457, loss_cls0: 2.0358, acc0: 92.8686, loss_bbox0: 3.3645, loss_cls1: 1.5473, loss_bbox1: 3.6349, loss_centerness1: 7.1158, loss_cls_aux0: 0.0176, loss_bbox_aux0: 0.0153, loss_iou_aux0: 0.0807, d0.loss_cls_aux0: 0.0135, d0.loss_bbox_aux0: 0.0409, d0.loss_iou_aux0: 0.2182, d1.loss_cls_aux0: 0.0158, d1.loss_bbox_aux0: 0.0184, d1.loss_iou_aux0: 0.0970, d2.loss_cls_aux0: 0.0146, d2.loss_bbox_aux0: 0.0161, d2.loss_iou_aux0: 0.0848, d3.loss_cls_aux0: 0.0146, d3.loss_bbox_aux0: 0.0153, d3.loss_iou_aux0: 0.0807, d4.loss_cls_aux0: 0.0169, d4.loss_bbox_aux0: 0.0153, d4.loss_iou_aux0: 0.0807, loss_cls_aux1: 0.0163, loss_bbox_aux1: 0.0387, loss_iou_aux1: 0.2088, d0.loss_cls_aux1: 0.0130, d0.loss_bbox_aux1: 0.0455, d0.loss_iou_aux1: 0.2400, d1.loss_cls_aux1: 0.0147, d1.loss_bbox_aux1: 0.0394, d1.loss_iou_aux1: 0.2124, d2.loss_cls_aux1: 0.0140, d2.loss_bbox_aux1: 0.0388, d2.loss_iou_aux1: 0.2093, d3.loss_cls_aux1: 0.0138, d3.loss_bbox_aux1: 0.0387, d3.loss_iou_aux1: 0.2088, d4.loss_cls_aux1: 0.0156, d4.loss_bbox_aux1: 0.0387, d4.loss_iou_aux1: 0.2088, loss: 25.3658, grad_norm: 108.3764
2024-03-18 22:26:16,967 - mmdet - INFO - Epoch [12][450/463]	lr: 1.000e-06, eta: 1:19:10, time: 2.700, data_time: 0.011, memory: 19333, enc_loss_cls: 0.1388, enc_loss_bbox: 0.0636, enc_loss_iou: 0.3371, loss_cls: 0.0860, loss_bbox: 0.0635, loss_iou: 0.3349, d0.loss_cls: 0.1629, d0.loss_bbox: 0.0630, d0.loss_iou: 0.3331, d1.loss_cls: 0.0948, d1.loss_bbox: 0.0630, d1.loss_iou: 0.3335, d2.loss_cls: 0.0900, d2.loss_bbox: 0.0642, d2.loss_iou: 0.3342, d3.loss_cls: 0.0863, d3.loss_bbox: 0.0634, d3.loss_iou: 0.3349, d4.loss_cls: 0.0862, d4.loss_bbox: 0.0634, d4.loss_iou: 0.3343, dn_loss_cls: 0.0091, dn_loss_bbox: 0.0333, dn_loss_iou: 0.2011, d0.dn_loss_cls: 0.0360, d0.dn_loss_bbox: 0.0471, d0.dn_loss_iou: 0.2749, d1.dn_loss_cls: 0.0126, d1.dn_loss_bbox: 0.0339, d1.dn_loss_iou: 0.2037, d2.dn_loss_cls: 0.0100, d2.dn_loss_bbox: 0.0333, d2.dn_loss_iou: 0.2005, d3.dn_loss_cls: 0.0088, d3.dn_loss_bbox: 0.0333, d3.dn_loss_iou: 0.2007, d4.dn_loss_cls: 0.0091, d4.dn_loss_bbox: 0.0332, d4.dn_loss_iou: 0.2006, loss_rpn_cls: 0.0287, loss_rpn_bbox: 0.1572, loss_cls0: 2.1126, acc0: 92.5154, loss_bbox0: 3.2903, loss_cls1: 1.5720, loss_bbox1: 3.6491, loss_centerness1: 7.1318, loss_cls_aux0: 0.0199, loss_bbox_aux0: 0.0153, loss_iou_aux0: 0.0845, d0.loss_cls_aux0: 0.0208, d0.loss_bbox_aux0: 0.0385, d0.loss_iou_aux0: 0.2177, d1.loss_cls_aux0: 0.0214, d1.loss_bbox_aux0: 0.0182, d1.loss_iou_aux0: 0.1016, d2.loss_cls_aux0: 0.0198, d2.loss_bbox_aux0: 0.0159, d2.loss_iou_aux0: 0.0881, d3.loss_cls_aux0: 0.0195, d3.loss_bbox_aux0: 0.0153, d3.loss_iou_aux0: 0.0843, d4.loss_cls_aux0: 0.0194, d4.loss_bbox_aux0: 0.0153, d4.loss_iou_aux0: 0.0844, loss_cls_aux1: 0.0167, loss_bbox_aux1: 0.0377, loss_iou_aux1: 0.2114, d0.loss_cls_aux1: 0.0204, d0.loss_bbox_aux1: 0.0451, d0.loss_iou_aux1: 0.2461, d1.loss_cls_aux1: 0.0193, d1.loss_bbox_aux1: 0.0386, d1.loss_iou_aux1: 0.2153, d2.loss_cls_aux1: 0.0193, d2.loss_bbox_aux1: 0.0377, d2.loss_iou_aux1: 0.2113, d3.loss_cls_aux1: 0.0176, d3.loss_bbox_aux1: 0.0377, d3.loss_iou_aux1: 0.2113, d4.loss_cls_aux1: 0.0169, d4.loss_bbox_aux1: 0.0377, d4.loss_iou_aux1: 0.2114, loss: 25.6055, grad_norm: 116.3260
2024-03-18 22:26:49,110 - mmdet - INFO - Saving checkpoint at 12 epochs
2024-03-18 22:28:19,595 - mmdet - INFO - Evaluating bbox...
2024-03-18 22:28:36,095 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.618
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.892
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.743
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.504
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.587
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.813
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.737
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.737
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.729
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.856

2024-03-18 22:28:36,095 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.657 | Thatch   | 0.582 |
+----------+-------+----------+-------+
2024-03-18 22:28:36,802 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_004/best_bbox_mAP_epoch_11.pth was removed
2024-03-18 22:28:43,020 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_12.pth.
2024-03-18 22:28:43,020 - mmdet - INFO - Best bbox_mAP is 0.6180 at 12 epoch.
2024-03-18 22:28:43,020 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 22:28:43,020 - mmdet - INFO - Epoch(val) [12][154]	bbox_mAP: 0.6180, bbox_mAP_50: 0.8920, bbox_mAP_75: 0.7430, bbox_mAP_s: 0.5040, bbox_mAP_m: 0.5870, bbox_mAP_l: 0.8130, bbox_mAP_copypaste: 0.618 0.892 0.743 0.504 0.587 0.813
2024-03-18 22:30:55,222 - mmdet - INFO - Epoch [13][50/463]	lr: 1.000e-06, eta: 1:16:20, time: 2.644, data_time: 0.058, memory: 19333, enc_loss_cls: 0.1398, enc_loss_bbox: 0.0559, enc_loss_iou: 0.3101, loss_cls: 0.0839, loss_bbox: 0.0546, loss_iou: 0.3030, d0.loss_cls: 0.1792, d0.loss_bbox: 0.0548, d0.loss_iou: 0.3034, d1.loss_cls: 0.0962, d1.loss_bbox: 0.0547, d1.loss_iou: 0.3032, d2.loss_cls: 0.0875, d2.loss_bbox: 0.0548, d2.loss_iou: 0.3034, d3.loss_cls: 0.0850, d3.loss_bbox: 0.0546, d3.loss_iou: 0.3029, d4.loss_cls: 0.0845, d4.loss_bbox: 0.0546, d4.loss_iou: 0.3030, dn_loss_cls: 0.0059, dn_loss_bbox: 0.0323, dn_loss_iou: 0.1922, d0.dn_loss_cls: 0.0276, d0.dn_loss_bbox: 0.0448, d0.dn_loss_iou: 0.2595, d1.dn_loss_cls: 0.0088, d1.dn_loss_bbox: 0.0330, d1.dn_loss_iou: 0.1951, d2.dn_loss_cls: 0.0068, d2.dn_loss_bbox: 0.0323, d2.dn_loss_iou: 0.1917, d3.dn_loss_cls: 0.0061, d3.dn_loss_bbox: 0.0323, d3.dn_loss_iou: 0.1917, d4.dn_loss_cls: 0.0060, d4.dn_loss_bbox: 0.0323, d4.dn_loss_iou: 0.1916, loss_rpn_cls: 0.0256, loss_rpn_bbox: 0.1568, loss_cls0: 1.9213, acc0: 93.1742, loss_bbox0: 3.1295, loss_cls1: 1.4359, loss_bbox1: 3.3542, loss_centerness1: 7.0968, loss_cls_aux0: 0.0112, loss_bbox_aux0: 0.0144, loss_iou_aux0: 0.0793, d0.loss_cls_aux0: 0.0154, d0.loss_bbox_aux0: 0.0373, d0.loss_iou_aux0: 0.2121, d1.loss_cls_aux0: 0.0156, d1.loss_bbox_aux0: 0.0171, d1.loss_iou_aux0: 0.0959, d2.loss_cls_aux0: 0.0147, d2.loss_bbox_aux0: 0.0150, d2.loss_iou_aux0: 0.0832, d3.loss_cls_aux0: 0.0111, d3.loss_bbox_aux0: 0.0143, d3.loss_iou_aux0: 0.0792, d4.loss_cls_aux0: 0.0107, d4.loss_bbox_aux0: 0.0143, d4.loss_iou_aux0: 0.0792, loss_cls_aux1: 0.0090, loss_bbox_aux1: 0.0357, loss_iou_aux1: 0.2042, d0.loss_cls_aux1: 0.0130, d0.loss_bbox_aux1: 0.0422, d0.loss_iou_aux1: 0.2385, d1.loss_cls_aux1: 0.0124, d1.loss_bbox_aux1: 0.0367, d1.loss_iou_aux1: 0.2098, d2.loss_cls_aux1: 0.0114, d2.loss_bbox_aux1: 0.0358, d2.loss_iou_aux1: 0.2045, d3.loss_cls_aux1: 0.0096, d3.loss_bbox_aux1: 0.0357, d3.loss_iou_aux1: 0.2043, d4.loss_cls_aux1: 0.0088, d4.loss_bbox_aux1: 0.0357, d4.loss_iou_aux1: 0.2042, loss: 24.2507, grad_norm: 109.4363
2024-03-18 22:33:00,818 - mmdet - INFO - Epoch [13][100/463]	lr: 1.000e-06, eta: 1:14:13, time: 2.512, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1331, enc_loss_bbox: 0.0716, enc_loss_iou: 0.3547, loss_cls: 0.0801, loss_bbox: 0.0705, loss_iou: 0.3536, d0.loss_cls: 0.1614, d0.loss_bbox: 0.0702, d0.loss_iou: 0.3513, d1.loss_cls: 0.0877, d1.loss_bbox: 0.0702, d1.loss_iou: 0.3519, d2.loss_cls: 0.0825, d2.loss_bbox: 0.0702, d2.loss_iou: 0.3546, d3.loss_cls: 0.0811, d3.loss_bbox: 0.0705, d3.loss_iou: 0.3535, d4.loss_cls: 0.0806, d4.loss_bbox: 0.0705, d4.loss_iou: 0.3536, dn_loss_cls: 0.0073, dn_loss_bbox: 0.0353, dn_loss_iou: 0.2010, d0.dn_loss_cls: 0.0320, d0.dn_loss_bbox: 0.0512, d0.dn_loss_iou: 0.2784, d1.dn_loss_cls: 0.0093, d1.dn_loss_bbox: 0.0363, d1.dn_loss_iou: 0.2040, d2.dn_loss_cls: 0.0076, d2.dn_loss_bbox: 0.0353, d2.dn_loss_iou: 0.1996, d3.dn_loss_cls: 0.0074, d3.dn_loss_bbox: 0.0353, d3.dn_loss_iou: 0.1996, d4.dn_loss_cls: 0.0075, d4.dn_loss_bbox: 0.0353, d4.dn_loss_iou: 0.1996, loss_rpn_cls: 0.0304, loss_rpn_bbox: 0.1570, loss_cls0: 2.2371, acc0: 92.1008, loss_bbox0: 3.5311, loss_cls1: 1.5527, loss_bbox1: 3.8151, loss_centerness1: 7.1465, loss_cls_aux0: 0.0135, loss_bbox_aux0: 0.0155, loss_iou_aux0: 0.0849, d0.loss_cls_aux0: 0.0136, d0.loss_bbox_aux0: 0.0421, d0.loss_iou_aux0: 0.2232, d1.loss_cls_aux0: 0.0138, d1.loss_bbox_aux0: 0.0188, d1.loss_iou_aux0: 0.1015, d2.loss_cls_aux0: 0.0119, d2.loss_bbox_aux0: 0.0163, d2.loss_iou_aux0: 0.0887, d3.loss_cls_aux0: 0.0120, d3.loss_bbox_aux0: 0.0155, d3.loss_iou_aux0: 0.0848, d4.loss_cls_aux0: 0.0127, d4.loss_bbox_aux0: 0.0155, d4.loss_iou_aux0: 0.0848, loss_cls_aux1: 0.0112, loss_bbox_aux1: 0.0404, loss_iou_aux1: 0.2176, d0.loss_cls_aux1: 0.0136, d0.loss_bbox_aux1: 0.0492, d0.loss_iou_aux1: 0.2574, d1.loss_cls_aux1: 0.0111, d1.loss_bbox_aux1: 0.0413, d1.loss_iou_aux1: 0.2222, d2.loss_cls_aux1: 0.0101, d2.loss_bbox_aux1: 0.0405, d2.loss_iou_aux1: 0.2177, d3.loss_cls_aux1: 0.0102, d3.loss_bbox_aux1: 0.0404, d3.loss_iou_aux1: 0.2175, d4.loss_cls_aux1: 0.0107, d4.loss_bbox_aux1: 0.0404, d4.loss_iou_aux1: 0.2176, loss: 26.2639, grad_norm: 110.8287
2024-03-18 22:35:11,545 - mmdet - INFO - Epoch [13][150/463]	lr: 1.000e-06, eta: 1:12:07, time: 2.615, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1316, enc_loss_bbox: 0.0617, enc_loss_iou: 0.3254, loss_cls: 0.0837, loss_bbox: 0.0621, loss_iou: 0.3246, d0.loss_cls: 0.1584, d0.loss_bbox: 0.0615, d0.loss_iou: 0.3223, d1.loss_cls: 0.0915, d1.loss_bbox: 0.0620, d1.loss_iou: 0.3238, d2.loss_cls: 0.0847, d2.loss_bbox: 0.0623, d2.loss_iou: 0.3242, d3.loss_cls: 0.0826, d3.loss_bbox: 0.0624, d3.loss_iou: 0.3243, d4.loss_cls: 0.0830, d4.loss_bbox: 0.0622, d4.loss_iou: 0.3242, dn_loss_cls: 0.0099, dn_loss_bbox: 0.0347, dn_loss_iou: 0.1932, d0.dn_loss_cls: 0.0355, d0.dn_loss_bbox: 0.0489, d0.dn_loss_iou: 0.2650, d1.dn_loss_cls: 0.0122, d1.dn_loss_bbox: 0.0353, d1.dn_loss_iou: 0.1963, d2.dn_loss_cls: 0.0102, d2.dn_loss_bbox: 0.0347, d2.dn_loss_iou: 0.1933, d3.dn_loss_cls: 0.0097, d3.dn_loss_bbox: 0.0347, d3.dn_loss_iou: 0.1932, d4.dn_loss_cls: 0.0099, d4.dn_loss_bbox: 0.0347, d4.dn_loss_iou: 0.1932, loss_rpn_cls: 0.0210, loss_rpn_bbox: 0.1565, loss_cls0: 2.0198, acc0: 93.0341, loss_bbox0: 3.2934, loss_cls1: 1.5526, loss_bbox1: 3.5405, loss_centerness1: 7.1283, loss_cls_aux0: 0.0171, loss_bbox_aux0: 0.0154, loss_iou_aux0: 0.0859, d0.loss_cls_aux0: 0.0170, d0.loss_bbox_aux0: 0.0394, d0.loss_iou_aux0: 0.2184, d1.loss_cls_aux0: 0.0193, d1.loss_bbox_aux0: 0.0186, d1.loss_iou_aux0: 0.1041, d2.loss_cls_aux0: 0.0178, d2.loss_bbox_aux0: 0.0161, d2.loss_iou_aux0: 0.0898, d3.loss_cls_aux0: 0.0174, d3.loss_bbox_aux0: 0.0154, d3.loss_iou_aux0: 0.0857, d4.loss_cls_aux0: 0.0170, d4.loss_bbox_aux0: 0.0154, d4.loss_iou_aux0: 0.0857, loss_cls_aux1: 0.0143, loss_bbox_aux1: 0.0377, loss_iou_aux1: 0.2089, d0.loss_cls_aux1: 0.0154, d0.loss_bbox_aux1: 0.0441, d0.loss_iou_aux1: 0.2389, d1.loss_cls_aux1: 0.0152, d1.loss_bbox_aux1: 0.0389, d1.loss_iou_aux1: 0.2139, d2.loss_cls_aux1: 0.0151, d2.loss_bbox_aux1: 0.0379, d2.loss_iou_aux1: 0.2097, d3.loss_cls_aux1: 0.0145, d3.loss_bbox_aux1: 0.0378, d3.loss_iou_aux1: 0.2088, d4.loss_cls_aux1: 0.0144, d4.loss_bbox_aux1: 0.0377, d4.loss_iou_aux1: 0.2089, loss: 25.1831, grad_norm: 127.4489
2024-03-18 22:37:22,073 - mmdet - INFO - Epoch [13][200/463]	lr: 1.000e-06, eta: 1:10:00, time: 2.611, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1169, enc_loss_bbox: 0.0621, enc_loss_iou: 0.3294, loss_cls: 0.0717, loss_bbox: 0.0610, loss_iou: 0.3250, d0.loss_cls: 0.1493, d0.loss_bbox: 0.0611, d0.loss_iou: 0.3238, d1.loss_cls: 0.0786, d1.loss_bbox: 0.0612, d1.loss_iou: 0.3246, d2.loss_cls: 0.0731, d2.loss_bbox: 0.0611, d2.loss_iou: 0.3251, d3.loss_cls: 0.0724, d3.loss_bbox: 0.0610, d3.loss_iou: 0.3250, d4.loss_cls: 0.0714, d4.loss_bbox: 0.0611, d4.loss_iou: 0.3255, dn_loss_cls: 0.0092, dn_loss_bbox: 0.0334, dn_loss_iou: 0.1956, d0.dn_loss_cls: 0.0330, d0.dn_loss_bbox: 0.0475, d0.dn_loss_iou: 0.2712, d1.dn_loss_cls: 0.0115, d1.dn_loss_bbox: 0.0340, d1.dn_loss_iou: 0.1990, d2.dn_loss_cls: 0.0097, d2.dn_loss_bbox: 0.0334, d2.dn_loss_iou: 0.1955, d3.dn_loss_cls: 0.0087, d3.dn_loss_bbox: 0.0334, d3.dn_loss_iou: 0.1956, d4.dn_loss_cls: 0.0088, d4.dn_loss_bbox: 0.0334, d4.dn_loss_iou: 0.1957, loss_rpn_cls: 0.0235, loss_rpn_bbox: 0.1387, loss_cls0: 2.0001, acc0: 93.0113, loss_bbox0: 3.3245, loss_cls1: 1.4652, loss_bbox1: 3.5937, loss_centerness1: 7.1086, loss_cls_aux0: 0.0178, loss_bbox_aux0: 0.0149, loss_iou_aux0: 0.0797, d0.loss_cls_aux0: 0.0185, d0.loss_bbox_aux0: 0.0392, d0.loss_iou_aux0: 0.2134, d1.loss_cls_aux0: 0.0180, d1.loss_bbox_aux0: 0.0174, d1.loss_iou_aux0: 0.0943, d2.loss_cls_aux0: 0.0195, d2.loss_bbox_aux0: 0.0156, d2.loss_iou_aux0: 0.0833, d3.loss_cls_aux0: 0.0189, d3.loss_bbox_aux0: 0.0149, d3.loss_iou_aux0: 0.0796, d4.loss_cls_aux0: 0.0178, d4.loss_bbox_aux0: 0.0149, d4.loss_iou_aux0: 0.0796, loss_cls_aux1: 0.0176, loss_bbox_aux1: 0.0376, loss_iou_aux1: 0.2085, d0.loss_cls_aux1: 0.0209, d0.loss_bbox_aux1: 0.0446, d0.loss_iou_aux1: 0.2410, d1.loss_cls_aux1: 0.0192, d1.loss_bbox_aux1: 0.0387, d1.loss_iou_aux1: 0.2142, d2.loss_cls_aux1: 0.0190, d2.loss_bbox_aux1: 0.0376, d2.loss_iou_aux1: 0.2085, d3.loss_cls_aux1: 0.0176, d3.loss_bbox_aux1: 0.0376, d3.loss_iou_aux1: 0.2084, d4.loss_cls_aux1: 0.0172, d4.loss_bbox_aux1: 0.0376, d4.loss_iou_aux1: 0.2085, loss: 25.0353, grad_norm: 109.5034
2024-03-18 22:39:31,962 - mmdet - INFO - Epoch [13][250/463]	lr: 1.000e-06, eta: 1:07:54, time: 2.598, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1302, enc_loss_bbox: 0.0682, enc_loss_iou: 0.3425, loss_cls: 0.0860, loss_bbox: 0.0666, loss_iou: 0.3312, d0.loss_cls: 0.1524, d0.loss_bbox: 0.0673, d0.loss_iou: 0.3342, d1.loss_cls: 0.0930, d1.loss_bbox: 0.0666, d1.loss_iou: 0.3311, d2.loss_cls: 0.0886, d2.loss_bbox: 0.0666, d2.loss_iou: 0.3312, d3.loss_cls: 0.0871, d3.loss_bbox: 0.0666, d3.loss_iou: 0.3312, d4.loss_cls: 0.0859, d4.loss_bbox: 0.0666, d4.loss_iou: 0.3312, dn_loss_cls: 0.0068, dn_loss_bbox: 0.0352, dn_loss_iou: 0.1953, d0.dn_loss_cls: 0.0308, d0.dn_loss_bbox: 0.0502, d0.dn_loss_iou: 0.2723, d1.dn_loss_cls: 0.0084, d1.dn_loss_bbox: 0.0360, d1.dn_loss_iou: 0.1989, d2.dn_loss_cls: 0.0070, d2.dn_loss_bbox: 0.0352, d2.dn_loss_iou: 0.1950, d3.dn_loss_cls: 0.0067, d3.dn_loss_bbox: 0.0352, d3.dn_loss_iou: 0.1949, d4.dn_loss_cls: 0.0068, d4.dn_loss_bbox: 0.0352, d4.dn_loss_iou: 0.1948, loss_rpn_cls: 0.0263, loss_rpn_bbox: 0.1633, loss_cls0: 2.0372, acc0: 92.8042, loss_bbox0: 3.2962, loss_cls1: 1.5861, loss_bbox1: 3.6403, loss_centerness1: 7.1260, loss_cls_aux0: 0.0102, loss_bbox_aux0: 0.0165, loss_iou_aux0: 0.0882, d0.loss_cls_aux0: 0.0102, d0.loss_bbox_aux0: 0.0420, d0.loss_iou_aux0: 0.2210, d1.loss_cls_aux0: 0.0101, d1.loss_bbox_aux0: 0.0199, d1.loss_iou_aux0: 0.1061, d2.loss_cls_aux0: 0.0104, d2.loss_bbox_aux0: 0.0173, d2.loss_iou_aux0: 0.0926, d3.loss_cls_aux0: 0.0097, d3.loss_bbox_aux0: 0.0165, d3.loss_iou_aux0: 0.0882, d4.loss_cls_aux0: 0.0101, d4.loss_bbox_aux0: 0.0165, d4.loss_iou_aux0: 0.0882, loss_cls_aux1: 0.0081, loss_bbox_aux1: 0.0389, loss_iou_aux1: 0.2083, d0.loss_cls_aux1: 0.0102, d0.loss_bbox_aux1: 0.0460, d0.loss_iou_aux1: 0.2428, d1.loss_cls_aux1: 0.0094, d1.loss_bbox_aux1: 0.0398, d1.loss_iou_aux1: 0.2134, d2.loss_cls_aux1: 0.0094, d2.loss_bbox_aux1: 0.0390, d2.loss_iou_aux1: 0.2088, d3.loss_cls_aux1: 0.0086, d3.loss_bbox_aux1: 0.0389, d3.loss_iou_aux1: 0.2084, d4.loss_cls_aux1: 0.0081, d4.loss_bbox_aux1: 0.0389, d4.loss_iou_aux1: 0.2083, loss: 25.4034, grad_norm: 122.7399
2024-03-18 22:41:44,814 - mmdet - INFO - Epoch [13][300/463]	lr: 1.000e-06, eta: 1:05:48, time: 2.657, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1472, enc_loss_bbox: 0.0622, enc_loss_iou: 0.3320, loss_cls: 0.0936, loss_bbox: 0.0614, loss_iou: 0.3255, d0.loss_cls: 0.1725, d0.loss_bbox: 0.0610, d0.loss_iou: 0.3256, d1.loss_cls: 0.0976, d1.loss_bbox: 0.0611, d1.loss_iou: 0.3257, d2.loss_cls: 0.0931, d2.loss_bbox: 0.0615, d2.loss_iou: 0.3261, d3.loss_cls: 0.0937, d3.loss_bbox: 0.0614, d3.loss_iou: 0.3254, d4.loss_cls: 0.0931, d4.loss_bbox: 0.0614, d4.loss_iou: 0.3255, dn_loss_cls: 0.0151, dn_loss_bbox: 0.0330, dn_loss_iou: 0.1929, d0.dn_loss_cls: 0.0471, d0.dn_loss_bbox: 0.0471, d0.dn_loss_iou: 0.2652, d1.dn_loss_cls: 0.0201, d1.dn_loss_bbox: 0.0338, d1.dn_loss_iou: 0.1962, d2.dn_loss_cls: 0.0176, d2.dn_loss_bbox: 0.0330, d2.dn_loss_iou: 0.1928, d3.dn_loss_cls: 0.0162, d3.dn_loss_bbox: 0.0330, d3.dn_loss_iou: 0.1926, d4.dn_loss_cls: 0.0159, d4.dn_loss_bbox: 0.0330, d4.dn_loss_iou: 0.1927, loss_rpn_cls: 0.0232, loss_rpn_bbox: 0.1430, loss_cls0: 2.2048, acc0: 92.3262, loss_bbox0: 3.4458, loss_cls1: 1.6298, loss_bbox1: 3.6112, loss_centerness1: 7.1174, loss_cls_aux0: 0.0333, loss_bbox_aux0: 0.0152, loss_iou_aux0: 0.0825, d0.loss_cls_aux0: 0.0320, d0.loss_bbox_aux0: 0.0389, d0.loss_iou_aux0: 0.2188, d1.loss_cls_aux0: 0.0382, d1.loss_bbox_aux0: 0.0183, d1.loss_iou_aux0: 0.1002, d2.loss_cls_aux0: 0.0367, d2.loss_bbox_aux0: 0.0159, d2.loss_iou_aux0: 0.0865, d3.loss_cls_aux0: 0.0351, d3.loss_bbox_aux0: 0.0152, d3.loss_iou_aux0: 0.0826, d4.loss_cls_aux0: 0.0334, d4.loss_bbox_aux0: 0.0152, d4.loss_iou_aux0: 0.0824, loss_cls_aux1: 0.0268, loss_bbox_aux1: 0.0358, loss_iou_aux1: 0.1998, d0.loss_cls_aux1: 0.0270, d0.loss_bbox_aux1: 0.0430, d0.loss_iou_aux1: 0.2356, d1.loss_cls_aux1: 0.0287, d1.loss_bbox_aux1: 0.0369, d1.loss_iou_aux1: 0.2055, d2.loss_cls_aux1: 0.0283, d2.loss_bbox_aux1: 0.0359, d2.loss_iou_aux1: 0.2000, d3.loss_cls_aux1: 0.0277, d3.loss_bbox_aux1: 0.0358, d3.loss_iou_aux1: 0.1998, d4.loss_cls_aux1: 0.0264, d4.loss_bbox_aux1: 0.0358, d4.loss_iou_aux1: 0.1998, loss: 25.8684, grad_norm: 111.8516
2024-03-18 22:43:46,973 - mmdet - INFO - Epoch [13][350/463]	lr: 1.000e-06, eta: 1:03:40, time: 2.443, data_time: 0.011, memory: 19333, enc_loss_cls: 0.1349, enc_loss_bbox: 0.0581, enc_loss_iou: 0.3192, loss_cls: 0.0795, loss_bbox: 0.0578, loss_iou: 0.3181, d0.loss_cls: 0.1596, d0.loss_bbox: 0.0573, d0.loss_iou: 0.3153, d1.loss_cls: 0.0890, d1.loss_bbox: 0.0581, d1.loss_iou: 0.3174, d2.loss_cls: 0.0830, d2.loss_bbox: 0.0577, d2.loss_iou: 0.3181, d3.loss_cls: 0.0804, d3.loss_bbox: 0.0577, d3.loss_iou: 0.3180, d4.loss_cls: 0.0790, d4.loss_bbox: 0.0578, d4.loss_iou: 0.3185, dn_loss_cls: 0.0070, dn_loss_bbox: 0.0333, dn_loss_iou: 0.1939, d0.dn_loss_cls: 0.0265, d0.dn_loss_bbox: 0.0464, d0.dn_loss_iou: 0.2594, d1.dn_loss_cls: 0.0083, d1.dn_loss_bbox: 0.0339, d1.dn_loss_iou: 0.1963, d2.dn_loss_cls: 0.0076, d2.dn_loss_bbox: 0.0333, d2.dn_loss_iou: 0.1935, d3.dn_loss_cls: 0.0070, d3.dn_loss_bbox: 0.0333, d3.dn_loss_iou: 0.1939, d4.dn_loss_cls: 0.0072, d4.dn_loss_bbox: 0.0333, d4.dn_loss_iou: 0.1939, loss_rpn_cls: 0.0198, loss_rpn_bbox: 0.1480, loss_cls0: 2.0245, acc0: 92.9648, loss_bbox0: 3.2754, loss_cls1: 1.4861, loss_bbox1: 3.5255, loss_centerness1: 7.1365, loss_cls_aux0: 0.0112, loss_bbox_aux0: 0.0136, loss_iou_aux0: 0.0748, d0.loss_cls_aux0: 0.0125, d0.loss_bbox_aux0: 0.0375, d0.loss_iou_aux0: 0.2083, d1.loss_cls_aux0: 0.0115, d1.loss_bbox_aux0: 0.0166, d1.loss_iou_aux0: 0.0916, d2.loss_cls_aux0: 0.0114, d2.loss_bbox_aux0: 0.0143, d2.loss_iou_aux0: 0.0792, d3.loss_cls_aux0: 0.0109, d3.loss_bbox_aux0: 0.0136, d3.loss_iou_aux0: 0.0748, d4.loss_cls_aux0: 0.0108, d4.loss_bbox_aux0: 0.0135, d4.loss_iou_aux0: 0.0748, loss_cls_aux1: 0.0081, loss_bbox_aux1: 0.0361, loss_iou_aux1: 0.2065, d0.loss_cls_aux1: 0.0099, d0.loss_bbox_aux1: 0.0434, d0.loss_iou_aux1: 0.2419, d1.loss_cls_aux1: 0.0089, d1.loss_bbox_aux1: 0.0371, d1.loss_iou_aux1: 0.2109, d2.loss_cls_aux1: 0.0088, d2.loss_bbox_aux1: 0.0363, d2.loss_iou_aux1: 0.2072, d3.loss_cls_aux1: 0.0085, d3.loss_bbox_aux1: 0.0361, d3.loss_iou_aux1: 0.2065, d4.loss_cls_aux1: 0.0081, d4.loss_bbox_aux1: 0.0361, d4.loss_iou_aux1: 0.2065, loss: 24.7961, grad_norm: 158.7825
2024-03-18 22:45:59,954 - mmdet - INFO - Epoch [13][400/463]	lr: 1.000e-06, eta: 1:01:34, time: 2.660, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1283, enc_loss_bbox: 0.0595, enc_loss_iou: 0.3256, loss_cls: 0.0805, loss_bbox: 0.0585, loss_iou: 0.3197, d0.loss_cls: 0.1626, d0.loss_bbox: 0.0581, d0.loss_iou: 0.3184, d1.loss_cls: 0.0882, d1.loss_bbox: 0.0584, d1.loss_iou: 0.3197, d2.loss_cls: 0.0839, d2.loss_bbox: 0.0583, d2.loss_iou: 0.3186, d3.loss_cls: 0.0803, d3.loss_bbox: 0.0584, d3.loss_iou: 0.3194, d4.loss_cls: 0.0814, d4.loss_bbox: 0.0583, d4.loss_iou: 0.3192, dn_loss_cls: 0.0152, dn_loss_bbox: 0.0324, dn_loss_iou: 0.1946, d0.dn_loss_cls: 0.0367, d0.dn_loss_bbox: 0.0451, d0.dn_loss_iou: 0.2637, d1.dn_loss_cls: 0.0158, d1.dn_loss_bbox: 0.0330, d1.dn_loss_iou: 0.1974, d2.dn_loss_cls: 0.0150, d2.dn_loss_bbox: 0.0324, d2.dn_loss_iou: 0.1944, d3.dn_loss_cls: 0.0146, d3.dn_loss_bbox: 0.0324, d3.dn_loss_iou: 0.1942, d4.dn_loss_cls: 0.0151, d4.dn_loss_bbox: 0.0324, d4.dn_loss_iou: 0.1943, loss_rpn_cls: 0.0132, loss_rpn_bbox: 0.1348, loss_cls0: 1.9730, acc0: 93.1508, loss_bbox0: 3.1468, loss_cls1: 1.4953, loss_bbox1: 3.5505, loss_centerness1: 7.1071, loss_cls_aux0: 0.0215, loss_bbox_aux0: 0.0135, loss_iou_aux0: 0.0766, d0.loss_cls_aux0: 0.0204, d0.loss_bbox_aux0: 0.0382, d0.loss_iou_aux0: 0.2141, d1.loss_cls_aux0: 0.0220, d1.loss_bbox_aux0: 0.0161, d1.loss_iou_aux0: 0.0915, d2.loss_cls_aux0: 0.0207, d2.loss_bbox_aux0: 0.0141, d2.loss_iou_aux0: 0.0804, d3.loss_cls_aux0: 0.0200, d3.loss_bbox_aux0: 0.0135, d3.loss_iou_aux0: 0.0764, d4.loss_cls_aux0: 0.0214, d4.loss_bbox_aux0: 0.0135, d4.loss_iou_aux0: 0.0764, loss_cls_aux1: 0.0122, loss_bbox_aux1: 0.0367, loss_iou_aux1: 0.2052, d0.loss_cls_aux1: 0.0133, d0.loss_bbox_aux1: 0.0432, d0.loss_iou_aux1: 0.2384, d1.loss_cls_aux1: 0.0133, d1.loss_bbox_aux1: 0.0378, d1.loss_iou_aux1: 0.2110, d2.loss_cls_aux1: 0.0128, d2.loss_bbox_aux1: 0.0368, d2.loss_iou_aux1: 0.2057, d3.loss_cls_aux1: 0.0121, d3.loss_bbox_aux1: 0.0367, d3.loss_iou_aux1: 0.2051, d4.loss_cls_aux1: 0.0122, d4.loss_bbox_aux1: 0.0367, d4.loss_iou_aux1: 0.2052, loss: 24.7597, grad_norm: 116.8544
2024-03-18 22:48:14,298 - mmdet - INFO - Epoch [13][450/463]	lr: 1.000e-06, eta: 0:59:29, time: 2.687, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1259, enc_loss_bbox: 0.0556, enc_loss_iou: 0.3158, loss_cls: 0.0806, loss_bbox: 0.0545, loss_iou: 0.3100, d0.loss_cls: 0.1591, d0.loss_bbox: 0.0547, d0.loss_iou: 0.3104, d1.loss_cls: 0.0871, d1.loss_bbox: 0.0543, d1.loss_iou: 0.3095, d2.loss_cls: 0.0836, d2.loss_bbox: 0.0545, d2.loss_iou: 0.3102, d3.loss_cls: 0.0816, d3.loss_bbox: 0.0545, d3.loss_iou: 0.3098, d4.loss_cls: 0.0810, d4.loss_bbox: 0.0545, d4.loss_iou: 0.3098, dn_loss_cls: 0.0057, dn_loss_bbox: 0.0313, dn_loss_iou: 0.1905, d0.dn_loss_cls: 0.0240, d0.dn_loss_bbox: 0.0430, d0.dn_loss_iou: 0.2558, d1.dn_loss_cls: 0.0079, d1.dn_loss_bbox: 0.0318, d1.dn_loss_iou: 0.1934, d2.dn_loss_cls: 0.0060, d2.dn_loss_bbox: 0.0313, d2.dn_loss_iou: 0.1906, d3.dn_loss_cls: 0.0055, d3.dn_loss_bbox: 0.0313, d3.dn_loss_iou: 0.1905, d4.dn_loss_cls: 0.0056, d4.dn_loss_bbox: 0.0313, d4.dn_loss_iou: 0.1905, loss_rpn_cls: 0.0234, loss_rpn_bbox: 0.1475, loss_cls0: 1.9358, acc0: 93.1552, loss_bbox0: 3.1055, loss_cls1: 1.4808, loss_bbox1: 3.4417, loss_centerness1: 7.1069, loss_cls_aux0: 0.0107, loss_bbox_aux0: 0.0128, loss_iou_aux0: 0.0766, d0.loss_cls_aux0: 0.0129, d0.loss_bbox_aux0: 0.0354, d0.loss_iou_aux0: 0.2108, d1.loss_cls_aux0: 0.0130, d1.loss_bbox_aux0: 0.0153, d1.loss_iou_aux0: 0.0916, d2.loss_cls_aux0: 0.0117, d2.loss_bbox_aux0: 0.0135, d2.loss_iou_aux0: 0.0805, d3.loss_cls_aux0: 0.0111, d3.loss_bbox_aux0: 0.0128, d3.loss_iou_aux0: 0.0765, d4.loss_cls_aux0: 0.0104, d4.loss_bbox_aux0: 0.0128, d4.loss_iou_aux0: 0.0765, loss_cls_aux1: 0.0080, loss_bbox_aux1: 0.0345, loss_iou_aux1: 0.2038, d0.loss_cls_aux1: 0.0105, d0.loss_bbox_aux1: 0.0405, d0.loss_iou_aux1: 0.2353, d1.loss_cls_aux1: 0.0099, d1.loss_bbox_aux1: 0.0355, d1.loss_iou_aux1: 0.2092, d2.loss_cls_aux1: 0.0092, d2.loss_bbox_aux1: 0.0345, d2.loss_iou_aux1: 0.2040, d3.loss_cls_aux1: 0.0086, d3.loss_bbox_aux1: 0.0346, d3.loss_iou_aux1: 0.2038, d4.loss_cls_aux1: 0.0083, d4.loss_bbox_aux1: 0.0345, d4.loss_iou_aux1: 0.2038, loss: 24.2776, grad_norm: 113.3707
2024-03-18 22:48:46,559 - mmdet - INFO - Saving checkpoint at 13 epochs
2024-03-18 22:50:16,350 - mmdet - INFO - Evaluating bbox...
2024-03-18 22:50:32,704 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.615
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.891
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.742
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.501
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.589
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.810
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.729
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.852

2024-03-18 22:50:32,704 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.657 | Thatch   | 0.576 |
+----------+-------+----------+-------+
2024-03-18 22:50:32,838 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 22:50:32,838 - mmdet - INFO - Epoch(val) [13][154]	bbox_mAP: 0.6150, bbox_mAP_50: 0.8910, bbox_mAP_75: 0.7420, bbox_mAP_s: 0.5010, bbox_mAP_m: 0.5890, bbox_mAP_l: 0.8100, bbox_mAP_copypaste: 0.615 0.891 0.742 0.501 0.589 0.810
2024-03-18 22:52:45,232 - mmdet - INFO - Epoch [14][50/463]	lr: 1.000e-06, eta: 0:56:42, time: 2.648, data_time: 0.058, memory: 19333, enc_loss_cls: 0.1316, enc_loss_bbox: 0.0625, enc_loss_iou: 0.3174, loss_cls: 0.0769, loss_bbox: 0.0619, loss_iou: 0.3141, d0.loss_cls: 0.1587, d0.loss_bbox: 0.0614, d0.loss_iou: 0.3115, d1.loss_cls: 0.0878, d1.loss_bbox: 0.0618, d1.loss_iou: 0.3133, d2.loss_cls: 0.0777, d2.loss_bbox: 0.0621, d2.loss_iou: 0.3154, d3.loss_cls: 0.0767, d3.loss_bbox: 0.0623, d3.loss_iou: 0.3145, d4.loss_cls: 0.0763, d4.loss_bbox: 0.0623, d4.loss_iou: 0.3148, dn_loss_cls: 0.0113, dn_loss_bbox: 0.0348, dn_loss_iou: 0.1983, d0.dn_loss_cls: 0.0336, d0.dn_loss_bbox: 0.0485, d0.dn_loss_iou: 0.2676, d1.dn_loss_cls: 0.0130, d1.dn_loss_bbox: 0.0355, d1.dn_loss_iou: 0.2006, d2.dn_loss_cls: 0.0113, d2.dn_loss_bbox: 0.0348, d2.dn_loss_iou: 0.1976, d3.dn_loss_cls: 0.0114, d3.dn_loss_bbox: 0.0348, d3.dn_loss_iou: 0.1976, d4.dn_loss_cls: 0.0111, d4.dn_loss_bbox: 0.0348, d4.dn_loss_iou: 0.1976, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.1263, loss_cls0: 1.9017, acc0: 93.4503, loss_bbox0: 3.1423, loss_cls1: 1.4535, loss_bbox1: 3.4388, loss_centerness1: 7.0926, loss_cls_aux0: 0.0204, loss_bbox_aux0: 0.0130, loss_iou_aux0: 0.0693, d0.loss_cls_aux0: 0.0199, d0.loss_bbox_aux0: 0.0384, d0.loss_iou_aux0: 0.2062, d1.loss_cls_aux0: 0.0197, d1.loss_bbox_aux0: 0.0161, d1.loss_iou_aux0: 0.0858, d2.loss_cls_aux0: 0.0201, d2.loss_bbox_aux0: 0.0139, d2.loss_iou_aux0: 0.0737, d3.loss_cls_aux0: 0.0206, d3.loss_bbox_aux0: 0.0130, d3.loss_iou_aux0: 0.0692, d4.loss_cls_aux0: 0.0205, d4.loss_bbox_aux0: 0.0130, d4.loss_iou_aux0: 0.0692, loss_cls_aux1: 0.0151, loss_bbox_aux1: 0.0380, loss_iou_aux1: 0.2054, d0.loss_cls_aux1: 0.0169, d0.loss_bbox_aux1: 0.0454, d0.loss_iou_aux1: 0.2371, d1.loss_cls_aux1: 0.0151, d1.loss_bbox_aux1: 0.0392, d1.loss_iou_aux1: 0.2107, d2.loss_cls_aux1: 0.0153, d2.loss_bbox_aux1: 0.0381, d2.loss_iou_aux1: 0.2057, d3.loss_cls_aux1: 0.0157, d3.loss_bbox_aux1: 0.0380, d3.loss_iou_aux1: 0.2054, d4.loss_cls_aux1: 0.0156, d4.loss_bbox_aux1: 0.0380, d4.loss_iou_aux1: 0.2054, loss: 24.4694, grad_norm: 103.0614
2024-03-18 22:54:50,856 - mmdet - INFO - Epoch [14][100/463]	lr: 1.000e-06, eta: 0:54:35, time: 2.512, data_time: 0.011, memory: 19333, enc_loss_cls: 0.1357, enc_loss_bbox: 0.0588, enc_loss_iou: 0.3117, loss_cls: 0.0863, loss_bbox: 0.0592, loss_iou: 0.3072, d0.loss_cls: 0.1623, d0.loss_bbox: 0.0584, d0.loss_iou: 0.3077, d1.loss_cls: 0.0904, d1.loss_bbox: 0.0588, d1.loss_iou: 0.3075, d2.loss_cls: 0.0875, d2.loss_bbox: 0.0592, d2.loss_iou: 0.3070, d3.loss_cls: 0.0853, d3.loss_bbox: 0.0592, d3.loss_iou: 0.3070, d4.loss_cls: 0.0855, d4.loss_bbox: 0.0592, d4.loss_iou: 0.3072, dn_loss_cls: 0.0154, dn_loss_bbox: 0.0333, dn_loss_iou: 0.1925, d0.dn_loss_cls: 0.0387, d0.dn_loss_bbox: 0.0470, d0.dn_loss_iou: 0.2643, d1.dn_loss_cls: 0.0162, d1.dn_loss_bbox: 0.0339, d1.dn_loss_iou: 0.1965, d2.dn_loss_cls: 0.0149, d2.dn_loss_bbox: 0.0333, d2.dn_loss_iou: 0.1928, d3.dn_loss_cls: 0.0141, d3.dn_loss_bbox: 0.0333, d3.dn_loss_iou: 0.1930, d4.dn_loss_cls: 0.0146, d4.dn_loss_bbox: 0.0333, d4.dn_loss_iou: 0.1929, loss_rpn_cls: 0.0164, loss_rpn_bbox: 0.1184, loss_cls0: 1.8591, acc0: 93.5468, loss_bbox0: 3.1514, loss_cls1: 1.4352, loss_bbox1: 3.3905, loss_centerness1: 7.1284, loss_cls_aux0: 0.0218, loss_bbox_aux0: 0.0121, loss_iou_aux0: 0.0634, d0.loss_cls_aux0: 0.0179, d0.loss_bbox_aux0: 0.0363, d0.loss_iou_aux0: 0.1993, d1.loss_cls_aux0: 0.0204, d1.loss_bbox_aux0: 0.0149, d1.loss_iou_aux0: 0.0799, d2.loss_cls_aux0: 0.0215, d2.loss_bbox_aux0: 0.0128, d2.loss_iou_aux0: 0.0671, d3.loss_cls_aux0: 0.0210, d3.loss_bbox_aux0: 0.0121, d3.loss_iou_aux0: 0.0631, d4.loss_cls_aux0: 0.0215, d4.loss_bbox_aux0: 0.0121, d4.loss_iou_aux0: 0.0632, loss_cls_aux1: 0.0185, loss_bbox_aux1: 0.0374, loss_iou_aux1: 0.2040, d0.loss_cls_aux1: 0.0167, d0.loss_bbox_aux1: 0.0433, d0.loss_iou_aux1: 0.2332, d1.loss_cls_aux1: 0.0177, d1.loss_bbox_aux1: 0.0384, d1.loss_iou_aux1: 0.2093, d2.loss_cls_aux1: 0.0188, d2.loss_bbox_aux1: 0.0375, d2.loss_iou_aux1: 0.2046, d3.loss_cls_aux1: 0.0186, d3.loss_bbox_aux1: 0.0374, d3.loss_iou_aux1: 0.2040, d4.loss_cls_aux1: 0.0183, d4.loss_bbox_aux1: 0.0374, d4.loss_iou_aux1: 0.2040, loss: 24.3205, grad_norm: 119.2415
2024-03-18 22:57:01,483 - mmdet - INFO - Epoch [14][150/463]	lr: 1.000e-06, eta: 0:52:28, time: 2.612, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1204, enc_loss_bbox: 0.0688, enc_loss_iou: 0.3501, loss_cls: 0.0742, loss_bbox: 0.0680, loss_iou: 0.3453, d0.loss_cls: 0.1429, d0.loss_bbox: 0.0683, d0.loss_iou: 0.3466, d1.loss_cls: 0.0796, d1.loss_bbox: 0.0682, d1.loss_iou: 0.3467, d2.loss_cls: 0.0752, d2.loss_bbox: 0.0681, d2.loss_iou: 0.3453, d3.loss_cls: 0.0743, d3.loss_bbox: 0.0681, d3.loss_iou: 0.3455, d4.loss_cls: 0.0742, d4.loss_bbox: 0.0681, d4.loss_iou: 0.3454, dn_loss_cls: 0.0053, dn_loss_bbox: 0.0357, dn_loss_iou: 0.1965, d0.dn_loss_cls: 0.0286, d0.dn_loss_bbox: 0.0517, d0.dn_loss_iou: 0.2739, d1.dn_loss_cls: 0.0073, d1.dn_loss_bbox: 0.0364, d1.dn_loss_iou: 0.1994, d2.dn_loss_cls: 0.0056, d2.dn_loss_bbox: 0.0357, d2.dn_loss_iou: 0.1966, d3.dn_loss_cls: 0.0054, d3.dn_loss_bbox: 0.0357, d3.dn_loss_iou: 0.1965, d4.dn_loss_cls: 0.0052, d4.dn_loss_bbox: 0.0357, d4.dn_loss_iou: 0.1965, loss_rpn_cls: 0.0272, loss_rpn_bbox: 0.1523, loss_cls0: 2.0507, acc0: 92.7375, loss_bbox0: 3.3513, loss_cls1: 1.5644, loss_bbox1: 3.8026, loss_centerness1: 7.1216, loss_cls_aux0: 0.0100, loss_bbox_aux0: 0.0151, loss_iou_aux0: 0.0844, d0.loss_cls_aux0: 0.0112, d0.loss_bbox_aux0: 0.0417, d0.loss_iou_aux0: 0.2226, d1.loss_cls_aux0: 0.0103, d1.loss_bbox_aux0: 0.0183, d1.loss_iou_aux0: 0.1010, d2.loss_cls_aux0: 0.0105, d2.loss_bbox_aux0: 0.0158, d2.loss_iou_aux0: 0.0881, d3.loss_cls_aux0: 0.0105, d3.loss_bbox_aux0: 0.0151, d3.loss_iou_aux0: 0.0843, d4.loss_cls_aux0: 0.0098, d4.loss_bbox_aux0: 0.0151, d4.loss_iou_aux0: 0.0843, loss_cls_aux1: 0.0084, loss_bbox_aux1: 0.0392, loss_iou_aux1: 0.2099, d0.loss_cls_aux1: 0.0109, d0.loss_bbox_aux1: 0.0473, d0.loss_iou_aux1: 0.2482, d1.loss_cls_aux1: 0.0089, d1.loss_bbox_aux1: 0.0405, d1.loss_iou_aux1: 0.2161, d2.loss_cls_aux1: 0.0079, d2.loss_bbox_aux1: 0.0393, d2.loss_iou_aux1: 0.2102, d3.loss_cls_aux1: 0.0080, d3.loss_bbox_aux1: 0.0392, d3.loss_iou_aux1: 0.2099, d4.loss_cls_aux1: 0.0083, d4.loss_bbox_aux1: 0.0392, d4.loss_iou_aux1: 0.2099, loss: 25.6104, grad_norm: 124.7725
2024-03-18 22:59:12,293 - mmdet - INFO - Epoch [14][200/463]	lr: 1.000e-06, eta: 0:50:22, time: 2.616, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1462, enc_loss_bbox: 0.0647, enc_loss_iou: 0.3465, loss_cls: 0.0896, loss_bbox: 0.0638, loss_iou: 0.3429, d0.loss_cls: 0.1702, d0.loss_bbox: 0.0637, d0.loss_iou: 0.3413, d1.loss_cls: 0.0984, d1.loss_bbox: 0.0637, d1.loss_iou: 0.3416, d2.loss_cls: 0.0924, d2.loss_bbox: 0.0639, d2.loss_iou: 0.3431, d3.loss_cls: 0.0905, d3.loss_bbox: 0.0638, d3.loss_iou: 0.3428, d4.loss_cls: 0.0892, d4.loss_bbox: 0.0639, d4.loss_iou: 0.3433, dn_loss_cls: 0.0077, dn_loss_bbox: 0.0324, dn_loss_iou: 0.1956, d0.dn_loss_cls: 0.0287, d0.dn_loss_bbox: 0.0464, d0.dn_loss_iou: 0.2700, d1.dn_loss_cls: 0.0092, d1.dn_loss_bbox: 0.0331, d1.dn_loss_iou: 0.1996, d2.dn_loss_cls: 0.0080, d2.dn_loss_bbox: 0.0324, d2.dn_loss_iou: 0.1959, d3.dn_loss_cls: 0.0076, d3.dn_loss_bbox: 0.0324, d3.dn_loss_iou: 0.1956, d4.dn_loss_cls: 0.0077, d4.dn_loss_bbox: 0.0324, d4.dn_loss_iou: 0.1956, loss_rpn_cls: 0.0208, loss_rpn_bbox: 0.1388, loss_cls0: 2.0327, acc0: 92.8479, loss_bbox0: 3.2663, loss_cls1: 1.6594, loss_bbox1: 3.7430, loss_centerness1: 7.1367, loss_cls_aux0: 0.0111, loss_bbox_aux0: 0.0145, loss_iou_aux0: 0.0817, d0.loss_cls_aux0: 0.0115, d0.loss_bbox_aux0: 0.0391, d0.loss_iou_aux0: 0.2243, d1.loss_cls_aux0: 0.0108, d1.loss_bbox_aux0: 0.0176, d1.loss_iou_aux0: 0.1006, d2.loss_cls_aux0: 0.0113, d2.loss_bbox_aux0: 0.0152, d2.loss_iou_aux0: 0.0859, d3.loss_cls_aux0: 0.0113, d3.loss_bbox_aux0: 0.0145, d3.loss_iou_aux0: 0.0817, d4.loss_cls_aux0: 0.0111, d4.loss_bbox_aux0: 0.0145, d4.loss_iou_aux0: 0.0817, loss_cls_aux1: 0.0113, loss_bbox_aux1: 0.0351, loss_iou_aux1: 0.2029, d0.loss_cls_aux1: 0.0124, d0.loss_bbox_aux1: 0.0430, d0.loss_iou_aux1: 0.2449, d1.loss_cls_aux1: 0.0121, d1.loss_bbox_aux1: 0.0360, d1.loss_iou_aux1: 0.2075, d2.loss_cls_aux1: 0.0117, d2.loss_bbox_aux1: 0.0352, d2.loss_iou_aux1: 0.2032, d3.loss_cls_aux1: 0.0115, d3.loss_bbox_aux1: 0.0351, d3.loss_iou_aux1: 0.2028, d4.loss_cls_aux1: 0.0114, d4.loss_bbox_aux1: 0.0351, d4.loss_iou_aux1: 0.2029, loss: 25.5462, grad_norm: 125.9282
2024-03-18 23:01:22,361 - mmdet - INFO - Epoch [14][250/463]	lr: 1.000e-06, eta: 0:48:15, time: 2.601, data_time: 0.011, memory: 19333, enc_loss_cls: 0.1307, enc_loss_bbox: 0.0588, enc_loss_iou: 0.3267, loss_cls: 0.0870, loss_bbox: 0.0576, loss_iou: 0.3209, d0.loss_cls: 0.1551, d0.loss_bbox: 0.0580, d0.loss_iou: 0.3214, d1.loss_cls: 0.0922, d1.loss_bbox: 0.0579, d1.loss_iou: 0.3215, d2.loss_cls: 0.0884, d2.loss_bbox: 0.0578, d2.loss_iou: 0.3214, d3.loss_cls: 0.0864, d3.loss_bbox: 0.0577, d3.loss_iou: 0.3211, d4.loss_cls: 0.0865, d4.loss_bbox: 0.0577, d4.loss_iou: 0.3211, dn_loss_cls: 0.0062, dn_loss_bbox: 0.0323, dn_loss_iou: 0.1885, d0.dn_loss_cls: 0.0256, d0.dn_loss_bbox: 0.0445, d0.dn_loss_iou: 0.2547, d1.dn_loss_cls: 0.0082, d1.dn_loss_bbox: 0.0329, d1.dn_loss_iou: 0.1915, d2.dn_loss_cls: 0.0068, d2.dn_loss_bbox: 0.0323, d2.dn_loss_iou: 0.1887, d3.dn_loss_cls: 0.0061, d3.dn_loss_bbox: 0.0323, d3.dn_loss_iou: 0.1885, d4.dn_loss_cls: 0.0061, d4.dn_loss_bbox: 0.0323, d4.dn_loss_iou: 0.1885, loss_rpn_cls: 0.0166, loss_rpn_bbox: 0.1445, loss_cls0: 2.0410, acc0: 92.8133, loss_bbox0: 3.2920, loss_cls1: 1.5243, loss_bbox1: 3.5961, loss_centerness1: 7.1319, loss_cls_aux0: 0.0108, loss_bbox_aux0: 0.0144, loss_iou_aux0: 0.0805, d0.loss_cls_aux0: 0.0122, d0.loss_bbox_aux0: 0.0387, d0.loss_iou_aux0: 0.2171, d1.loss_cls_aux0: 0.0123, d1.loss_bbox_aux0: 0.0172, d1.loss_iou_aux0: 0.0963, d2.loss_cls_aux0: 0.0118, d2.loss_bbox_aux0: 0.0150, d2.loss_iou_aux0: 0.0841, d3.loss_cls_aux0: 0.0108, d3.loss_bbox_aux0: 0.0144, d3.loss_iou_aux0: 0.0802, d4.loss_cls_aux0: 0.0106, d4.loss_bbox_aux0: 0.0144, d4.loss_iou_aux0: 0.0803, loss_cls_aux1: 0.0095, loss_bbox_aux1: 0.0361, loss_iou_aux1: 0.2090, d0.loss_cls_aux1: 0.0116, d0.loss_bbox_aux1: 0.0420, d0.loss_iou_aux1: 0.2415, d1.loss_cls_aux1: 0.0105, d1.loss_bbox_aux1: 0.0373, d1.loss_iou_aux1: 0.2148, d2.loss_cls_aux1: 0.0095, d2.loss_bbox_aux1: 0.0362, d2.loss_iou_aux1: 0.2093, d3.loss_cls_aux1: 0.0093, d3.loss_bbox_aux1: 0.0361, d3.loss_iou_aux1: 0.2089, d4.loss_cls_aux1: 0.0096, d4.loss_bbox_aux1: 0.0361, d4.loss_iou_aux1: 0.2090, loss: 24.9953, grad_norm: 107.2324
2024-03-18 23:03:35,360 - mmdet - INFO - Epoch [14][300/463]	lr: 1.000e-06, eta: 0:46:09, time: 2.660, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1268, enc_loss_bbox: 0.0669, enc_loss_iou: 0.3416, loss_cls: 0.0755, loss_bbox: 0.0675, loss_iou: 0.3433, d0.loss_cls: 0.1496, d0.loss_bbox: 0.0671, d0.loss_iou: 0.3399, d1.loss_cls: 0.0795, d1.loss_bbox: 0.0679, d1.loss_iou: 0.3442, d2.loss_cls: 0.0747, d2.loss_bbox: 0.0676, d2.loss_iou: 0.3440, d3.loss_cls: 0.0751, d3.loss_bbox: 0.0675, d3.loss_iou: 0.3430, d4.loss_cls: 0.0759, d4.loss_bbox: 0.0671, d4.loss_iou: 0.3430, dn_loss_cls: 0.0082, dn_loss_bbox: 0.0347, dn_loss_iou: 0.1961, d0.dn_loss_cls: 0.0315, d0.dn_loss_bbox: 0.0490, d0.dn_loss_iou: 0.2678, d1.dn_loss_cls: 0.0104, d1.dn_loss_bbox: 0.0354, d1.dn_loss_iou: 0.1996, d2.dn_loss_cls: 0.0087, d2.dn_loss_bbox: 0.0346, d2.dn_loss_iou: 0.1959, d3.dn_loss_cls: 0.0081, d3.dn_loss_bbox: 0.0347, d3.dn_loss_iou: 0.1961, d4.dn_loss_cls: 0.0081, d4.dn_loss_bbox: 0.0347, d4.dn_loss_iou: 0.1961, loss_rpn_cls: 0.0321, loss_rpn_bbox: 0.1713, loss_cls0: 2.1066, acc0: 92.6855, loss_bbox0: 3.4396, loss_cls1: 1.5912, loss_bbox1: 3.6780, loss_centerness1: 7.1009, loss_cls_aux0: 0.0136, loss_bbox_aux0: 0.0170, loss_iou_aux0: 0.0875, d0.loss_cls_aux0: 0.0160, d0.loss_bbox_aux0: 0.0414, d0.loss_iou_aux0: 0.2232, d1.loss_cls_aux0: 0.0159, d1.loss_bbox_aux0: 0.0201, d1.loss_iou_aux0: 0.1043, d2.loss_cls_aux0: 0.0158, d2.loss_bbox_aux0: 0.0177, d2.loss_iou_aux0: 0.0916, d3.loss_cls_aux0: 0.0142, d3.loss_bbox_aux0: 0.0170, d3.loss_iou_aux0: 0.0875, d4.loss_cls_aux0: 0.0127, d4.loss_bbox_aux0: 0.0170, d4.loss_iou_aux0: 0.0875, loss_cls_aux1: 0.0118, loss_bbox_aux1: 0.0385, loss_iou_aux1: 0.2078, d0.loss_cls_aux1: 0.0151, d0.loss_bbox_aux1: 0.0461, d0.loss_iou_aux1: 0.2438, d1.loss_cls_aux1: 0.0137, d1.loss_bbox_aux1: 0.0393, d1.loss_iou_aux1: 0.2125, d2.loss_cls_aux1: 0.0132, d2.loss_bbox_aux1: 0.0384, d2.loss_iou_aux1: 0.2075, d3.loss_cls_aux1: 0.0127, d3.loss_bbox_aux1: 0.0384, d3.loss_iou_aux1: 0.2079, d4.loss_cls_aux1: 0.0114, d4.loss_bbox_aux1: 0.0385, d4.loss_iou_aux1: 0.2078, loss: 25.7009, grad_norm: 115.9231
2024-03-18 23:05:37,631 - mmdet - INFO - Epoch [14][350/463]	lr: 1.000e-06, eta: 0:44:01, time: 2.445, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1326, enc_loss_bbox: 0.0621, enc_loss_iou: 0.3298, loss_cls: 0.0807, loss_bbox: 0.0603, loss_iou: 0.3229, d0.loss_cls: 0.1557, d0.loss_bbox: 0.0612, d0.loss_iou: 0.3251, d1.loss_cls: 0.0904, d1.loss_bbox: 0.0606, d1.loss_iou: 0.3237, d2.loss_cls: 0.0833, d2.loss_bbox: 0.0604, d2.loss_iou: 0.3239, d3.loss_cls: 0.0803, d3.loss_bbox: 0.0603, d3.loss_iou: 0.3229, d4.loss_cls: 0.0792, d4.loss_bbox: 0.0603, d4.loss_iou: 0.3229, dn_loss_cls: 0.0096, dn_loss_bbox: 0.0334, dn_loss_iou: 0.1997, d0.dn_loss_cls: 0.0340, d0.dn_loss_bbox: 0.0472, d0.dn_loss_iou: 0.2728, d1.dn_loss_cls: 0.0120, d1.dn_loss_bbox: 0.0340, d1.dn_loss_iou: 0.2014, d2.dn_loss_cls: 0.0097, d2.dn_loss_bbox: 0.0334, d2.dn_loss_iou: 0.1983, d3.dn_loss_cls: 0.0091, d3.dn_loss_bbox: 0.0334, d3.dn_loss_iou: 0.1980, d4.dn_loss_cls: 0.0093, d4.dn_loss_bbox: 0.0334, d4.dn_loss_iou: 0.1981, loss_rpn_cls: 0.0187, loss_rpn_bbox: 0.1501, loss_cls0: 2.0676, acc0: 92.9348, loss_bbox0: 3.3048, loss_cls1: 1.5449, loss_bbox1: 3.5824, loss_centerness1: 7.1273, loss_cls_aux0: 0.0211, loss_bbox_aux0: 0.0160, loss_iou_aux0: 0.0872, d0.loss_cls_aux0: 0.0231, d0.loss_bbox_aux0: 0.0382, d0.loss_iou_aux0: 0.2164, d1.loss_cls_aux0: 0.0262, d1.loss_bbox_aux0: 0.0189, d1.loss_iou_aux0: 0.1022, d2.loss_cls_aux0: 0.0222, d2.loss_bbox_aux0: 0.0166, d2.loss_iou_aux0: 0.0907, d3.loss_cls_aux0: 0.0198, d3.loss_bbox_aux0: 0.0160, d3.loss_iou_aux0: 0.0871, d4.loss_cls_aux0: 0.0194, d4.loss_bbox_aux0: 0.0160, d4.loss_iou_aux0: 0.0871, loss_cls_aux1: 0.0211, loss_bbox_aux1: 0.0373, loss_iou_aux1: 0.2080, d0.loss_cls_aux1: 0.0233, d0.loss_bbox_aux1: 0.0433, d0.loss_iou_aux1: 0.2386, d1.loss_cls_aux1: 0.0241, d1.loss_bbox_aux1: 0.0383, d1.loss_iou_aux1: 0.2131, d2.loss_cls_aux1: 0.0206, d2.loss_bbox_aux1: 0.0373, d2.loss_iou_aux1: 0.2085, d3.loss_cls_aux1: 0.0196, d3.loss_bbox_aux1: 0.0373, d3.loss_iou_aux1: 0.2081, d4.loss_cls_aux1: 0.0198, d4.loss_bbox_aux1: 0.0373, d4.loss_iou_aux1: 0.2080, loss: 25.3287, grad_norm: 101.3798
2024-03-18 23:07:50,468 - mmdet - INFO - Epoch [14][400/463]	lr: 1.000e-06, eta: 0:41:55, time: 2.657, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1311, enc_loss_bbox: 0.0629, enc_loss_iou: 0.3338, loss_cls: 0.0806, loss_bbox: 0.0621, loss_iou: 0.3289, d0.loss_cls: 0.1517, d0.loss_bbox: 0.0628, d0.loss_iou: 0.3304, d1.loss_cls: 0.0880, d1.loss_bbox: 0.0625, d1.loss_iou: 0.3281, d2.loss_cls: 0.0801, d2.loss_bbox: 0.0622, d2.loss_iou: 0.3294, d3.loss_cls: 0.0820, d3.loss_bbox: 0.0620, d3.loss_iou: 0.3277, d4.loss_cls: 0.0805, d4.loss_bbox: 0.0621, d4.loss_iou: 0.3290, dn_loss_cls: 0.0071, dn_loss_bbox: 0.0338, dn_loss_iou: 0.1946, d0.dn_loss_cls: 0.0307, d0.dn_loss_bbox: 0.0482, d0.dn_loss_iou: 0.2691, d1.dn_loss_cls: 0.0093, d1.dn_loss_bbox: 0.0345, d1.dn_loss_iou: 0.1982, d2.dn_loss_cls: 0.0075, d2.dn_loss_bbox: 0.0338, d2.dn_loss_iou: 0.1945, d3.dn_loss_cls: 0.0072, d3.dn_loss_bbox: 0.0338, d3.dn_loss_iou: 0.1944, d4.dn_loss_cls: 0.0071, d4.dn_loss_bbox: 0.0338, d4.dn_loss_iou: 0.1946, loss_rpn_cls: 0.0310, loss_rpn_bbox: 0.1607, loss_cls0: 2.1863, acc0: 92.3570, loss_bbox0: 3.5574, loss_cls1: 1.6136, loss_bbox1: 3.6160, loss_centerness1: 7.1173, loss_cls_aux0: 0.0108, loss_bbox_aux0: 0.0147, loss_iou_aux0: 0.0817, d0.loss_cls_aux0: 0.0116, d0.loss_bbox_aux0: 0.0403, d0.loss_iou_aux0: 0.2217, d1.loss_cls_aux0: 0.0124, d1.loss_bbox_aux0: 0.0180, d1.loss_iou_aux0: 0.0999, d2.loss_cls_aux0: 0.0113, d2.loss_bbox_aux0: 0.0154, d2.loss_iou_aux0: 0.0859, d3.loss_cls_aux0: 0.0102, d3.loss_bbox_aux0: 0.0147, d3.loss_iou_aux0: 0.0815, d4.loss_cls_aux0: 0.0107, d4.loss_bbox_aux0: 0.0147, d4.loss_iou_aux0: 0.0816, loss_cls_aux1: 0.0100, loss_bbox_aux1: 0.0362, loss_iou_aux1: 0.2001, d0.loss_cls_aux1: 0.0114, d0.loss_bbox_aux1: 0.0442, d0.loss_iou_aux1: 0.2392, d1.loss_cls_aux1: 0.0109, d1.loss_bbox_aux1: 0.0373, d1.loss_iou_aux1: 0.2058, d2.loss_cls_aux1: 0.0099, d2.loss_bbox_aux1: 0.0363, d2.loss_iou_aux1: 0.2006, d3.loss_cls_aux1: 0.0095, d3.loss_bbox_aux1: 0.0362, d3.loss_iou_aux1: 0.2001, d4.loss_cls_aux1: 0.0098, d4.loss_bbox_aux1: 0.0362, d4.loss_iou_aux1: 0.2001, loss: 25.6235, grad_norm: 126.3955
2024-03-18 23:10:05,197 - mmdet - INFO - Epoch [14][450/463]	lr: 1.000e-06, eta: 0:39:49, time: 2.695, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1525, enc_loss_bbox: 0.0612, enc_loss_iou: 0.3201, loss_cls: 0.0932, loss_bbox: 0.0619, loss_iou: 0.3152, d0.loss_cls: 0.1756, d0.loss_bbox: 0.0593, d0.loss_iou: 0.3111, d1.loss_cls: 0.0989, d1.loss_bbox: 0.0603, d1.loss_iou: 0.3152, d2.loss_cls: 0.0954, d2.loss_bbox: 0.0620, d2.loss_iou: 0.3147, d3.loss_cls: 0.0926, d3.loss_bbox: 0.0612, d3.loss_iou: 0.3148, d4.loss_cls: 0.0923, d4.loss_bbox: 0.0619, d4.loss_iou: 0.3154, dn_loss_cls: 0.0165, dn_loss_bbox: 0.0321, dn_loss_iou: 0.1882, d0.dn_loss_cls: 0.0488, d0.dn_loss_bbox: 0.0449, d0.dn_loss_iou: 0.2556, d1.dn_loss_cls: 0.0236, d1.dn_loss_bbox: 0.0328, d1.dn_loss_iou: 0.1917, d2.dn_loss_cls: 0.0200, d2.dn_loss_bbox: 0.0321, d2.dn_loss_iou: 0.1880, d3.dn_loss_cls: 0.0180, d3.dn_loss_bbox: 0.0321, d3.dn_loss_iou: 0.1879, d4.dn_loss_cls: 0.0171, d4.dn_loss_bbox: 0.0321, d4.dn_loss_iou: 0.1880, loss_rpn_cls: 0.0266, loss_rpn_bbox: 0.1654, loss_cls0: 2.2082, acc0: 92.5684, loss_bbox0: 3.3414, loss_cls1: 1.5653, loss_bbox1: 3.4345, loss_centerness1: 7.1232, loss_cls_aux0: 0.0313, loss_bbox_aux0: 0.0146, loss_iou_aux0: 0.0790, d0.loss_cls_aux0: 0.0324, d0.loss_bbox_aux0: 0.0371, d0.loss_iou_aux0: 0.2103, d1.loss_cls_aux0: 0.0399, d1.loss_bbox_aux0: 0.0173, d1.loss_iou_aux0: 0.0950, d2.loss_cls_aux0: 0.0356, d2.loss_bbox_aux0: 0.0153, d2.loss_iou_aux0: 0.0829, d3.loss_cls_aux0: 0.0330, d3.loss_bbox_aux0: 0.0146, d3.loss_iou_aux0: 0.0789, d4.loss_cls_aux0: 0.0321, d4.loss_bbox_aux0: 0.0146, d4.loss_iou_aux0: 0.0790, loss_cls_aux1: 0.0188, loss_bbox_aux1: 0.0363, loss_iou_aux1: 0.2025, d0.loss_cls_aux1: 0.0232, d0.loss_bbox_aux1: 0.0423, d0.loss_iou_aux1: 0.2336, d1.loss_cls_aux1: 0.0235, d1.loss_bbox_aux1: 0.0370, d1.loss_iou_aux1: 0.2060, d2.loss_cls_aux1: 0.0222, d2.loss_bbox_aux1: 0.0364, d2.loss_iou_aux1: 0.2033, d3.loss_cls_aux1: 0.0209, d3.loss_bbox_aux1: 0.0363, d3.loss_iou_aux1: 0.2025, d4.loss_cls_aux1: 0.0192, d4.loss_bbox_aux1: 0.0363, d4.loss_iou_aux1: 0.2025, loss: 25.3947, grad_norm: 114.1832
2024-03-18 23:10:37,374 - mmdet - INFO - Saving checkpoint at 14 epochs
2024-03-18 23:12:06,786 - mmdet - INFO - Evaluating bbox...
2024-03-18 23:12:23,261 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.891
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.741
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.498
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.589
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.812
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.733
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.735
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.735
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.727
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.854

2024-03-18 23:12:23,262 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.657 | Thatch   | 0.577 |
+----------+-------+----------+-------+
2024-03-18 23:12:23,403 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 23:12:23,403 - mmdet - INFO - Epoch(val) [14][154]	bbox_mAP: 0.6160, bbox_mAP_50: 0.8910, bbox_mAP_75: 0.7410, bbox_mAP_s: 0.4980, bbox_mAP_m: 0.5890, bbox_mAP_l: 0.8120, bbox_mAP_copypaste: 0.616 0.891 0.741 0.498 0.589 0.812
2024-03-18 23:14:35,796 - mmdet - INFO - Epoch [15][50/463]	lr: 1.000e-06, eta: 0:37:05, time: 2.647, data_time: 0.059, memory: 19333, enc_loss_cls: 0.1323, enc_loss_bbox: 0.0616, enc_loss_iou: 0.3287, loss_cls: 0.0837, loss_bbox: 0.0608, loss_iou: 0.3247, d0.loss_cls: 0.1576, d0.loss_bbox: 0.0604, d0.loss_iou: 0.3239, d1.loss_cls: 0.0906, d1.loss_bbox: 0.0610, d1.loss_iou: 0.3253, d2.loss_cls: 0.0864, d2.loss_bbox: 0.0609, d2.loss_iou: 0.3249, d3.loss_cls: 0.0841, d3.loss_bbox: 0.0609, d3.loss_iou: 0.3247, d4.loss_cls: 0.0840, d4.loss_bbox: 0.0608, d4.loss_iou: 0.3247, dn_loss_cls: 0.0081, dn_loss_bbox: 0.0352, dn_loss_iou: 0.1944, d0.dn_loss_cls: 0.0315, d0.dn_loss_bbox: 0.0502, d0.dn_loss_iou: 0.2680, d1.dn_loss_cls: 0.0099, d1.dn_loss_bbox: 0.0359, d1.dn_loss_iou: 0.1980, d2.dn_loss_cls: 0.0087, d2.dn_loss_bbox: 0.0352, d2.dn_loss_iou: 0.1942, d3.dn_loss_cls: 0.0080, d3.dn_loss_bbox: 0.0352, d3.dn_loss_iou: 0.1941, d4.dn_loss_cls: 0.0082, d4.dn_loss_bbox: 0.0351, d4.dn_loss_iou: 0.1940, loss_rpn_cls: 0.0210, loss_rpn_bbox: 0.1573, loss_cls0: 2.0626, acc0: 92.7066, loss_bbox0: 3.4210, loss_cls1: 1.5276, loss_bbox1: 3.6193, loss_centerness1: 7.1231, loss_cls_aux0: 0.0131, loss_bbox_aux0: 0.0150, loss_iou_aux0: 0.0807, d0.loss_cls_aux0: 0.0154, d0.loss_bbox_aux0: 0.0398, d0.loss_iou_aux0: 0.2150, d1.loss_cls_aux0: 0.0150, d1.loss_bbox_aux0: 0.0181, d1.loss_iou_aux0: 0.0975, d2.loss_cls_aux0: 0.0136, d2.loss_bbox_aux0: 0.0158, d2.loss_iou_aux0: 0.0847, d3.loss_cls_aux0: 0.0127, d3.loss_bbox_aux0: 0.0150, d3.loss_iou_aux0: 0.0805, d4.loss_cls_aux0: 0.0128, d4.loss_bbox_aux0: 0.0150, d4.loss_iou_aux0: 0.0805, loss_cls_aux1: 0.0121, loss_bbox_aux1: 0.0382, loss_iou_aux1: 0.2100, d0.loss_cls_aux1: 0.0153, d0.loss_bbox_aux1: 0.0453, d0.loss_iou_aux1: 0.2465, d1.loss_cls_aux1: 0.0140, d1.loss_bbox_aux1: 0.0391, d1.loss_iou_aux1: 0.2157, d2.loss_cls_aux1: 0.0145, d2.loss_bbox_aux1: 0.0382, d2.loss_iou_aux1: 0.2103, d3.loss_cls_aux1: 0.0128, d3.loss_bbox_aux1: 0.0382, d3.loss_iou_aux1: 0.2100, d4.loss_cls_aux1: 0.0125, d4.loss_bbox_aux1: 0.0382, d4.loss_iou_aux1: 0.2100, loss: 25.3593, grad_norm: 104.6468
2024-03-18 23:16:41,504 - mmdet - INFO - Epoch [15][100/463]	lr: 1.000e-06, eta: 0:34:58, time: 2.514, data_time: 0.011, memory: 19333, enc_loss_cls: 0.1276, enc_loss_bbox: 0.0641, enc_loss_iou: 0.3307, loss_cls: 0.0866, loss_bbox: 0.0630, loss_iou: 0.3252, d0.loss_cls: 0.1504, d0.loss_bbox: 0.0634, d0.loss_iou: 0.3274, d1.loss_cls: 0.0861, d1.loss_bbox: 0.0635, d1.loss_iou: 0.3282, d2.loss_cls: 0.0844, d2.loss_bbox: 0.0634, d2.loss_iou: 0.3269, d3.loss_cls: 0.0842, d3.loss_bbox: 0.0635, d3.loss_iou: 0.3276, d4.loss_cls: 0.0867, d4.loss_bbox: 0.0630, d4.loss_iou: 0.3252, dn_loss_cls: 0.0090, dn_loss_bbox: 0.0341, dn_loss_iou: 0.1960, d0.dn_loss_cls: 0.0361, d0.dn_loss_bbox: 0.0484, d0.dn_loss_iou: 0.2683, d1.dn_loss_cls: 0.0122, d1.dn_loss_bbox: 0.0348, d1.dn_loss_iou: 0.1993, d2.dn_loss_cls: 0.0096, d2.dn_loss_bbox: 0.0341, d2.dn_loss_iou: 0.1962, d3.dn_loss_cls: 0.0090, d3.dn_loss_bbox: 0.0341, d3.dn_loss_iou: 0.1960, d4.dn_loss_cls: 0.0092, d4.dn_loss_bbox: 0.0341, d4.dn_loss_iou: 0.1959, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.1450, loss_cls0: 2.0921, acc0: 92.8159, loss_bbox0: 3.2346, loss_cls1: 1.5549, loss_bbox1: 3.5791, loss_centerness1: 7.1530, loss_cls_aux0: 0.0171, loss_bbox_aux0: 0.0145, loss_iou_aux0: 0.0755, d0.loss_cls_aux0: 0.0177, d0.loss_bbox_aux0: 0.0391, d0.loss_iou_aux0: 0.2098, d1.loss_cls_aux0: 0.0192, d1.loss_bbox_aux0: 0.0177, d1.loss_iou_aux0: 0.0927, d2.loss_cls_aux0: 0.0150, d2.loss_bbox_aux0: 0.0153, d2.loss_iou_aux0: 0.0795, d3.loss_cls_aux0: 0.0154, d3.loss_bbox_aux0: 0.0145, d3.loss_iou_aux0: 0.0753, d4.loss_cls_aux0: 0.0163, d4.loss_bbox_aux0: 0.0145, d4.loss_iou_aux0: 0.0754, loss_cls_aux1: 0.0139, loss_bbox_aux1: 0.0371, loss_iou_aux1: 0.2013, d0.loss_cls_aux1: 0.0167, d0.loss_bbox_aux1: 0.0440, d0.loss_iou_aux1: 0.2371, d1.loss_cls_aux1: 0.0160, d1.loss_bbox_aux1: 0.0379, d1.loss_iou_aux1: 0.2065, d2.loss_cls_aux1: 0.0136, d2.loss_bbox_aux1: 0.0372, d2.loss_iou_aux1: 0.2019, d3.loss_cls_aux1: 0.0136, d3.loss_bbox_aux1: 0.0371, d3.loss_iou_aux1: 0.2012, d4.loss_cls_aux1: 0.0136, d4.loss_bbox_aux1: 0.0371, d4.loss_iou_aux1: 0.2013, loss: 25.1649, grad_norm: 116.7003
2024-03-18 23:18:52,388 - mmdet - INFO - Epoch [15][150/463]	lr: 1.000e-06, eta: 0:32:51, time: 2.618, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1324, enc_loss_bbox: 0.0653, enc_loss_iou: 0.3341, loss_cls: 0.0848, loss_bbox: 0.0631, loss_iou: 0.3292, d0.loss_cls: 0.1557, d0.loss_bbox: 0.0641, d0.loss_iou: 0.3295, d1.loss_cls: 0.0888, d1.loss_bbox: 0.0642, d1.loss_iou: 0.3310, d2.loss_cls: 0.0857, d2.loss_bbox: 0.0631, d2.loss_iou: 0.3297, d3.loss_cls: 0.0843, d3.loss_bbox: 0.0630, d3.loss_iou: 0.3291, d4.loss_cls: 0.0843, d4.loss_bbox: 0.0631, d4.loss_iou: 0.3289, dn_loss_cls: 0.0099, dn_loss_bbox: 0.0340, dn_loss_iou: 0.1961, d0.dn_loss_cls: 0.0305, d0.dn_loss_bbox: 0.0478, d0.dn_loss_iou: 0.2651, d1.dn_loss_cls: 0.0114, d1.dn_loss_bbox: 0.0346, d1.dn_loss_iou: 0.1971, d2.dn_loss_cls: 0.0101, d2.dn_loss_bbox: 0.0340, d2.dn_loss_iou: 0.1942, d3.dn_loss_cls: 0.0098, d3.dn_loss_bbox: 0.0340, d3.dn_loss_iou: 0.1944, d4.dn_loss_cls: 0.0103, d4.dn_loss_bbox: 0.0340, d4.dn_loss_iou: 0.1945, loss_rpn_cls: 0.0301, loss_rpn_bbox: 0.1581, loss_cls0: 1.9428, acc0: 93.1779, loss_bbox0: 3.2312, loss_cls1: 1.5278, loss_bbox1: 3.6174, loss_centerness1: 7.1294, loss_cls_aux0: 0.0118, loss_bbox_aux0: 0.0163, loss_iou_aux0: 0.0868, d0.loss_cls_aux0: 0.0106, d0.loss_bbox_aux0: 0.0400, d0.loss_iou_aux0: 0.2158, d1.loss_cls_aux0: 0.0113, d1.loss_bbox_aux0: 0.0193, d1.loss_iou_aux0: 0.1034, d2.loss_cls_aux0: 0.0119, d2.loss_bbox_aux0: 0.0170, d2.loss_iou_aux0: 0.0905, d3.loss_cls_aux0: 0.0116, d3.loss_bbox_aux0: 0.0163, d3.loss_iou_aux0: 0.0866, d4.loss_cls_aux0: 0.0121, d4.loss_bbox_aux0: 0.0163, d4.loss_iou_aux0: 0.0867, loss_cls_aux1: 0.0062, loss_bbox_aux1: 0.0388, loss_iou_aux1: 0.2143, d0.loss_cls_aux1: 0.0076, d0.loss_bbox_aux1: 0.0461, d0.loss_iou_aux1: 0.2482, d1.loss_cls_aux1: 0.0065, d1.loss_bbox_aux1: 0.0396, d1.loss_iou_aux1: 0.2186, d2.loss_cls_aux1: 0.0063, d2.loss_bbox_aux1: 0.0389, d2.loss_iou_aux1: 0.2146, d3.loss_cls_aux1: 0.0061, d3.loss_bbox_aux1: 0.0388, d3.loss_iou_aux1: 0.2143, d4.loss_cls_aux1: 0.0061, d4.loss_bbox_aux1: 0.0388, d4.loss_iou_aux1: 0.2143, loss: 25.1202, grad_norm: 125.5153
2024-03-18 23:21:03,202 - mmdet - INFO - Epoch [15][200/463]	lr: 1.000e-06, eta: 0:30:45, time: 2.616, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1368, enc_loss_bbox: 0.0569, enc_loss_iou: 0.3264, loss_cls: 0.0810, loss_bbox: 0.0563, loss_iou: 0.3210, d0.loss_cls: 0.1625, d0.loss_bbox: 0.0559, d0.loss_iou: 0.3208, d1.loss_cls: 0.0908, d1.loss_bbox: 0.0561, d1.loss_iou: 0.3210, d2.loss_cls: 0.0831, d2.loss_bbox: 0.0561, d2.loss_iou: 0.3206, d3.loss_cls: 0.0823, d3.loss_bbox: 0.0562, d3.loss_iou: 0.3208, d4.loss_cls: 0.0816, d4.loss_bbox: 0.0563, d4.loss_iou: 0.3210, dn_loss_cls: 0.0094, dn_loss_bbox: 0.0326, dn_loss_iou: 0.1960, d0.dn_loss_cls: 0.0337, d0.dn_loss_bbox: 0.0457, d0.dn_loss_iou: 0.2682, d1.dn_loss_cls: 0.0117, d1.dn_loss_bbox: 0.0332, d1.dn_loss_iou: 0.1990, d2.dn_loss_cls: 0.0100, d2.dn_loss_bbox: 0.0326, d2.dn_loss_iou: 0.1959, d3.dn_loss_cls: 0.0095, d3.dn_loss_bbox: 0.0326, d3.dn_loss_iou: 0.1958, d4.dn_loss_cls: 0.0094, d4.dn_loss_bbox: 0.0326, d4.dn_loss_iou: 0.1960, loss_rpn_cls: 0.0218, loss_rpn_bbox: 0.1328, loss_cls0: 1.9181, acc0: 93.4735, loss_bbox0: 3.1809, loss_cls1: 1.5062, loss_bbox1: 3.5535, loss_centerness1: 7.1367, loss_cls_aux0: 0.0205, loss_bbox_aux0: 0.0127, loss_iou_aux0: 0.0732, d0.loss_cls_aux0: 0.0209, d0.loss_bbox_aux0: 0.0363, d0.loss_iou_aux0: 0.2132, d1.loss_cls_aux0: 0.0234, d1.loss_bbox_aux0: 0.0154, d1.loss_iou_aux0: 0.0895, d2.loss_cls_aux0: 0.0203, d2.loss_bbox_aux0: 0.0134, d2.loss_iou_aux0: 0.0772, d3.loss_cls_aux0: 0.0205, d3.loss_bbox_aux0: 0.0127, d3.loss_iou_aux0: 0.0732, d4.loss_cls_aux0: 0.0203, d4.loss_bbox_aux0: 0.0127, d4.loss_iou_aux0: 0.0732, loss_cls_aux1: 0.0143, loss_bbox_aux1: 0.0363, loss_iou_aux1: 0.2147, d0.loss_cls_aux1: 0.0152, d0.loss_bbox_aux1: 0.0422, d0.loss_iou_aux1: 0.2469, d1.loss_cls_aux1: 0.0158, d1.loss_bbox_aux1: 0.0374, d1.loss_iou_aux1: 0.2218, d2.loss_cls_aux1: 0.0144, d2.loss_bbox_aux1: 0.0363, d2.loss_iou_aux1: 0.2153, d3.loss_cls_aux1: 0.0151, d3.loss_bbox_aux1: 0.0363, d3.loss_iou_aux1: 0.2147, d4.loss_cls_aux1: 0.0146, d4.loss_bbox_aux1: 0.0363, d4.loss_iou_aux1: 0.2147, loss: 24.8285, grad_norm: 114.8127
2024-03-18 23:23:13,411 - mmdet - INFO - Epoch [15][250/463]	lr: 1.000e-06, eta: 0:28:38, time: 2.604, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1240, enc_loss_bbox: 0.0618, enc_loss_iou: 0.3345, loss_cls: 0.0758, loss_bbox: 0.0616, loss_iou: 0.3279, d0.loss_cls: 0.1458, d0.loss_bbox: 0.0615, d0.loss_iou: 0.3290, d1.loss_cls: 0.0812, d1.loss_bbox: 0.0616, d1.loss_iou: 0.3287, d2.loss_cls: 0.0772, d2.loss_bbox: 0.0616, d2.loss_iou: 0.3281, d3.loss_cls: 0.0775, d3.loss_bbox: 0.0613, d3.loss_iou: 0.3271, d4.loss_cls: 0.0759, d4.loss_bbox: 0.0614, d4.loss_iou: 0.3274, dn_loss_cls: 0.0058, dn_loss_bbox: 0.0336, dn_loss_iou: 0.1974, d0.dn_loss_cls: 0.0285, d0.dn_loss_bbox: 0.0474, d0.dn_loss_iou: 0.2708, d1.dn_loss_cls: 0.0078, d1.dn_loss_bbox: 0.0342, d1.dn_loss_iou: 0.2009, d2.dn_loss_cls: 0.0063, d2.dn_loss_bbox: 0.0336, d2.dn_loss_iou: 0.1976, d3.dn_loss_cls: 0.0059, d3.dn_loss_bbox: 0.0336, d3.dn_loss_iou: 0.1974, d4.dn_loss_cls: 0.0059, d4.dn_loss_bbox: 0.0336, d4.dn_loss_iou: 0.1975, loss_rpn_cls: 0.0186, loss_rpn_bbox: 0.1467, loss_cls0: 2.1201, acc0: 92.5444, loss_bbox0: 3.4772, loss_cls1: 1.5248, loss_bbox1: 3.6410, loss_centerness1: 7.1211, loss_cls_aux0: 0.0099, loss_bbox_aux0: 0.0149, loss_iou_aux0: 0.0855, d0.loss_cls_aux0: 0.0115, d0.loss_bbox_aux0: 0.0388, d0.loss_iou_aux0: 0.2200, d1.loss_cls_aux0: 0.0103, d1.loss_bbox_aux0: 0.0179, d1.loss_iou_aux0: 0.1026, d2.loss_cls_aux0: 0.0103, d2.loss_bbox_aux0: 0.0156, d2.loss_iou_aux0: 0.0893, d3.loss_cls_aux0: 0.0096, d3.loss_bbox_aux0: 0.0149, d3.loss_iou_aux0: 0.0855, d4.loss_cls_aux0: 0.0094, d4.loss_bbox_aux0: 0.0149, d4.loss_iou_aux0: 0.0855, loss_cls_aux1: 0.0088, loss_bbox_aux1: 0.0377, loss_iou_aux1: 0.2127, d0.loss_cls_aux1: 0.0103, d0.loss_bbox_aux1: 0.0438, d0.loss_iou_aux1: 0.2451, d1.loss_cls_aux1: 0.0085, d1.loss_bbox_aux1: 0.0386, d1.loss_iou_aux1: 0.2177, d2.loss_cls_aux1: 0.0085, d2.loss_bbox_aux1: 0.0378, d2.loss_iou_aux1: 0.2133, d3.loss_cls_aux1: 0.0086, d3.loss_bbox_aux1: 0.0377, d3.loss_iou_aux1: 0.2127, d4.loss_cls_aux1: 0.0085, d4.loss_bbox_aux1: 0.0377, d4.loss_iou_aux1: 0.2127, loss: 25.4251, grad_norm: 100.9720
2024-03-18 23:25:26,571 - mmdet - INFO - Epoch [15][300/463]	lr: 1.000e-06, eta: 0:26:31, time: 2.663, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1364, enc_loss_bbox: 0.0607, enc_loss_iou: 0.3198, loss_cls: 0.0936, loss_bbox: 0.0587, loss_iou: 0.3141, d0.loss_cls: 0.1617, d0.loss_bbox: 0.0588, d0.loss_iou: 0.3136, d1.loss_cls: 0.0960, d1.loss_bbox: 0.0588, d1.loss_iou: 0.3144, d2.loss_cls: 0.0946, d2.loss_bbox: 0.0587, d2.loss_iou: 0.3146, d3.loss_cls: 0.0920, d3.loss_bbox: 0.0587, d3.loss_iou: 0.3148, d4.loss_cls: 0.0928, d4.loss_bbox: 0.0588, d4.loss_iou: 0.3145, dn_loss_cls: 0.0078, dn_loss_bbox: 0.0337, dn_loss_iou: 0.1958, d0.dn_loss_cls: 0.0290, d0.dn_loss_bbox: 0.0475, d0.dn_loss_iou: 0.2666, d1.dn_loss_cls: 0.0091, d1.dn_loss_bbox: 0.0343, d1.dn_loss_iou: 0.1990, d2.dn_loss_cls: 0.0074, d2.dn_loss_bbox: 0.0337, d2.dn_loss_iou: 0.1957, d3.dn_loss_cls: 0.0076, d3.dn_loss_bbox: 0.0337, d3.dn_loss_iou: 0.1957, d4.dn_loss_cls: 0.0076, d4.dn_loss_bbox: 0.0337, d4.dn_loss_iou: 0.1958, loss_rpn_cls: 0.0658, loss_rpn_bbox: 0.1452, loss_cls0: 1.9451, acc0: 93.0947, loss_bbox0: 3.1042, loss_cls1: 1.5519, loss_bbox1: 3.4971, loss_centerness1: 7.1311, loss_cls_aux0: 0.0098, loss_bbox_aux0: 0.0134, loss_iou_aux0: 0.0743, d0.loss_cls_aux0: 0.0115, d0.loss_bbox_aux0: 0.0389, d0.loss_iou_aux0: 0.2138, d1.loss_cls_aux0: 0.0115, d1.loss_bbox_aux0: 0.0167, d1.loss_iou_aux0: 0.0914, d2.loss_cls_aux0: 0.0099, d2.loss_bbox_aux0: 0.0141, d2.loss_iou_aux0: 0.0785, d3.loss_cls_aux0: 0.0093, d3.loss_bbox_aux0: 0.0134, d3.loss_iou_aux0: 0.0743, d4.loss_cls_aux0: 0.0094, d4.loss_bbox_aux0: 0.0134, d4.loss_iou_aux0: 0.0743, loss_cls_aux1: 0.0076, loss_bbox_aux1: 0.0369, loss_iou_aux1: 0.2025, d0.loss_cls_aux1: 0.0103, d0.loss_bbox_aux1: 0.0430, d0.loss_iou_aux1: 0.2346, d1.loss_cls_aux1: 0.0092, d1.loss_bbox_aux1: 0.0375, d1.loss_iou_aux1: 0.2062, d2.loss_cls_aux1: 0.0082, d2.loss_bbox_aux1: 0.0370, d2.loss_iou_aux1: 0.2031, d3.loss_cls_aux1: 0.0077, d3.loss_bbox_aux1: 0.0369, d3.loss_iou_aux1: 0.2025, d4.loss_cls_aux1: 0.0073, d4.loss_bbox_aux1: 0.0369, d4.loss_iou_aux1: 0.2025, loss: 24.6682, grad_norm: 129.4813
2024-03-18 23:27:28,878 - mmdet - INFO - Epoch [15][350/463]	lr: 1.000e-06, eta: 0:24:24, time: 2.446, data_time: 0.007, memory: 19333, enc_loss_cls: 0.1262, enc_loss_bbox: 0.0579, enc_loss_iou: 0.3099, loss_cls: 0.0768, loss_bbox: 0.0564, loss_iou: 0.3038, d0.loss_cls: 0.1498, d0.loss_bbox: 0.0562, d0.loss_iou: 0.3038, d1.loss_cls: 0.0857, d1.loss_bbox: 0.0562, d1.loss_iou: 0.3022, d2.loss_cls: 0.0779, d2.loss_bbox: 0.0565, d2.loss_iou: 0.3048, d3.loss_cls: 0.0768, d3.loss_bbox: 0.0563, d3.loss_iou: 0.3041, d4.loss_cls: 0.0766, d4.loss_bbox: 0.0564, d4.loss_iou: 0.3042, dn_loss_cls: 0.0084, dn_loss_bbox: 0.0329, dn_loss_iou: 0.1942, d0.dn_loss_cls: 0.0297, d0.dn_loss_bbox: 0.0456, d0.dn_loss_iou: 0.2623, d1.dn_loss_cls: 0.0103, d1.dn_loss_bbox: 0.0335, d1.dn_loss_iou: 0.1972, d2.dn_loss_cls: 0.0083, d2.dn_loss_bbox: 0.0329, d2.dn_loss_iou: 0.1943, d3.dn_loss_cls: 0.0079, d3.dn_loss_bbox: 0.0329, d3.dn_loss_iou: 0.1942, d4.dn_loss_cls: 0.0082, d4.dn_loss_bbox: 0.0329, d4.dn_loss_iou: 0.1942, loss_rpn_cls: 0.0232, loss_rpn_bbox: 0.1440, loss_cls0: 2.0040, acc0: 92.9444, loss_bbox0: 3.2750, loss_cls1: 1.4370, loss_bbox1: 3.3616, loss_centerness1: 7.1266, loss_cls_aux0: 0.0115, loss_bbox_aux0: 0.0149, loss_iou_aux0: 0.0795, d0.loss_cls_aux0: 0.0121, d0.loss_bbox_aux0: 0.0382, d0.loss_iou_aux0: 0.2117, d1.loss_cls_aux0: 0.0134, d1.loss_bbox_aux0: 0.0175, d1.loss_iou_aux0: 0.0948, d2.loss_cls_aux0: 0.0125, d2.loss_bbox_aux0: 0.0156, d2.loss_iou_aux0: 0.0836, d3.loss_cls_aux0: 0.0117, d3.loss_bbox_aux0: 0.0149, d3.loss_iou_aux0: 0.0795, d4.loss_cls_aux0: 0.0118, d4.loss_bbox_aux0: 0.0149, d4.loss_iou_aux0: 0.0795, loss_cls_aux1: 0.0069, loss_bbox_aux1: 0.0363, loss_iou_aux1: 0.2009, d0.loss_cls_aux1: 0.0087, d0.loss_bbox_aux1: 0.0423, d0.loss_iou_aux1: 0.2294, d1.loss_cls_aux1: 0.0083, d1.loss_bbox_aux1: 0.0370, d1.loss_iou_aux1: 0.2054, d2.loss_cls_aux1: 0.0072, d2.loss_bbox_aux1: 0.0363, d2.loss_iou_aux1: 0.2012, d3.loss_cls_aux1: 0.0068, d3.loss_bbox_aux1: 0.0363, d3.loss_iou_aux1: 0.2009, d4.loss_cls_aux1: 0.0069, d4.loss_bbox_aux1: 0.0363, d4.loss_iou_aux1: 0.2009, loss: 24.4149, grad_norm: 107.7770
2024-03-18 23:29:41,701 - mmdet - INFO - Epoch [15][400/463]	lr: 1.000e-06, eta: 0:22:17, time: 2.656, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1366, enc_loss_bbox: 0.0593, enc_loss_iou: 0.3172, loss_cls: 0.0926, loss_bbox: 0.0577, loss_iou: 0.3115, d0.loss_cls: 0.1707, d0.loss_bbox: 0.0582, d0.loss_iou: 0.3123, d1.loss_cls: 0.0968, d1.loss_bbox: 0.0581, d1.loss_iou: 0.3126, d2.loss_cls: 0.0944, d2.loss_bbox: 0.0581, d2.loss_iou: 0.3123, d3.loss_cls: 0.0923, d3.loss_bbox: 0.0580, d3.loss_iou: 0.3116, d4.loss_cls: 0.0908, d4.loss_bbox: 0.0580, d4.loss_iou: 0.3116, dn_loss_cls: 0.0155, dn_loss_bbox: 0.0333, dn_loss_iou: 0.1873, d0.dn_loss_cls: 0.0437, d0.dn_loss_bbox: 0.0474, d0.dn_loss_iou: 0.2578, d1.dn_loss_cls: 0.0195, d1.dn_loss_bbox: 0.0342, d1.dn_loss_iou: 0.1912, d2.dn_loss_cls: 0.0163, d2.dn_loss_bbox: 0.0333, d2.dn_loss_iou: 0.1875, d3.dn_loss_cls: 0.0160, d3.dn_loss_bbox: 0.0333, d3.dn_loss_iou: 0.1873, d4.dn_loss_cls: 0.0154, d4.dn_loss_bbox: 0.0333, d4.dn_loss_iou: 0.1873, loss_rpn_cls: 0.0170, loss_rpn_bbox: 0.1469, loss_cls0: 2.1759, acc0: 92.5636, loss_bbox0: 3.3425, loss_cls1: 1.5678, loss_bbox1: 3.4590, loss_centerness1: 7.0862, loss_cls_aux0: 0.0338, loss_bbox_aux0: 0.0153, loss_iou_aux0: 0.0822, d0.loss_cls_aux0: 0.0373, d0.loss_bbox_aux0: 0.0386, d0.loss_iou_aux0: 0.2093, d1.loss_cls_aux0: 0.0427, d1.loss_bbox_aux0: 0.0175, d1.loss_iou_aux0: 0.0946, d2.loss_cls_aux0: 0.0381, d2.loss_bbox_aux0: 0.0159, d2.loss_iou_aux0: 0.0853, d3.loss_cls_aux0: 0.0353, d3.loss_bbox_aux0: 0.0153, d3.loss_iou_aux0: 0.0822, d4.loss_cls_aux0: 0.0334, d4.loss_bbox_aux0: 0.0152, d4.loss_iou_aux0: 0.0821, loss_cls_aux1: 0.0298, loss_bbox_aux1: 0.0353, loss_iou_aux1: 0.1958, d0.loss_cls_aux1: 0.0337, d0.loss_bbox_aux1: 0.0423, d0.loss_iou_aux1: 0.2315, d1.loss_cls_aux1: 0.0337, d1.loss_bbox_aux1: 0.0363, d1.loss_iou_aux1: 0.2010, d2.loss_cls_aux1: 0.0309, d2.loss_bbox_aux1: 0.0353, d2.loss_iou_aux1: 0.1958, d3.loss_cls_aux1: 0.0308, d3.loss_bbox_aux1: 0.0353, d3.loss_iou_aux1: 0.1957, d4.loss_cls_aux1: 0.0297, d4.loss_bbox_aux1: 0.0353, d4.loss_iou_aux1: 0.1957, loss: 25.3037, grad_norm: 129.3877
2024-03-18 23:31:56,422 - mmdet - INFO - Epoch [15][450/463]	lr: 1.000e-06, eta: 0:20:10, time: 2.695, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1322, enc_loss_bbox: 0.0674, enc_loss_iou: 0.3505, loss_cls: 0.0844, loss_bbox: 0.0654, loss_iou: 0.3454, d0.loss_cls: 0.1585, d0.loss_bbox: 0.0658, d0.loss_iou: 0.3456, d1.loss_cls: 0.0899, d1.loss_bbox: 0.0655, d1.loss_iou: 0.3461, d2.loss_cls: 0.0851, d2.loss_bbox: 0.0657, d2.loss_iou: 0.3460, d3.loss_cls: 0.0848, d3.loss_bbox: 0.0655, d3.loss_iou: 0.3453, d4.loss_cls: 0.0842, d4.loss_bbox: 0.0654, d4.loss_iou: 0.3455, dn_loss_cls: 0.0108, dn_loss_bbox: 0.0323, dn_loss_iou: 0.1999, d0.dn_loss_cls: 0.0431, d0.dn_loss_bbox: 0.0458, d0.dn_loss_iou: 0.2727, d1.dn_loss_cls: 0.0161, d1.dn_loss_bbox: 0.0330, d1.dn_loss_iou: 0.2030, d2.dn_loss_cls: 0.0138, d2.dn_loss_bbox: 0.0323, d2.dn_loss_iou: 0.1993, d3.dn_loss_cls: 0.0119, d3.dn_loss_bbox: 0.0322, d3.dn_loss_iou: 0.1990, d4.dn_loss_cls: 0.0112, d4.dn_loss_bbox: 0.0322, d4.dn_loss_iou: 0.1989, loss_rpn_cls: 0.0193, loss_rpn_bbox: 0.1461, loss_cls0: 2.0502, acc0: 92.8913, loss_bbox0: 3.3287, loss_cls1: 1.6385, loss_bbox1: 3.7501, loss_centerness1: 7.1401, loss_cls_aux0: 0.0239, loss_bbox_aux0: 0.0151, loss_iou_aux0: 0.0813, d0.loss_cls_aux0: 0.0214, d0.loss_bbox_aux0: 0.0382, d0.loss_iou_aux0: 0.2179, d1.loss_cls_aux0: 0.0247, d1.loss_bbox_aux0: 0.0181, d1.loss_iou_aux0: 0.0984, d2.loss_cls_aux0: 0.0231, d2.loss_bbox_aux0: 0.0157, d2.loss_iou_aux0: 0.0851, d3.loss_cls_aux0: 0.0225, d3.loss_bbox_aux0: 0.0151, d3.loss_iou_aux0: 0.0812, d4.loss_cls_aux0: 0.0236, d4.loss_bbox_aux0: 0.0151, d4.loss_iou_aux0: 0.0812, loss_cls_aux1: 0.0144, loss_bbox_aux1: 0.0377, loss_iou_aux1: 0.2089, d0.loss_cls_aux1: 0.0151, d0.loss_bbox_aux1: 0.0451, d0.loss_iou_aux1: 0.2470, d1.loss_cls_aux1: 0.0156, d1.loss_bbox_aux1: 0.0387, d1.loss_iou_aux1: 0.2137, d2.loss_cls_aux1: 0.0144, d2.loss_bbox_aux1: 0.0378, d2.loss_iou_aux1: 0.2093, d3.loss_cls_aux1: 0.0136, d3.loss_bbox_aux1: 0.0377, d3.loss_iou_aux1: 0.2089, d4.loss_cls_aux1: 0.0138, d4.loss_bbox_aux1: 0.0377, d4.loss_iou_aux1: 0.2089, loss: 25.7847, grad_norm: 106.1396
2024-03-18 23:32:28,590 - mmdet - INFO - Saving checkpoint at 15 epochs
2024-03-18 23:33:56,506 - mmdet - INFO - Evaluating bbox...
2024-03-18 23:34:13,090 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.616
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.891
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.742
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.499
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.591
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.809
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.729
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.853

2024-03-18 23:34:13,091 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.657 | Thatch   | 0.579 |
+----------+-------+----------+-------+
2024-03-18 23:34:13,230 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 23:34:13,230 - mmdet - INFO - Epoch(val) [15][154]	bbox_mAP: 0.6160, bbox_mAP_50: 0.8910, bbox_mAP_75: 0.7420, bbox_mAP_s: 0.4990, bbox_mAP_m: 0.5910, bbox_mAP_l: 0.8090, bbox_mAP_copypaste: 0.616 0.891 0.742 0.499 0.591 0.809
2024-03-18 23:36:25,598 - mmdet - INFO - Epoch [16][50/463]	lr: 1.000e-06, eta: 0:17:29, time: 2.647, data_time: 0.059, memory: 19333, enc_loss_cls: 0.1290, enc_loss_bbox: 0.0595, enc_loss_iou: 0.3322, loss_cls: 0.0751, loss_bbox: 0.0582, loss_iou: 0.3275, d0.loss_cls: 0.1496, d0.loss_bbox: 0.0584, d0.loss_iou: 0.3266, d1.loss_cls: 0.0852, d1.loss_bbox: 0.0583, d1.loss_iou: 0.3265, d2.loss_cls: 0.0769, d2.loss_bbox: 0.0583, d2.loss_iou: 0.3275, d3.loss_cls: 0.0751, d3.loss_bbox: 0.0586, d3.loss_iou: 0.3280, d4.loss_cls: 0.0753, d4.loss_bbox: 0.0583, d4.loss_iou: 0.3277, dn_loss_cls: 0.0102, dn_loss_bbox: 0.0325, dn_loss_iou: 0.1956, d0.dn_loss_cls: 0.0372, d0.dn_loss_bbox: 0.0457, d0.dn_loss_iou: 0.2674, d1.dn_loss_cls: 0.0132, d1.dn_loss_bbox: 0.0332, d1.dn_loss_iou: 0.1986, d2.dn_loss_cls: 0.0114, d2.dn_loss_bbox: 0.0325, d2.dn_loss_iou: 0.1955, d3.dn_loss_cls: 0.0107, d3.dn_loss_bbox: 0.0325, d3.dn_loss_iou: 0.1949, d4.dn_loss_cls: 0.0102, d4.dn_loss_bbox: 0.0325, d4.dn_loss_iou: 0.1956, loss_rpn_cls: 0.0175, loss_rpn_bbox: 0.1247, loss_cls0: 1.8725, acc0: 93.4734, loss_bbox0: 3.2232, loss_cls1: 1.4770, loss_bbox1: 3.5618, loss_centerness1: 7.1264, loss_cls_aux0: 0.0185, loss_bbox_aux0: 0.0129, loss_iou_aux0: 0.0736, d0.loss_cls_aux0: 0.0160, d0.loss_bbox_aux0: 0.0371, d0.loss_iou_aux0: 0.2121, d1.loss_cls_aux0: 0.0203, d1.loss_bbox_aux0: 0.0157, d1.loss_iou_aux0: 0.0893, d2.loss_cls_aux0: 0.0188, d2.loss_bbox_aux0: 0.0135, d2.loss_iou_aux0: 0.0770, d3.loss_cls_aux0: 0.0171, d3.loss_bbox_aux0: 0.0129, d3.loss_iou_aux0: 0.0734, d4.loss_cls_aux0: 0.0183, d4.loss_bbox_aux0: 0.0129, d4.loss_iou_aux0: 0.0735, loss_cls_aux1: 0.0140, loss_bbox_aux1: 0.0369, loss_iou_aux1: 0.2128, d0.loss_cls_aux1: 0.0126, d0.loss_bbox_aux1: 0.0429, d0.loss_iou_aux1: 0.2425, d1.loss_cls_aux1: 0.0133, d1.loss_bbox_aux1: 0.0376, d1.loss_iou_aux1: 0.2161, d2.loss_cls_aux1: 0.0141, d2.loss_bbox_aux1: 0.0369, d2.loss_iou_aux1: 0.2128, d3.loss_cls_aux1: 0.0139, d3.loss_bbox_aux1: 0.0369, d3.loss_iou_aux1: 0.2129, d4.loss_cls_aux1: 0.0145, d4.loss_bbox_aux1: 0.0369, d4.loss_iou_aux1: 0.2128, loss: 24.7573, grad_norm: 107.3195
2024-03-18 23:38:31,603 - mmdet - INFO - Epoch [16][100/463]	lr: 1.000e-06, eta: 0:15:21, time: 2.520, data_time: 0.011, memory: 19333, enc_loss_cls: 0.1280, enc_loss_bbox: 0.0661, enc_loss_iou: 0.3526, loss_cls: 0.0865, loss_bbox: 0.0650, loss_iou: 0.3459, d0.loss_cls: 0.1536, d0.loss_bbox: 0.0656, d0.loss_iou: 0.3475, d1.loss_cls: 0.0925, d1.loss_bbox: 0.0653, d1.loss_iou: 0.3462, d2.loss_cls: 0.0904, d2.loss_bbox: 0.0651, d2.loss_iou: 0.3455, d3.loss_cls: 0.0873, d3.loss_bbox: 0.0649, d3.loss_iou: 0.3459, d4.loss_cls: 0.0855, d4.loss_bbox: 0.0649, d4.loss_iou: 0.3459, dn_loss_cls: 0.0093, dn_loss_bbox: 0.0334, dn_loss_iou: 0.1915, d0.dn_loss_cls: 0.0343, d0.dn_loss_bbox: 0.0469, d0.dn_loss_iou: 0.2620, d1.dn_loss_cls: 0.0117, d1.dn_loss_bbox: 0.0341, d1.dn_loss_iou: 0.1948, d2.dn_loss_cls: 0.0098, d2.dn_loss_bbox: 0.0334, d2.dn_loss_iou: 0.1914, d3.dn_loss_cls: 0.0091, d3.dn_loss_bbox: 0.0334, d3.dn_loss_iou: 0.1914, d4.dn_loss_cls: 0.0090, d4.dn_loss_bbox: 0.0334, d4.dn_loss_iou: 0.1914, loss_rpn_cls: 0.0194, loss_rpn_bbox: 0.1551, loss_cls0: 2.1018, acc0: 92.7221, loss_bbox0: 3.3962, loss_cls1: 1.6622, loss_bbox1: 3.8300, loss_centerness1: 7.1532, loss_cls_aux0: 0.0218, loss_bbox_aux0: 0.0142, loss_iou_aux0: 0.0782, d0.loss_cls_aux0: 0.0267, d0.loss_bbox_aux0: 0.0388, d0.loss_iou_aux0: 0.2163, d1.loss_cls_aux0: 0.0293, d1.loss_bbox_aux0: 0.0170, d1.loss_iou_aux0: 0.0940, d2.loss_cls_aux0: 0.0276, d2.loss_bbox_aux0: 0.0148, d2.loss_iou_aux0: 0.0820, d3.loss_cls_aux0: 0.0222, d3.loss_bbox_aux0: 0.0142, d3.loss_iou_aux0: 0.0781, d4.loss_cls_aux0: 0.0201, d4.loss_bbox_aux0: 0.0141, d4.loss_iou_aux0: 0.0781, loss_cls_aux1: 0.0251, loss_bbox_aux1: 0.0387, loss_iou_aux1: 0.2195, d0.loss_cls_aux1: 0.0351, d0.loss_bbox_aux1: 0.0458, d0.loss_iou_aux1: 0.2551, d1.loss_cls_aux1: 0.0346, d1.loss_bbox_aux1: 0.0394, d1.loss_iou_aux1: 0.2228, d2.loss_cls_aux1: 0.0314, d2.loss_bbox_aux1: 0.0388, d2.loss_iou_aux1: 0.2197, d3.loss_cls_aux1: 0.0251, d3.loss_bbox_aux1: 0.0387, d3.loss_iou_aux1: 0.2194, d4.loss_cls_aux1: 0.0240, d4.loss_bbox_aux1: 0.0387, d4.loss_iou_aux1: 0.2195, loss: 26.1075, grad_norm: 119.9256
2024-03-18 23:40:42,425 - mmdet - INFO - Epoch [16][150/463]	lr: 1.000e-06, eta: 0:13:15, time: 2.616, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1290, enc_loss_bbox: 0.0611, enc_loss_iou: 0.3348, loss_cls: 0.0871, loss_bbox: 0.0596, loss_iou: 0.3272, d0.loss_cls: 0.1556, d0.loss_bbox: 0.0603, d0.loss_iou: 0.3293, d1.loss_cls: 0.0948, d1.loss_bbox: 0.0599, d1.loss_iou: 0.3255, d2.loss_cls: 0.0879, d2.loss_bbox: 0.0600, d2.loss_iou: 0.3280, d3.loss_cls: 0.0867, d3.loss_bbox: 0.0597, d3.loss_iou: 0.3279, d4.loss_cls: 0.0869, d4.loss_bbox: 0.0595, d4.loss_iou: 0.3269, dn_loss_cls: 0.0091, dn_loss_bbox: 0.0330, dn_loss_iou: 0.1981, d0.dn_loss_cls: 0.0289, d0.dn_loss_bbox: 0.0468, d0.dn_loss_iou: 0.2682, d1.dn_loss_cls: 0.0098, d1.dn_loss_bbox: 0.0336, d1.dn_loss_iou: 0.1997, d2.dn_loss_cls: 0.0094, d2.dn_loss_bbox: 0.0329, d2.dn_loss_iou: 0.1960, d3.dn_loss_cls: 0.0091, d3.dn_loss_bbox: 0.0330, d3.dn_loss_iou: 0.1967, d4.dn_loss_cls: 0.0090, d4.dn_loss_bbox: 0.0330, d4.dn_loss_iou: 0.1960, loss_rpn_cls: 0.0221, loss_rpn_bbox: 0.1648, loss_cls0: 1.9799, acc0: 92.9786, loss_bbox0: 3.2360, loss_cls1: 1.4996, loss_bbox1: 3.5523, loss_centerness1: 7.1665, loss_cls_aux0: 0.0166, loss_bbox_aux0: 0.0154, loss_iou_aux0: 0.0844, d0.loss_cls_aux0: 0.0125, d0.loss_bbox_aux0: 0.0385, d0.loss_iou_aux0: 0.2153, d1.loss_cls_aux0: 0.0142, d1.loss_bbox_aux0: 0.0181, d1.loss_iou_aux0: 0.1006, d2.loss_cls_aux0: 0.0153, d2.loss_bbox_aux0: 0.0161, d2.loss_iou_aux0: 0.0879, d3.loss_cls_aux0: 0.0164, d3.loss_bbox_aux0: 0.0154, d3.loss_iou_aux0: 0.0842, d4.loss_cls_aux0: 0.0165, d4.loss_bbox_aux0: 0.0154, d4.loss_iou_aux0: 0.0843, loss_cls_aux1: 0.0147, loss_bbox_aux1: 0.0366, loss_iou_aux1: 0.2080, d0.loss_cls_aux1: 0.0131, d0.loss_bbox_aux1: 0.0437, d0.loss_iou_aux1: 0.2435, d1.loss_cls_aux1: 0.0118, d1.loss_bbox_aux1: 0.0379, d1.loss_iou_aux1: 0.2151, d2.loss_cls_aux1: 0.0132, d2.loss_bbox_aux1: 0.0367, d2.loss_iou_aux1: 0.2085, d3.loss_cls_aux1: 0.0151, d3.loss_bbox_aux1: 0.0366, d3.loss_iou_aux1: 0.2080, d4.loss_cls_aux1: 0.0150, d4.loss_bbox_aux1: 0.0366, d4.loss_iou_aux1: 0.2080, loss: 25.0798, grad_norm: 123.9014
2024-03-18 23:42:53,200 - mmdet - INFO - Epoch [16][200/463]	lr: 1.000e-06, eta: 0:11:08, time: 2.616, data_time: 0.009, memory: 19333, enc_loss_cls: 0.1379, enc_loss_bbox: 0.0622, enc_loss_iou: 0.3238, loss_cls: 0.0904, loss_bbox: 0.0614, loss_iou: 0.3184, d0.loss_cls: 0.1624, d0.loss_bbox: 0.0616, d0.loss_iou: 0.3199, d1.loss_cls: 0.0970, d1.loss_bbox: 0.0600, d1.loss_iou: 0.3171, d2.loss_cls: 0.0904, d2.loss_bbox: 0.0613, d2.loss_iou: 0.3191, d3.loss_cls: 0.0918, d3.loss_bbox: 0.0613, d3.loss_iou: 0.3179, d4.loss_cls: 0.0906, d4.loss_bbox: 0.0613, d4.loss_iou: 0.3188, dn_loss_cls: 0.0062, dn_loss_bbox: 0.0341, dn_loss_iou: 0.1914, d0.dn_loss_cls: 0.0288, d0.dn_loss_bbox: 0.0481, d0.dn_loss_iou: 0.2617, d1.dn_loss_cls: 0.0081, d1.dn_loss_bbox: 0.0348, d1.dn_loss_iou: 0.1946, d2.dn_loss_cls: 0.0066, d2.dn_loss_bbox: 0.0341, d2.dn_loss_iou: 0.1915, d3.dn_loss_cls: 0.0062, d3.dn_loss_bbox: 0.0341, d3.dn_loss_iou: 0.1914, d4.dn_loss_cls: 0.0063, d4.dn_loss_bbox: 0.0341, d4.dn_loss_iou: 0.1915, loss_rpn_cls: 0.0360, loss_rpn_bbox: 0.1453, loss_cls0: 2.0948, acc0: 92.4962, loss_bbox0: 3.2311, loss_cls1: 1.5737, loss_bbox1: 3.5406, loss_centerness1: 7.0993, loss_cls_aux0: 0.0131, loss_bbox_aux0: 0.0149, loss_iou_aux0: 0.0796, d0.loss_cls_aux0: 0.0143, d0.loss_bbox_aux0: 0.0387, d0.loss_iou_aux0: 0.2098, d1.loss_cls_aux0: 0.0141, d1.loss_bbox_aux0: 0.0179, d1.loss_iou_aux0: 0.0955, d2.loss_cls_aux0: 0.0130, d2.loss_bbox_aux0: 0.0155, d2.loss_iou_aux0: 0.0828, d3.loss_cls_aux0: 0.0128, d3.loss_bbox_aux0: 0.0149, d3.loss_iou_aux0: 0.0796, d4.loss_cls_aux0: 0.0128, d4.loss_bbox_aux0: 0.0149, d4.loss_iou_aux0: 0.0795, loss_cls_aux1: 0.0099, loss_bbox_aux1: 0.0383, loss_iou_aux1: 0.2059, d0.loss_cls_aux1: 0.0115, d0.loss_bbox_aux1: 0.0444, d0.loss_iou_aux1: 0.2355, d1.loss_cls_aux1: 0.0104, d1.loss_bbox_aux1: 0.0390, d1.loss_iou_aux1: 0.2100, d2.loss_cls_aux1: 0.0101, d2.loss_bbox_aux1: 0.0382, d2.loss_iou_aux1: 0.2061, d3.loss_cls_aux1: 0.0100, d3.loss_bbox_aux1: 0.0383, d3.loss_iou_aux1: 0.2060, d4.loss_cls_aux1: 0.0095, d4.loss_bbox_aux1: 0.0383, d4.loss_iou_aux1: 0.2059, loss: 25.0403, grad_norm: 166.4315
2024-03-18 23:45:03,329 - mmdet - INFO - Epoch [16][250/463]	lr: 1.000e-06, eta: 0:09:01, time: 2.602, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1285, enc_loss_bbox: 0.0659, enc_loss_iou: 0.3341, loss_cls: 0.0850, loss_bbox: 0.0645, loss_iou: 0.3274, d0.loss_cls: 0.1515, d0.loss_bbox: 0.0645, d0.loss_iou: 0.3280, d1.loss_cls: 0.0917, d1.loss_bbox: 0.0644, d1.loss_iou: 0.3273, d2.loss_cls: 0.0858, d2.loss_bbox: 0.0643, d2.loss_iou: 0.3274, d3.loss_cls: 0.0856, d3.loss_bbox: 0.0644, d3.loss_iou: 0.3272, d4.loss_cls: 0.0854, d4.loss_bbox: 0.0644, d4.loss_iou: 0.3272, dn_loss_cls: 0.0078, dn_loss_bbox: 0.0343, dn_loss_iou: 0.1938, d0.dn_loss_cls: 0.0322, d0.dn_loss_bbox: 0.0493, d0.dn_loss_iou: 0.2690, d1.dn_loss_cls: 0.0099, d1.dn_loss_bbox: 0.0350, d1.dn_loss_iou: 0.1969, d2.dn_loss_cls: 0.0080, d2.dn_loss_bbox: 0.0343, d2.dn_loss_iou: 0.1939, d3.dn_loss_cls: 0.0079, d3.dn_loss_bbox: 0.0343, d3.dn_loss_iou: 0.1937, d4.dn_loss_cls: 0.0077, d4.dn_loss_bbox: 0.0343, d4.dn_loss_iou: 0.1938, loss_rpn_cls: 0.0251, loss_rpn_bbox: 0.1581, loss_cls0: 2.0956, acc0: 92.7278, loss_bbox0: 3.2958, loss_cls1: 1.5412, loss_bbox1: 3.6128, loss_centerness1: 7.1435, loss_cls_aux0: 0.0140, loss_bbox_aux0: 0.0167, loss_iou_aux0: 0.0870, d0.loss_cls_aux0: 0.0160, d0.loss_bbox_aux0: 0.0405, d0.loss_iou_aux0: 0.2138, d1.loss_cls_aux0: 0.0161, d1.loss_bbox_aux0: 0.0192, d1.loss_iou_aux0: 0.1007, d2.loss_cls_aux0: 0.0146, d2.loss_bbox_aux0: 0.0173, d2.loss_iou_aux0: 0.0905, d3.loss_cls_aux0: 0.0139, d3.loss_bbox_aux0: 0.0167, d3.loss_iou_aux0: 0.0869, d4.loss_cls_aux0: 0.0134, d4.loss_bbox_aux0: 0.0167, d4.loss_iou_aux0: 0.0869, loss_cls_aux1: 0.0116, loss_bbox_aux1: 0.0392, loss_iou_aux1: 0.2082, d0.loss_cls_aux1: 0.0152, d0.loss_bbox_aux1: 0.0461, d0.loss_iou_aux1: 0.2392, d1.loss_cls_aux1: 0.0137, d1.loss_bbox_aux1: 0.0403, d1.loss_iou_aux1: 0.2135, d2.loss_cls_aux1: 0.0129, d2.loss_bbox_aux1: 0.0393, d2.loss_iou_aux1: 0.2086, d3.loss_cls_aux1: 0.0122, d3.loss_bbox_aux1: 0.0392, d3.loss_iou_aux1: 0.2081, d4.loss_cls_aux1: 0.0116, d4.loss_bbox_aux1: 0.0392, d4.loss_iou_aux1: 0.2082, loss: 25.3598, grad_norm: 108.0205
2024-03-18 23:47:16,252 - mmdet - INFO - Epoch [16][300/463]	lr: 1.000e-06, eta: 0:06:54, time: 2.658, data_time: 0.008, memory: 19333, enc_loss_cls: 0.1406, enc_loss_bbox: 0.0611, enc_loss_iou: 0.3192, loss_cls: 0.0916, loss_bbox: 0.0591, loss_iou: 0.3121, d0.loss_cls: 0.1706, d0.loss_bbox: 0.0591, d0.loss_iou: 0.3105, d1.loss_cls: 0.0954, d1.loss_bbox: 0.0596, d1.loss_iou: 0.3138, d2.loss_cls: 0.0903, d2.loss_bbox: 0.0595, d2.loss_iou: 0.3133, d3.loss_cls: 0.0919, d3.loss_bbox: 0.0593, d3.loss_iou: 0.3127, d4.loss_cls: 0.0914, d4.loss_bbox: 0.0592, d4.loss_iou: 0.3124, dn_loss_cls: 0.0068, dn_loss_bbox: 0.0330, dn_loss_iou: 0.1923, d0.dn_loss_cls: 0.0268, d0.dn_loss_bbox: 0.0462, d0.dn_loss_iou: 0.2621, d1.dn_loss_cls: 0.0085, d1.dn_loss_bbox: 0.0336, d1.dn_loss_iou: 0.1960, d2.dn_loss_cls: 0.0071, d2.dn_loss_bbox: 0.0330, d2.dn_loss_iou: 0.1928, d3.dn_loss_cls: 0.0070, d3.dn_loss_bbox: 0.0330, d3.dn_loss_iou: 0.1926, d4.dn_loss_cls: 0.0069, d4.dn_loss_bbox: 0.0330, d4.dn_loss_iou: 0.1924, loss_rpn_cls: 0.0155, loss_rpn_bbox: 0.1295, loss_cls0: 1.8969, acc0: 93.4111, loss_bbox0: 3.1582, loss_cls1: 1.5289, loss_bbox1: 3.4869, loss_centerness1: 7.1166, loss_cls_aux0: 0.0078, loss_bbox_aux0: 0.0134, loss_iou_aux0: 0.0735, d0.loss_cls_aux0: 0.0106, d0.loss_bbox_aux0: 0.0381, d0.loss_iou_aux0: 0.2097, d1.loss_cls_aux0: 0.0103, d1.loss_bbox_aux0: 0.0162, d1.loss_iou_aux0: 0.0891, d2.loss_cls_aux0: 0.0090, d2.loss_bbox_aux0: 0.0140, d2.loss_iou_aux0: 0.0770, d3.loss_cls_aux0: 0.0092, d3.loss_bbox_aux0: 0.0134, d3.loss_iou_aux0: 0.0735, d4.loss_cls_aux0: 0.0080, d4.loss_bbox_aux0: 0.0134, d4.loss_iou_aux0: 0.0735, loss_cls_aux1: 0.0091, loss_bbox_aux1: 0.0363, loss_iou_aux1: 0.1997, d0.loss_cls_aux1: 0.0114, d0.loss_bbox_aux1: 0.0436, d0.loss_iou_aux1: 0.2367, d1.loss_cls_aux1: 0.0115, d1.loss_bbox_aux1: 0.0376, d1.loss_iou_aux1: 0.2062, d2.loss_cls_aux1: 0.0096, d2.loss_bbox_aux1: 0.0363, d2.loss_iou_aux1: 0.1998, d3.loss_cls_aux1: 0.0100, d3.loss_bbox_aux1: 0.0363, d3.loss_iou_aux1: 0.1997, d4.loss_cls_aux1: 0.0092, d4.loss_bbox_aux1: 0.0363, d4.loss_iou_aux1: 0.1997, loss: 24.5070, grad_norm: 124.8052
2024-03-18 23:49:18,269 - mmdet - INFO - Epoch [16][350/463]	lr: 1.000e-06, eta: 0:04:47, time: 2.440, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1243, enc_loss_bbox: 0.0606, enc_loss_iou: 0.3220, loss_cls: 0.0804, loss_bbox: 0.0613, loss_iou: 0.3178, d0.loss_cls: 0.1485, d0.loss_bbox: 0.0599, d0.loss_iou: 0.3179, d1.loss_cls: 0.0863, d1.loss_bbox: 0.0594, d1.loss_iou: 0.3169, d2.loss_cls: 0.0809, d2.loss_bbox: 0.0614, d2.loss_iou: 0.3181, d3.loss_cls: 0.0805, d3.loss_bbox: 0.0613, d3.loss_iou: 0.3179, d4.loss_cls: 0.0796, d4.loss_bbox: 0.0613, d4.loss_iou: 0.3178, dn_loss_cls: 0.0082, dn_loss_bbox: 0.0327, dn_loss_iou: 0.1915, d0.dn_loss_cls: 0.0281, d0.dn_loss_bbox: 0.0453, d0.dn_loss_iou: 0.2577, d1.dn_loss_cls: 0.0096, d1.dn_loss_bbox: 0.0333, d1.dn_loss_iou: 0.1939, d2.dn_loss_cls: 0.0079, d2.dn_loss_bbox: 0.0327, d2.dn_loss_iou: 0.1912, d3.dn_loss_cls: 0.0077, d3.dn_loss_bbox: 0.0327, d3.dn_loss_iou: 0.1913, d4.dn_loss_cls: 0.0081, d4.dn_loss_bbox: 0.0327, d4.dn_loss_iou: 0.1914, loss_rpn_cls: 0.0124, loss_rpn_bbox: 0.1355, loss_cls0: 1.9984, acc0: 92.9327, loss_bbox0: 3.1734, loss_cls1: 1.4705, loss_bbox1: 3.5183, loss_centerness1: 7.1342, loss_cls_aux0: 0.0139, loss_bbox_aux0: 0.0148, loss_iou_aux0: 0.0810, d0.loss_cls_aux0: 0.0144, d0.loss_bbox_aux0: 0.0382, d0.loss_iou_aux0: 0.2127, d1.loss_cls_aux0: 0.0150, d1.loss_bbox_aux0: 0.0176, d1.loss_iou_aux0: 0.0961, d2.loss_cls_aux0: 0.0134, d2.loss_bbox_aux0: 0.0154, d2.loss_iou_aux0: 0.0850, d3.loss_cls_aux0: 0.0116, d3.loss_bbox_aux0: 0.0148, d3.loss_iou_aux0: 0.0809, d4.loss_cls_aux0: 0.0129, d4.loss_bbox_aux0: 0.0148, d4.loss_iou_aux0: 0.0810, loss_cls_aux1: 0.0127, loss_bbox_aux1: 0.0363, loss_iou_aux1: 0.2031, d0.loss_cls_aux1: 0.0147, d0.loss_bbox_aux1: 0.0430, d0.loss_iou_aux1: 0.2347, d1.loss_cls_aux1: 0.0140, d1.loss_bbox_aux1: 0.0371, d1.loss_iou_aux1: 0.2074, d2.loss_cls_aux1: 0.0132, d2.loss_bbox_aux1: 0.0364, d2.loss_iou_aux1: 0.2035, d3.loss_cls_aux1: 0.0118, d3.loss_bbox_aux1: 0.0363, d3.loss_iou_aux1: 0.2031, d4.loss_cls_aux1: 0.0122, d4.loss_bbox_aux1: 0.0363, d4.loss_iou_aux1: 0.2031, loss: 24.6646, grad_norm: 153.2695
2024-03-18 23:51:30,925 - mmdet - INFO - Epoch [16][400/463]	lr: 1.000e-06, eta: 0:02:40, time: 2.653, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1240, enc_loss_bbox: 0.0622, enc_loss_iou: 0.3400, loss_cls: 0.0768, loss_bbox: 0.0624, loss_iou: 0.3363, d0.loss_cls: 0.1545, d0.loss_bbox: 0.0616, d0.loss_iou: 0.3368, d1.loss_cls: 0.0857, d1.loss_bbox: 0.0619, d1.loss_iou: 0.3363, d2.loss_cls: 0.0777, d2.loss_bbox: 0.0623, d2.loss_iou: 0.3373, d3.loss_cls: 0.0767, d3.loss_bbox: 0.0623, d3.loss_iou: 0.3368, d4.loss_cls: 0.0764, d4.loss_bbox: 0.0623, d4.loss_iou: 0.3366, dn_loss_cls: 0.0085, dn_loss_bbox: 0.0334, dn_loss_iou: 0.1956, d0.dn_loss_cls: 0.0352, d0.dn_loss_bbox: 0.0483, d0.dn_loss_iou: 0.2711, d1.dn_loss_cls: 0.0130, d1.dn_loss_bbox: 0.0343, d1.dn_loss_iou: 0.1983, d2.dn_loss_cls: 0.0098, d2.dn_loss_bbox: 0.0335, d2.dn_loss_iou: 0.1948, d3.dn_loss_cls: 0.0091, d3.dn_loss_bbox: 0.0334, d3.dn_loss_iou: 0.1948, d4.dn_loss_cls: 0.0089, d4.dn_loss_bbox: 0.0334, d4.dn_loss_iou: 0.1948, loss_rpn_cls: 0.0200, loss_rpn_bbox: 0.1582, loss_cls0: 2.1059, acc0: 92.8708, loss_bbox0: 3.3531, loss_cls1: 1.5948, loss_bbox1: 3.6405, loss_centerness1: 7.1224, loss_cls_aux0: 0.0128, loss_bbox_aux0: 0.0145, loss_iou_aux0: 0.0795, d0.loss_cls_aux0: 0.0187, d0.loss_bbox_aux0: 0.0379, d0.loss_iou_aux0: 0.2132, d1.loss_cls_aux0: 0.0203, d1.loss_bbox_aux0: 0.0173, d1.loss_iou_aux0: 0.0969, d2.loss_cls_aux0: 0.0178, d2.loss_bbox_aux0: 0.0152, d2.loss_iou_aux0: 0.0837, d3.loss_cls_aux0: 0.0156, d3.loss_bbox_aux0: 0.0145, d3.loss_iou_aux0: 0.0794, d4.loss_cls_aux0: 0.0134, d4.loss_bbox_aux0: 0.0145, d4.loss_iou_aux0: 0.0795, loss_cls_aux1: 0.0139, loss_bbox_aux1: 0.0359, loss_iou_aux1: 0.2030, d0.loss_cls_aux1: 0.0198, d0.loss_bbox_aux1: 0.0429, d0.loss_iou_aux1: 0.2392, d1.loss_cls_aux1: 0.0182, d1.loss_bbox_aux1: 0.0371, d1.loss_iou_aux1: 0.2092, d2.loss_cls_aux1: 0.0188, d2.loss_bbox_aux1: 0.0359, d2.loss_iou_aux1: 0.2034, d3.loss_cls_aux1: 0.0158, d3.loss_bbox_aux1: 0.0358, d3.loss_iou_aux1: 0.2030, d4.loss_cls_aux1: 0.0138, d4.loss_bbox_aux1: 0.0359, d4.loss_iou_aux1: 0.2030, loss: 25.4411, grad_norm: 111.8114
2024-03-18 23:53:45,650 - mmdet - INFO - Epoch [16][450/463]	lr: 1.000e-06, eta: 0:00:33, time: 2.695, data_time: 0.010, memory: 19333, enc_loss_cls: 0.1278, enc_loss_bbox: 0.0635, enc_loss_iou: 0.3326, loss_cls: 0.0796, loss_bbox: 0.0627, loss_iou: 0.3296, d0.loss_cls: 0.1545, d0.loss_bbox: 0.0625, d0.loss_iou: 0.3287, d1.loss_cls: 0.0841, d1.loss_bbox: 0.0635, d1.loss_iou: 0.3308, d2.loss_cls: 0.0807, d2.loss_bbox: 0.0631, d2.loss_iou: 0.3303, d3.loss_cls: 0.0813, d3.loss_bbox: 0.0625, d3.loss_iou: 0.3292, d4.loss_cls: 0.0804, d4.loss_bbox: 0.0625, d4.loss_iou: 0.3292, dn_loss_cls: 0.0066, dn_loss_bbox: 0.0349, dn_loss_iou: 0.1989, d0.dn_loss_cls: 0.0307, d0.dn_loss_bbox: 0.0492, d0.dn_loss_iou: 0.2734, d1.dn_loss_cls: 0.0093, d1.dn_loss_bbox: 0.0354, d1.dn_loss_iou: 0.2019, d2.dn_loss_cls: 0.0073, d2.dn_loss_bbox: 0.0349, d2.dn_loss_iou: 0.1989, d3.dn_loss_cls: 0.0066, d3.dn_loss_bbox: 0.0349, d3.dn_loss_iou: 0.1988, d4.dn_loss_cls: 0.0066, d4.dn_loss_bbox: 0.0349, d4.dn_loss_iou: 0.1989, loss_rpn_cls: 0.0179, loss_rpn_bbox: 0.1547, loss_cls0: 2.0358, acc0: 92.7556, loss_bbox0: 3.3766, loss_cls1: 1.5596, loss_bbox1: 3.6978, loss_centerness1: 7.1333, loss_cls_aux0: 0.0119, loss_bbox_aux0: 0.0154, loss_iou_aux0: 0.0828, d0.loss_cls_aux0: 0.0118, d0.loss_bbox_aux0: 0.0411, d0.loss_iou_aux0: 0.2259, d1.loss_cls_aux0: 0.0116, d1.loss_bbox_aux0: 0.0182, d1.loss_iou_aux0: 0.0986, d2.loss_cls_aux0: 0.0107, d2.loss_bbox_aux0: 0.0161, d2.loss_iou_aux0: 0.0870, d3.loss_cls_aux0: 0.0105, d3.loss_bbox_aux0: 0.0154, d3.loss_iou_aux0: 0.0828, d4.loss_cls_aux0: 0.0114, d4.loss_bbox_aux0: 0.0154, d4.loss_iou_aux0: 0.0827, loss_cls_aux1: 0.0101, loss_bbox_aux1: 0.0386, loss_iou_aux1: 0.2102, d0.loss_cls_aux1: 0.0110, d0.loss_bbox_aux1: 0.0455, d0.loss_iou_aux1: 0.2443, d1.loss_cls_aux1: 0.0104, d1.loss_bbox_aux1: 0.0396, d1.loss_iou_aux1: 0.2147, d2.loss_cls_aux1: 0.0098, d2.loss_bbox_aux1: 0.0386, d2.loss_iou_aux1: 0.2106, d3.loss_cls_aux1: 0.0091, d3.loss_bbox_aux1: 0.0386, d3.loss_iou_aux1: 0.2102, d4.loss_cls_aux1: 0.0100, d4.loss_bbox_aux1: 0.0386, d4.loss_iou_aux1: 0.2102, loss: 25.4259, grad_norm: 117.2736
2024-03-18 23:54:17,951 - mmdet - INFO - Saving checkpoint at 16 epochs
2024-03-18 23:55:44,463 - mmdet - INFO - Evaluating bbox...
2024-03-18 23:56:00,154 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.618
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.893
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.743
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.500
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.588
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.811
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.734
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.736
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.728
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.856

2024-03-18 23:56:00,154 - mmdet - INFO - 
+----------+-------+----------+-------+
| category | AP    | category | AP    |
+----------+-------+----------+-------+
| Tin      | 0.657 | Thatch   | 0.580 |
+----------+-------+----------+-------+
2024-03-18 23:56:00,278 - mmdet - INFO - Exp name: co_dino_5scale_swin_large_16e_o365tococo.py
2024-03-18 23:56:00,278 - mmdet - INFO - Epoch(val) [16][154]	bbox_mAP: 0.6180, bbox_mAP_50: 0.8930, bbox_mAP_75: 0.7430, bbox_mAP_s: 0.5000, bbox_mAP_m: 0.5880, bbox_mAP_l: 0.8110, bbox_mAP_copypaste: 0.618 0.893 0.743 0.500 0.588 0.811
