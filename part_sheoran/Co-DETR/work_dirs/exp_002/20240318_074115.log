2024-03-18 07:41:15,454 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.9.18 (main, Sep 11 2023, 13:41:44) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA GeForce RTX 3090
CUDA_HOME: None
GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0
PyTorch: 1.13.1+cu117
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.14.1+cu117
OpenCV: 4.9.0
MMCV: 1.7.0
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.7
MMDetection: 2.25.3+bf3d49d
------------------------------------------------------------

2024-03-18 07:41:17,950 - mmdet - INFO - Distributed training: True
2024-03-18 07:41:20,365 - mmdet - INFO - Config:
dataset_type = 'CocoDataset'
data_root = '/mnt/md0/arm_unicef/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='AutoAugment',
        policies=[[{
            'type':
            'Resize',
            'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333),
                          (608, 1333), (640, 1333), (672, 1333), (704, 1333),
                          (736, 1333), (768, 1333), (800, 1333)],
            'multiscale_mode':
            'value',
            'keep_ratio':
            True
        }],
                  [{
                      'type': 'Resize',
                      'img_scale': [(400, 4200), (500, 4200), (600, 4200)],
                      'multiscale_mode': 'value',
                      'keep_ratio': True
                  }, {
                      'type': 'RandomCrop',
                      'crop_type': 'absolute_range',
                      'crop_size': (384, 600),
                      'allow_negative_crop': True
                  }, {
                      'type':
                      'Resize',
                      'img_scale': [(480, 1333), (512, 1333), (544, 1333),
                                    (576, 1333), (608, 1333), (640, 1333),
                                    (672, 1333), (704, 1333), (736, 1333),
                                    (768, 1333), (800, 1333)],
                      'multiscale_mode':
                      'value',
                      'override':
                      True,
                      'keep_ratio':
                      True
                  }]]),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=1),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=1),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        ann_file='/mnt/md0/arm_unicef/mmdet_data_v1//Fold_0/train_data.json',
        img_prefix='/mnt/md0/arm_unicef/train_images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations', with_bbox=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='AutoAugment',
                policies=[[{
                    'type':
                    'Resize',
                    'img_scale': [(480, 1333), (512, 1333), (544, 1333),
                                  (576, 1333), (608, 1333), (640, 1333),
                                  (672, 1333), (704, 1333), (736, 1333),
                                  (768, 1333), (800, 1333)],
                    'multiscale_mode':
                    'value',
                    'keep_ratio':
                    True
                }],
                          [{
                              'type': 'Resize',
                              'img_scale': [(400, 4200), (500, 4200),
                                            (600, 4200)],
                              'multiscale_mode': 'value',
                              'keep_ratio': True
                          }, {
                              'type': 'RandomCrop',
                              'crop_type': 'absolute_range',
                              'crop_size': (384, 600),
                              'allow_negative_crop': True
                          }, {
                              'type':
                              'Resize',
                              'img_scale': [(480, 1333), (512, 1333),
                                            (544, 1333), (576, 1333),
                                            (608, 1333), (640, 1333),
                                            (672, 1333), (704, 1333),
                                            (736, 1333), (768, 1333),
                                            (800, 1333)],
                              'multiscale_mode':
                              'value',
                              'override':
                              True,
                              'keep_ratio':
                              True
                          }]]),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=1),
            dict(type='DefaultFormatBundle'),
            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
        ],
        filter_empty_gt=False),
    val=dict(
        type='CocoDataset',
        ann_file='/mnt/md0/arm_unicef/mmdet_data_v1//Fold_0/valid_data.json',
        img_prefix='/mnt/md0/arm_unicef/train_images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=1),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='CocoDataset',
        ann_file='/mnt/md0/arm_unicef/mmdet_data_v1//Fold_0/valid_data.json',
        img_prefix='/mnt/md0/arm_unicef/train_images/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=1),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(
    interval=1, metric='bbox', classwise=True, save_best='bbox_mAP')
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = './pretrained/co_deformable_detr_swin_base_3x_coco.pth'
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
auto_scale_lr = dict(enable=False, base_batch_size=16)
num_dec_layer = 6
lambda_2 = 2.0
model = dict(
    type='CoDETR',
    backbone=dict(
        type='SwinTransformerV1',
        embed_dim=128,
        depths=[2, 2, 18, 2],
        num_heads=[4, 8, 16, 32],
        out_indices=(1, 2, 3),
        window_size=12,
        ape=False,
        drop_path_rate=0.4,
        patch_norm=True,
        use_checkpoint=False,
        pretrained=None),
    neck=dict(
        type='ChannelMapper',
        in_channels=[256, 512, 1024],
        kernel_size=1,
        out_channels=256,
        act_cfg=None,
        norm_cfg=dict(type='GN', num_groups=32),
        num_outs=4),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            octave_base_scale=4,
            scales_per_octave=3,
            ratios=[0.5, 1.0, 2.0],
            strides=[8, 16, 32, 64, 128]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=12.0),
        loss_bbox=dict(type='L1Loss', loss_weight=12.0)),
    query_head=dict(
        type='CoDeformDETRHead',
        num_query=300,
        num_classes=3,
        in_channels=2048,
        sync_cls_avg_factor=True,
        with_box_refine=True,
        as_two_stage=True,
        mixed_selection=True,
        transformer=dict(
            type='CoDeformableDetrTransformer',
            num_co_heads=2,
            encoder=dict(
                type='DetrTransformerEncoder',
                num_layers=6,
                transformerlayers=dict(
                    type='BaseTransformerLayer',
                    attn_cfgs=dict(
                        type='MultiScaleDeformableAttention',
                        embed_dims=256,
                        dropout=0.0),
                    feedforward_channels=2048,
                    ffn_dropout=0.0,
                    operation_order=('self_attn', 'norm', 'ffn', 'norm'))),
            decoder=dict(
                type='CoDeformableDetrTransformerDecoder',
                num_layers=6,
                return_intermediate=True,
                look_forward_twice=True,
                transformerlayers=dict(
                    type='DetrTransformerDecoderLayer',
                    attn_cfgs=[
                        dict(
                            type='MultiheadAttention',
                            embed_dims=256,
                            num_heads=8,
                            dropout=0.0),
                        dict(
                            type='MultiScaleDeformableAttention',
                            embed_dims=256,
                            dropout=0.0)
                    ],
                    feedforward_channels=2048,
                    ffn_dropout=0.0,
                    operation_order=('self_attn', 'norm', 'cross_attn', 'norm',
                                     'ffn', 'norm')))),
        positional_encoding=dict(
            type='SinePositionalEncoding',
            num_feats=128,
            normalize=True,
            offset=-0.5),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=2.0),
        loss_bbox=dict(type='L1Loss', loss_weight=5.0),
        loss_iou=dict(type='GIoULoss', loss_weight=2.0)),
    roi_head=[
        dict(
            type='CoStandardRoIHead',
            bbox_roi_extractor=dict(
                type='SingleRoIExtractor',
                roi_layer=dict(
                    type='RoIAlign', output_size=7, sampling_ratio=0),
                out_channels=256,
                featmap_strides=[8, 16, 32, 64],
                finest_scale=112),
            bbox_head=dict(
                type='Shared2FCBBoxHead',
                in_channels=256,
                fc_out_channels=1024,
                roi_feat_size=7,
                num_classes=3,
                bbox_coder=dict(
                    type='DeltaXYWHBBoxCoder',
                    target_means=[0.0, 0.0, 0.0, 0.0],
                    target_stds=[0.1, 0.1, 0.2, 0.2]),
                reg_class_agnostic=False,
                reg_decoded_bbox=True,
                loss_cls=dict(
                    type='CrossEntropyLoss',
                    use_sigmoid=False,
                    loss_weight=12.0),
                loss_bbox=dict(type='GIoULoss', loss_weight=120.0)))
    ],
    bbox_head=[
        dict(
            type='CoATSSHead',
            num_classes=3,
            in_channels=256,
            stacked_convs=1,
            feat_channels=256,
            anchor_generator=dict(
                type='AnchorGenerator',
                ratios=[1.0],
                octave_base_scale=8,
                scales_per_octave=1,
                strides=[8, 16, 32, 64, 128]),
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            loss_cls=dict(
                type='FocalLoss',
                use_sigmoid=True,
                gamma=2.0,
                alpha=0.25,
                loss_weight=12.0),
            loss_bbox=dict(type='GIoULoss', loss_weight=24.0),
            loss_centerness=dict(
                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=12.0))
    ],
    train_cfg=[
        dict(
            assigner=dict(
                type='HungarianAssigner',
                cls_cost=dict(type='FocalLossCost', weight=2.0),
                reg_cost=dict(
                    type='BBoxL1Cost', weight=5.0, box_format='xywh'),
                iou_cost=dict(type='IoUCost', iou_mode='giou', weight=2.0))),
        dict(
            rpn=dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.7,
                    neg_iou_thr=0.3,
                    min_pos_iou=0.3,
                    match_low_quality=True,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=256,
                    pos_fraction=0.5,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=False),
                allowed_border=-1,
                pos_weight=-1,
                debug=False),
            rpn_proposal=dict(
                nms_pre=4000,
                max_per_img=1000,
                nms=dict(type='nms', iou_threshold=0.7),
                min_bbox_size=0),
            rcnn=dict(
                assigner=dict(
                    type='MaxIoUAssigner',
                    pos_iou_thr=0.5,
                    neg_iou_thr=0.5,
                    min_pos_iou=0.5,
                    match_low_quality=False,
                    ignore_iof_thr=-1),
                sampler=dict(
                    type='RandomSampler',
                    num=512,
                    pos_fraction=0.25,
                    neg_pos_ub=-1,
                    add_gt_as_proposals=True),
                pos_weight=-1,
                debug=False)),
        dict(
            assigner=dict(type='ATSSAssigner', topk=9),
            allowed_border=-1,
            pos_weight=-1,
            debug=False)
    ],
    test_cfg=[
        dict(max_per_img=100),
        dict(
            rpn=dict(
                nms_pre=1000,
                max_per_img=1000,
                nms=dict(type='nms', iou_threshold=0.7),
                min_bbox_size=0),
            rcnn=dict(
                score_thr=0.0,
                nms=dict(type='nms', iou_threshold=0.5),
                max_per_img=100)),
        dict(
            nms_pre=1000,
            min_bbox_size=0,
            score_thr=0.0,
            nms=dict(type='nms', iou_threshold=0.6),
            max_per_img=100)
    ])
optimizer = dict(
    type='AdamW',
    lr=0.0002,
    weight_decay=0.05,
    paramwise_cfg=dict(
        custom_keys=dict(
            backbone=dict(lr_mult=0.1),
            sampling_offsets=dict(lr_mult=0.1),
            reference_points=dict(lr_mult=0.1))))
optimizer_config = dict(grad_clip=dict(max_norm=0.1, norm_type=2))
lr_config = dict(policy='step', step=[30])
runner = dict(type='EpochBasedRunner', max_epochs=36)
pretrained = None
work_dir = './work_dirs/exp_002'
auto_resume = False
gpu_ids = range(0, 4)

2024-03-18 07:41:21,478 - mmdet - INFO - Set random seed to 1053227464, deterministic: True
2024-03-18 07:41:22,200 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
Name of parameter - Initialization information

rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_cls.weight - torch.Size([9, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_cls.bias - torch.Size([9]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_reg.weight - torch.Size([36, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_reg.bias - torch.Size([36]): 
NormalInit: mean=0, std=0.01, bias=0 
2024-03-18 07:41:22,286 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
Name of parameter - Initialization information

bbox_head.fc_cls.weight - torch.Size([4, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.fc_cls.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.fc_reg.weight - torch.Size([12, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

bbox_head.fc_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.001, bias=0 

bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

bbox_head.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 
2024-03-18 07:41:22,517 - mmdet - INFO - initialize CoATSSHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'atss_cls', 'std': 0.01, 'bias_prob': 0.01}}
Name of parameter - Initialization information

cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

cls_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

cls_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

reg_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

reg_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

atss_cls.weight - torch.Size([3, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

atss_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

atss_reg.weight - torch.Size([4, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

atss_reg.bias - torch.Size([4]): 
NormalInit: mean=0, std=0.01, bias=0 

atss_centerness.weight - torch.Size([1, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

atss_centerness.bias - torch.Size([1]): 
NormalInit: mean=0, std=0.01, bias=0 

scales.0.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

scales.1.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

scales.2.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

scales.3.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoATSSHead  

scales.4.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoATSSHead  
2024-03-18 07:41:23,144 - mmdet - INFO - initialize ChannelMapper with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
Name of parameter - Initialization information

backbone.patch_embed.proj.weight - torch.Size([128, 3, 4, 4]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.patch_embed.proj.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.patch_embed.norm.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.patch_embed.norm.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.norm1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.norm1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.attn.relative_position_bias_table - torch.Size([529, 4]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.attn.qkv.weight - torch.Size([384, 128]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.attn.qkv.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.attn.proj.weight - torch.Size([128, 128]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.attn.proj.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.0.mlp.fc1.weight - torch.Size([512, 128]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.mlp.fc1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.mlp.fc2.weight - torch.Size([128, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.0.mlp.fc2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.norm1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.1.norm1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.1.attn.relative_position_bias_table - torch.Size([529, 4]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.1.attn.qkv.weight - torch.Size([384, 128]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.attn.qkv.bias - torch.Size([384]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.attn.proj.weight - torch.Size([128, 128]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.attn.proj.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.norm2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.1.norm2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.blocks.1.mlp.fc1.weight - torch.Size([512, 128]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.mlp.fc1.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.mlp.fc2.weight - torch.Size([128, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.blocks.1.mlp.fc2.bias - torch.Size([128]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.downsample.reduction.weight - torch.Size([256, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.0.downsample.norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.0.downsample.norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.attn.relative_position_bias_table - torch.Size([529, 8]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.attn.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.attn.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.attn.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.attn.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.0.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.0.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.1.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.1.attn.relative_position_bias_table - torch.Size([529, 8]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.1.attn.qkv.weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.attn.qkv.bias - torch.Size([768]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.attn.proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.attn.proj.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.norm2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.1.norm2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.blocks.1.mlp.fc1.weight - torch.Size([1024, 256]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.mlp.fc1.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.mlp.fc2.weight - torch.Size([256, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.blocks.1.mlp.fc2.bias - torch.Size([256]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.downsample.reduction.weight - torch.Size([512, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.1.downsample.norm.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.1.downsample.norm.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.0.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.0.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.1.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.1.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.1.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.1.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.1.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.1.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.2.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.2.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.2.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.2.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.2.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.2.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.3.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.3.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.3.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.3.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.3.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.3.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.4.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.4.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.4.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.4.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.4.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.4.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.5.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.5.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.5.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.5.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.5.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.5.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.6.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.6.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.6.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.6.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.6.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.6.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.7.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.7.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.7.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.7.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.7.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.7.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.8.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.8.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.8.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.8.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.8.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.8.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.9.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.9.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.9.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.9.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.9.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.9.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.10.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.10.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.10.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.10.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.10.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.10.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.11.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.11.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.11.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.11.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.11.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.11.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.12.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.12.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.12.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.12.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.12.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.12.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.13.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.13.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.13.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.13.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.13.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.13.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.14.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.14.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.14.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.14.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.14.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.14.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.15.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.15.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.15.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.15.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.15.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.15.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.16.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.16.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.16.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.16.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.16.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.16.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.norm1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.17.norm1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.17.attn.relative_position_bias_table - torch.Size([529, 16]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.17.attn.qkv.weight - torch.Size([1536, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.attn.qkv.bias - torch.Size([1536]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.attn.proj.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.attn.proj.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.17.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.blocks.17.mlp.fc1.weight - torch.Size([2048, 512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.mlp.fc1.bias - torch.Size([2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.mlp.fc2.weight - torch.Size([512, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.blocks.17.mlp.fc2.bias - torch.Size([512]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.downsample.reduction.weight - torch.Size([1024, 2048]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.2.downsample.norm.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.2.downsample.norm.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.attn.relative_position_bias_table - torch.Size([529, 32]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.attn.qkv.weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.attn.qkv.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.attn.proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.attn.proj.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.0.mlp.fc1.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.mlp.fc1.bias - torch.Size([4096]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.mlp.fc2.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.0.mlp.fc2.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.norm1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.1.norm1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.1.attn.relative_position_bias_table - torch.Size([529, 32]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.1.attn.qkv.weight - torch.Size([3072, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.attn.qkv.bias - torch.Size([3072]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.attn.proj.weight - torch.Size([1024, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.attn.proj.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.norm2.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.1.norm2.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.layers.3.blocks.1.mlp.fc1.weight - torch.Size([4096, 1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.mlp.fc1.bias - torch.Size([4096]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.mlp.fc2.weight - torch.Size([1024, 4096]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.layers.3.blocks.1.mlp.fc2.bias - torch.Size([1024]): 
Initialized by user-defined `init_weights` in SwinTransformerV1  

backbone.norm1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm3.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

backbone.norm3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.convs.1.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.1.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.convs.2.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.convs.2.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.extra_convs.0.conv.weight - torch.Size([256, 1024, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.extra_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

neck.extra_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.level_embeds - torch.Size([4, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.0.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.0.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.1.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.1.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.2.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.2.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.3.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.3.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.4.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.4.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.5.attentions.0.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.attentions.0.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.5.attentions.0.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.encoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.0.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.1.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.2.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.3.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.4.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight - torch.Size([128, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.value_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.5.attentions.1.value_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.enc_output.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.enc_output.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.enc_output_norm.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.enc_output_norm.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.pos_trans.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.pos_trans.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.pos_trans_norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.pos_trans_norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.head_pos_embed.weight - torch.Size([2, 1]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.aux_pos_trans.0.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.aux_pos_trans.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.aux_pos_trans.1.weight - torch.Size([512, 512]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.aux_pos_trans.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.aux_pos_trans_norm.0.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.aux_pos_trans_norm.0.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.aux_pos_trans_norm.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.aux_pos_trans_norm.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.pos_feats_trans.0.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.pos_feats_trans.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.pos_feats_trans.1.weight - torch.Size([256, 256]): 
Initialized by user-defined `init_weights` in CoDeformDETRHead  

query_head.transformer.pos_feats_trans.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.pos_feats_norm.0.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.pos_feats_norm.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.pos_feats_norm.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.transformer.pos_feats_norm.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.downsample.0.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.downsample.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.0.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.0.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.1.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.1.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.2.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.2.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.3.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.3.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.4.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.4.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.5.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.5.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.6.weight - torch.Size([3, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.cls_branches.6.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.0.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.1.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.2.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.3.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.4.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.5.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.0.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.0.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.2.weight - torch.Size([256, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.4.weight - torch.Size([4, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.reg_branches.6.4.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

query_head.query_embedding.weight - torch.Size([300, 256]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_cls.weight - torch.Size([9, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_cls.bias - torch.Size([9]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_reg.weight - torch.Size([36, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of CoDETR  

rpn_head.rpn_reg.bias - torch.Size([36]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.fc_cls.weight - torch.Size([4, 1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.fc_cls.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.fc_reg.weight - torch.Size([12, 1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.fc_reg.bias - torch.Size([12]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

roi_head.0.bbox_head.shared_fcs.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.cls_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.cls_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.reg_convs.0.gn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.reg_convs.0.gn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_cls.weight - torch.Size([3, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_cls.bias - torch.Size([3]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_reg.weight - torch.Size([4, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_reg.bias - torch.Size([4]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_centerness.weight - torch.Size([1, 256, 3, 3]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.atss_centerness.bias - torch.Size([1]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.scales.0.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.scales.1.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.scales.2.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.scales.3.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoDETR  

bbox_head.0.scales.4.scale - torch.Size([]): 
The value is the same before and after calling `init_weights` of CoDETR  
2024-03-18 07:41:23,626 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.
2024-03-18 07:41:23,714 - mmdet - INFO - load checkpoint from local path: ./pretrained/co_deformable_detr_swin_base_3x_coco.pth
2024-03-18 07:41:24,123 - mmdet - WARNING - The model and loaded state dict do not match exactly

size mismatch for query_head.cls_branches.0.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).
size mismatch for query_head.cls_branches.0.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([3]).
size mismatch for query_head.cls_branches.1.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).
size mismatch for query_head.cls_branches.1.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([3]).
size mismatch for query_head.cls_branches.2.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).
size mismatch for query_head.cls_branches.2.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([3]).
size mismatch for query_head.cls_branches.3.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).
size mismatch for query_head.cls_branches.3.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([3]).
size mismatch for query_head.cls_branches.4.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).
size mismatch for query_head.cls_branches.4.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([3]).
size mismatch for query_head.cls_branches.5.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).
size mismatch for query_head.cls_branches.5.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([3]).
size mismatch for query_head.cls_branches.6.weight: copying a param with shape torch.Size([80, 256]) from checkpoint, the shape in current model is torch.Size([3, 256]).
size mismatch for query_head.cls_branches.6.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([3]).
size mismatch for roi_head.0.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).
size mismatch for roi_head.0.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([4]).
size mismatch for roi_head.0.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([12, 1024]).
size mismatch for roi_head.0.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([12]).
size mismatch for bbox_head.0.atss_cls.weight: copying a param with shape torch.Size([80, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([3, 256, 3, 3]).
size mismatch for bbox_head.0.atss_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([3]).
2024-03-18 07:41:24,128 - mmdet - INFO - Start running, host: harshit@harshit, work_dir: /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_002
2024-03-18 07:41:24,128 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) NumClassCheckHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) DistEvalHook                       
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2024-03-18 07:41:24,128 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs
2024-03-18 07:41:24,129 - mmdet - INFO - Checkpoints will be saved to /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_002 by HardDiskBackend.
2024-03-18 07:42:09,798 - mmdet - INFO - Epoch [1][50/232]	lr: 2.000e-05, eta: 2:06:21, time: 0.913, data_time: 0.079, memory: 17573, enc_loss_cls: 1.9287, enc_loss_bbox: 0.0666, enc_loss_iou: 0.3469, loss_cls: 0.7395, loss_bbox: 0.1336, loss_iou: 0.4930, d0.loss_cls: 0.9452, d0.loss_bbox: 0.1320, d0.loss_iou: 0.4860, d1.loss_cls: 0.7064, d1.loss_bbox: 0.1344, d1.loss_iou: 0.5002, d2.loss_cls: 0.7010, d2.loss_bbox: 0.1352, d2.loss_iou: 0.5017, d3.loss_cls: 0.7523, d3.loss_bbox: 0.1335, d3.loss_iou: 0.4937, d4.loss_cls: 0.7302, d4.loss_bbox: 0.1343, d4.loss_iou: 0.4962, loss_rpn_cls: 0.1586, loss_rpn_bbox: 0.1411, loss_cls0: 4.6530, acc0: 85.4795, loss_bbox0: 5.3871, loss_cls1: 6.7124, loss_bbox1: 4.5885, loss_centerness1: 7.5130, loss_cls_aux0: 0.5749, loss_bbox_aux0: 0.0496, loss_iou_aux0: 0.2452, d0.loss_cls_aux0: 0.6159, d0.loss_bbox_aux0: 0.0695, d0.loss_iou_aux0: 0.3388, d1.loss_cls_aux0: 0.5095, d1.loss_bbox_aux0: 0.0530, d1.loss_iou_aux0: 0.2605, d2.loss_cls_aux0: 0.5648, d2.loss_bbox_aux0: 0.0493, d2.loss_iou_aux0: 0.2433, d3.loss_cls_aux0: 0.6183, d3.loss_bbox_aux0: 0.0494, d3.loss_iou_aux0: 0.2439, d4.loss_cls_aux0: 0.5831, d4.loss_bbox_aux0: 0.0495, d4.loss_iou_aux0: 0.2444, loss_cls_aux1: 0.5826, loss_bbox_aux1: 0.0743, loss_iou_aux1: 0.3624, d0.loss_cls_aux1: 0.6843, d0.loss_bbox_aux1: 0.0875, d0.loss_iou_aux1: 0.4276, d1.loss_cls_aux1: 0.5209, d1.loss_bbox_aux1: 0.0750, d1.loss_iou_aux1: 0.3669, d2.loss_cls_aux1: 0.5738, d2.loss_bbox_aux1: 0.0741, d2.loss_iou_aux1: 0.3615, d3.loss_cls_aux1: 0.6288, d3.loss_bbox_aux1: 0.0742, d3.loss_iou_aux1: 0.3616, d4.loss_cls_aux1: 0.5920, d4.loss_bbox_aux1: 0.0742, d4.loss_iou_aux1: 0.3620, loss: 51.4912, grad_norm: 102.4608
2024-03-18 07:42:50,258 - mmdet - INFO - Epoch [1][100/232]	lr: 2.000e-05, eta: 1:58:26, time: 0.809, data_time: 0.012, memory: 17573, enc_loss_cls: 1.3205, enc_loss_bbox: 0.0615, enc_loss_iou: 0.3444, loss_cls: 0.2617, loss_bbox: 0.0883, loss_iou: 0.4316, d0.loss_cls: 0.4472, d0.loss_bbox: 0.0850, d0.loss_iou: 0.4227, d1.loss_cls: 0.2977, d1.loss_bbox: 0.0877, d1.loss_iou: 0.4283, d2.loss_cls: 0.2659, d2.loss_bbox: 0.0889, d2.loss_iou: 0.4295, d3.loss_cls: 0.2622, d3.loss_bbox: 0.0879, d3.loss_iou: 0.4306, d4.loss_cls: 0.2577, d4.loss_bbox: 0.0883, d4.loss_iou: 0.4317, loss_rpn_cls: 0.0826, loss_rpn_bbox: 0.1507, loss_cls0: 2.2685, acc0: 92.4641, loss_bbox0: 3.5400, loss_cls1: 2.1257, loss_bbox1: 4.3762, loss_centerness1: 7.5183, loss_cls_aux0: 0.1131, loss_bbox_aux0: 0.0358, loss_iou_aux0: 0.1855, d0.loss_cls_aux0: 0.1586, d0.loss_bbox_aux0: 0.0597, d0.loss_iou_aux0: 0.3038, d1.loss_cls_aux0: 0.1050, d1.loss_bbox_aux0: 0.0401, d1.loss_iou_aux0: 0.2080, d2.loss_cls_aux0: 0.1124, d2.loss_bbox_aux0: 0.0356, d2.loss_iou_aux0: 0.1846, d3.loss_cls_aux0: 0.1233, d3.loss_bbox_aux0: 0.0357, d3.loss_iou_aux0: 0.1849, d4.loss_cls_aux0: 0.1174, d4.loss_bbox_aux0: 0.0357, d4.loss_iou_aux0: 0.1852, loss_cls_aux1: 0.1141, loss_bbox_aux1: 0.0631, loss_iou_aux1: 0.3284, d0.loss_cls_aux1: 0.1752, d0.loss_bbox_aux1: 0.0729, d0.loss_iou_aux1: 0.3784, d1.loss_cls_aux1: 0.0994, d1.loss_bbox_aux1: 0.0631, d1.loss_iou_aux1: 0.3287, d2.loss_cls_aux1: 0.1100, d2.loss_bbox_aux1: 0.0630, d2.loss_iou_aux1: 0.3280, d3.loss_cls_aux1: 0.1248, d3.loss_bbox_aux1: 0.0630, d3.loss_iou_aux1: 0.3281, d4.loss_cls_aux1: 0.1184, d4.loss_bbox_aux1: 0.0631, d4.loss_iou_aux1: 0.3282, loss: 32.0557, grad_norm: 86.7993
2024-03-18 07:43:31,186 - mmdet - INFO - Epoch [1][150/232]	lr: 2.000e-05, eta: 1:55:46, time: 0.818, data_time: 0.009, memory: 17573, enc_loss_cls: 0.8512, enc_loss_bbox: 0.0641, enc_loss_iou: 0.3355, loss_cls: 0.2158, loss_bbox: 0.0887, loss_iou: 0.4109, d0.loss_cls: 0.3623, d0.loss_bbox: 0.0877, d0.loss_iou: 0.4068, d1.loss_cls: 0.2566, d1.loss_bbox: 0.0877, d1.loss_iou: 0.4075, d2.loss_cls: 0.2278, d2.loss_bbox: 0.0882, d2.loss_iou: 0.4089, d3.loss_cls: 0.2152, d3.loss_bbox: 0.0884, d3.loss_iou: 0.4097, d4.loss_cls: 0.2147, d4.loss_bbox: 0.0892, d4.loss_iou: 0.4106, loss_rpn_cls: 0.0955, loss_rpn_bbox: 0.1740, loss_cls0: 2.2489, acc0: 92.4881, loss_bbox0: 3.2906, loss_cls1: 1.7683, loss_bbox1: 4.1441, loss_centerness1: 7.5212, loss_cls_aux0: 0.0710, loss_bbox_aux0: 0.0345, loss_iou_aux0: 0.1702, d0.loss_cls_aux0: 0.0970, d0.loss_bbox_aux0: 0.0581, d0.loss_iou_aux0: 0.2833, d1.loss_cls_aux0: 0.0726, d1.loss_bbox_aux0: 0.0395, d1.loss_iou_aux0: 0.1958, d2.loss_cls_aux0: 0.0708, d2.loss_bbox_aux0: 0.0344, d2.loss_iou_aux0: 0.1693, d3.loss_cls_aux0: 0.0732, d3.loss_bbox_aux0: 0.0344, d3.loss_iou_aux0: 0.1696, d4.loss_cls_aux0: 0.0726, d4.loss_bbox_aux0: 0.0345, d4.loss_iou_aux0: 0.1699, loss_cls_aux1: 0.0694, loss_bbox_aux1: 0.0613, loss_iou_aux1: 0.3090, d0.loss_cls_aux1: 0.0953, d0.loss_bbox_aux1: 0.0713, d0.loss_iou_aux1: 0.3562, d1.loss_cls_aux1: 0.0644, d1.loss_bbox_aux1: 0.0615, d1.loss_iou_aux1: 0.3100, d2.loss_cls_aux1: 0.0663, d2.loss_bbox_aux1: 0.0612, d2.loss_iou_aux1: 0.3085, d3.loss_cls_aux1: 0.0716, d3.loss_bbox_aux1: 0.0612, d3.loss_iou_aux1: 0.3086, d4.loss_cls_aux1: 0.0711, d4.loss_bbox_aux1: 0.0613, d4.loss_iou_aux1: 0.3088, loss: 29.5377, grad_norm: 86.5338
2024-03-18 07:44:12,411 - mmdet - INFO - Epoch [1][200/232]	lr: 2.000e-05, eta: 1:54:18, time: 0.825, data_time: 0.009, memory: 17573, enc_loss_cls: 0.5814, enc_loss_bbox: 0.0649, enc_loss_iou: 0.3539, loss_cls: 0.2112, loss_bbox: 0.0832, loss_iou: 0.4012, d0.loss_cls: 0.3244, d0.loss_bbox: 0.0840, d0.loss_iou: 0.4044, d1.loss_cls: 0.2412, d1.loss_bbox: 0.0837, d1.loss_iou: 0.4010, d2.loss_cls: 0.2173, d2.loss_bbox: 0.0838, d2.loss_iou: 0.4008, d3.loss_cls: 0.2108, d3.loss_bbox: 0.0836, d3.loss_iou: 0.4006, d4.loss_cls: 0.2112, d4.loss_bbox: 0.0830, d4.loss_iou: 0.4007, loss_rpn_cls: 0.0802, loss_rpn_bbox: 0.1570, loss_cls0: 2.1515, acc0: 93.0580, loss_bbox0: 3.2057, loss_cls1: 1.6784, loss_bbox1: 4.1366, loss_centerness1: 7.5280, loss_cls_aux0: 0.0629, loss_bbox_aux0: 0.0311, loss_iou_aux0: 0.1577, d0.loss_cls_aux0: 0.0827, d0.loss_bbox_aux0: 0.0561, d0.loss_iou_aux0: 0.2779, d1.loss_cls_aux0: 0.0671, d1.loss_bbox_aux0: 0.0371, d1.loss_iou_aux0: 0.1863, d2.loss_cls_aux0: 0.0642, d2.loss_bbox_aux0: 0.0310, d2.loss_iou_aux0: 0.1564, d3.loss_cls_aux0: 0.0635, d3.loss_bbox_aux0: 0.0311, d3.loss_iou_aux0: 0.1568, d4.loss_cls_aux0: 0.0637, d4.loss_bbox_aux0: 0.0311, d4.loss_iou_aux0: 0.1572, loss_cls_aux1: 0.0645, loss_bbox_aux1: 0.0588, loss_iou_aux1: 0.3046, d0.loss_cls_aux1: 0.0851, d0.loss_bbox_aux1: 0.0688, d0.loss_iou_aux1: 0.3538, d1.loss_cls_aux1: 0.0640, d1.loss_bbox_aux1: 0.0592, d1.loss_iou_aux1: 0.3071, d2.loss_cls_aux1: 0.0645, d2.loss_bbox_aux1: 0.0587, d2.loss_iou_aux1: 0.3040, d3.loss_cls_aux1: 0.0659, d3.loss_bbox_aux1: 0.0588, d3.loss_iou_aux1: 0.3042, d4.loss_cls_aux1: 0.0659, d4.loss_bbox_aux1: 0.0588, d4.loss_iou_aux1: 0.3044, loss: 28.6285, grad_norm: 79.0639
2024-03-18 07:44:38,887 - mmdet - INFO - Saving checkpoint at 1 epochs
2024-03-18 07:45:00,915 - mmdet - INFO - Evaluating bbox...
2024-03-18 07:45:05,909 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.369
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.566
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.440
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.285
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.355
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.522
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.667
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.595
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.821

2024-03-18 07:45:05,909 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.011 | Tin      | 0.603 | Thatch   | 0.493 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 07:45:09,219 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_1.pth.
2024-03-18 07:45:09,219 - mmdet - INFO - Best bbox_mAP is 0.3690 at 1 epoch.
2024-03-18 07:45:09,220 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 07:45:09,220 - mmdet - INFO - Epoch(val) [1][154]	bbox_mAP: 0.3690, bbox_mAP_50: 0.5660, bbox_mAP_75: 0.4400, bbox_mAP_s: 0.2850, bbox_mAP_m: 0.3550, bbox_mAP_l: 0.5220, bbox_mAP_copypaste: 0.369 0.566 0.440 0.285 0.355 0.522
2024-03-18 07:45:52,628 - mmdet - INFO - Epoch [2][50/232]	lr: 2.000e-05, eta: 1:40:57, time: 0.868, data_time: 0.060, memory: 17573, enc_loss_cls: 0.3756, enc_loss_bbox: 0.0717, enc_loss_iou: 0.3906, loss_cls: 0.1926, loss_bbox: 0.0735, loss_iou: 0.3871, d0.loss_cls: 0.2689, d0.loss_bbox: 0.0732, d0.loss_iou: 0.3897, d1.loss_cls: 0.2128, d1.loss_bbox: 0.0732, d1.loss_iou: 0.3869, d2.loss_cls: 0.1987, d2.loss_bbox: 0.0731, d2.loss_iou: 0.3855, d3.loss_cls: 0.1947, d3.loss_bbox: 0.0733, d3.loss_iou: 0.3862, d4.loss_cls: 0.1934, d4.loss_bbox: 0.0733, d4.loss_iou: 0.3865, loss_rpn_cls: 0.0617, loss_rpn_bbox: 0.1443, loss_cls0: 1.9130, acc0: 93.6218, loss_bbox0: 3.0843, loss_cls1: 1.5605, loss_bbox1: 4.1433, loss_centerness1: 7.4999, loss_cls_aux0: 0.0548, loss_bbox_aux0: 0.0279, loss_iou_aux0: 0.1416, d0.loss_cls_aux0: 0.0704, d0.loss_bbox_aux0: 0.0523, d0.loss_iou_aux0: 0.2672, d1.loss_cls_aux0: 0.0598, d1.loss_bbox_aux0: 0.0319, d1.loss_iou_aux0: 0.1636, d2.loss_cls_aux0: 0.0555, d2.loss_bbox_aux0: 0.0278, d2.loss_iou_aux0: 0.1405, d3.loss_cls_aux0: 0.0546, d3.loss_bbox_aux0: 0.0278, d3.loss_iou_aux0: 0.1408, d4.loss_cls_aux0: 0.0548, d4.loss_bbox_aux0: 0.0279, d4.loss_iou_aux0: 0.1412, loss_cls_aux1: 0.0710, loss_bbox_aux1: 0.0571, loss_iou_aux1: 0.3055, d0.loss_cls_aux1: 0.0830, d0.loss_bbox_aux1: 0.0664, d0.loss_iou_aux1: 0.3536, d1.loss_cls_aux1: 0.0720, d1.loss_bbox_aux1: 0.0577, d1.loss_iou_aux1: 0.3084, d2.loss_cls_aux1: 0.0709, d2.loss_bbox_aux1: 0.0570, d2.loss_iou_aux1: 0.3050, d3.loss_cls_aux1: 0.0713, d3.loss_bbox_aux1: 0.0570, d3.loss_iou_aux1: 0.3052, d4.loss_cls_aux1: 0.0711, d4.loss_bbox_aux1: 0.0570, d4.loss_iou_aux1: 0.3053, loss: 27.4819, grad_norm: 87.9890
2024-03-18 07:46:32,932 - mmdet - INFO - Epoch [2][100/232]	lr: 2.000e-05, eta: 1:41:26, time: 0.806, data_time: 0.010, memory: 17573, enc_loss_cls: 0.2823, enc_loss_bbox: 0.0781, enc_loss_iou: 0.4027, loss_cls: 0.1508, loss_bbox: 0.0731, loss_iou: 0.3763, d0.loss_cls: 0.2097, d0.loss_bbox: 0.0738, d0.loss_iou: 0.3794, d1.loss_cls: 0.1668, d1.loss_bbox: 0.0731, d1.loss_iou: 0.3750, d2.loss_cls: 0.1573, d2.loss_bbox: 0.0730, d2.loss_iou: 0.3750, d3.loss_cls: 0.1518, d3.loss_bbox: 0.0732, d3.loss_iou: 0.3759, d4.loss_cls: 0.1506, d4.loss_bbox: 0.0731, d4.loss_iou: 0.3760, loss_rpn_cls: 0.0569, loss_rpn_bbox: 0.1438, loss_cls0: 1.8832, acc0: 93.6676, loss_bbox0: 3.0355, loss_cls1: 1.3658, loss_bbox1: 4.1866, loss_centerness1: 7.5389, loss_cls_aux0: 0.0369, loss_bbox_aux0: 0.0297, loss_iou_aux0: 0.1449, d0.loss_cls_aux0: 0.0518, d0.loss_bbox_aux0: 0.0544, d0.loss_iou_aux0: 0.2704, d1.loss_cls_aux0: 0.0416, d1.loss_bbox_aux0: 0.0348, d1.loss_iou_aux0: 0.1703, d2.loss_cls_aux0: 0.0382, d2.loss_bbox_aux0: 0.0296, d2.loss_iou_aux0: 0.1439, d3.loss_cls_aux0: 0.0369, d3.loss_bbox_aux0: 0.0296, d3.loss_iou_aux0: 0.1442, d4.loss_cls_aux0: 0.0369, d4.loss_bbox_aux0: 0.0297, d4.loss_iou_aux0: 0.1445, loss_cls_aux1: 0.0337, loss_bbox_aux1: 0.0575, loss_iou_aux1: 0.3004, d0.loss_cls_aux1: 0.0427, d0.loss_bbox_aux1: 0.0667, d0.loss_iou_aux1: 0.3460, d1.loss_cls_aux1: 0.0344, d1.loss_bbox_aux1: 0.0580, d1.loss_iou_aux1: 0.3021, d2.loss_cls_aux1: 0.0337, d2.loss_bbox_aux1: 0.0574, d2.loss_iou_aux1: 0.2999, d3.loss_cls_aux1: 0.0338, d3.loss_bbox_aux1: 0.0574, d3.loss_iou_aux1: 0.3001, d4.loss_cls_aux1: 0.0338, d4.loss_bbox_aux1: 0.0574, d4.loss_iou_aux1: 0.3002, loss: 26.5410, grad_norm: 80.1240
2024-03-18 07:47:13,745 - mmdet - INFO - Epoch [2][150/232]	lr: 2.000e-05, eta: 1:41:48, time: 0.816, data_time: 0.011, memory: 17573, enc_loss_cls: 0.2645, enc_loss_bbox: 0.0793, enc_loss_iou: 0.3999, loss_cls: 0.1723, loss_bbox: 0.0732, loss_iou: 0.3687, d0.loss_cls: 0.2331, d0.loss_bbox: 0.0738, d0.loss_iou: 0.3721, d1.loss_cls: 0.1927, d1.loss_bbox: 0.0733, d1.loss_iou: 0.3684, d2.loss_cls: 0.1761, d2.loss_bbox: 0.0732, d2.loss_iou: 0.3679, d3.loss_cls: 0.1714, d3.loss_bbox: 0.0732, d3.loss_iou: 0.3682, d4.loss_cls: 0.1723, d4.loss_bbox: 0.0731, d4.loss_iou: 0.3682, loss_rpn_cls: 0.0582, loss_rpn_bbox: 0.1398, loss_cls0: 1.8480, acc0: 93.8425, loss_bbox0: 2.9213, loss_cls1: 1.4693, loss_bbox1: 3.9834, loss_centerness1: 7.4858, loss_cls_aux0: 0.0496, loss_bbox_aux0: 0.0303, loss_iou_aux0: 0.1467, d0.loss_cls_aux0: 0.0622, d0.loss_bbox_aux0: 0.0549, d0.loss_iou_aux0: 0.2694, d1.loss_cls_aux0: 0.0561, d1.loss_bbox_aux0: 0.0351, d1.loss_iou_aux0: 0.1710, d2.loss_cls_aux0: 0.0509, d2.loss_bbox_aux0: 0.0301, d2.loss_iou_aux0: 0.1454, d3.loss_cls_aux0: 0.0492, d3.loss_bbox_aux0: 0.0302, d3.loss_iou_aux0: 0.1458, d4.loss_cls_aux0: 0.0493, d4.loss_bbox_aux0: 0.0303, d4.loss_iou_aux0: 0.1462, loss_cls_aux1: 0.0451, loss_bbox_aux1: 0.0574, loss_iou_aux1: 0.2923, d0.loss_cls_aux1: 0.0520, d0.loss_bbox_aux1: 0.0676, d0.loss_iou_aux1: 0.3423, d1.loss_cls_aux1: 0.0467, d1.loss_bbox_aux1: 0.0578, d1.loss_iou_aux1: 0.2941, d2.loss_cls_aux1: 0.0450, d2.loss_bbox_aux1: 0.0573, d2.loss_iou_aux1: 0.2917, d3.loss_cls_aux1: 0.0447, d3.loss_bbox_aux1: 0.0573, d3.loss_iou_aux1: 0.2919, d4.loss_cls_aux1: 0.0449, d4.loss_bbox_aux1: 0.0573, d4.loss_iou_aux1: 0.2921, loss: 26.4106, grad_norm: 77.6274
2024-03-18 07:47:55,152 - mmdet - INFO - Epoch [2][200/232]	lr: 2.000e-05, eta: 1:42:06, time: 0.828, data_time: 0.011, memory: 17573, enc_loss_cls: 0.2314, enc_loss_bbox: 0.0789, enc_loss_iou: 0.4015, loss_cls: 0.1608, loss_bbox: 0.0773, loss_iou: 0.3870, d0.loss_cls: 0.2169, d0.loss_bbox: 0.0776, d0.loss_iou: 0.3910, d1.loss_cls: 0.1746, d1.loss_bbox: 0.0776, d1.loss_iou: 0.3875, d2.loss_cls: 0.1619, d2.loss_bbox: 0.0776, d2.loss_iou: 0.3874, d3.loss_cls: 0.1594, d3.loss_bbox: 0.0775, d3.loss_iou: 0.3872, d4.loss_cls: 0.1593, d4.loss_bbox: 0.0774, d4.loss_iou: 0.3871, loss_rpn_cls: 0.0828, loss_rpn_bbox: 0.1631, loss_cls0: 1.9049, acc0: 93.6804, loss_bbox0: 3.0746, loss_cls1: 1.3684, loss_bbox1: 4.2680, loss_centerness1: 7.5436, loss_cls_aux0: 0.0374, loss_bbox_aux0: 0.0283, loss_iou_aux0: 0.1412, d0.loss_cls_aux0: 0.0497, d0.loss_bbox_aux0: 0.0537, d0.loss_iou_aux0: 0.2677, d1.loss_cls_aux0: 0.0430, d1.loss_bbox_aux0: 0.0319, d1.loss_iou_aux0: 0.1594, d2.loss_cls_aux0: 0.0389, d2.loss_bbox_aux0: 0.0281, d2.loss_iou_aux0: 0.1395, d3.loss_cls_aux0: 0.0375, d3.loss_bbox_aux0: 0.0282, d3.loss_iou_aux0: 0.1399, d4.loss_cls_aux0: 0.0374, d4.loss_bbox_aux0: 0.0282, d4.loss_iou_aux0: 0.1405, loss_cls_aux1: 0.0337, loss_bbox_aux1: 0.0602, loss_iou_aux1: 0.3080, d0.loss_cls_aux1: 0.0405, d0.loss_bbox_aux1: 0.0683, d0.loss_iou_aux1: 0.3479, d1.loss_cls_aux1: 0.0366, d1.loss_bbox_aux1: 0.0607, d1.loss_iou_aux1: 0.3100, d2.loss_cls_aux1: 0.0348, d2.loss_bbox_aux1: 0.0601, d2.loss_iou_aux1: 0.3074, d3.loss_cls_aux1: 0.0338, d3.loss_bbox_aux1: 0.0601, d3.loss_iou_aux1: 0.3076, d4.loss_cls_aux1: 0.0338, d4.loss_bbox_aux1: 0.0602, d4.loss_iou_aux1: 0.3078, loss: 26.8446, grad_norm: 81.2505
2024-03-18 07:48:21,885 - mmdet - INFO - Saving checkpoint at 2 epochs
2024-03-18 07:48:44,045 - mmdet - INFO - Evaluating bbox...
2024-03-18 07:48:49,552 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.380
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.575
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.298
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.364
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.528
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.826

2024-03-18 07:48:49,552 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.013 | Tin      | 0.622 | Thatch   | 0.504 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 07:48:49,927 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_002/best_bbox_mAP_epoch_1.pth was removed
2024-03-18 07:48:53,218 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_2.pth.
2024-03-18 07:48:53,218 - mmdet - INFO - Best bbox_mAP is 0.3800 at 2 epoch.
2024-03-18 07:48:53,218 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 07:48:53,218 - mmdet - INFO - Epoch(val) [2][154]	bbox_mAP: 0.3800, bbox_mAP_50: 0.5750, bbox_mAP_75: 0.4520, bbox_mAP_s: 0.2980, bbox_mAP_m: 0.3640, bbox_mAP_l: 0.5280, bbox_mAP_copypaste: 0.380 0.575 0.452 0.298 0.364 0.528
2024-03-18 07:49:36,759 - mmdet - INFO - Epoch [3][50/232]	lr: 2.000e-05, eta: 1:35:59, time: 0.871, data_time: 0.060, memory: 17573, enc_loss_cls: 0.2019, enc_loss_bbox: 0.0817, enc_loss_iou: 0.4131, loss_cls: 0.1478, loss_bbox: 0.0757, loss_iou: 0.3859, d0.loss_cls: 0.2200, d0.loss_bbox: 0.0761, d0.loss_iou: 0.3897, d1.loss_cls: 0.1640, d1.loss_bbox: 0.0749, d1.loss_iou: 0.3852, d2.loss_cls: 0.1524, d2.loss_bbox: 0.0752, d2.loss_iou: 0.3853, d3.loss_cls: 0.1488, d3.loss_bbox: 0.0753, d3.loss_iou: 0.3849, d4.loss_cls: 0.1479, d4.loss_bbox: 0.0755, d4.loss_iou: 0.3853, loss_rpn_cls: 0.0564, loss_rpn_bbox: 0.1556, loss_cls0: 1.8962, acc0: 93.5901, loss_bbox0: 3.0382, loss_cls1: 1.3356, loss_bbox1: 4.3739, loss_centerness1: 7.5313, loss_cls_aux0: 0.0403, loss_bbox_aux0: 0.0272, loss_iou_aux0: 0.1344, d0.loss_cls_aux0: 0.0520, d0.loss_bbox_aux0: 0.0531, d0.loss_iou_aux0: 0.2603, d1.loss_cls_aux0: 0.0453, d1.loss_bbox_aux0: 0.0318, d1.loss_iou_aux0: 0.1559, d2.loss_cls_aux0: 0.0415, d2.loss_bbox_aux0: 0.0270, d2.loss_iou_aux0: 0.1335, d3.loss_cls_aux0: 0.0398, d3.loss_bbox_aux0: 0.0271, d3.loss_iou_aux0: 0.1338, d4.loss_cls_aux0: 0.0402, d4.loss_bbox_aux0: 0.0271, d4.loss_iou_aux0: 0.1341, loss_cls_aux1: 0.0371, loss_bbox_aux1: 0.0604, loss_iou_aux1: 0.3102, d0.loss_cls_aux1: 0.0435, d0.loss_bbox_aux1: 0.0711, d0.loss_iou_aux1: 0.3594, d1.loss_cls_aux1: 0.0386, d1.loss_bbox_aux1: 0.0610, d1.loss_iou_aux1: 0.3133, d2.loss_cls_aux1: 0.0373, d2.loss_bbox_aux1: 0.0603, d2.loss_iou_aux1: 0.3098, d3.loss_cls_aux1: 0.0369, d3.loss_bbox_aux1: 0.0603, d3.loss_iou_aux1: 0.3099, d4.loss_cls_aux1: 0.0373, d4.loss_bbox_aux1: 0.0604, d4.loss_iou_aux1: 0.3100, loss: 26.7548, grad_norm: 94.5802
2024-03-18 07:50:17,098 - mmdet - INFO - Epoch [3][100/232]	lr: 2.000e-05, eta: 1:36:12, time: 0.807, data_time: 0.012, memory: 17573, enc_loss_cls: 0.2080, enc_loss_bbox: 0.0769, enc_loss_iou: 0.3887, loss_cls: 0.1631, loss_bbox: 0.0737, loss_iou: 0.3725, d0.loss_cls: 0.2106, d0.loss_bbox: 0.0734, d0.loss_iou: 0.3745, d1.loss_cls: 0.1714, d1.loss_bbox: 0.0742, d1.loss_iou: 0.3729, d2.loss_cls: 0.1628, d2.loss_bbox: 0.0738, d2.loss_iou: 0.3725, d3.loss_cls: 0.1622, d3.loss_bbox: 0.0740, d3.loss_iou: 0.3727, d4.loss_cls: 0.1620, d4.loss_bbox: 0.0739, d4.loss_iou: 0.3726, loss_rpn_cls: 0.0466, loss_rpn_bbox: 0.1279, loss_cls0: 1.8276, acc0: 93.9888, loss_bbox0: 2.9162, loss_cls1: 1.3663, loss_bbox1: 4.0759, loss_centerness1: 7.4962, loss_cls_aux0: 0.0447, loss_bbox_aux0: 0.0259, loss_iou_aux0: 0.1273, d0.loss_cls_aux0: 0.0537, d0.loss_bbox_aux0: 0.0538, d0.loss_iou_aux0: 0.2637, d1.loss_cls_aux0: 0.0485, d1.loss_bbox_aux0: 0.0312, d1.loss_iou_aux0: 0.1536, d2.loss_cls_aux0: 0.0446, d2.loss_bbox_aux0: 0.0258, d2.loss_iou_aux0: 0.1262, d3.loss_cls_aux0: 0.0441, d3.loss_bbox_aux0: 0.0258, d3.loss_iou_aux0: 0.1265, d4.loss_cls_aux0: 0.0446, d4.loss_bbox_aux0: 0.0259, d4.loss_iou_aux0: 0.1268, loss_cls_aux1: 0.0376, loss_bbox_aux1: 0.0589, loss_iou_aux1: 0.2970, d0.loss_cls_aux1: 0.0411, d0.loss_bbox_aux1: 0.0686, d0.loss_iou_aux1: 0.3451, d1.loss_cls_aux1: 0.0385, d1.loss_bbox_aux1: 0.0594, d1.loss_iou_aux1: 0.2996, d2.loss_cls_aux1: 0.0372, d2.loss_bbox_aux1: 0.0589, d2.loss_iou_aux1: 0.2967, d3.loss_cls_aux1: 0.0368, d3.loss_bbox_aux1: 0.0589, d3.loss_iou_aux1: 0.2968, d4.loss_cls_aux1: 0.0373, d4.loss_bbox_aux1: 0.0589, d4.loss_iou_aux1: 0.2969, loss: 26.0600, grad_norm: 77.1386
2024-03-18 07:50:58,071 - mmdet - INFO - Epoch [3][150/232]	lr: 2.000e-05, eta: 1:36:24, time: 0.819, data_time: 0.011, memory: 17573, enc_loss_cls: 0.1909, enc_loss_bbox: 0.0770, enc_loss_iou: 0.3955, loss_cls: 0.1556, loss_bbox: 0.0723, loss_iou: 0.3726, d0.loss_cls: 0.2046, d0.loss_bbox: 0.0741, d0.loss_iou: 0.3785, d1.loss_cls: 0.1640, d1.loss_bbox: 0.0733, d1.loss_iou: 0.3753, d2.loss_cls: 0.1552, d2.loss_bbox: 0.0728, d2.loss_iou: 0.3732, d3.loss_cls: 0.1526, d3.loss_bbox: 0.0725, d3.loss_iou: 0.3727, d4.loss_cls: 0.1537, d4.loss_bbox: 0.0724, d4.loss_iou: 0.3726, loss_rpn_cls: 0.0515, loss_rpn_bbox: 0.1436, loss_cls0: 1.8046, acc0: 93.9806, loss_bbox0: 2.9448, loss_cls1: 1.3628, loss_bbox1: 4.1100, loss_centerness1: 7.4872, loss_cls_aux0: 0.0394, loss_bbox_aux0: 0.0265, loss_iou_aux0: 0.1307, d0.loss_cls_aux0: 0.0494, d0.loss_bbox_aux0: 0.0550, d0.loss_iou_aux0: 0.2680, d1.loss_cls_aux0: 0.0439, d1.loss_bbox_aux0: 0.0316, d1.loss_iou_aux0: 0.1551, d2.loss_cls_aux0: 0.0401, d2.loss_bbox_aux0: 0.0264, d2.loss_iou_aux0: 0.1292, d3.loss_cls_aux0: 0.0390, d3.loss_bbox_aux0: 0.0264, d3.loss_iou_aux0: 0.1296, d4.loss_cls_aux0: 0.0391, d4.loss_bbox_aux0: 0.0265, d4.loss_iou_aux0: 0.1301, loss_cls_aux1: 0.0392, loss_bbox_aux1: 0.0583, loss_iou_aux1: 0.2987, d0.loss_cls_aux1: 0.0431, d0.loss_bbox_aux1: 0.0704, d0.loss_iou_aux1: 0.3547, d1.loss_cls_aux1: 0.0404, d1.loss_bbox_aux1: 0.0589, d1.loss_iou_aux1: 0.3014, d2.loss_cls_aux1: 0.0391, d2.loss_bbox_aux1: 0.0582, d2.loss_iou_aux1: 0.2983, d3.loss_cls_aux1: 0.0386, d3.loss_bbox_aux1: 0.0583, d3.loss_iou_aux1: 0.2984, d4.loss_cls_aux1: 0.0388, d4.loss_bbox_aux1: 0.0583, d4.loss_iou_aux1: 0.2985, loss: 26.0737, grad_norm: 70.7593
2024-03-18 07:51:39,422 - mmdet - INFO - Epoch [3][200/232]	lr: 2.000e-05, eta: 1:36:33, time: 0.827, data_time: 0.011, memory: 17573, enc_loss_cls: 0.1915, enc_loss_bbox: 0.0770, enc_loss_iou: 0.3960, loss_cls: 0.1559, loss_bbox: 0.0739, loss_iou: 0.3754, d0.loss_cls: 0.2047, d0.loss_bbox: 0.0742, d0.loss_iou: 0.3792, d1.loss_cls: 0.1663, d1.loss_bbox: 0.0736, d1.loss_iou: 0.3753, d2.loss_cls: 0.1565, d2.loss_bbox: 0.0738, d2.loss_iou: 0.3749, d3.loss_cls: 0.1550, d3.loss_bbox: 0.0739, d3.loss_iou: 0.3751, d4.loss_cls: 0.1555, d4.loss_bbox: 0.0738, d4.loss_iou: 0.3751, loss_rpn_cls: 0.0707, loss_rpn_bbox: 0.1618, loss_cls0: 1.8879, acc0: 93.6538, loss_bbox0: 2.9378, loss_cls1: 1.3186, loss_bbox1: 4.1772, loss_centerness1: 7.5491, loss_cls_aux0: 0.0417, loss_bbox_aux0: 0.0282, loss_iou_aux0: 0.1414, d0.loss_cls_aux0: 0.0512, d0.loss_bbox_aux0: 0.0533, d0.loss_iou_aux0: 0.2664, d1.loss_cls_aux0: 0.0461, d1.loss_bbox_aux0: 0.0328, d1.loss_iou_aux0: 0.1633, d2.loss_cls_aux0: 0.0421, d2.loss_bbox_aux0: 0.0281, d2.loss_iou_aux0: 0.1402, d3.loss_cls_aux0: 0.0415, d3.loss_bbox_aux0: 0.0281, d3.loss_iou_aux0: 0.1406, d4.loss_cls_aux0: 0.0419, d4.loss_bbox_aux0: 0.0282, d4.loss_iou_aux0: 0.1409, loss_cls_aux1: 0.0321, loss_bbox_aux1: 0.0582, loss_iou_aux1: 0.3044, d0.loss_cls_aux1: 0.0361, d0.loss_bbox_aux1: 0.0678, d0.loss_iou_aux1: 0.3487, d1.loss_cls_aux1: 0.0333, d1.loss_bbox_aux1: 0.0589, d1.loss_iou_aux1: 0.3067, d2.loss_cls_aux1: 0.0317, d2.loss_bbox_aux1: 0.0582, d2.loss_iou_aux1: 0.3041, d3.loss_cls_aux1: 0.0317, d3.loss_bbox_aux1: 0.0582, d3.loss_iou_aux1: 0.3042, d4.loss_cls_aux1: 0.0320, d4.loss_bbox_aux1: 0.0582, d4.loss_iou_aux1: 0.3043, loss: 26.3445, grad_norm: 69.1889
2024-03-18 07:52:06,212 - mmdet - INFO - Saving checkpoint at 3 epochs
2024-03-18 07:52:28,203 - mmdet - INFO - Evaluating bbox...
2024-03-18 07:52:33,207 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.583
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.300
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.366
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.551
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.618
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.831

2024-03-18 07:52:33,207 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.022 | Tin      | 0.624 | Thatch   | 0.503 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 07:52:33,575 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_002/best_bbox_mAP_epoch_2.pth was removed
2024-03-18 07:52:36,876 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_3.pth.
2024-03-18 07:52:36,877 - mmdet - INFO - Best bbox_mAP is 0.3830 at 3 epoch.
2024-03-18 07:52:36,877 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 07:52:36,877 - mmdet - INFO - Epoch(val) [3][154]	bbox_mAP: 0.3830, bbox_mAP_50: 0.5830, bbox_mAP_75: 0.4520, bbox_mAP_s: 0.3000, bbox_mAP_m: 0.3660, bbox_mAP_l: 0.5510, bbox_mAP_copypaste: 0.383 0.583 0.452 0.300 0.366 0.551
2024-03-18 07:53:20,412 - mmdet - INFO - Epoch [4][50/232]	lr: 2.000e-05, eta: 1:32:25, time: 0.870, data_time: 0.061, memory: 17573, enc_loss_cls: 0.1791, enc_loss_bbox: 0.0783, enc_loss_iou: 0.3949, loss_cls: 0.1467, loss_bbox: 0.0707, loss_iou: 0.3575, d0.loss_cls: 0.1911, d0.loss_bbox: 0.0720, d0.loss_iou: 0.3663, d1.loss_cls: 0.1579, d1.loss_bbox: 0.0710, d1.loss_iou: 0.3602, d2.loss_cls: 0.1506, d2.loss_bbox: 0.0707, d2.loss_iou: 0.3577, d3.loss_cls: 0.1469, d3.loss_bbox: 0.0705, d3.loss_iou: 0.3572, d4.loss_cls: 0.1459, d4.loss_bbox: 0.0707, d4.loss_iou: 0.3576, loss_rpn_cls: 0.0521, loss_rpn_bbox: 0.1343, loss_cls0: 1.7768, acc0: 94.0462, loss_bbox0: 2.8272, loss_cls1: 1.3124, loss_bbox1: 3.9945, loss_centerness1: 7.5251, loss_cls_aux0: 0.0426, loss_bbox_aux0: 0.0254, loss_iou_aux0: 0.1237, d0.loss_cls_aux0: 0.0519, d0.loss_bbox_aux0: 0.0517, d0.loss_iou_aux0: 0.2548, d1.loss_cls_aux0: 0.0472, d1.loss_bbox_aux0: 0.0308, d1.loss_iou_aux0: 0.1501, d2.loss_cls_aux0: 0.0426, d2.loss_bbox_aux0: 0.0252, d2.loss_iou_aux0: 0.1225, d3.loss_cls_aux0: 0.0419, d3.loss_bbox_aux0: 0.0253, d3.loss_iou_aux0: 0.1228, d4.loss_cls_aux0: 0.0422, d4.loss_bbox_aux0: 0.0253, d4.loss_iou_aux0: 0.1232, loss_cls_aux1: 0.0393, loss_bbox_aux1: 0.0553, loss_iou_aux1: 0.2874, d0.loss_cls_aux1: 0.0456, d0.loss_bbox_aux1: 0.0640, d0.loss_iou_aux1: 0.3286, d1.loss_cls_aux1: 0.0417, d1.loss_bbox_aux1: 0.0561, d1.loss_iou_aux1: 0.2901, d2.loss_cls_aux1: 0.0394, d2.loss_bbox_aux1: 0.0553, d2.loss_iou_aux1: 0.2872, d3.loss_cls_aux1: 0.0384, d3.loss_bbox_aux1: 0.0553, d3.loss_iou_aux1: 0.2872, d4.loss_cls_aux1: 0.0391, d4.loss_bbox_aux1: 0.0553, d4.loss_iou_aux1: 0.2873, loss: 25.4980, grad_norm: 68.1660
2024-03-18 07:54:00,920 - mmdet - INFO - Epoch [4][100/232]	lr: 2.000e-05, eta: 1:32:27, time: 0.810, data_time: 0.011, memory: 17573, enc_loss_cls: 0.1777, enc_loss_bbox: 0.0772, enc_loss_iou: 0.4097, loss_cls: 0.1451, loss_bbox: 0.0676, loss_iou: 0.3668, d0.loss_cls: 0.1993, d0.loss_bbox: 0.0692, d0.loss_iou: 0.3753, d1.loss_cls: 0.1566, d1.loss_bbox: 0.0682, d1.loss_iou: 0.3684, d2.loss_cls: 0.1476, d2.loss_bbox: 0.0675, d2.loss_iou: 0.3666, d3.loss_cls: 0.1444, d3.loss_bbox: 0.0674, d3.loss_iou: 0.3667, d4.loss_cls: 0.1441, d4.loss_bbox: 0.0674, d4.loss_iou: 0.3667, loss_rpn_cls: 0.0441, loss_rpn_bbox: 0.1343, loss_cls0: 1.7963, acc0: 93.9433, loss_bbox0: 2.9226, loss_cls1: 1.2262, loss_bbox1: 4.0019, loss_centerness1: 7.5136, loss_cls_aux0: 0.0311, loss_bbox_aux0: 0.0256, loss_iou_aux0: 0.1327, d0.loss_cls_aux0: 0.0409, d0.loss_bbox_aux0: 0.0528, d0.loss_iou_aux0: 0.2717, d1.loss_cls_aux0: 0.0351, d1.loss_bbox_aux0: 0.0297, d1.loss_iou_aux0: 0.1540, d2.loss_cls_aux0: 0.0316, d2.loss_bbox_aux0: 0.0254, d2.loss_iou_aux0: 0.1314, d3.loss_cls_aux0: 0.0310, d3.loss_bbox_aux0: 0.0255, d3.loss_iou_aux0: 0.1317, d4.loss_cls_aux0: 0.0311, d4.loss_bbox_aux0: 0.0255, d4.loss_iou_aux0: 0.1322, loss_cls_aux1: 0.0267, loss_bbox_aux1: 0.0547, loss_iou_aux1: 0.2945, d0.loss_cls_aux1: 0.0303, d0.loss_bbox_aux1: 0.0666, d0.loss_iou_aux1: 0.3573, d1.loss_cls_aux1: 0.0269, d1.loss_bbox_aux1: 0.0553, d1.loss_iou_aux1: 0.2975, d2.loss_cls_aux1: 0.0263, d2.loss_bbox_aux1: 0.0546, d2.loss_iou_aux1: 0.2939, d3.loss_cls_aux1: 0.0266, d3.loss_bbox_aux1: 0.0546, d3.loss_iou_aux1: 0.2941, d4.loss_cls_aux1: 0.0269, d4.loss_bbox_aux1: 0.0546, d4.loss_iou_aux1: 0.2943, loss: 25.5332, grad_norm: 72.7033
2024-03-18 07:54:42,135 - mmdet - INFO - Epoch [4][150/232]	lr: 2.000e-05, eta: 1:32:30, time: 0.824, data_time: 0.010, memory: 17573, enc_loss_cls: 0.1770, enc_loss_bbox: 0.0774, enc_loss_iou: 0.3943, loss_cls: 0.1440, loss_bbox: 0.0688, loss_iou: 0.3591, d0.loss_cls: 0.1939, d0.loss_bbox: 0.0705, d0.loss_iou: 0.3661, d1.loss_cls: 0.1553, d1.loss_bbox: 0.0696, d1.loss_iou: 0.3606, d2.loss_cls: 0.1460, d2.loss_bbox: 0.0690, d2.loss_iou: 0.3586, d3.loss_cls: 0.1434, d3.loss_bbox: 0.0690, d3.loss_iou: 0.3591, d4.loss_cls: 0.1430, d4.loss_bbox: 0.0688, d4.loss_iou: 0.3592, loss_rpn_cls: 0.0524, loss_rpn_bbox: 0.1702, loss_cls0: 1.8686, acc0: 93.6781, loss_bbox0: 3.0092, loss_cls1: 1.2920, loss_bbox1: 4.0100, loss_centerness1: 7.4984, loss_cls_aux0: 0.0312, loss_bbox_aux0: 0.0293, loss_iou_aux0: 0.1412, d0.loss_cls_aux0: 0.0424, d0.loss_bbox_aux0: 0.0543, d0.loss_iou_aux0: 0.2650, d1.loss_cls_aux0: 0.0357, d1.loss_bbox_aux0: 0.0343, d1.loss_iou_aux0: 0.1647, d2.loss_cls_aux0: 0.0322, d2.loss_bbox_aux0: 0.0291, d2.loss_iou_aux0: 0.1394, d3.loss_cls_aux0: 0.0311, d3.loss_bbox_aux0: 0.0292, d3.loss_iou_aux0: 0.1400, d4.loss_cls_aux0: 0.0309, d4.loss_bbox_aux0: 0.0292, d4.loss_iou_aux0: 0.1405, loss_cls_aux1: 0.0247, loss_bbox_aux1: 0.0572, loss_iou_aux1: 0.2932, d0.loss_cls_aux1: 0.0315, d0.loss_bbox_aux1: 0.0662, d0.loss_iou_aux1: 0.3379, d1.loss_cls_aux1: 0.0276, d1.loss_bbox_aux1: 0.0578, d1.loss_iou_aux1: 0.2962, d2.loss_cls_aux1: 0.0261, d2.loss_bbox_aux1: 0.0571, d2.loss_iou_aux1: 0.2927, d3.loss_cls_aux1: 0.0248, d3.loss_bbox_aux1: 0.0571, d3.loss_iou_aux1: 0.2928, d4.loss_cls_aux1: 0.0246, d4.loss_bbox_aux1: 0.0571, d4.loss_iou_aux1: 0.2930, loss: 25.7709, grad_norm: 66.9570
2024-03-18 07:55:23,616 - mmdet - INFO - Epoch [4][200/232]	lr: 2.000e-05, eta: 1:32:31, time: 0.830, data_time: 0.009, memory: 17573, enc_loss_cls: 0.1734, enc_loss_bbox: 0.0767, enc_loss_iou: 0.4002, loss_cls: 0.1558, loss_bbox: 0.0689, loss_iou: 0.3694, d0.loss_cls: 0.1935, d0.loss_bbox: 0.0703, d0.loss_iou: 0.3753, d1.loss_cls: 0.1626, d1.loss_bbox: 0.0694, d1.loss_iou: 0.3705, d2.loss_cls: 0.1541, d2.loss_bbox: 0.0691, d2.loss_iou: 0.3703, d3.loss_cls: 0.1556, d3.loss_bbox: 0.0687, d3.loss_iou: 0.3688, d4.loss_cls: 0.1548, d4.loss_bbox: 0.0689, d4.loss_iou: 0.3694, loss_rpn_cls: 0.0555, loss_rpn_bbox: 0.1361, loss_cls0: 1.6907, acc0: 94.3434, loss_bbox0: 2.8613, loss_cls1: 1.3332, loss_bbox1: 4.0283, loss_centerness1: 7.4961, loss_cls_aux0: 0.0349, loss_bbox_aux0: 0.0263, loss_iou_aux0: 0.1329, d0.loss_cls_aux0: 0.0429, d0.loss_bbox_aux0: 0.0538, d0.loss_iou_aux0: 0.2709, d1.loss_cls_aux0: 0.0366, d1.loss_bbox_aux0: 0.0312, d1.loss_iou_aux0: 0.1576, d2.loss_cls_aux0: 0.0343, d2.loss_bbox_aux0: 0.0261, d2.loss_iou_aux0: 0.1310, d3.loss_cls_aux0: 0.0344, d3.loss_bbox_aux0: 0.0261, d3.loss_iou_aux0: 0.1314, d4.loss_cls_aux0: 0.0344, d4.loss_bbox_aux0: 0.0262, d4.loss_iou_aux0: 0.1320, loss_cls_aux1: 0.0408, loss_bbox_aux1: 0.0546, loss_iou_aux1: 0.2879, d0.loss_cls_aux1: 0.0447, d0.loss_bbox_aux1: 0.0655, d0.loss_iou_aux1: 0.3411, d1.loss_cls_aux1: 0.0426, d1.loss_bbox_aux1: 0.0552, d1.loss_iou_aux1: 0.2899, d2.loss_cls_aux1: 0.0409, d2.loss_bbox_aux1: 0.0545, d2.loss_iou_aux1: 0.2872, d3.loss_cls_aux1: 0.0408, d3.loss_bbox_aux1: 0.0546, d3.loss_iou_aux1: 0.2874, d4.loss_cls_aux1: 0.0406, d4.loss_bbox_aux1: 0.0546, d4.loss_iou_aux1: 0.2876, loss: 25.6004, grad_norm: 79.7129
2024-03-18 07:55:50,325 - mmdet - INFO - Saving checkpoint at 4 epochs
2024-03-18 07:56:12,359 - mmdet - INFO - Evaluating bbox...
2024-03-18 07:56:17,454 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.593
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.466
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.308
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.381
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.715
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.715
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.715
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.661
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.709
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.830

2024-03-18 07:56:17,454 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.040 | Tin      | 0.623 | Thatch   | 0.530 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 07:56:17,844 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_002/best_bbox_mAP_epoch_3.pth was removed
2024-03-18 07:56:21,199 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_4.pth.
2024-03-18 07:56:21,200 - mmdet - INFO - Best bbox_mAP is 0.3980 at 4 epoch.
2024-03-18 07:56:21,200 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 07:56:21,200 - mmdet - INFO - Epoch(val) [4][154]	bbox_mAP: 0.3980, bbox_mAP_50: 0.5930, bbox_mAP_75: 0.4660, bbox_mAP_s: 0.3080, bbox_mAP_m: 0.3810, bbox_mAP_l: 0.6200, bbox_mAP_copypaste: 0.398 0.593 0.466 0.308 0.381 0.620
2024-03-18 07:57:04,717 - mmdet - INFO - Epoch [5][50/232]	lr: 2.000e-05, eta: 1:29:17, time: 0.870, data_time: 0.061, memory: 17573, enc_loss_cls: 0.1664, enc_loss_bbox: 0.0727, enc_loss_iou: 0.3914, loss_cls: 0.1370, loss_bbox: 0.0678, loss_iou: 0.3636, d0.loss_cls: 0.1772, d0.loss_bbox: 0.0689, d0.loss_iou: 0.3695, d1.loss_cls: 0.1491, d1.loss_bbox: 0.0679, d1.loss_iou: 0.3646, d2.loss_cls: 0.1389, d2.loss_bbox: 0.0679, d2.loss_iou: 0.3635, d3.loss_cls: 0.1369, d3.loss_bbox: 0.0675, d3.loss_iou: 0.3630, d4.loss_cls: 0.1363, d4.loss_bbox: 0.0677, d4.loss_iou: 0.3634, loss_rpn_cls: 0.0407, loss_rpn_bbox: 0.1347, loss_cls0: 1.6330, acc0: 94.4772, loss_bbox0: 2.7967, loss_cls1: 1.2239, loss_bbox1: 3.9734, loss_centerness1: 7.4900, loss_cls_aux0: 0.0269, loss_bbox_aux0: 0.0233, loss_iou_aux0: 0.1196, d0.loss_cls_aux0: 0.0361, d0.loss_bbox_aux0: 0.0480, d0.loss_iou_aux0: 0.2509, d1.loss_cls_aux0: 0.0307, d1.loss_bbox_aux0: 0.0273, d1.loss_iou_aux0: 0.1401, d2.loss_cls_aux0: 0.0273, d2.loss_bbox_aux0: 0.0231, d2.loss_iou_aux0: 0.1174, d3.loss_cls_aux0: 0.0269, d3.loss_bbox_aux0: 0.0232, d3.loss_iou_aux0: 0.1179, d4.loss_cls_aux0: 0.0266, d4.loss_bbox_aux0: 0.0232, d4.loss_iou_aux0: 0.1186, loss_cls_aux1: 0.0243, loss_bbox_aux1: 0.0527, loss_iou_aux1: 0.2849, d0.loss_cls_aux1: 0.0288, d0.loss_bbox_aux1: 0.0618, d0.loss_iou_aux1: 0.3336, d1.loss_cls_aux1: 0.0264, d1.loss_bbox_aux1: 0.0532, d1.loss_iou_aux1: 0.2878, d2.loss_cls_aux1: 0.0251, d2.loss_bbox_aux1: 0.0527, d2.loss_iou_aux1: 0.2845, d3.loss_cls_aux1: 0.0244, d3.loss_bbox_aux1: 0.0527, d3.loss_iou_aux1: 0.2846, d4.loss_cls_aux1: 0.0242, d4.loss_bbox_aux1: 0.0527, d4.loss_iou_aux1: 0.2847, loss: 24.8399, grad_norm: 75.3469
2024-03-18 07:57:45,451 - mmdet - INFO - Epoch [5][100/232]	lr: 2.000e-05, eta: 1:29:12, time: 0.815, data_time: 0.010, memory: 17573, enc_loss_cls: 0.1650, enc_loss_bbox: 0.0767, enc_loss_iou: 0.3947, loss_cls: 0.1346, loss_bbox: 0.0713, loss_iou: 0.3684, d0.loss_cls: 0.1723, d0.loss_bbox: 0.0732, d0.loss_iou: 0.3778, d1.loss_cls: 0.1458, d1.loss_bbox: 0.0717, d1.loss_iou: 0.3712, d2.loss_cls: 0.1387, d2.loss_bbox: 0.0711, d2.loss_iou: 0.3683, d3.loss_cls: 0.1335, d3.loss_bbox: 0.0716, d3.loss_iou: 0.3688, d4.loss_cls: 0.1338, d4.loss_bbox: 0.0713, d4.loss_iou: 0.3684, loss_rpn_cls: 0.0489, loss_rpn_bbox: 0.1333, loss_cls0: 1.7490, acc0: 94.1255, loss_bbox0: 2.9501, loss_cls1: 1.2393, loss_bbox1: 4.1876, loss_centerness1: 7.5145, loss_cls_aux0: 0.0323, loss_bbox_aux0: 0.0250, loss_iou_aux0: 0.1277, d0.loss_cls_aux0: 0.0412, d0.loss_bbox_aux0: 0.0514, d0.loss_iou_aux0: 0.2587, d1.loss_cls_aux0: 0.0365, d1.loss_bbox_aux0: 0.0295, d1.loss_iou_aux0: 0.1511, d2.loss_cls_aux0: 0.0330, d2.loss_bbox_aux0: 0.0248, d2.loss_iou_aux0: 0.1257, d3.loss_cls_aux0: 0.0323, d3.loss_bbox_aux0: 0.0248, d3.loss_iou_aux0: 0.1263, d4.loss_cls_aux0: 0.0322, d4.loss_bbox_aux0: 0.0249, d4.loss_iou_aux0: 0.1270, loss_cls_aux1: 0.0277, loss_bbox_aux1: 0.0564, loss_iou_aux1: 0.2945, d0.loss_cls_aux1: 0.0333, d0.loss_bbox_aux1: 0.0661, d0.loss_iou_aux1: 0.3389, d1.loss_cls_aux1: 0.0303, d1.loss_bbox_aux1: 0.0575, d1.loss_iou_aux1: 0.2991, d2.loss_cls_aux1: 0.0279, d2.loss_bbox_aux1: 0.0563, d2.loss_iou_aux1: 0.2940, d3.loss_cls_aux1: 0.0277, d3.loss_bbox_aux1: 0.0564, d3.loss_iou_aux1: 0.2942, d4.loss_cls_aux1: 0.0275, d4.loss_bbox_aux1: 0.0564, d4.loss_iou_aux1: 0.2943, loss: 25.6136, grad_norm: 75.3127
2024-03-18 07:58:26,374 - mmdet - INFO - Epoch [5][150/232]	lr: 2.000e-05, eta: 1:29:05, time: 0.818, data_time: 0.011, memory: 17573, enc_loss_cls: 0.1673, enc_loss_bbox: 0.0782, enc_loss_iou: 0.4019, loss_cls: 0.1450, loss_bbox: 0.0732, loss_iou: 0.3771, d0.loss_cls: 0.1976, d0.loss_bbox: 0.0733, d0.loss_iou: 0.3798, d1.loss_cls: 0.1602, d1.loss_bbox: 0.0730, d1.loss_iou: 0.3761, d2.loss_cls: 0.1511, d2.loss_bbox: 0.0731, d2.loss_iou: 0.3764, d3.loss_cls: 0.1477, d3.loss_bbox: 0.0733, d3.loss_iou: 0.3769, d4.loss_cls: 0.1457, d4.loss_bbox: 0.0733, d4.loss_iou: 0.3771, loss_rpn_cls: 0.0617, loss_rpn_bbox: 0.1499, loss_cls0: 1.8244, acc0: 93.9651, loss_bbox0: 2.9652, loss_cls1: 1.2997, loss_bbox1: 4.0323, loss_centerness1: 7.5298, loss_cls_aux0: 0.0358, loss_bbox_aux0: 0.0265, loss_iou_aux0: 0.1309, d0.loss_cls_aux0: 0.0467, d0.loss_bbox_aux0: 0.0517, d0.loss_iou_aux0: 0.2536, d1.loss_cls_aux0: 0.0387, d1.loss_bbox_aux0: 0.0307, d1.loss_iou_aux0: 0.1515, d2.loss_cls_aux0: 0.0359, d2.loss_bbox_aux0: 0.0264, d2.loss_iou_aux0: 0.1299, d3.loss_cls_aux0: 0.0352, d3.loss_bbox_aux0: 0.0264, d3.loss_iou_aux0: 0.1303, d4.loss_cls_aux0: 0.0358, d4.loss_bbox_aux0: 0.0265, d4.loss_iou_aux0: 0.1306, loss_cls_aux1: 0.0379, loss_bbox_aux1: 0.0566, loss_iou_aux1: 0.2894, d0.loss_cls_aux1: 0.0446, d0.loss_bbox_aux1: 0.0658, d0.loss_iou_aux1: 0.3342, d1.loss_cls_aux1: 0.0387, d1.loss_bbox_aux1: 0.0573, d1.loss_iou_aux1: 0.2930, d2.loss_cls_aux1: 0.0370, d2.loss_bbox_aux1: 0.0565, d2.loss_iou_aux1: 0.2891, d3.loss_cls_aux1: 0.0373, d3.loss_bbox_aux1: 0.0565, d3.loss_iou_aux1: 0.2891, d4.loss_cls_aux1: 0.0380, d4.loss_bbox_aux1: 0.0565, d4.loss_iou_aux1: 0.2892, loss: 25.8704, grad_norm: 65.9284
2024-03-18 07:59:07,937 - mmdet - INFO - Epoch [5][200/232]	lr: 2.000e-05, eta: 1:29:00, time: 0.831, data_time: 0.010, memory: 17573, enc_loss_cls: 0.1739, enc_loss_bbox: 0.0727, enc_loss_iou: 0.3848, loss_cls: 0.1546, loss_bbox: 0.0658, loss_iou: 0.3555, d0.loss_cls: 0.1904, d0.loss_bbox: 0.0676, d0.loss_iou: 0.3638, d1.loss_cls: 0.1657, d1.loss_bbox: 0.0661, d1.loss_iou: 0.3568, d2.loss_cls: 0.1570, d2.loss_bbox: 0.0655, d2.loss_iou: 0.3546, d3.loss_cls: 0.1556, d3.loss_bbox: 0.0657, d3.loss_iou: 0.3547, d4.loss_cls: 0.1552, d4.loss_bbox: 0.0657, d4.loss_iou: 0.3552, loss_rpn_cls: 0.0594, loss_rpn_bbox: 0.1441, loss_cls0: 1.6654, acc0: 94.4382, loss_bbox0: 2.7436, loss_cls1: 1.2705, loss_bbox1: 3.9128, loss_centerness1: 7.4590, loss_cls_aux0: 0.0321, loss_bbox_aux0: 0.0259, loss_iou_aux0: 0.1306, d0.loss_cls_aux0: 0.0416, d0.loss_bbox_aux0: 0.0494, d0.loss_iou_aux0: 0.2485, d1.loss_cls_aux0: 0.0353, d1.loss_bbox_aux0: 0.0307, d1.loss_iou_aux0: 0.1541, d2.loss_cls_aux0: 0.0324, d2.loss_bbox_aux0: 0.0258, d2.loss_iou_aux0: 0.1289, d3.loss_cls_aux0: 0.0311, d3.loss_bbox_aux0: 0.0258, d3.loss_iou_aux0: 0.1293, d4.loss_cls_aux0: 0.0318, d4.loss_bbox_aux0: 0.0259, d4.loss_iou_aux0: 0.1298, loss_cls_aux1: 0.0297, loss_bbox_aux1: 0.0544, loss_iou_aux1: 0.2859, d0.loss_cls_aux1: 0.0340, d0.loss_bbox_aux1: 0.0624, d0.loss_iou_aux1: 0.3258, d1.loss_cls_aux1: 0.0308, d1.loss_bbox_aux1: 0.0552, d1.loss_iou_aux1: 0.2897, d2.loss_cls_aux1: 0.0299, d2.loss_bbox_aux1: 0.0543, d2.loss_iou_aux1: 0.2856, d3.loss_cls_aux1: 0.0292, d3.loss_bbox_aux1: 0.0543, d3.loss_iou_aux1: 0.2857, d4.loss_cls_aux1: 0.0295, d4.loss_bbox_aux1: 0.0544, d4.loss_iou_aux1: 0.2857, loss: 24.9870, grad_norm: 69.6107
2024-03-18 07:59:34,743 - mmdet - INFO - Saving checkpoint at 5 epochs
2024-03-18 07:59:56,873 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:00:01,903 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.605
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.482
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.309
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.374
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.786
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.703
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.703
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.703
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.623
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.708
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.824

2024-03-18 08:00:01,903 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.061 | Tin      | 0.620 | Thatch   | 0.526 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:00:02,298 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_002/best_bbox_mAP_epoch_4.pth was removed
2024-03-18 08:00:05,682 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_5.pth.
2024-03-18 08:00:05,683 - mmdet - INFO - Best bbox_mAP is 0.4020 at 5 epoch.
2024-03-18 08:00:05,683 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:00:05,683 - mmdet - INFO - Epoch(val) [5][154]	bbox_mAP: 0.4020, bbox_mAP_50: 0.6050, bbox_mAP_75: 0.4820, bbox_mAP_s: 0.3090, bbox_mAP_m: 0.3740, bbox_mAP_l: 0.7860, bbox_mAP_copypaste: 0.402 0.605 0.482 0.309 0.374 0.786
2024-03-18 08:00:49,506 - mmdet - INFO - Epoch [6][50/232]	lr: 2.000e-05, eta: 1:26:20, time: 0.876, data_time: 0.060, memory: 17573, enc_loss_cls: 0.1548, enc_loss_bbox: 0.0750, enc_loss_iou: 0.3949, loss_cls: 0.1340, loss_bbox: 0.0697, loss_iou: 0.3710, d0.loss_cls: 0.1833, d0.loss_bbox: 0.0702, d0.loss_iou: 0.3740, d1.loss_cls: 0.1453, d1.loss_bbox: 0.0697, d1.loss_iou: 0.3705, d2.loss_cls: 0.1349, d2.loss_bbox: 0.0697, d2.loss_iou: 0.3703, d3.loss_cls: 0.1325, d3.loss_bbox: 0.0697, d3.loss_iou: 0.3707, d4.loss_cls: 0.1328, d4.loss_bbox: 0.0699, d4.loss_iou: 0.3712, loss_rpn_cls: 0.0500, loss_rpn_bbox: 0.1597, loss_cls0: 1.9135, acc0: 93.5781, loss_bbox0: 3.1530, loss_cls1: 1.1797, loss_bbox1: 4.1541, loss_centerness1: 7.5451, loss_cls_aux0: 0.0352, loss_bbox_aux0: 0.0276, loss_iou_aux0: 0.1373, d0.loss_cls_aux0: 0.0443, d0.loss_bbox_aux0: 0.0521, d0.loss_iou_aux0: 0.2610, d1.loss_cls_aux0: 0.0386, d1.loss_bbox_aux0: 0.0316, d1.loss_iou_aux0: 0.1572, d2.loss_cls_aux0: 0.0359, d2.loss_bbox_aux0: 0.0274, d2.loss_iou_aux0: 0.1351, d3.loss_cls_aux0: 0.0342, d3.loss_bbox_aux0: 0.0274, d3.loss_iou_aux0: 0.1357, d4.loss_cls_aux0: 0.0346, d4.loss_bbox_aux0: 0.0275, d4.loss_iou_aux0: 0.1363, loss_cls_aux1: 0.0297, loss_bbox_aux1: 0.0566, loss_iou_aux1: 0.2989, d0.loss_cls_aux1: 0.0344, d0.loss_bbox_aux1: 0.0693, d0.loss_iou_aux1: 0.3594, d1.loss_cls_aux1: 0.0310, d1.loss_bbox_aux1: 0.0575, d1.loss_iou_aux1: 0.3036, d2.loss_cls_aux1: 0.0301, d2.loss_bbox_aux1: 0.0564, d2.loss_iou_aux1: 0.2982, d3.loss_cls_aux1: 0.0289, d3.loss_bbox_aux1: 0.0565, d3.loss_iou_aux1: 0.2984, d4.loss_cls_aux1: 0.0292, d4.loss_bbox_aux1: 0.0565, d4.loss_iou_aux1: 0.2986, loss: 26.0616, grad_norm: 72.6213
2024-03-18 08:01:30,957 - mmdet - INFO - Epoch [6][100/232]	lr: 2.000e-05, eta: 1:26:13, time: 0.829, data_time: 0.011, memory: 17573, enc_loss_cls: 0.1649, enc_loss_bbox: 0.0725, enc_loss_iou: 0.3874, loss_cls: 0.1416, loss_bbox: 0.0649, loss_iou: 0.3529, d0.loss_cls: 0.1820, d0.loss_bbox: 0.0668, d0.loss_iou: 0.3605, d1.loss_cls: 0.1491, d1.loss_bbox: 0.0655, d1.loss_iou: 0.3552, d2.loss_cls: 0.1429, d2.loss_bbox: 0.0651, d2.loss_iou: 0.3529, d3.loss_cls: 0.1402, d3.loss_bbox: 0.0651, d3.loss_iou: 0.3527, d4.loss_cls: 0.1409, d4.loss_bbox: 0.0649, d4.loss_iou: 0.3528, loss_rpn_cls: 0.0481, loss_rpn_bbox: 0.1277, loss_cls0: 1.5814, acc0: 94.6096, loss_bbox0: 2.7318, loss_cls1: 1.1974, loss_bbox1: 3.8645, loss_centerness1: 7.4864, loss_cls_aux0: 0.0297, loss_bbox_aux0: 0.0237, loss_iou_aux0: 0.1213, d0.loss_cls_aux0: 0.0391, d0.loss_bbox_aux0: 0.0494, d0.loss_iou_aux0: 0.2537, d1.loss_cls_aux0: 0.0328, d1.loss_bbox_aux0: 0.0282, d1.loss_iou_aux0: 0.1444, d2.loss_cls_aux0: 0.0301, d2.loss_bbox_aux0: 0.0236, d2.loss_iou_aux0: 0.1203, d3.loss_cls_aux0: 0.0294, d3.loss_bbox_aux0: 0.0236, d3.loss_iou_aux0: 0.1205, d4.loss_cls_aux0: 0.0297, d4.loss_bbox_aux0: 0.0237, d4.loss_iou_aux0: 0.1209, loss_cls_aux1: 0.0283, loss_bbox_aux1: 0.0518, loss_iou_aux1: 0.2774, d0.loss_cls_aux1: 0.0314, d0.loss_bbox_aux1: 0.0617, d0.loss_iou_aux1: 0.3275, d1.loss_cls_aux1: 0.0299, d1.loss_bbox_aux1: 0.0522, d1.loss_iou_aux1: 0.2799, d2.loss_cls_aux1: 0.0285, d2.loss_bbox_aux1: 0.0517, d2.loss_iou_aux1: 0.2769, d3.loss_cls_aux1: 0.0284, d3.loss_bbox_aux1: 0.0518, d3.loss_iou_aux1: 0.2771, d4.loss_cls_aux1: 0.0284, d4.loss_bbox_aux1: 0.0518, d4.loss_iou_aux1: 0.2772, loss: 24.5341, grad_norm: 66.9710
2024-03-18 08:02:12,119 - mmdet - INFO - Epoch [6][150/232]	lr: 2.000e-05, eta: 1:26:01, time: 0.823, data_time: 0.011, memory: 17573, enc_loss_cls: 0.1498, enc_loss_bbox: 0.0780, enc_loss_iou: 0.3947, loss_cls: 0.1246, loss_bbox: 0.0684, loss_iou: 0.3594, d0.loss_cls: 0.1646, d0.loss_bbox: 0.0697, d0.loss_iou: 0.3654, d1.loss_cls: 0.1346, d1.loss_bbox: 0.0688, d1.loss_iou: 0.3605, d2.loss_cls: 0.1271, d2.loss_bbox: 0.0685, d2.loss_iou: 0.3592, d3.loss_cls: 0.1250, d3.loss_bbox: 0.0685, d3.loss_iou: 0.3594, d4.loss_cls: 0.1251, d4.loss_bbox: 0.0682, d4.loss_iou: 0.3590, loss_rpn_cls: 0.0471, loss_rpn_bbox: 0.1476, loss_cls0: 1.7066, acc0: 94.2771, loss_bbox0: 2.8356, loss_cls1: 1.1601, loss_bbox1: 3.9360, loss_centerness1: 7.4993, loss_cls_aux0: 0.0292, loss_bbox_aux0: 0.0253, loss_iou_aux0: 0.1245, d0.loss_cls_aux0: 0.0382, d0.loss_bbox_aux0: 0.0512, d0.loss_iou_aux0: 0.2519, d1.loss_cls_aux0: 0.0325, d1.loss_bbox_aux0: 0.0304, d1.loss_iou_aux0: 0.1489, d2.loss_cls_aux0: 0.0299, d2.loss_bbox_aux0: 0.0252, d2.loss_iou_aux0: 0.1234, d3.loss_cls_aux0: 0.0288, d3.loss_bbox_aux0: 0.0252, d3.loss_iou_aux0: 0.1237, d4.loss_cls_aux0: 0.0290, d4.loss_bbox_aux0: 0.0253, d4.loss_iou_aux0: 0.1241, loss_cls_aux1: 0.0299, loss_bbox_aux1: 0.0544, loss_iou_aux1: 0.2854, d0.loss_cls_aux1: 0.0350, d0.loss_bbox_aux1: 0.0651, d0.loss_iou_aux1: 0.3366, d1.loss_cls_aux1: 0.0319, d1.loss_bbox_aux1: 0.0551, d1.loss_iou_aux1: 0.2885, d2.loss_cls_aux1: 0.0301, d2.loss_bbox_aux1: 0.0543, d2.loss_iou_aux1: 0.2850, d3.loss_cls_aux1: 0.0294, d3.loss_bbox_aux1: 0.0543, d3.loss_iou_aux1: 0.2851, d4.loss_cls_aux1: 0.0296, d4.loss_bbox_aux1: 0.0543, d4.loss_iou_aux1: 0.2852, loss: 24.8868, grad_norm: 66.4489
2024-03-18 08:02:53,698 - mmdet - INFO - Epoch [6][200/232]	lr: 2.000e-05, eta: 1:25:50, time: 0.832, data_time: 0.012, memory: 17573, enc_loss_cls: 0.1642, enc_loss_bbox: 0.0733, enc_loss_iou: 0.3802, loss_cls: 0.1412, loss_bbox: 0.0689, loss_iou: 0.3599, d0.loss_cls: 0.1850, d0.loss_bbox: 0.0697, d0.loss_iou: 0.3635, d1.loss_cls: 0.1546, d1.loss_bbox: 0.0688, d1.loss_iou: 0.3599, d2.loss_cls: 0.1453, d2.loss_bbox: 0.0688, d2.loss_iou: 0.3594, d3.loss_cls: 0.1422, d3.loss_bbox: 0.0688, d3.loss_iou: 0.3596, d4.loss_cls: 0.1411, d4.loss_bbox: 0.0688, d4.loss_iou: 0.3597, loss_rpn_cls: 0.0519, loss_rpn_bbox: 0.1356, loss_cls0: 1.5840, acc0: 94.6502, loss_bbox0: 2.7020, loss_cls1: 1.2108, loss_bbox1: 3.9239, loss_centerness1: 7.4889, loss_cls_aux0: 0.0250, loss_bbox_aux0: 0.0247, loss_iou_aux0: 0.1229, d0.loss_cls_aux0: 0.0359, d0.loss_bbox_aux0: 0.0505, d0.loss_iou_aux0: 0.2507, d1.loss_cls_aux0: 0.0284, d1.loss_bbox_aux0: 0.0291, d1.loss_iou_aux0: 0.1447, d2.loss_cls_aux0: 0.0252, d2.loss_bbox_aux0: 0.0245, d2.loss_iou_aux0: 0.1211, d3.loss_cls_aux0: 0.0242, d3.loss_bbox_aux0: 0.0245, d3.loss_iou_aux0: 0.1215, d4.loss_cls_aux0: 0.0244, d4.loss_bbox_aux0: 0.0246, d4.loss_iou_aux0: 0.1221, loss_cls_aux1: 0.0230, loss_bbox_aux1: 0.0548, loss_iou_aux1: 0.2835, d0.loss_cls_aux1: 0.0305, d0.loss_bbox_aux1: 0.0625, d0.loss_iou_aux1: 0.3200, d1.loss_cls_aux1: 0.0257, d1.loss_bbox_aux1: 0.0555, d1.loss_iou_aux1: 0.2865, d2.loss_cls_aux1: 0.0233, d2.loss_bbox_aux1: 0.0548, d2.loss_iou_aux1: 0.2829, d3.loss_cls_aux1: 0.0224, d3.loss_bbox_aux1: 0.0548, d3.loss_iou_aux1: 0.2831, d4.loss_cls_aux1: 0.0224, d4.loss_bbox_aux1: 0.0548, d4.loss_iou_aux1: 0.2833, loss: 24.6475, grad_norm: 70.4931
2024-03-18 08:03:20,578 - mmdet - INFO - Saving checkpoint at 6 epochs
2024-03-18 08:03:42,391 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:03:47,794 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.589
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.465
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.310
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.370
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.527
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.701
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.701
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.701
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.699
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.822

2024-03-18 08:03:47,795 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.026 | Tin      | 0.610 | Thatch   | 0.538 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:03:47,851 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:03:47,851 - mmdet - INFO - Epoch(val) [6][154]	bbox_mAP: 0.3910, bbox_mAP_50: 0.5890, bbox_mAP_75: 0.4650, bbox_mAP_s: 0.3100, bbox_mAP_m: 0.3700, bbox_mAP_l: 0.5270, bbox_mAP_copypaste: 0.391 0.589 0.465 0.310 0.370 0.527
2024-03-18 08:04:31,454 - mmdet - INFO - Epoch [7][50/232]	lr: 2.000e-05, eta: 1:23:29, time: 0.872, data_time: 0.061, memory: 17638, enc_loss_cls: 0.1513, enc_loss_bbox: 0.0748, enc_loss_iou: 0.3857, loss_cls: 0.1348, loss_bbox: 0.0704, loss_iou: 0.3641, d0.loss_cls: 0.1776, d0.loss_bbox: 0.0708, d0.loss_iou: 0.3669, d1.loss_cls: 0.1465, d1.loss_bbox: 0.0705, d1.loss_iou: 0.3647, d2.loss_cls: 0.1363, d2.loss_bbox: 0.0703, d2.loss_iou: 0.3636, d3.loss_cls: 0.1343, d3.loss_bbox: 0.0703, d3.loss_iou: 0.3640, d4.loss_cls: 0.1341, d4.loss_bbox: 0.0704, d4.loss_iou: 0.3641, loss_rpn_cls: 0.0465, loss_rpn_bbox: 0.1341, loss_cls0: 1.6897, acc0: 94.3115, loss_bbox0: 2.8973, loss_cls1: 1.2196, loss_bbox1: 4.0115, loss_centerness1: 7.4716, loss_cls_aux0: 0.0334, loss_bbox_aux0: 0.0259, loss_iou_aux0: 0.1251, d0.loss_cls_aux0: 0.0411, d0.loss_bbox_aux0: 0.0519, d0.loss_iou_aux0: 0.2563, d1.loss_cls_aux0: 0.0360, d1.loss_bbox_aux0: 0.0302, d1.loss_iou_aux0: 0.1472, d2.loss_cls_aux0: 0.0331, d2.loss_bbox_aux0: 0.0258, d2.loss_iou_aux0: 0.1240, d3.loss_cls_aux0: 0.0331, d3.loss_bbox_aux0: 0.0258, d3.loss_iou_aux0: 0.1243, d4.loss_cls_aux0: 0.0331, d4.loss_bbox_aux0: 0.0259, d4.loss_iou_aux0: 0.1246, loss_cls_aux1: 0.0354, loss_bbox_aux1: 0.0548, loss_iou_aux1: 0.2835, d0.loss_cls_aux1: 0.0385, d0.loss_bbox_aux1: 0.0640, d0.loss_iou_aux1: 0.3292, d1.loss_cls_aux1: 0.0368, d1.loss_bbox_aux1: 0.0559, d1.loss_iou_aux1: 0.2883, d2.loss_cls_aux1: 0.0355, d2.loss_bbox_aux1: 0.0547, d2.loss_iou_aux1: 0.2832, d3.loss_cls_aux1: 0.0351, d3.loss_bbox_aux1: 0.0547, d3.loss_iou_aux1: 0.2833, d4.loss_cls_aux1: 0.0352, d4.loss_bbox_aux1: 0.0548, d4.loss_iou_aux1: 0.2833, loss: 25.1588, grad_norm: 70.1743
2024-03-18 08:05:11,959 - mmdet - INFO - Epoch [7][100/232]	lr: 2.000e-05, eta: 1:23:12, time: 0.810, data_time: 0.011, memory: 17638, enc_loss_cls: 0.1493, enc_loss_bbox: 0.0724, enc_loss_iou: 0.3835, loss_cls: 0.1243, loss_bbox: 0.0663, loss_iou: 0.3512, d0.loss_cls: 0.1722, d0.loss_bbox: 0.0674, d0.loss_iou: 0.3572, d1.loss_cls: 0.1377, d1.loss_bbox: 0.0662, d1.loss_iou: 0.3510, d2.loss_cls: 0.1278, d2.loss_bbox: 0.0663, d2.loss_iou: 0.3504, d3.loss_cls: 0.1238, d3.loss_bbox: 0.0663, d3.loss_iou: 0.3508, d4.loss_cls: 0.1240, d4.loss_bbox: 0.0663, d4.loss_iou: 0.3509, loss_rpn_cls: 0.0564, loss_rpn_bbox: 0.1496, loss_cls0: 1.6055, acc0: 94.5411, loss_bbox0: 2.8136, loss_cls1: 1.1227, loss_bbox1: 3.9669, loss_centerness1: 7.4792, loss_cls_aux0: 0.0274, loss_bbox_aux0: 0.0253, loss_iou_aux0: 0.1298, d0.loss_cls_aux0: 0.0347, d0.loss_bbox_aux0: 0.0494, d0.loss_iou_aux0: 0.2501, d1.loss_cls_aux0: 0.0305, d1.loss_bbox_aux0: 0.0293, d1.loss_iou_aux0: 0.1498, d2.loss_cls_aux0: 0.0270, d2.loss_bbox_aux0: 0.0251, d2.loss_iou_aux0: 0.1277, d3.loss_cls_aux0: 0.0270, d3.loss_bbox_aux0: 0.0251, d3.loss_iou_aux0: 0.1283, d4.loss_cls_aux0: 0.0274, d4.loss_bbox_aux0: 0.0252, d4.loss_iou_aux0: 0.1289, loss_cls_aux1: 0.0221, loss_bbox_aux1: 0.0538, loss_iou_aux1: 0.2864, d0.loss_cls_aux1: 0.0256, d0.loss_bbox_aux1: 0.0628, d0.loss_iou_aux1: 0.3310, d1.loss_cls_aux1: 0.0231, d1.loss_bbox_aux1: 0.0541, d1.loss_iou_aux1: 0.2885, d2.loss_cls_aux1: 0.0217, d2.loss_bbox_aux1: 0.0536, d2.loss_iou_aux1: 0.2857, d3.loss_cls_aux1: 0.0213, d3.loss_bbox_aux1: 0.0537, d3.loss_iou_aux1: 0.2859, d4.loss_cls_aux1: 0.0218, d4.loss_bbox_aux1: 0.0537, d4.loss_iou_aux1: 0.2861, loss: 24.6186, grad_norm: 68.5761
2024-03-18 08:05:52,956 - mmdet - INFO - Epoch [7][150/232]	lr: 2.000e-05, eta: 1:22:56, time: 0.820, data_time: 0.011, memory: 17638, enc_loss_cls: 0.1531, enc_loss_bbox: 0.0680, enc_loss_iou: 0.3786, loss_cls: 0.1328, loss_bbox: 0.0623, loss_iou: 0.3481, d0.loss_cls: 0.1719, d0.loss_bbox: 0.0631, d0.loss_iou: 0.3541, d1.loss_cls: 0.1392, d1.loss_bbox: 0.0626, d1.loss_iou: 0.3494, d2.loss_cls: 0.1334, d2.loss_bbox: 0.0625, d2.loss_iou: 0.3482, d3.loss_cls: 0.1309, d3.loss_bbox: 0.0623, d3.loss_iou: 0.3481, d4.loss_cls: 0.1312, d4.loss_bbox: 0.0623, d4.loss_iou: 0.3481, loss_rpn_cls: 0.0354, loss_rpn_bbox: 0.1349, loss_cls0: 1.5566, acc0: 94.7972, loss_bbox0: 2.6798, loss_cls1: 1.1887, loss_bbox1: 3.8388, loss_centerness1: 7.5022, loss_cls_aux0: 0.0312, loss_bbox_aux0: 0.0233, loss_iou_aux0: 0.1223, d0.loss_cls_aux0: 0.0404, d0.loss_bbox_aux0: 0.0469, d0.loss_iou_aux0: 0.2483, d1.loss_cls_aux0: 0.0347, d1.loss_bbox_aux0: 0.0268, d1.loss_iou_aux0: 0.1400, d2.loss_cls_aux0: 0.0318, d2.loss_bbox_aux0: 0.0231, d2.loss_iou_aux0: 0.1206, d3.loss_cls_aux0: 0.0305, d3.loss_bbox_aux0: 0.0232, d3.loss_iou_aux0: 0.1210, d4.loss_cls_aux0: 0.0308, d4.loss_bbox_aux0: 0.0233, d4.loss_iou_aux0: 0.1216, loss_cls_aux1: 0.0272, loss_bbox_aux1: 0.0501, loss_iou_aux1: 0.2777, d0.loss_cls_aux1: 0.0317, d0.loss_bbox_aux1: 0.0607, d0.loss_iou_aux1: 0.3338, d1.loss_cls_aux1: 0.0291, d1.loss_bbox_aux1: 0.0510, d1.loss_iou_aux1: 0.2825, d2.loss_cls_aux1: 0.0277, d2.loss_bbox_aux1: 0.0500, d2.loss_iou_aux1: 0.2775, d3.loss_cls_aux1: 0.0269, d3.loss_bbox_aux1: 0.0500, d3.loss_iou_aux1: 0.2776, d4.loss_cls_aux1: 0.0271, d4.loss_bbox_aux1: 0.0501, d4.loss_iou_aux1: 0.2776, loss: 24.2945, grad_norm: 70.7930
2024-03-18 08:06:34,367 - mmdet - INFO - Epoch [7][200/232]	lr: 2.000e-05, eta: 1:22:40, time: 0.828, data_time: 0.010, memory: 17638, enc_loss_cls: 0.1550, enc_loss_bbox: 0.0758, enc_loss_iou: 0.3843, loss_cls: 0.1314, loss_bbox: 0.0715, loss_iou: 0.3625, d0.loss_cls: 0.1769, d0.loss_bbox: 0.0715, d0.loss_iou: 0.3670, d1.loss_cls: 0.1432, d1.loss_bbox: 0.0706, d1.loss_iou: 0.3617, d2.loss_cls: 0.1334, d2.loss_bbox: 0.0713, d2.loss_iou: 0.3622, d3.loss_cls: 0.1315, d3.loss_bbox: 0.0713, d3.loss_iou: 0.3622, d4.loss_cls: 0.1307, d4.loss_bbox: 0.0716, d4.loss_iou: 0.3627, loss_rpn_cls: 0.0579, loss_rpn_bbox: 0.1467, loss_cls0: 1.7576, acc0: 94.1275, loss_bbox0: 3.0300, loss_cls1: 1.2184, loss_bbox1: 3.9786, loss_centerness1: 7.4994, loss_cls_aux0: 0.0259, loss_bbox_aux0: 0.0254, loss_iou_aux0: 0.1223, d0.loss_cls_aux0: 0.0390, d0.loss_bbox_aux0: 0.0509, d0.loss_iou_aux0: 0.2500, d1.loss_cls_aux0: 0.0306, d1.loss_bbox_aux0: 0.0300, d1.loss_iou_aux0: 0.1442, d2.loss_cls_aux0: 0.0274, d2.loss_bbox_aux0: 0.0252, d2.loss_iou_aux0: 0.1213, d3.loss_cls_aux0: 0.0258, d3.loss_bbox_aux0: 0.0253, d3.loss_iou_aux0: 0.1216, d4.loss_cls_aux0: 0.0257, d4.loss_bbox_aux0: 0.0253, d4.loss_iou_aux0: 0.1219, loss_cls_aux1: 0.0242, loss_bbox_aux1: 0.0552, loss_iou_aux1: 0.2824, d0.loss_cls_aux1: 0.0327, d0.loss_bbox_aux1: 0.0629, d0.loss_iou_aux1: 0.3226, d1.loss_cls_aux1: 0.0276, d1.loss_bbox_aux1: 0.0560, d1.loss_iou_aux1: 0.2859, d2.loss_cls_aux1: 0.0251, d2.loss_bbox_aux1: 0.0551, d2.loss_iou_aux1: 0.2821, d3.loss_cls_aux1: 0.0244, d3.loss_bbox_aux1: 0.0552, d3.loss_iou_aux1: 0.2822, d4.loss_cls_aux1: 0.0242, d4.loss_bbox_aux1: 0.0552, d4.loss_iou_aux1: 0.2823, loss: 25.2298, grad_norm: 67.7042
2024-03-18 08:07:01,182 - mmdet - INFO - Saving checkpoint at 7 epochs
2024-03-18 08:07:23,134 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:07:28,832 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.588
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.471
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.303
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.376
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.638
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.695
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.791

2024-03-18 08:07:28,832 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.033 | Tin      | 0.628 | Thatch   | 0.513 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:07:28,893 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:07:28,894 - mmdet - INFO - Epoch(val) [7][154]	bbox_mAP: 0.3910, bbox_mAP_50: 0.5880, bbox_mAP_75: 0.4710, bbox_mAP_s: 0.3030, bbox_mAP_m: 0.3760, bbox_mAP_l: 0.6400, bbox_mAP_copypaste: 0.391 0.588 0.471 0.303 0.376 0.640
2024-03-18 08:08:12,469 - mmdet - INFO - Epoch [8][50/232]	lr: 2.000e-05, eta: 1:20:34, time: 0.871, data_time: 0.060, memory: 17638, enc_loss_cls: 0.1405, enc_loss_bbox: 0.0738, enc_loss_iou: 0.3857, loss_cls: 0.1232, loss_bbox: 0.0656, loss_iou: 0.3488, d0.loss_cls: 0.1598, d0.loss_bbox: 0.0663, d0.loss_iou: 0.3523, d1.loss_cls: 0.1316, d1.loss_bbox: 0.0653, d1.loss_iou: 0.3481, d2.loss_cls: 0.1252, d2.loss_bbox: 0.0653, d2.loss_iou: 0.3475, d3.loss_cls: 0.1219, d3.loss_bbox: 0.0658, d3.loss_iou: 0.3489, d4.loss_cls: 0.1211, d4.loss_bbox: 0.0658, d4.loss_iou: 0.3492, loss_rpn_cls: 0.0437, loss_rpn_bbox: 0.1256, loss_cls0: 1.5303, acc0: 94.8326, loss_bbox0: 2.6973, loss_cls1: 1.1541, loss_bbox1: 3.8975, loss_centerness1: 7.4643, loss_cls_aux0: 0.0278, loss_bbox_aux0: 0.0239, loss_iou_aux0: 0.1187, d0.loss_cls_aux0: 0.0372, d0.loss_bbox_aux0: 0.0485, d0.loss_iou_aux0: 0.2487, d1.loss_cls_aux0: 0.0317, d1.loss_bbox_aux0: 0.0279, d1.loss_iou_aux0: 0.1400, d2.loss_cls_aux0: 0.0288, d2.loss_bbox_aux0: 0.0237, d2.loss_iou_aux0: 0.1171, d3.loss_cls_aux0: 0.0272, d3.loss_bbox_aux0: 0.0238, d3.loss_iou_aux0: 0.1175, d4.loss_cls_aux0: 0.0275, d4.loss_bbox_aux0: 0.0238, d4.loss_iou_aux0: 0.1180, loss_cls_aux1: 0.0274, loss_bbox_aux1: 0.0534, loss_iou_aux1: 0.2828, d0.loss_cls_aux1: 0.0316, d0.loss_bbox_aux1: 0.0628, d0.loss_iou_aux1: 0.3307, d1.loss_cls_aux1: 0.0293, d1.loss_bbox_aux1: 0.0543, d1.loss_iou_aux1: 0.2874, d2.loss_cls_aux1: 0.0274, d2.loss_bbox_aux1: 0.0533, d2.loss_iou_aux1: 0.2822, d3.loss_cls_aux1: 0.0263, d3.loss_bbox_aux1: 0.0533, d3.loss_iou_aux1: 0.2823, d4.loss_cls_aux1: 0.0268, d4.loss_bbox_aux1: 0.0534, d4.loss_iou_aux1: 0.2825, loss: 24.2434, grad_norm: 69.5551
2024-03-18 08:08:53,225 - mmdet - INFO - Epoch [8][100/232]	lr: 2.000e-05, eta: 1:20:15, time: 0.815, data_time: 0.012, memory: 17638, enc_loss_cls: 0.1561, enc_loss_bbox: 0.0718, enc_loss_iou: 0.3803, loss_cls: 0.1328, loss_bbox: 0.0650, loss_iou: 0.3507, d0.loss_cls: 0.1774, d0.loss_bbox: 0.0668, d0.loss_iou: 0.3574, d1.loss_cls: 0.1454, d1.loss_bbox: 0.0656, d1.loss_iou: 0.3522, d2.loss_cls: 0.1361, d2.loss_bbox: 0.0651, d2.loss_iou: 0.3504, d3.loss_cls: 0.1337, d3.loss_bbox: 0.0648, d3.loss_iou: 0.3497, d4.loss_cls: 0.1326, d4.loss_bbox: 0.0650, d4.loss_iou: 0.3505, loss_rpn_cls: 0.0474, loss_rpn_bbox: 0.1568, loss_cls0: 1.7660, acc0: 94.0218, loss_bbox0: 2.9110, loss_cls1: 1.1395, loss_bbox1: 3.8319, loss_centerness1: 7.5194, loss_cls_aux0: 0.0273, loss_bbox_aux0: 0.0280, loss_iou_aux0: 0.1376, d0.loss_cls_aux0: 0.0343, d0.loss_bbox_aux0: 0.0538, d0.loss_iou_aux0: 0.2681, d1.loss_cls_aux0: 0.0283, d1.loss_bbox_aux0: 0.0323, d1.loss_iou_aux0: 0.1601, d2.loss_cls_aux0: 0.0271, d2.loss_bbox_aux0: 0.0279, d2.loss_iou_aux0: 0.1367, d3.loss_cls_aux0: 0.0267, d3.loss_bbox_aux0: 0.0280, d3.loss_iou_aux0: 0.1370, d4.loss_cls_aux0: 0.0273, d4.loss_bbox_aux0: 0.0280, d4.loss_iou_aux0: 0.1373, loss_cls_aux1: 0.0255, loss_bbox_aux1: 0.0534, loss_iou_aux1: 0.2825, d0.loss_cls_aux1: 0.0275, d0.loss_bbox_aux1: 0.0652, d0.loss_iou_aux1: 0.3404, d1.loss_cls_aux1: 0.0260, d1.loss_bbox_aux1: 0.0544, d1.loss_iou_aux1: 0.2872, d2.loss_cls_aux1: 0.0251, d2.loss_bbox_aux1: 0.0533, d2.loss_iou_aux1: 0.2820, d3.loss_cls_aux1: 0.0250, d3.loss_bbox_aux1: 0.0534, d3.loss_iou_aux1: 0.2821, d4.loss_cls_aux1: 0.0256, d4.loss_bbox_aux1: 0.0534, d4.loss_iou_aux1: 0.2823, loss: 24.9316, grad_norm: 64.8549
2024-03-18 08:09:34,376 - mmdet - INFO - Epoch [8][150/232]	lr: 2.000e-05, eta: 1:19:57, time: 0.823, data_time: 0.009, memory: 17638, enc_loss_cls: 0.1373, enc_loss_bbox: 0.0741, enc_loss_iou: 0.3774, loss_cls: 0.1167, loss_bbox: 0.0678, loss_iou: 0.3477, d0.loss_cls: 0.1604, d0.loss_bbox: 0.0683, d0.loss_iou: 0.3505, d1.loss_cls: 0.1267, d1.loss_bbox: 0.0679, d1.loss_iou: 0.3480, d2.loss_cls: 0.1184, d2.loss_bbox: 0.0679, d2.loss_iou: 0.3478, d3.loss_cls: 0.1170, d3.loss_bbox: 0.0677, d3.loss_iou: 0.3474, d4.loss_cls: 0.1172, d4.loss_bbox: 0.0677, d4.loss_iou: 0.3475, loss_rpn_cls: 0.0534, loss_rpn_bbox: 0.1446, loss_cls0: 1.6954, acc0: 94.1571, loss_bbox0: 2.9114, loss_cls1: 1.1378, loss_bbox1: 3.9444, loss_centerness1: 7.5084, loss_cls_aux0: 0.0271, loss_bbox_aux0: 0.0271, loss_iou_aux0: 0.1313, d0.loss_cls_aux0: 0.0371, d0.loss_bbox_aux0: 0.0499, d0.loss_iou_aux0: 0.2493, d1.loss_cls_aux0: 0.0313, d1.loss_bbox_aux0: 0.0311, d1.loss_iou_aux0: 0.1519, d2.loss_cls_aux0: 0.0278, d2.loss_bbox_aux0: 0.0269, d2.loss_iou_aux0: 0.1303, d3.loss_cls_aux0: 0.0267, d3.loss_bbox_aux0: 0.0270, d3.loss_iou_aux0: 0.1306, d4.loss_cls_aux0: 0.0269, d4.loss_bbox_aux0: 0.0270, d4.loss_iou_aux0: 0.1309, loss_cls_aux1: 0.0227, loss_bbox_aux1: 0.0543, loss_iou_aux1: 0.2792, d0.loss_cls_aux1: 0.0272, d0.loss_bbox_aux1: 0.0621, d0.loss_iou_aux1: 0.3171, d1.loss_cls_aux1: 0.0247, d1.loss_bbox_aux1: 0.0550, d1.loss_iou_aux1: 0.2824, d2.loss_cls_aux1: 0.0230, d2.loss_bbox_aux1: 0.0542, d2.loss_iou_aux1: 0.2787, d3.loss_cls_aux1: 0.0225, d3.loss_bbox_aux1: 0.0543, d3.loss_iou_aux1: 0.2788, d4.loss_cls_aux1: 0.0223, d4.loss_bbox_aux1: 0.0543, d4.loss_iou_aux1: 0.2790, loss: 24.7189, grad_norm: 70.3017
2024-03-18 08:10:15,986 - mmdet - INFO - Epoch [8][200/232]	lr: 2.000e-05, eta: 1:19:39, time: 0.832, data_time: 0.010, memory: 17638, enc_loss_cls: 0.1466, enc_loss_bbox: 0.0778, enc_loss_iou: 0.4103, loss_cls: 0.1305, loss_bbox: 0.0740, loss_iou: 0.3840, d0.loss_cls: 0.1699, d0.loss_bbox: 0.0746, d0.loss_iou: 0.3910, d1.loss_cls: 0.1389, d1.loss_bbox: 0.0738, d1.loss_iou: 0.3846, d2.loss_cls: 0.1336, d2.loss_bbox: 0.0737, d2.loss_iou: 0.3838, d3.loss_cls: 0.1305, d3.loss_bbox: 0.0739, d3.loss_iou: 0.3837, d4.loss_cls: 0.1303, d4.loss_bbox: 0.0740, d4.loss_iou: 0.3839, loss_rpn_cls: 0.0496, loss_rpn_bbox: 0.1539, loss_cls0: 1.7876, acc0: 93.9996, loss_bbox0: 2.9787, loss_cls1: 1.2119, loss_bbox1: 4.1972, loss_centerness1: 7.5321, loss_cls_aux0: 0.0357, loss_bbox_aux0: 0.0266, loss_iou_aux0: 0.1296, d0.loss_cls_aux0: 0.0427, d0.loss_bbox_aux0: 0.0514, d0.loss_iou_aux0: 0.2575, d1.loss_cls_aux0: 0.0384, d1.loss_bbox_aux0: 0.0301, d1.loss_iou_aux0: 0.1483, d2.loss_cls_aux0: 0.0359, d2.loss_bbox_aux0: 0.0264, d2.loss_iou_aux0: 0.1278, d3.loss_cls_aux0: 0.0355, d3.loss_bbox_aux0: 0.0265, d3.loss_iou_aux0: 0.1283, d4.loss_cls_aux0: 0.0357, d4.loss_bbox_aux0: 0.0265, d4.loss_iou_aux0: 0.1289, loss_cls_aux1: 0.0336, loss_bbox_aux1: 0.0569, loss_iou_aux1: 0.2933, d0.loss_cls_aux1: 0.0378, d0.loss_bbox_aux1: 0.0675, d0.loss_iou_aux1: 0.3451, d1.loss_cls_aux1: 0.0368, d1.loss_bbox_aux1: 0.0579, d1.loss_iou_aux1: 0.2979, d2.loss_cls_aux1: 0.0341, d2.loss_bbox_aux1: 0.0568, d2.loss_iou_aux1: 0.2931, d3.loss_cls_aux1: 0.0328, d3.loss_bbox_aux1: 0.0569, d3.loss_iou_aux1: 0.2932, d4.loss_cls_aux1: 0.0338, d4.loss_bbox_aux1: 0.0569, d4.loss_iou_aux1: 0.2932, loss: 25.8439, grad_norm: 69.9099
2024-03-18 08:10:42,697 - mmdet - INFO - Saving checkpoint at 8 epochs
2024-03-18 08:11:04,733 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:11:09,765 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.605
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.319
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.582
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.704
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.704
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.704
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.636
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.707
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.830

2024-03-18 08:11:09,765 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.056 | Tin      | 0.624 | Thatch   | 0.524 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:11:09,823 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:11:09,823 - mmdet - INFO - Epoch(val) [8][154]	bbox_mAP: 0.4020, bbox_mAP_50: 0.6050, bbox_mAP_75: 0.4770, bbox_mAP_s: 0.3190, bbox_mAP_m: 0.3840, bbox_mAP_l: 0.5820, bbox_mAP_copypaste: 0.402 0.605 0.477 0.319 0.384 0.582
2024-03-18 08:11:53,750 - mmdet - INFO - Epoch [9][50/232]	lr: 2.000e-05, eta: 1:17:44, time: 0.878, data_time: 0.062, memory: 17638, enc_loss_cls: 0.1409, enc_loss_bbox: 0.0678, enc_loss_iou: 0.3596, loss_cls: 0.1236, loss_bbox: 0.0625, loss_iou: 0.3340, d0.loss_cls: 0.1578, d0.loss_bbox: 0.0639, d0.loss_iou: 0.3406, d1.loss_cls: 0.1323, d1.loss_bbox: 0.0629, d1.loss_iou: 0.3357, d2.loss_cls: 0.1232, d2.loss_bbox: 0.0626, d2.loss_iou: 0.3341, d3.loss_cls: 0.1218, d3.loss_bbox: 0.0626, d3.loss_iou: 0.3338, d4.loss_cls: 0.1218, d4.loss_bbox: 0.0625, d4.loss_iou: 0.3340, loss_rpn_cls: 0.0452, loss_rpn_bbox: 0.1411, loss_cls0: 1.6263, acc0: 94.5764, loss_bbox0: 2.7776, loss_cls1: 1.1457, loss_bbox1: 3.6903, loss_centerness1: 7.4858, loss_cls_aux0: 0.0293, loss_bbox_aux0: 0.0244, loss_iou_aux0: 0.1212, d0.loss_cls_aux0: 0.0385, d0.loss_bbox_aux0: 0.0476, d0.loss_iou_aux0: 0.2410, d1.loss_cls_aux0: 0.0329, d1.loss_bbox_aux0: 0.0279, d1.loss_iou_aux0: 0.1384, d2.loss_cls_aux0: 0.0295, d2.loss_bbox_aux0: 0.0242, d2.loss_iou_aux0: 0.1191, d3.loss_cls_aux0: 0.0292, d3.loss_bbox_aux0: 0.0243, d3.loss_iou_aux0: 0.1197, d4.loss_cls_aux0: 0.0292, d4.loss_bbox_aux0: 0.0243, d4.loss_iou_aux0: 0.1203, loss_cls_aux1: 0.0293, loss_bbox_aux1: 0.0505, loss_iou_aux1: 0.2650, d0.loss_cls_aux1: 0.0350, d0.loss_bbox_aux1: 0.0576, d0.loss_iou_aux1: 0.3045, d1.loss_cls_aux1: 0.0322, d1.loss_bbox_aux1: 0.0512, d1.loss_iou_aux1: 0.2686, d2.loss_cls_aux1: 0.0290, d2.loss_bbox_aux1: 0.0504, d2.loss_iou_aux1: 0.2648, d3.loss_cls_aux1: 0.0287, d3.loss_bbox_aux1: 0.0505, d3.loss_iou_aux1: 0.2648, d4.loss_cls_aux1: 0.0289, d4.loss_bbox_aux1: 0.0505, d4.loss_iou_aux1: 0.2649, loss: 23.9979, grad_norm: 69.3839
2024-03-18 08:12:34,420 - mmdet - INFO - Epoch [9][100/232]	lr: 2.000e-05, eta: 1:17:23, time: 0.813, data_time: 0.010, memory: 17638, enc_loss_cls: 0.1463, enc_loss_bbox: 0.0692, enc_loss_iou: 0.3627, loss_cls: 0.1289, loss_bbox: 0.0644, loss_iou: 0.3431, d0.loss_cls: 0.1628, d0.loss_bbox: 0.0649, d0.loss_iou: 0.3447, d1.loss_cls: 0.1385, d1.loss_bbox: 0.0648, d1.loss_iou: 0.3423, d2.loss_cls: 0.1308, d2.loss_bbox: 0.0644, d2.loss_iou: 0.3422, d3.loss_cls: 0.1287, d3.loss_bbox: 0.0645, d3.loss_iou: 0.3427, d4.loss_cls: 0.1286, d4.loss_bbox: 0.0644, d4.loss_iou: 0.3428, loss_rpn_cls: 0.0382, loss_rpn_bbox: 0.1313, loss_cls0: 1.5667, acc0: 94.6589, loss_bbox0: 2.7716, loss_cls1: 1.1392, loss_bbox1: 3.7805, loss_centerness1: 7.4861, loss_cls_aux0: 0.0234, loss_bbox_aux0: 0.0240, loss_iou_aux0: 0.1180, d0.loss_cls_aux0: 0.0318, d0.loss_bbox_aux0: 0.0487, d0.loss_iou_aux0: 0.2426, d1.loss_cls_aux0: 0.0262, d1.loss_bbox_aux0: 0.0271, d1.loss_iou_aux0: 0.1332, d2.loss_cls_aux0: 0.0232, d2.loss_bbox_aux0: 0.0238, d2.loss_iou_aux0: 0.1167, d3.loss_cls_aux0: 0.0225, d3.loss_bbox_aux0: 0.0238, d3.loss_iou_aux0: 0.1170, d4.loss_cls_aux0: 0.0228, d4.loss_bbox_aux0: 0.0239, d4.loss_iou_aux0: 0.1174, loss_cls_aux1: 0.0219, loss_bbox_aux1: 0.0524, loss_iou_aux1: 0.2716, d0.loss_cls_aux1: 0.0249, d0.loss_bbox_aux1: 0.0600, d0.loss_iou_aux1: 0.3085, d1.loss_cls_aux1: 0.0235, d1.loss_bbox_aux1: 0.0527, d1.loss_iou_aux1: 0.2740, d2.loss_cls_aux1: 0.0216, d2.loss_bbox_aux1: 0.0523, d2.loss_iou_aux1: 0.2712, d3.loss_cls_aux1: 0.0216, d3.loss_bbox_aux1: 0.0523, d3.loss_iou_aux1: 0.2714, d4.loss_cls_aux1: 0.0215, d4.loss_bbox_aux1: 0.0523, d4.loss_iou_aux1: 0.2715, loss: 24.0467, grad_norm: 65.9132
2024-03-18 08:13:15,519 - mmdet - INFO - Epoch [9][150/232]	lr: 2.000e-05, eta: 1:17:02, time: 0.822, data_time: 0.010, memory: 17638, enc_loss_cls: 0.1398, enc_loss_bbox: 0.0746, enc_loss_iou: 0.4003, loss_cls: 0.1272, loss_bbox: 0.0682, loss_iou: 0.3676, d0.loss_cls: 0.1633, d0.loss_bbox: 0.0688, d0.loss_iou: 0.3716, d1.loss_cls: 0.1343, d1.loss_bbox: 0.0677, d1.loss_iou: 0.3667, d2.loss_cls: 0.1261, d2.loss_bbox: 0.0681, d2.loss_iou: 0.3671, d3.loss_cls: 0.1253, d3.loss_bbox: 0.0681, d3.loss_iou: 0.3674, d4.loss_cls: 0.1268, d4.loss_bbox: 0.0681, d4.loss_iou: 0.3673, loss_rpn_cls: 0.0423, loss_rpn_bbox: 0.1566, loss_cls0: 1.6542, acc0: 94.4609, loss_bbox0: 2.8466, loss_cls1: 1.1489, loss_bbox1: 4.1590, loss_centerness1: 7.5157, loss_cls_aux0: 0.0301, loss_bbox_aux0: 0.0240, loss_iou_aux0: 0.1241, d0.loss_cls_aux0: 0.0381, d0.loss_bbox_aux0: 0.0478, d0.loss_iou_aux0: 0.2506, d1.loss_cls_aux0: 0.0326, d1.loss_bbox_aux0: 0.0277, d1.loss_iou_aux0: 0.1431, d2.loss_cls_aux0: 0.0298, d2.loss_bbox_aux0: 0.0238, d2.loss_iou_aux0: 0.1228, d3.loss_cls_aux0: 0.0296, d3.loss_bbox_aux0: 0.0238, d3.loss_iou_aux0: 0.1231, d4.loss_cls_aux0: 0.0299, d4.loss_bbox_aux0: 0.0239, d4.loss_iou_aux0: 0.1236, loss_cls_aux1: 0.0269, loss_bbox_aux1: 0.0545, loss_iou_aux1: 0.2931, d0.loss_cls_aux1: 0.0299, d0.loss_bbox_aux1: 0.0643, d0.loss_iou_aux1: 0.3405, d1.loss_cls_aux1: 0.0290, d1.loss_bbox_aux1: 0.0554, d1.loss_iou_aux1: 0.2975, d2.loss_cls_aux1: 0.0270, d2.loss_bbox_aux1: 0.0545, d2.loss_iou_aux1: 0.2928, d3.loss_cls_aux1: 0.0265, d3.loss_bbox_aux1: 0.0545, d3.loss_iou_aux1: 0.2929, d4.loss_cls_aux1: 0.0265, d4.loss_bbox_aux1: 0.0545, d4.loss_iou_aux1: 0.2930, loss: 25.1189, grad_norm: 65.8665
2024-03-18 08:13:56,986 - mmdet - INFO - Epoch [9][200/232]	lr: 2.000e-05, eta: 1:16:41, time: 0.829, data_time: 0.010, memory: 17638, enc_loss_cls: 0.1503, enc_loss_bbox: 0.0760, enc_loss_iou: 0.3979, loss_cls: 0.1244, loss_bbox: 0.0705, loss_iou: 0.3716, d0.loss_cls: 0.1608, d0.loss_bbox: 0.0712, d0.loss_iou: 0.3748, d1.loss_cls: 0.1340, d1.loss_bbox: 0.0705, d1.loss_iou: 0.3707, d2.loss_cls: 0.1273, d2.loss_bbox: 0.0705, d2.loss_iou: 0.3708, d3.loss_cls: 0.1230, d3.loss_bbox: 0.0706, d3.loss_iou: 0.3716, d4.loss_cls: 0.1230, d4.loss_bbox: 0.0706, d4.loss_iou: 0.3717, loss_rpn_cls: 0.0438, loss_rpn_bbox: 0.1448, loss_cls0: 1.7195, acc0: 94.1698, loss_bbox0: 2.8648, loss_cls1: 1.1755, loss_bbox1: 4.0013, loss_centerness1: 7.5163, loss_cls_aux0: 0.0271, loss_bbox_aux0: 0.0275, loss_iou_aux0: 0.1353, d0.loss_cls_aux0: 0.0342, d0.loss_bbox_aux0: 0.0504, d0.loss_iou_aux0: 0.2483, d1.loss_cls_aux0: 0.0292, d1.loss_bbox_aux0: 0.0313, d1.loss_iou_aux0: 0.1538, d2.loss_cls_aux0: 0.0280, d2.loss_bbox_aux0: 0.0273, d2.loss_iou_aux0: 0.1340, d3.loss_cls_aux0: 0.0271, d3.loss_bbox_aux0: 0.0274, d3.loss_iou_aux0: 0.1343, d4.loss_cls_aux0: 0.0269, d4.loss_bbox_aux0: 0.0274, d4.loss_iou_aux0: 0.1348, loss_cls_aux1: 0.0222, loss_bbox_aux1: 0.0552, loss_iou_aux1: 0.2897, d0.loss_cls_aux1: 0.0245, d0.loss_bbox_aux1: 0.0639, d0.loss_iou_aux1: 0.3292, d1.loss_cls_aux1: 0.0237, d1.loss_bbox_aux1: 0.0558, d1.loss_iou_aux1: 0.2926, d2.loss_cls_aux1: 0.0229, d2.loss_bbox_aux1: 0.0552, d2.loss_iou_aux1: 0.2894, d3.loss_cls_aux1: 0.0221, d3.loss_bbox_aux1: 0.0552, d3.loss_iou_aux1: 0.2895, d4.loss_cls_aux1: 0.0221, d4.loss_bbox_aux1: 0.0552, d4.loss_iou_aux1: 0.2896, loss: 25.1004, grad_norm: 72.1900
2024-03-18 08:14:23,704 - mmdet - INFO - Saving checkpoint at 9 epochs
2024-03-18 08:14:45,515 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:14:51,442 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.627
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.493
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.305
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.392
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.792
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.628
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.829

2024-03-18 08:14:51,443 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.087 | Tin      | 0.628 | Thatch   | 0.520 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:14:51,833 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_002/best_bbox_mAP_epoch_5.pth was removed
2024-03-18 08:14:55,177 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_9.pth.
2024-03-18 08:14:55,178 - mmdet - INFO - Best bbox_mAP is 0.4120 at 9 epoch.
2024-03-18 08:14:55,178 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:14:55,178 - mmdet - INFO - Epoch(val) [9][154]	bbox_mAP: 0.4120, bbox_mAP_50: 0.6270, bbox_mAP_75: 0.4930, bbox_mAP_s: 0.3050, bbox_mAP_m: 0.3920, bbox_mAP_l: 0.7920, bbox_mAP_copypaste: 0.412 0.627 0.493 0.305 0.392 0.792
2024-03-18 08:15:39,030 - mmdet - INFO - Epoch [10][50/232]	lr: 2.000e-05, eta: 1:14:54, time: 0.877, data_time: 0.062, memory: 17650, enc_loss_cls: 0.1457, enc_loss_bbox: 0.0726, enc_loss_iou: 0.3863, loss_cls: 0.1253, loss_bbox: 0.0684, loss_iou: 0.3608, d0.loss_cls: 0.1619, d0.loss_bbox: 0.0687, d0.loss_iou: 0.3618, d1.loss_cls: 0.1337, d1.loss_bbox: 0.0686, d1.loss_iou: 0.3609, d2.loss_cls: 0.1252, d2.loss_bbox: 0.0690, d2.loss_iou: 0.3610, d3.loss_cls: 0.1233, d3.loss_bbox: 0.0692, d3.loss_iou: 0.3618, d4.loss_cls: 0.1246, d4.loss_bbox: 0.0684, d4.loss_iou: 0.3607, loss_rpn_cls: 0.0340, loss_rpn_bbox: 0.1303, loss_cls0: 1.6358, acc0: 94.4504, loss_bbox0: 2.7811, loss_cls1: 1.1454, loss_bbox1: 3.9770, loss_centerness1: 7.4750, loss_cls_aux0: 0.0298, loss_bbox_aux0: 0.0232, loss_iou_aux0: 0.1131, d0.loss_cls_aux0: 0.0377, d0.loss_bbox_aux0: 0.0500, d0.loss_iou_aux0: 0.2488, d1.loss_cls_aux0: 0.0323, d1.loss_bbox_aux0: 0.0275, d1.loss_iou_aux0: 0.1352, d2.loss_cls_aux0: 0.0288, d2.loss_bbox_aux0: 0.0230, d2.loss_iou_aux0: 0.1117, d3.loss_cls_aux0: 0.0287, d3.loss_bbox_aux0: 0.0231, d3.loss_iou_aux0: 0.1120, d4.loss_cls_aux0: 0.0290, d4.loss_bbox_aux0: 0.0231, d4.loss_iou_aux0: 0.1125, loss_cls_aux1: 0.0236, loss_bbox_aux1: 0.0545, loss_iou_aux1: 0.2852, d0.loss_cls_aux1: 0.0257, d0.loss_bbox_aux1: 0.0643, d0.loss_iou_aux1: 0.3363, d1.loss_cls_aux1: 0.0247, d1.loss_bbox_aux1: 0.0556, d1.loss_iou_aux1: 0.2908, d2.loss_cls_aux1: 0.0235, d2.loss_bbox_aux1: 0.0544, d2.loss_iou_aux1: 0.2847, d3.loss_cls_aux1: 0.0231, d3.loss_bbox_aux1: 0.0545, d3.loss_iou_aux1: 0.2849, d4.loss_cls_aux1: 0.0230, d4.loss_bbox_aux1: 0.0545, d4.loss_iou_aux1: 0.2850, loss: 24.5945, grad_norm: 65.6990
2024-03-18 08:16:19,541 - mmdet - INFO - Epoch [10][100/232]	lr: 2.000e-05, eta: 1:14:30, time: 0.810, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1331, enc_loss_bbox: 0.0739, enc_loss_iou: 0.3836, loss_cls: 0.1135, loss_bbox: 0.0686, loss_iou: 0.3616, d0.loss_cls: 0.1493, d0.loss_bbox: 0.0688, d0.loss_iou: 0.3635, d1.loss_cls: 0.1218, d1.loss_bbox: 0.0683, d1.loss_iou: 0.3608, d2.loss_cls: 0.1166, d2.loss_bbox: 0.0684, d2.loss_iou: 0.3610, d3.loss_cls: 0.1139, d3.loss_bbox: 0.0685, d3.loss_iou: 0.3616, d4.loss_cls: 0.1131, d4.loss_bbox: 0.0685, d4.loss_iou: 0.3615, loss_rpn_cls: 0.0378, loss_rpn_bbox: 0.1428, loss_cls0: 1.5564, acc0: 94.7313, loss_bbox0: 2.7678, loss_cls1: 1.0905, loss_bbox1: 3.9205, loss_centerness1: 7.4990, loss_cls_aux0: 0.0231, loss_bbox_aux0: 0.0247, loss_iou_aux0: 0.1219, d0.loss_cls_aux0: 0.0314, d0.loss_bbox_aux0: 0.0502, d0.loss_iou_aux0: 0.2485, d1.loss_cls_aux0: 0.0260, d1.loss_bbox_aux0: 0.0291, d1.loss_iou_aux0: 0.1436, d2.loss_cls_aux0: 0.0236, d2.loss_bbox_aux0: 0.0245, d2.loss_iou_aux0: 0.1204, d3.loss_cls_aux0: 0.0229, d3.loss_bbox_aux0: 0.0246, d3.loss_iou_aux0: 0.1208, d4.loss_cls_aux0: 0.0234, d4.loss_bbox_aux0: 0.0246, d4.loss_iou_aux0: 0.1213, loss_cls_aux1: 0.0176, loss_bbox_aux1: 0.0533, loss_iou_aux1: 0.2785, d0.loss_cls_aux1: 0.0205, d0.loss_bbox_aux1: 0.0632, d0.loss_iou_aux1: 0.3252, d1.loss_cls_aux1: 0.0190, d1.loss_bbox_aux1: 0.0541, d1.loss_iou_aux1: 0.2823, d2.loss_cls_aux1: 0.0187, d2.loss_bbox_aux1: 0.0532, d2.loss_iou_aux1: 0.2778, d3.loss_cls_aux1: 0.0180, d3.loss_bbox_aux1: 0.0532, d3.loss_iou_aux1: 0.2780, d4.loss_cls_aux1: 0.0179, d4.loss_bbox_aux1: 0.0533, d4.loss_iou_aux1: 0.2783, loss: 24.2816, grad_norm: 73.1168
2024-03-18 08:17:00,774 - mmdet - INFO - Epoch [10][150/232]	lr: 2.000e-05, eta: 1:14:07, time: 0.825, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1477, enc_loss_bbox: 0.0744, enc_loss_iou: 0.3861, loss_cls: 0.1360, loss_bbox: 0.0689, loss_iou: 0.3598, d0.loss_cls: 0.1777, d0.loss_bbox: 0.0690, d0.loss_iou: 0.3620, d1.loss_cls: 0.1490, d1.loss_bbox: 0.0693, d1.loss_iou: 0.3605, d2.loss_cls: 0.1447, d2.loss_bbox: 0.0684, d2.loss_iou: 0.3596, d3.loss_cls: 0.1362, d3.loss_bbox: 0.0689, d3.loss_iou: 0.3599, d4.loss_cls: 0.1363, d4.loss_bbox: 0.0689, d4.loss_iou: 0.3598, loss_rpn_cls: 0.0532, loss_rpn_bbox: 0.1453, loss_cls0: 1.6239, acc0: 94.5182, loss_bbox0: 2.6993, loss_cls1: 1.1732, loss_bbox1: 3.9622, loss_centerness1: 7.5239, loss_cls_aux0: 0.0273, loss_bbox_aux0: 0.0259, loss_iou_aux0: 0.1286, d0.loss_cls_aux0: 0.0353, d0.loss_bbox_aux0: 0.0491, d0.loss_iou_aux0: 0.2487, d1.loss_cls_aux0: 0.0306, d1.loss_bbox_aux0: 0.0298, d1.loss_iou_aux0: 0.1492, d2.loss_cls_aux0: 0.0281, d2.loss_bbox_aux0: 0.0257, d2.loss_iou_aux0: 0.1272, d3.loss_cls_aux0: 0.0269, d3.loss_bbox_aux0: 0.0257, d3.loss_iou_aux0: 0.1276, d4.loss_cls_aux0: 0.0269, d4.loss_bbox_aux0: 0.0258, d4.loss_iou_aux0: 0.1281, loss_cls_aux1: 0.0270, loss_bbox_aux1: 0.0550, loss_iou_aux1: 0.2876, d0.loss_cls_aux1: 0.0294, d0.loss_bbox_aux1: 0.0622, d0.loss_iou_aux1: 0.3241, d1.loss_cls_aux1: 0.0285, d1.loss_bbox_aux1: 0.0556, d1.loss_iou_aux1: 0.2914, d2.loss_cls_aux1: 0.0271, d2.loss_bbox_aux1: 0.0549, d2.loss_iou_aux1: 0.2871, d3.loss_cls_aux1: 0.0264, d3.loss_bbox_aux1: 0.0549, d3.loss_iou_aux1: 0.2872, d4.loss_cls_aux1: 0.0267, d4.loss_bbox_aux1: 0.0549, d4.loss_iou_aux1: 0.2874, loss: 24.7778, grad_norm: 64.1285
2024-03-18 08:17:42,114 - mmdet - INFO - Epoch [10][200/232]	lr: 2.000e-05, eta: 1:13:44, time: 0.827, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1488, enc_loss_bbox: 0.0696, enc_loss_iou: 0.3798, loss_cls: 0.1267, loss_bbox: 0.0637, loss_iou: 0.3535, d0.loss_cls: 0.1631, d0.loss_bbox: 0.0642, d0.loss_iou: 0.3575, d1.loss_cls: 0.1366, d1.loss_bbox: 0.0640, d1.loss_iou: 0.3553, d2.loss_cls: 0.1280, d2.loss_bbox: 0.0638, d2.loss_iou: 0.3537, d3.loss_cls: 0.1273, d3.loss_bbox: 0.0636, d3.loss_iou: 0.3529, d4.loss_cls: 0.1258, d4.loss_bbox: 0.0638, d4.loss_iou: 0.3535, loss_rpn_cls: 0.0511, loss_rpn_bbox: 0.1420, loss_cls0: 1.5683, acc0: 94.7308, loss_bbox0: 2.6981, loss_cls1: 1.1023, loss_bbox1: 3.8676, loss_centerness1: 7.5095, loss_cls_aux0: 0.0226, loss_bbox_aux0: 0.0231, loss_iou_aux0: 0.1204, d0.loss_cls_aux0: 0.0333, d0.loss_bbox_aux0: 0.0475, d0.loss_iou_aux0: 0.2443, d1.loss_cls_aux0: 0.0275, d1.loss_bbox_aux0: 0.0270, d1.loss_iou_aux0: 0.1404, d2.loss_cls_aux0: 0.0249, d2.loss_bbox_aux0: 0.0228, d2.loss_iou_aux0: 0.1184, d3.loss_cls_aux0: 0.0228, d3.loss_bbox_aux0: 0.0229, d3.loss_iou_aux0: 0.1189, d4.loss_cls_aux0: 0.0225, d4.loss_bbox_aux0: 0.0230, d4.loss_iou_aux0: 0.1196, loss_cls_aux1: 0.0204, loss_bbox_aux1: 0.0518, loss_iou_aux1: 0.2808, d0.loss_cls_aux1: 0.0262, d0.loss_bbox_aux1: 0.0603, d0.loss_iou_aux1: 0.3235, d1.loss_cls_aux1: 0.0232, d1.loss_bbox_aux1: 0.0523, d1.loss_iou_aux1: 0.2835, d2.loss_cls_aux1: 0.0217, d2.loss_bbox_aux1: 0.0516, d2.loss_iou_aux1: 0.2801, d3.loss_cls_aux1: 0.0203, d3.loss_bbox_aux1: 0.0517, d3.loss_iou_aux1: 0.2803, d4.loss_cls_aux1: 0.0204, d4.loss_bbox_aux1: 0.0517, d4.loss_iou_aux1: 0.2805, loss: 24.2165, grad_norm: 65.4371
2024-03-18 08:18:08,829 - mmdet - INFO - Saving checkpoint at 10 epochs
2024-03-18 08:18:30,780 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:18:36,240 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.598
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.476
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.327
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.580
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.695
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.827

2024-03-18 08:18:36,240 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.036 | Tin      | 0.622 | Thatch   | 0.536 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:18:36,298 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:18:36,298 - mmdet - INFO - Epoch(val) [10][154]	bbox_mAP: 0.3980, bbox_mAP_50: 0.5980, bbox_mAP_75: 0.4760, bbox_mAP_s: 0.3270, bbox_mAP_m: 0.3770, bbox_mAP_l: 0.5800, bbox_mAP_copypaste: 0.398 0.598 0.476 0.327 0.377 0.580
2024-03-18 08:19:20,026 - mmdet - INFO - Epoch [11][50/232]	lr: 2.000e-05, eta: 1:12:04, time: 0.874, data_time: 0.062, memory: 17650, enc_loss_cls: 0.1362, enc_loss_bbox: 0.0669, enc_loss_iou: 0.3699, loss_cls: 0.1187, loss_bbox: 0.0628, loss_iou: 0.3439, d0.loss_cls: 0.1579, d0.loss_bbox: 0.0627, d0.loss_iou: 0.3488, d1.loss_cls: 0.1320, d1.loss_bbox: 0.0623, d1.loss_iou: 0.3446, d2.loss_cls: 0.1221, d2.loss_bbox: 0.0623, d2.loss_iou: 0.3438, d3.loss_cls: 0.1188, d3.loss_bbox: 0.0626, d3.loss_iou: 0.3438, d4.loss_cls: 0.1174, d4.loss_bbox: 0.0628, d4.loss_iou: 0.3441, loss_rpn_cls: 0.0464, loss_rpn_bbox: 0.1388, loss_cls0: 1.4870, acc0: 95.0310, loss_bbox0: 2.7002, loss_cls1: 1.1005, loss_bbox1: 3.7937, loss_centerness1: 7.4929, loss_cls_aux0: 0.0274, loss_bbox_aux0: 0.0234, loss_iou_aux0: 0.1208, d0.loss_cls_aux0: 0.0354, d0.loss_bbox_aux0: 0.0465, d0.loss_iou_aux0: 0.2418, d1.loss_cls_aux0: 0.0300, d1.loss_bbox_aux0: 0.0264, d1.loss_iou_aux0: 0.1354, d2.loss_cls_aux0: 0.0274, d2.loss_bbox_aux0: 0.0232, d2.loss_iou_aux0: 0.1183, d3.loss_cls_aux0: 0.0265, d3.loss_bbox_aux0: 0.0232, d3.loss_iou_aux0: 0.1190, d4.loss_cls_aux0: 0.0269, d4.loss_bbox_aux0: 0.0233, d4.loss_iou_aux0: 0.1198, loss_cls_aux1: 0.0235, loss_bbox_aux1: 0.0493, loss_iou_aux1: 0.2711, d0.loss_cls_aux1: 0.0282, d0.loss_bbox_aux1: 0.0572, d0.loss_iou_aux1: 0.3131, d1.loss_cls_aux1: 0.0255, d1.loss_bbox_aux1: 0.0500, d1.loss_iou_aux1: 0.2742, d2.loss_cls_aux1: 0.0235, d2.loss_bbox_aux1: 0.0492, d2.loss_iou_aux1: 0.2706, d3.loss_cls_aux1: 0.0229, d3.loss_bbox_aux1: 0.0492, d3.loss_iou_aux1: 0.2707, d4.loss_cls_aux1: 0.0231, d4.loss_bbox_aux1: 0.0492, d4.loss_iou_aux1: 0.2709, loss: 23.8597, grad_norm: 67.2610
2024-03-18 08:20:00,487 - mmdet - INFO - Epoch [11][100/232]	lr: 2.000e-05, eta: 1:11:38, time: 0.809, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1323, enc_loss_bbox: 0.0714, enc_loss_iou: 0.3769, loss_cls: 0.1179, loss_bbox: 0.0652, loss_iou: 0.3489, d0.loss_cls: 0.1609, d0.loss_bbox: 0.0657, d0.loss_iou: 0.3524, d1.loss_cls: 0.1307, d1.loss_bbox: 0.0649, d1.loss_iou: 0.3486, d2.loss_cls: 0.1232, d2.loss_bbox: 0.0648, d2.loss_iou: 0.3477, d3.loss_cls: 0.1183, d3.loss_bbox: 0.0651, d3.loss_iou: 0.3483, d4.loss_cls: 0.1174, d4.loss_bbox: 0.0652, d4.loss_iou: 0.3488, loss_rpn_cls: 0.0475, loss_rpn_bbox: 0.1467, loss_cls0: 1.5651, acc0: 94.6851, loss_bbox0: 2.7838, loss_cls1: 1.0762, loss_bbox1: 3.8805, loss_centerness1: 7.5106, loss_cls_aux0: 0.0243, loss_bbox_aux0: 0.0236, loss_iou_aux0: 0.1214, d0.loss_cls_aux0: 0.0316, d0.loss_bbox_aux0: 0.0461, d0.loss_iou_aux0: 0.2377, d1.loss_cls_aux0: 0.0276, d1.loss_bbox_aux0: 0.0272, d1.loss_iou_aux0: 0.1406, d2.loss_cls_aux0: 0.0255, d2.loss_bbox_aux0: 0.0234, d2.loss_iou_aux0: 0.1194, d3.loss_cls_aux0: 0.0243, d3.loss_bbox_aux0: 0.0235, d3.loss_iou_aux0: 0.1199, d4.loss_cls_aux0: 0.0242, d4.loss_bbox_aux0: 0.0235, d4.loss_iou_aux0: 0.1205, loss_cls_aux1: 0.0221, loss_bbox_aux1: 0.0514, loss_iou_aux1: 0.2721, d0.loss_cls_aux1: 0.0247, d0.loss_bbox_aux1: 0.0587, d0.loss_iou_aux1: 0.3100, d1.loss_cls_aux1: 0.0227, d1.loss_bbox_aux1: 0.0521, d1.loss_iou_aux1: 0.2755, d2.loss_cls_aux1: 0.0222, d2.loss_bbox_aux1: 0.0513, d2.loss_iou_aux1: 0.2714, d3.loss_cls_aux1: 0.0221, d3.loss_bbox_aux1: 0.0513, d3.loss_iou_aux1: 0.2716, d4.loss_cls_aux1: 0.0219, d4.loss_bbox_aux1: 0.0514, d4.loss_iou_aux1: 0.2718, loss: 24.1539, grad_norm: 64.7072
2024-03-18 08:20:41,668 - mmdet - INFO - Epoch [11][150/232]	lr: 2.000e-05, eta: 1:11:14, time: 0.824, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1396, enc_loss_bbox: 0.0678, enc_loss_iou: 0.3710, loss_cls: 0.1213, loss_bbox: 0.0639, loss_iou: 0.3499, d0.loss_cls: 0.1611, d0.loss_bbox: 0.0645, d0.loss_iou: 0.3555, d1.loss_cls: 0.1318, d1.loss_bbox: 0.0640, d1.loss_iou: 0.3512, d2.loss_cls: 0.1232, d2.loss_bbox: 0.0638, d2.loss_iou: 0.3491, d3.loss_cls: 0.1220, d3.loss_bbox: 0.0636, d3.loss_iou: 0.3487, d4.loss_cls: 0.1207, d4.loss_bbox: 0.0638, d4.loss_iou: 0.3497, loss_rpn_cls: 0.0414, loss_rpn_bbox: 0.1390, loss_cls0: 1.5763, acc0: 94.6976, loss_bbox0: 2.7073, loss_cls1: 1.1187, loss_bbox1: 3.8087, loss_centerness1: 7.4842, loss_cls_aux0: 0.0260, loss_bbox_aux0: 0.0243, loss_iou_aux0: 0.1221, d0.loss_cls_aux0: 0.0321, d0.loss_bbox_aux0: 0.0482, d0.loss_iou_aux0: 0.2449, d1.loss_cls_aux0: 0.0269, d1.loss_bbox_aux0: 0.0282, d1.loss_iou_aux0: 0.1412, d2.loss_cls_aux0: 0.0251, d2.loss_bbox_aux0: 0.0241, d2.loss_iou_aux0: 0.1206, d3.loss_cls_aux0: 0.0253, d3.loss_bbox_aux0: 0.0242, d3.loss_iou_aux0: 0.1210, d4.loss_cls_aux0: 0.0256, d4.loss_bbox_aux0: 0.0242, d4.loss_iou_aux0: 0.1215, loss_cls_aux1: 0.0281, loss_bbox_aux1: 0.0509, loss_iou_aux1: 0.2726, d0.loss_cls_aux1: 0.0291, d0.loss_bbox_aux1: 0.0580, d0.loss_iou_aux1: 0.3145, d1.loss_cls_aux1: 0.0278, d1.loss_bbox_aux1: 0.0515, d1.loss_iou_aux1: 0.2764, d2.loss_cls_aux1: 0.0272, d2.loss_bbox_aux1: 0.0508, d2.loss_iou_aux1: 0.2722, d3.loss_cls_aux1: 0.0275, d3.loss_bbox_aux1: 0.0508, d3.loss_iou_aux1: 0.2723, d4.loss_cls_aux1: 0.0281, d4.loss_bbox_aux1: 0.0508, d4.loss_iou_aux1: 0.2725, loss: 24.0884, grad_norm: 64.3089
2024-03-18 08:21:23,050 - mmdet - INFO - Epoch [11][200/232]	lr: 2.000e-05, eta: 1:10:49, time: 0.828, data_time: 0.009, memory: 17650, enc_loss_cls: 0.1376, enc_loss_bbox: 0.0799, enc_loss_iou: 0.3904, loss_cls: 0.1217, loss_bbox: 0.0726, loss_iou: 0.3608, d0.loss_cls: 0.1598, d0.loss_bbox: 0.0734, d0.loss_iou: 0.3662, d1.loss_cls: 0.1309, d1.loss_bbox: 0.0730, d1.loss_iou: 0.3633, d2.loss_cls: 0.1268, d2.loss_bbox: 0.0723, d2.loss_iou: 0.3603, d3.loss_cls: 0.1219, d3.loss_bbox: 0.0725, d3.loss_iou: 0.3607, d4.loss_cls: 0.1214, d4.loss_bbox: 0.0726, d4.loss_iou: 0.3608, loss_rpn_cls: 0.0399, loss_rpn_bbox: 0.1316, loss_cls0: 1.6174, acc0: 94.5186, loss_bbox0: 2.8108, loss_cls1: 1.1509, loss_bbox1: 3.9748, loss_centerness1: 7.4549, loss_cls_aux0: 0.0258, loss_bbox_aux0: 0.0250, loss_iou_aux0: 0.1161, d0.loss_cls_aux0: 0.0341, d0.loss_bbox_aux0: 0.0524, d0.loss_iou_aux0: 0.2476, d1.loss_cls_aux0: 0.0282, d1.loss_bbox_aux0: 0.0292, d1.loss_iou_aux0: 0.1344, d2.loss_cls_aux0: 0.0263, d2.loss_bbox_aux0: 0.0248, d2.loss_iou_aux0: 0.1144, d3.loss_cls_aux0: 0.0247, d3.loss_bbox_aux0: 0.0248, d3.loss_iou_aux0: 0.1148, d4.loss_cls_aux0: 0.0251, d4.loss_bbox_aux0: 0.0249, d4.loss_iou_aux0: 0.1154, loss_cls_aux1: 0.0210, loss_bbox_aux1: 0.0549, loss_iou_aux1: 0.2752, d0.loss_cls_aux1: 0.0243, d0.loss_bbox_aux1: 0.0636, d0.loss_iou_aux1: 0.3167, d1.loss_cls_aux1: 0.0225, d1.loss_bbox_aux1: 0.0560, d1.loss_iou_aux1: 0.2798, d2.loss_cls_aux1: 0.0209, d2.loss_bbox_aux1: 0.0549, d2.loss_iou_aux1: 0.2752, d3.loss_cls_aux1: 0.0205, d3.loss_bbox_aux1: 0.0549, d3.loss_iou_aux1: 0.2752, d4.loss_cls_aux1: 0.0208, d4.loss_bbox_aux1: 0.0549, d4.loss_iou_aux1: 0.2752, loss: 24.5339, grad_norm: 69.1725
2024-03-18 08:21:50,115 - mmdet - INFO - Saving checkpoint at 11 epochs
2024-03-18 08:22:12,178 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:22:17,862 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.643
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.509
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.355
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.406
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.750
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.635
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.788

2024-03-18 08:22:17,862 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.115 | Tin      | 0.624 | Thatch   | 0.539 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:22:18,234 - mmdet - INFO - The previous best checkpoint /mnt/md0/arm_unicef/MMDET/Co-DETR/work_dirs/exp_002/best_bbox_mAP_epoch_9.pth was removed
2024-03-18 08:22:21,589 - mmdet - INFO - Now best checkpoint is saved as best_bbox_mAP_epoch_11.pth.
2024-03-18 08:22:21,590 - mmdet - INFO - Best bbox_mAP is 0.4260 at 11 epoch.
2024-03-18 08:22:21,590 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:22:21,590 - mmdet - INFO - Epoch(val) [11][154]	bbox_mAP: 0.4260, bbox_mAP_50: 0.6430, bbox_mAP_75: 0.5090, bbox_mAP_s: 0.3550, bbox_mAP_m: 0.4060, bbox_mAP_l: 0.7500, bbox_mAP_copypaste: 0.426 0.643 0.509 0.355 0.406 0.750
2024-03-18 08:23:05,272 - mmdet - INFO - Epoch [12][50/232]	lr: 2.000e-05, eta: 1:09:14, time: 0.873, data_time: 0.061, memory: 17650, enc_loss_cls: 0.1510, enc_loss_bbox: 0.0721, enc_loss_iou: 0.3824, loss_cls: 0.1283, loss_bbox: 0.0666, loss_iou: 0.3550, d0.loss_cls: 0.1711, d0.loss_bbox: 0.0675, d0.loss_iou: 0.3608, d1.loss_cls: 0.1445, d1.loss_bbox: 0.0667, d1.loss_iou: 0.3556, d2.loss_cls: 0.1356, d2.loss_bbox: 0.0665, d2.loss_iou: 0.3542, d3.loss_cls: 0.1292, d3.loss_bbox: 0.0666, d3.loss_iou: 0.3545, d4.loss_cls: 0.1270, d4.loss_bbox: 0.0666, d4.loss_iou: 0.3549, loss_rpn_cls: 0.0420, loss_rpn_bbox: 0.1453, loss_cls0: 1.6813, acc0: 94.2279, loss_bbox0: 2.8504, loss_cls1: 1.1623, loss_bbox1: 3.9269, loss_centerness1: 7.5181, loss_cls_aux0: 0.0227, loss_bbox_aux0: 0.0256, loss_iou_aux0: 0.1256, d0.loss_cls_aux0: 0.0311, d0.loss_bbox_aux0: 0.0511, d0.loss_iou_aux0: 0.2524, d1.loss_cls_aux0: 0.0260, d1.loss_bbox_aux0: 0.0292, d1.loss_iou_aux0: 0.1445, d2.loss_cls_aux0: 0.0245, d2.loss_bbox_aux0: 0.0254, d2.loss_iou_aux0: 0.1240, d3.loss_cls_aux0: 0.0232, d3.loss_bbox_aux0: 0.0255, d3.loss_iou_aux0: 0.1245, d4.loss_cls_aux0: 0.0230, d4.loss_bbox_aux0: 0.0255, d4.loss_iou_aux0: 0.1250, loss_cls_aux1: 0.0213, loss_bbox_aux1: 0.0516, loss_iou_aux1: 0.2743, d0.loss_cls_aux1: 0.0254, d0.loss_bbox_aux1: 0.0609, d0.loss_iou_aux1: 0.3211, d1.loss_cls_aux1: 0.0230, d1.loss_bbox_aux1: 0.0527, d1.loss_iou_aux1: 0.2800, d2.loss_cls_aux1: 0.0216, d2.loss_bbox_aux1: 0.0515, d2.loss_iou_aux1: 0.2740, d3.loss_cls_aux1: 0.0214, d3.loss_bbox_aux1: 0.0515, d3.loss_iou_aux1: 0.2741, d4.loss_cls_aux1: 0.0216, d4.loss_bbox_aux1: 0.0515, d4.loss_iou_aux1: 0.2742, loss: 24.6837, grad_norm: 78.0723
2024-03-18 08:23:45,789 - mmdet - INFO - Epoch [12][100/232]	lr: 2.000e-05, eta: 1:08:47, time: 0.810, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1364, enc_loss_bbox: 0.0683, enc_loss_iou: 0.3646, loss_cls: 0.1163, loss_bbox: 0.0641, loss_iou: 0.3421, d0.loss_cls: 0.1707, d0.loss_bbox: 0.0639, d0.loss_iou: 0.3431, d1.loss_cls: 0.1377, d1.loss_bbox: 0.0633, d1.loss_iou: 0.3412, d2.loss_cls: 0.1225, d2.loss_bbox: 0.0634, d2.loss_iou: 0.3409, d3.loss_cls: 0.1177, d3.loss_bbox: 0.0634, d3.loss_iou: 0.3411, d4.loss_cls: 0.1170, d4.loss_bbox: 0.0634, d4.loss_iou: 0.3414, loss_rpn_cls: 0.0305, loss_rpn_bbox: 0.1178, loss_cls0: 1.4896, acc0: 94.9863, loss_bbox0: 2.5837, loss_cls1: 1.0904, loss_bbox1: 3.7683, loss_centerness1: 7.4643, loss_cls_aux0: 0.0321, loss_bbox_aux0: 0.0217, loss_iou_aux0: 0.1054, d0.loss_cls_aux0: 0.0398, d0.loss_bbox_aux0: 0.0454, d0.loss_iou_aux0: 0.2309, d1.loss_cls_aux0: 0.0355, d1.loss_bbox_aux0: 0.0254, d1.loss_iou_aux0: 0.1242, d2.loss_cls_aux0: 0.0321, d2.loss_bbox_aux0: 0.0215, d2.loss_iou_aux0: 0.1038, d3.loss_cls_aux0: 0.0312, d3.loss_bbox_aux0: 0.0216, d3.loss_iou_aux0: 0.1042, d4.loss_cls_aux0: 0.0311, d4.loss_bbox_aux0: 0.0216, d4.loss_iou_aux0: 0.1047, loss_cls_aux1: 0.0278, loss_bbox_aux1: 0.0506, loss_iou_aux1: 0.2700, d0.loss_cls_aux1: 0.0322, d0.loss_bbox_aux1: 0.0587, d0.loss_iou_aux1: 0.3119, d1.loss_cls_aux1: 0.0305, d1.loss_bbox_aux1: 0.0514, d1.loss_iou_aux1: 0.2736, d2.loss_cls_aux1: 0.0288, d2.loss_bbox_aux1: 0.0505, d2.loss_iou_aux1: 0.2696, d3.loss_cls_aux1: 0.0271, d3.loss_bbox_aux1: 0.0505, d3.loss_iou_aux1: 0.2697, d4.loss_cls_aux1: 0.0271, d4.loss_bbox_aux1: 0.0505, d4.loss_iou_aux1: 0.2698, loss: 23.6094, grad_norm: 72.6597
2024-03-18 08:24:26,780 - mmdet - INFO - Epoch [12][150/232]	lr: 2.000e-05, eta: 1:08:21, time: 0.820, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1493, enc_loss_bbox: 0.0712, enc_loss_iou: 0.3801, loss_cls: 0.1179, loss_bbox: 0.0668, loss_iou: 0.3565, d0.loss_cls: 0.1529, d0.loss_bbox: 0.0679, d0.loss_iou: 0.3619, d1.loss_cls: 0.1281, d1.loss_bbox: 0.0672, d1.loss_iou: 0.3573, d2.loss_cls: 0.1192, d2.loss_bbox: 0.0667, d2.loss_iou: 0.3560, d3.loss_cls: 0.1162, d3.loss_bbox: 0.0667, d3.loss_iou: 0.3561, d4.loss_cls: 0.1182, d4.loss_bbox: 0.0663, d4.loss_iou: 0.3562, loss_rpn_cls: 0.0396, loss_rpn_bbox: 0.1247, loss_cls0: 1.5308, acc0: 94.7928, loss_bbox0: 2.7602, loss_cls1: 1.0602, loss_bbox1: 3.7863, loss_centerness1: 7.4765, loss_cls_aux0: 0.0196, loss_bbox_aux0: 0.0215, loss_iou_aux0: 0.1051, d0.loss_cls_aux0: 0.0278, d0.loss_bbox_aux0: 0.0464, d0.loss_iou_aux0: 0.2379, d1.loss_cls_aux0: 0.0215, d1.loss_bbox_aux0: 0.0250, d1.loss_iou_aux0: 0.1246, d2.loss_cls_aux0: 0.0201, d2.loss_bbox_aux0: 0.0213, d2.loss_iou_aux0: 0.1040, d3.loss_cls_aux0: 0.0194, d3.loss_bbox_aux0: 0.0213, d3.loss_iou_aux0: 0.1043, d4.loss_cls_aux0: 0.0195, d4.loss_bbox_aux0: 0.0214, d4.loss_iou_aux0: 0.1047, loss_cls_aux1: 0.0128, loss_bbox_aux1: 0.0514, loss_iou_aux1: 0.2716, d0.loss_cls_aux1: 0.0157, d0.loss_bbox_aux1: 0.0590, d0.loss_iou_aux1: 0.3097, d1.loss_cls_aux1: 0.0144, d1.loss_bbox_aux1: 0.0524, d1.loss_iou_aux1: 0.2766, d2.loss_cls_aux1: 0.0139, d2.loss_bbox_aux1: 0.0514, d2.loss_iou_aux1: 0.2714, d3.loss_cls_aux1: 0.0130, d3.loss_bbox_aux1: 0.0514, d3.loss_iou_aux1: 0.2714, d4.loss_cls_aux1: 0.0128, d4.loss_bbox_aux1: 0.0514, d4.loss_iou_aux1: 0.2715, loss: 23.8144, grad_norm: 68.9056
2024-03-18 08:25:08,192 - mmdet - INFO - Epoch [12][200/232]	lr: 2.000e-05, eta: 1:07:55, time: 0.828, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1437, enc_loss_bbox: 0.0729, enc_loss_iou: 0.3810, loss_cls: 0.1255, loss_bbox: 0.0663, loss_iou: 0.3530, d0.loss_cls: 0.1626, d0.loss_bbox: 0.0672, d0.loss_iou: 0.3580, d1.loss_cls: 0.1326, d1.loss_bbox: 0.0666, d1.loss_iou: 0.3546, d2.loss_cls: 0.1255, d2.loss_bbox: 0.0665, d2.loss_iou: 0.3536, d3.loss_cls: 0.1252, d3.loss_bbox: 0.0661, d3.loss_iou: 0.3524, d4.loss_cls: 0.1242, d4.loss_bbox: 0.0662, d4.loss_iou: 0.3528, loss_rpn_cls: 0.0445, loss_rpn_bbox: 0.1460, loss_cls0: 1.5487, acc0: 94.7365, loss_bbox0: 2.6993, loss_cls1: 1.1140, loss_bbox1: 3.9176, loss_centerness1: 7.4837, loss_cls_aux0: 0.0214, loss_bbox_aux0: 0.0255, loss_iou_aux0: 0.1265, d0.loss_cls_aux0: 0.0295, d0.loss_bbox_aux0: 0.0506, d0.loss_iou_aux0: 0.2495, d1.loss_cls_aux0: 0.0244, d1.loss_bbox_aux0: 0.0308, d1.loss_iou_aux0: 0.1525, d2.loss_cls_aux0: 0.0223, d2.loss_bbox_aux0: 0.0254, d2.loss_iou_aux0: 0.1256, d3.loss_cls_aux0: 0.0211, d3.loss_bbox_aux0: 0.0255, d3.loss_iou_aux0: 0.1259, d4.loss_cls_aux0: 0.0211, d4.loss_bbox_aux0: 0.0255, d4.loss_iou_aux0: 0.1261, loss_cls_aux1: 0.0215, loss_bbox_aux1: 0.0531, loss_iou_aux1: 0.2832, d0.loss_cls_aux1: 0.0266, d0.loss_bbox_aux1: 0.0622, d0.loss_iou_aux1: 0.3271, d1.loss_cls_aux1: 0.0247, d1.loss_bbox_aux1: 0.0536, d1.loss_iou_aux1: 0.2862, d2.loss_cls_aux1: 0.0234, d2.loss_bbox_aux1: 0.0530, d2.loss_iou_aux1: 0.2830, d3.loss_cls_aux1: 0.0214, d3.loss_bbox_aux1: 0.0530, d3.loss_iou_aux1: 0.2831, d4.loss_cls_aux1: 0.0212, d4.loss_bbox_aux1: 0.0530, d4.loss_iou_aux1: 0.2831, loss: 24.3122, grad_norm: 71.9732
2024-03-18 08:25:35,075 - mmdet - INFO - Saving checkpoint at 12 epochs
2024-03-18 08:25:57,302 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:26:03,274 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.611
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.488
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.311
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.789
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.718
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.718
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.718
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.721
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.824

2024-03-18 08:26:03,275 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.073 | Tin      | 0.632 | Thatch   | 0.523 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:26:03,340 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:26:03,340 - mmdet - INFO - Epoch(val) [12][154]	bbox_mAP: 0.4090, bbox_mAP_50: 0.6110, bbox_mAP_75: 0.4880, bbox_mAP_s: 0.3110, bbox_mAP_m: 0.3940, bbox_mAP_l: 0.7890, bbox_mAP_copypaste: 0.409 0.611 0.488 0.311 0.394 0.789
2024-03-18 08:26:47,014 - mmdet - INFO - Epoch [13][50/232]	lr: 2.000e-05, eta: 1:06:24, time: 0.873, data_time: 0.062, memory: 17650, enc_loss_cls: 0.1288, enc_loss_bbox: 0.0678, enc_loss_iou: 0.3687, loss_cls: 0.1092, loss_bbox: 0.0630, loss_iou: 0.3438, d0.loss_cls: 0.1441, d0.loss_bbox: 0.0636, d0.loss_iou: 0.3470, d1.loss_cls: 0.1182, d1.loss_bbox: 0.0631, d1.loss_iou: 0.3445, d2.loss_cls: 0.1105, d2.loss_bbox: 0.0628, d2.loss_iou: 0.3432, d3.loss_cls: 0.1086, d3.loss_bbox: 0.0629, d3.loss_iou: 0.3435, d4.loss_cls: 0.1084, d4.loss_bbox: 0.0630, d4.loss_iou: 0.3437, loss_rpn_cls: 0.0364, loss_rpn_bbox: 0.1406, loss_cls0: 1.5762, acc0: 94.6990, loss_bbox0: 2.7780, loss_cls1: 1.0391, loss_bbox1: 3.7857, loss_centerness1: 7.4899, loss_cls_aux0: 0.0306, loss_bbox_aux0: 0.0240, loss_iou_aux0: 0.1232, d0.loss_cls_aux0: 0.0345, d0.loss_bbox_aux0: 0.0474, d0.loss_iou_aux0: 0.2443, d1.loss_cls_aux0: 0.0309, d1.loss_bbox_aux0: 0.0283, d1.loss_iou_aux0: 0.1452, d2.loss_cls_aux0: 0.0293, d2.loss_bbox_aux0: 0.0238, d2.loss_iou_aux0: 0.1217, d3.loss_cls_aux0: 0.0305, d3.loss_bbox_aux0: 0.0239, d3.loss_iou_aux0: 0.1221, d4.loss_cls_aux0: 0.0309, d4.loss_bbox_aux0: 0.0239, d4.loss_iou_aux0: 0.1226, loss_cls_aux1: 0.0238, loss_bbox_aux1: 0.0522, loss_iou_aux1: 0.2793, d0.loss_cls_aux1: 0.0250, d0.loss_bbox_aux1: 0.0586, d0.loss_iou_aux1: 0.3139, d1.loss_cls_aux1: 0.0233, d1.loss_bbox_aux1: 0.0528, d1.loss_iou_aux1: 0.2830, d2.loss_cls_aux1: 0.0229, d2.loss_bbox_aux1: 0.0521, d2.loss_iou_aux1: 0.2789, d3.loss_cls_aux1: 0.0234, d3.loss_bbox_aux1: 0.0522, d3.loss_iou_aux1: 0.2790, d4.loss_cls_aux1: 0.0239, d4.loss_bbox_aux1: 0.0522, d4.loss_iou_aux1: 0.2792, loss: 23.9672, grad_norm: 65.8158
2024-03-18 08:27:27,736 - mmdet - INFO - Epoch [13][100/232]	lr: 2.000e-05, eta: 1:05:57, time: 0.814, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1355, enc_loss_bbox: 0.0716, enc_loss_iou: 0.3700, loss_cls: 0.1166, loss_bbox: 0.0654, loss_iou: 0.3395, d0.loss_cls: 0.1508, d0.loss_bbox: 0.0661, d0.loss_iou: 0.3447, d1.loss_cls: 0.1243, d1.loss_bbox: 0.0655, d1.loss_iou: 0.3408, d2.loss_cls: 0.1180, d2.loss_bbox: 0.0655, d2.loss_iou: 0.3396, d3.loss_cls: 0.1170, d3.loss_bbox: 0.0653, d3.loss_iou: 0.3393, d4.loss_cls: 0.1163, d4.loss_bbox: 0.0654, d4.loss_iou: 0.3395, loss_rpn_cls: 0.0455, loss_rpn_bbox: 0.1370, loss_cls0: 1.5016, acc0: 94.8156, loss_bbox0: 2.7253, loss_cls1: 1.1297, loss_bbox1: 3.7844, loss_centerness1: 7.4852, loss_cls_aux0: 0.0198, loss_bbox_aux0: 0.0240, loss_iou_aux0: 0.1164, d0.loss_cls_aux0: 0.0265, d0.loss_bbox_aux0: 0.0490, d0.loss_iou_aux0: 0.2395, d1.loss_cls_aux0: 0.0220, d1.loss_bbox_aux0: 0.0280, d1.loss_iou_aux0: 0.1354, d2.loss_cls_aux0: 0.0196, d2.loss_bbox_aux0: 0.0238, d2.loss_iou_aux0: 0.1151, d3.loss_cls_aux0: 0.0188, d3.loss_bbox_aux0: 0.0239, d3.loss_iou_aux0: 0.1154, d4.loss_cls_aux0: 0.0195, d4.loss_bbox_aux0: 0.0239, d4.loss_iou_aux0: 0.1159, loss_cls_aux1: 0.0195, loss_bbox_aux1: 0.0519, loss_iou_aux1: 0.2692, d0.loss_cls_aux1: 0.0226, d0.loss_bbox_aux1: 0.0588, d0.loss_iou_aux1: 0.3040, d1.loss_cls_aux1: 0.0210, d1.loss_bbox_aux1: 0.0525, d1.loss_iou_aux1: 0.2722, d2.loss_cls_aux1: 0.0195, d2.loss_bbox_aux1: 0.0518, d2.loss_iou_aux1: 0.2688, d3.loss_cls_aux1: 0.0188, d3.loss_bbox_aux1: 0.0518, d3.loss_iou_aux1: 0.2689, d4.loss_cls_aux1: 0.0193, d4.loss_bbox_aux1: 0.0518, d4.loss_iou_aux1: 0.2690, loss: 23.7930, grad_norm: 65.8345
2024-03-18 08:28:08,844 - mmdet - INFO - Epoch [13][150/232]	lr: 2.000e-05, eta: 1:05:30, time: 0.822, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1374, enc_loss_bbox: 0.0709, enc_loss_iou: 0.3776, loss_cls: 0.1225, loss_bbox: 0.0680, loss_iou: 0.3593, d0.loss_cls: 0.1528, d0.loss_bbox: 0.0679, d0.loss_iou: 0.3614, d1.loss_cls: 0.1289, d1.loss_bbox: 0.0677, d1.loss_iou: 0.3583, d2.loss_cls: 0.1245, d2.loss_bbox: 0.0678, d2.loss_iou: 0.3582, d3.loss_cls: 0.1210, d3.loss_bbox: 0.0680, d3.loss_iou: 0.3593, d4.loss_cls: 0.1215, d4.loss_bbox: 0.0680, d4.loss_iou: 0.3594, loss_rpn_cls: 0.0421, loss_rpn_bbox: 0.1387, loss_cls0: 1.5816, acc0: 94.6853, loss_bbox0: 2.6069, loss_cls1: 1.0768, loss_bbox1: 3.8966, loss_centerness1: 7.4872, loss_cls_aux0: 0.0265, loss_bbox_aux0: 0.0233, loss_iou_aux0: 0.1142, d0.loss_cls_aux0: 0.0328, d0.loss_bbox_aux0: 0.0475, d0.loss_iou_aux0: 0.2397, d1.loss_cls_aux0: 0.0296, d1.loss_bbox_aux0: 0.0274, d1.loss_iou_aux0: 0.1352, d2.loss_cls_aux0: 0.0269, d2.loss_bbox_aux0: 0.0232, d2.loss_iou_aux0: 0.1131, d3.loss_cls_aux0: 0.0259, d3.loss_bbox_aux0: 0.0232, d3.loss_iou_aux0: 0.1134, d4.loss_cls_aux0: 0.0259, d4.loss_bbox_aux0: 0.0232, d4.loss_iou_aux0: 0.1137, loss_cls_aux1: 0.0225, loss_bbox_aux1: 0.0516, loss_iou_aux1: 0.2745, d0.loss_cls_aux1: 0.0248, d0.loss_bbox_aux1: 0.0593, d0.loss_iou_aux1: 0.3156, d1.loss_cls_aux1: 0.0234, d1.loss_bbox_aux1: 0.0529, d1.loss_iou_aux1: 0.2803, d2.loss_cls_aux1: 0.0215, d2.loss_bbox_aux1: 0.0516, d2.loss_iou_aux1: 0.2742, d3.loss_cls_aux1: 0.0220, d3.loss_bbox_aux1: 0.0516, d3.loss_iou_aux1: 0.2743, d4.loss_cls_aux1: 0.0222, d4.loss_bbox_aux1: 0.0516, d4.loss_iou_aux1: 0.2744, loss: 24.0631, grad_norm: 65.2484
2024-03-18 08:28:50,542 - mmdet - INFO - Epoch [13][200/232]	lr: 2.000e-05, eta: 1:05:03, time: 0.834, data_time: 0.007, memory: 17650, enc_loss_cls: 0.1340, enc_loss_bbox: 0.0741, enc_loss_iou: 0.3838, loss_cls: 0.1104, loss_bbox: 0.0660, loss_iou: 0.3472, d0.loss_cls: 0.1441, d0.loss_bbox: 0.0669, d0.loss_iou: 0.3527, d1.loss_cls: 0.1194, d1.loss_bbox: 0.0659, d1.loss_iou: 0.3477, d2.loss_cls: 0.1124, d2.loss_bbox: 0.0659, d2.loss_iou: 0.3467, d3.loss_cls: 0.1107, d3.loss_bbox: 0.0658, d3.loss_iou: 0.3464, d4.loss_cls: 0.1104, d4.loss_bbox: 0.0658, d4.loss_iou: 0.3467, loss_rpn_cls: 0.0421, loss_rpn_bbox: 0.1412, loss_cls0: 1.5279, acc0: 94.8510, loss_bbox0: 2.6301, loss_cls1: 1.0670, loss_bbox1: 3.8210, loss_centerness1: 7.4996, loss_cls_aux0: 0.0251, loss_bbox_aux0: 0.0249, loss_iou_aux0: 0.1204, d0.loss_cls_aux0: 0.0323, d0.loss_bbox_aux0: 0.0500, d0.loss_iou_aux0: 0.2460, d1.loss_cls_aux0: 0.0272, d1.loss_bbox_aux0: 0.0294, d1.loss_iou_aux0: 0.1424, d2.loss_cls_aux0: 0.0253, d2.loss_bbox_aux0: 0.0248, d2.loss_iou_aux0: 0.1195, d3.loss_cls_aux0: 0.0246, d3.loss_bbox_aux0: 0.0248, d3.loss_iou_aux0: 0.1197, d4.loss_cls_aux0: 0.0248, d4.loss_bbox_aux0: 0.0248, d4.loss_iou_aux0: 0.1200, loss_cls_aux1: 0.0229, loss_bbox_aux1: 0.0516, loss_iou_aux1: 0.2697, d0.loss_cls_aux1: 0.0262, d0.loss_bbox_aux1: 0.0635, d0.loss_iou_aux1: 0.3287, d1.loss_cls_aux1: 0.0234, d1.loss_bbox_aux1: 0.0533, d1.loss_iou_aux1: 0.2772, d2.loss_cls_aux1: 0.0226, d2.loss_bbox_aux1: 0.0515, d2.loss_iou_aux1: 0.2693, d3.loss_cls_aux1: 0.0220, d3.loss_bbox_aux1: 0.0515, d3.loss_iou_aux1: 0.2694, d4.loss_cls_aux1: 0.0226, d4.loss_bbox_aux1: 0.0516, d4.loss_iou_aux1: 0.2695, loss: 23.8646, grad_norm: 65.3115
2024-03-18 08:29:17,234 - mmdet - INFO - Saving checkpoint at 13 epochs
2024-03-18 08:29:39,232 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:29:45,113 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.409
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.608
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.480
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.313
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.793
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.686
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.594
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.827

2024-03-18 08:29:45,113 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.050 | Tin      | 0.629 | Thatch   | 0.547 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:29:45,163 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:29:45,164 - mmdet - INFO - Epoch(val) [13][154]	bbox_mAP: 0.4090, bbox_mAP_50: 0.6080, bbox_mAP_75: 0.4800, bbox_mAP_s: 0.3130, bbox_mAP_m: 0.3940, bbox_mAP_l: 0.7930, bbox_mAP_copypaste: 0.409 0.608 0.480 0.313 0.394 0.793
2024-03-18 08:30:29,033 - mmdet - INFO - Epoch [14][50/232]	lr: 2.000e-05, eta: 1:03:36, time: 0.877, data_time: 0.061, memory: 17650, enc_loss_cls: 0.1311, enc_loss_bbox: 0.0679, enc_loss_iou: 0.3704, loss_cls: 0.1086, loss_bbox: 0.0627, loss_iou: 0.3447, d0.loss_cls: 0.1438, d0.loss_bbox: 0.0639, d0.loss_iou: 0.3505, d1.loss_cls: 0.1172, d1.loss_bbox: 0.0633, d1.loss_iou: 0.3469, d2.loss_cls: 0.1104, d2.loss_bbox: 0.0630, d2.loss_iou: 0.3452, d3.loss_cls: 0.1089, d3.loss_bbox: 0.0630, d3.loss_iou: 0.3442, d4.loss_cls: 0.1087, d4.loss_bbox: 0.0627, d4.loss_iou: 0.3445, loss_rpn_cls: 0.0312, loss_rpn_bbox: 0.1365, loss_cls0: 1.4879, acc0: 94.9190, loss_bbox0: 2.6619, loss_cls1: 0.9930, loss_bbox1: 3.6984, loss_centerness1: 7.4878, loss_cls_aux0: 0.0208, loss_bbox_aux0: 0.0211, loss_iou_aux0: 0.1079, d0.loss_cls_aux0: 0.0266, d0.loss_bbox_aux0: 0.0453, d0.loss_iou_aux0: 0.2322, d1.loss_cls_aux0: 0.0219, d1.loss_bbox_aux0: 0.0247, d1.loss_iou_aux0: 0.1259, d2.loss_cls_aux0: 0.0205, d2.loss_bbox_aux0: 0.0210, d2.loss_iou_aux0: 0.1064, d3.loss_cls_aux0: 0.0203, d3.loss_bbox_aux0: 0.0210, d3.loss_iou_aux0: 0.1069, d4.loss_cls_aux0: 0.0207, d4.loss_bbox_aux0: 0.0211, d4.loss_iou_aux0: 0.1073, loss_cls_aux1: 0.0174, loss_bbox_aux1: 0.0509, loss_iou_aux1: 0.2718, d0.loss_cls_aux1: 0.0184, d0.loss_bbox_aux1: 0.0581, d0.loss_iou_aux1: 0.3102, d1.loss_cls_aux1: 0.0175, d1.loss_bbox_aux1: 0.0518, d1.loss_iou_aux1: 0.2759, d2.loss_cls_aux1: 0.0171, d2.loss_bbox_aux1: 0.0509, d2.loss_iou_aux1: 0.2714, d3.loss_cls_aux1: 0.0169, d3.loss_bbox_aux1: 0.0509, d3.loss_iou_aux1: 0.2715, d4.loss_cls_aux1: 0.0173, d4.loss_bbox_aux1: 0.0509, d4.loss_iou_aux1: 0.2716, loss: 23.3803, grad_norm: 72.8982
2024-03-18 08:31:10,613 - mmdet - INFO - Epoch [14][100/232]	lr: 2.000e-05, eta: 1:03:09, time: 0.832, data_time: 0.013, memory: 17650, enc_loss_cls: 0.1294, enc_loss_bbox: 0.0678, enc_loss_iou: 0.3602, loss_cls: 0.1046, loss_bbox: 0.0631, loss_iou: 0.3363, d0.loss_cls: 0.1466, d0.loss_bbox: 0.0641, d0.loss_iou: 0.3424, d1.loss_cls: 0.1143, d1.loss_bbox: 0.0631, d1.loss_iou: 0.3367, d2.loss_cls: 0.1072, d2.loss_bbox: 0.0630, d2.loss_iou: 0.3355, d3.loss_cls: 0.1050, d3.loss_bbox: 0.0631, d3.loss_iou: 0.3357, d4.loss_cls: 0.1039, d4.loss_bbox: 0.0630, d4.loss_iou: 0.3361, loss_rpn_cls: 0.0372, loss_rpn_bbox: 0.1443, loss_cls0: 1.5639, acc0: 94.7115, loss_bbox0: 2.6832, loss_cls1: 1.0227, loss_bbox1: 3.7140, loss_centerness1: 7.4857, loss_cls_aux0: 0.0214, loss_bbox_aux0: 0.0250, loss_iou_aux0: 0.1226, d0.loss_cls_aux0: 0.0278, d0.loss_bbox_aux0: 0.0484, d0.loss_iou_aux0: 0.2397, d1.loss_cls_aux0: 0.0230, d1.loss_bbox_aux0: 0.0284, d1.loss_iou_aux0: 0.1389, d2.loss_cls_aux0: 0.0214, d2.loss_bbox_aux0: 0.0248, d2.loss_iou_aux0: 0.1211, d3.loss_cls_aux0: 0.0211, d3.loss_bbox_aux0: 0.0249, d3.loss_iou_aux0: 0.1215, d4.loss_cls_aux0: 0.0210, d4.loss_bbox_aux0: 0.0249, d4.loss_iou_aux0: 0.1220, loss_cls_aux1: 0.0180, loss_bbox_aux1: 0.0512, loss_iou_aux1: 0.2697, d0.loss_cls_aux1: 0.0203, d0.loss_bbox_aux1: 0.0598, d0.loss_iou_aux1: 0.3134, d1.loss_cls_aux1: 0.0190, d1.loss_bbox_aux1: 0.0521, d1.loss_iou_aux1: 0.2744, d2.loss_cls_aux1: 0.0185, d2.loss_bbox_aux1: 0.0511, d2.loss_iou_aux1: 0.2693, d3.loss_cls_aux1: 0.0180, d3.loss_bbox_aux1: 0.0512, d3.loss_iou_aux1: 0.2694, d4.loss_cls_aux1: 0.0178, d4.loss_bbox_aux1: 0.0512, d4.loss_iou_aux1: 0.2695, loss: 23.5643, grad_norm: 67.5784
2024-03-18 08:31:52,342 - mmdet - INFO - Epoch [14][150/232]	lr: 2.000e-05, eta: 1:02:42, time: 0.835, data_time: 0.012, memory: 17650, enc_loss_cls: 0.1235, enc_loss_bbox: 0.0758, enc_loss_iou: 0.3893, loss_cls: 0.0996, loss_bbox: 0.0693, loss_iou: 0.3606, d0.loss_cls: 0.1331, d0.loss_bbox: 0.0711, d0.loss_iou: 0.3679, d1.loss_cls: 0.1080, d1.loss_bbox: 0.0695, d1.loss_iou: 0.3617, d2.loss_cls: 0.1027, d2.loss_bbox: 0.0692, d2.loss_iou: 0.3598, d3.loss_cls: 0.1015, d3.loss_bbox: 0.0693, d3.loss_iou: 0.3600, d4.loss_cls: 0.1005, d4.loss_bbox: 0.0693, d4.loss_iou: 0.3606, loss_rpn_cls: 0.0422, loss_rpn_bbox: 0.1441, loss_cls0: 1.5144, acc0: 94.7931, loss_bbox0: 2.7072, loss_cls1: 1.0790, loss_bbox1: 4.0078, loss_centerness1: 7.5116, loss_cls_aux0: 0.0138, loss_bbox_aux0: 0.0249, loss_iou_aux0: 0.1193, d0.loss_cls_aux0: 0.0206, d0.loss_bbox_aux0: 0.0490, d0.loss_iou_aux0: 0.2438, d1.loss_cls_aux0: 0.0161, d1.loss_bbox_aux0: 0.0287, d1.loss_iou_aux0: 0.1373, d2.loss_cls_aux0: 0.0143, d2.loss_bbox_aux0: 0.0247, d2.loss_iou_aux0: 0.1178, d3.loss_cls_aux0: 0.0141, d3.loss_bbox_aux0: 0.0247, d3.loss_iou_aux0: 0.1182, d4.loss_cls_aux0: 0.0139, d4.loss_bbox_aux0: 0.0248, d4.loss_iou_aux0: 0.1187, loss_cls_aux1: 0.0138, loss_bbox_aux1: 0.0523, loss_iou_aux1: 0.2768, d0.loss_cls_aux1: 0.0175, d0.loss_bbox_aux1: 0.0618, d0.loss_iou_aux1: 0.3226, d1.loss_cls_aux1: 0.0152, d1.loss_bbox_aux1: 0.0531, d1.loss_iou_aux1: 0.2812, d2.loss_cls_aux1: 0.0136, d2.loss_bbox_aux1: 0.0522, d2.loss_iou_aux1: 0.2765, d3.loss_cls_aux1: 0.0138, d3.loss_bbox_aux1: 0.0523, d3.loss_iou_aux1: 0.2766, d4.loss_cls_aux1: 0.0138, d4.loss_bbox_aux1: 0.0523, d4.loss_iou_aux1: 0.2767, loss: 24.0753, grad_norm: 62.9035
2024-03-18 08:32:34,180 - mmdet - INFO - Epoch [14][200/232]	lr: 2.000e-05, eta: 1:02:15, time: 0.837, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1264, enc_loss_bbox: 0.0718, enc_loss_iou: 0.3719, loss_cls: 0.1104, loss_bbox: 0.0674, loss_iou: 0.3507, d0.loss_cls: 0.1441, d0.loss_bbox: 0.0670, d0.loss_iou: 0.3519, d1.loss_cls: 0.1182, d1.loss_bbox: 0.0671, d1.loss_iou: 0.3503, d2.loss_cls: 0.1134, d2.loss_bbox: 0.0673, d2.loss_iou: 0.3504, d3.loss_cls: 0.1112, d3.loss_bbox: 0.0673, d3.loss_iou: 0.3503, d4.loss_cls: 0.1104, d4.loss_bbox: 0.0674, d4.loss_iou: 0.3504, loss_rpn_cls: 0.0443, loss_rpn_bbox: 0.1349, loss_cls0: 1.5482, acc0: 94.8092, loss_bbox0: 2.7069, loss_cls1: 1.0756, loss_bbox1: 3.8860, loss_centerness1: 7.5004, loss_cls_aux0: 0.0218, loss_bbox_aux0: 0.0238, loss_iou_aux0: 0.1155, d0.loss_cls_aux0: 0.0305, d0.loss_bbox_aux0: 0.0493, d0.loss_iou_aux0: 0.2400, d1.loss_cls_aux0: 0.0254, d1.loss_bbox_aux0: 0.0280, d1.loss_iou_aux0: 0.1366, d2.loss_cls_aux0: 0.0221, d2.loss_bbox_aux0: 0.0235, d2.loss_iou_aux0: 0.1138, d3.loss_cls_aux0: 0.0212, d3.loss_bbox_aux0: 0.0236, d3.loss_iou_aux0: 0.1143, d4.loss_cls_aux0: 0.0213, d4.loss_bbox_aux0: 0.0237, d4.loss_iou_aux0: 0.1148, loss_cls_aux1: 0.0235, loss_bbox_aux1: 0.0523, loss_iou_aux1: 0.2735, d0.loss_cls_aux1: 0.0271, d0.loss_bbox_aux1: 0.0621, d0.loss_iou_aux1: 0.3244, d1.loss_cls_aux1: 0.0252, d1.loss_bbox_aux1: 0.0531, d1.loss_iou_aux1: 0.2789, d2.loss_cls_aux1: 0.0239, d2.loss_bbox_aux1: 0.0522, d2.loss_iou_aux1: 0.2730, d3.loss_cls_aux1: 0.0231, d3.loss_bbox_aux1: 0.0522, d3.loss_iou_aux1: 0.2732, d4.loss_cls_aux1: 0.0231, d4.loss_bbox_aux1: 0.0522, d4.loss_iou_aux1: 0.2733, loss: 23.9969, grad_norm: 65.3463
2024-03-18 08:33:01,204 - mmdet - INFO - Saving checkpoint at 14 epochs
2024-03-18 08:33:23,376 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:33:28,585 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.604
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.475
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.303
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.745
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.693
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.620
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.695
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.788

2024-03-18 08:33:28,585 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.044 | Tin      | 0.616 | Thatch   | 0.534 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:33:28,643 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:33:28,644 - mmdet - INFO - Epoch(val) [14][154]	bbox_mAP: 0.3980, bbox_mAP_50: 0.6040, bbox_mAP_75: 0.4750, bbox_mAP_s: 0.3030, bbox_mAP_m: 0.3830, bbox_mAP_l: 0.7450, bbox_mAP_copypaste: 0.398 0.604 0.475 0.303 0.383 0.745
2024-03-18 08:34:12,385 - mmdet - INFO - Epoch [15][50/232]	lr: 2.000e-05, eta: 1:00:51, time: 0.875, data_time: 0.060, memory: 17650, enc_loss_cls: 0.1239, enc_loss_bbox: 0.0661, enc_loss_iou: 0.3569, loss_cls: 0.1033, loss_bbox: 0.0612, loss_iou: 0.3315, d0.loss_cls: 0.1442, d0.loss_bbox: 0.0621, d0.loss_iou: 0.3365, d1.loss_cls: 0.1153, d1.loss_bbox: 0.0614, d1.loss_iou: 0.3324, d2.loss_cls: 0.1055, d2.loss_bbox: 0.0611, d2.loss_iou: 0.3309, d3.loss_cls: 0.1027, d3.loss_bbox: 0.0611, d3.loss_iou: 0.3311, d4.loss_cls: 0.1026, d4.loss_bbox: 0.0612, d4.loss_iou: 0.3313, loss_rpn_cls: 0.0355, loss_rpn_bbox: 0.1359, loss_cls0: 1.4206, acc0: 95.1753, loss_bbox0: 2.5575, loss_cls1: 0.9847, loss_bbox1: 3.7527, loss_centerness1: 7.4867, loss_cls_aux0: 0.0191, loss_bbox_aux0: 0.0222, loss_iou_aux0: 0.1128, d0.loss_cls_aux0: 0.0265, d0.loss_bbox_aux0: 0.0458, d0.loss_iou_aux0: 0.2378, d1.loss_cls_aux0: 0.0207, d1.loss_bbox_aux0: 0.0261, d1.loss_iou_aux0: 0.1343, d2.loss_cls_aux0: 0.0186, d2.loss_bbox_aux0: 0.0220, d2.loss_iou_aux0: 0.1115, d3.loss_cls_aux0: 0.0187, d3.loss_bbox_aux0: 0.0220, d3.loss_iou_aux0: 0.1118, d4.loss_cls_aux0: 0.0186, d4.loss_bbox_aux0: 0.0221, d4.loss_iou_aux0: 0.1122, loss_cls_aux1: 0.0151, loss_bbox_aux1: 0.0505, loss_iou_aux1: 0.2701, d0.loss_cls_aux1: 0.0177, d0.loss_bbox_aux1: 0.0579, d0.loss_iou_aux1: 0.3097, d1.loss_cls_aux1: 0.0161, d1.loss_bbox_aux1: 0.0512, d1.loss_iou_aux1: 0.2742, d2.loss_cls_aux1: 0.0146, d2.loss_bbox_aux1: 0.0504, d2.loss_iou_aux1: 0.2698, d3.loss_cls_aux1: 0.0151, d3.loss_bbox_aux1: 0.0504, d3.loss_iou_aux1: 0.2698, d4.loss_cls_aux1: 0.0148, d4.loss_bbox_aux1: 0.0505, d4.loss_iou_aux1: 0.2699, loss: 23.1264, grad_norm: 63.5867
2024-03-18 08:34:53,620 - mmdet - INFO - Epoch [15][100/232]	lr: 2.000e-05, eta: 1:00:22, time: 0.825, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1261, enc_loss_bbox: 0.0703, enc_loss_iou: 0.3618, loss_cls: 0.0993, loss_bbox: 0.0654, loss_iou: 0.3388, d0.loss_cls: 0.1364, d0.loss_bbox: 0.0664, d0.loss_iou: 0.3439, d1.loss_cls: 0.1083, d1.loss_bbox: 0.0656, d1.loss_iou: 0.3394, d2.loss_cls: 0.1031, d2.loss_bbox: 0.0652, d2.loss_iou: 0.3380, d3.loss_cls: 0.1004, d3.loss_bbox: 0.0653, d3.loss_iou: 0.3382, d4.loss_cls: 0.0996, d4.loss_bbox: 0.0654, d4.loss_iou: 0.3385, loss_rpn_cls: 0.0454, loss_rpn_bbox: 0.1337, loss_cls0: 1.4656, acc0: 94.9605, loss_bbox0: 2.6834, loss_cls1: 1.0352, loss_bbox1: 3.7584, loss_centerness1: 7.4655, loss_cls_aux0: 0.0153, loss_bbox_aux0: 0.0247, loss_iou_aux0: 0.1199, d0.loss_cls_aux0: 0.0229, d0.loss_bbox_aux0: 0.0491, d0.loss_iou_aux0: 0.2397, d1.loss_cls_aux0: 0.0175, d1.loss_bbox_aux0: 0.0284, d1.loss_iou_aux0: 0.1370, d2.loss_cls_aux0: 0.0154, d2.loss_bbox_aux0: 0.0245, d2.loss_iou_aux0: 0.1179, d3.loss_cls_aux0: 0.0150, d3.loss_bbox_aux0: 0.0245, d3.loss_iou_aux0: 0.1185, d4.loss_cls_aux0: 0.0151, d4.loss_bbox_aux0: 0.0246, d4.loss_iou_aux0: 0.1192, loss_cls_aux1: 0.0122, loss_bbox_aux1: 0.0520, loss_iou_aux1: 0.2681, d0.loss_cls_aux1: 0.0158, d0.loss_bbox_aux1: 0.0605, d0.loss_iou_aux1: 0.3096, d1.loss_cls_aux1: 0.0134, d1.loss_bbox_aux1: 0.0527, d1.loss_iou_aux1: 0.2719, d2.loss_cls_aux1: 0.0129, d2.loss_bbox_aux1: 0.0519, d2.loss_iou_aux1: 0.2676, d3.loss_cls_aux1: 0.0123, d3.loss_bbox_aux1: 0.0519, d3.loss_iou_aux1: 0.2678, d4.loss_cls_aux1: 0.0121, d4.loss_bbox_aux1: 0.0519, d4.loss_iou_aux1: 0.2679, loss: 23.4044, grad_norm: 66.3474
2024-03-18 08:35:35,216 - mmdet - INFO - Epoch [15][150/232]	lr: 2.000e-05, eta: 0:59:54, time: 0.832, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1304, enc_loss_bbox: 0.0679, enc_loss_iou: 0.3608, loss_cls: 0.1108, loss_bbox: 0.0645, loss_iou: 0.3433, d0.loss_cls: 0.1438, d0.loss_bbox: 0.0646, d0.loss_iou: 0.3458, d1.loss_cls: 0.1224, d1.loss_bbox: 0.0644, d1.loss_iou: 0.3433, d2.loss_cls: 0.1140, d2.loss_bbox: 0.0643, d2.loss_iou: 0.3424, d3.loss_cls: 0.1123, d3.loss_bbox: 0.0643, d3.loss_iou: 0.3427, d4.loss_cls: 0.1110, d4.loss_bbox: 0.0645, d4.loss_iou: 0.3433, loss_rpn_cls: 0.0406, loss_rpn_bbox: 0.1348, loss_cls0: 1.4907, acc0: 94.9814, loss_bbox0: 2.6460, loss_cls1: 1.0427, loss_bbox1: 3.8154, loss_centerness1: 7.5198, loss_cls_aux0: 0.0218, loss_bbox_aux0: 0.0212, loss_iou_aux0: 0.1096, d0.loss_cls_aux0: 0.0280, d0.loss_bbox_aux0: 0.0460, d0.loss_iou_aux0: 0.2402, d1.loss_cls_aux0: 0.0239, d1.loss_bbox_aux0: 0.0251, d1.loss_iou_aux0: 0.1290, d2.loss_cls_aux0: 0.0219, d2.loss_bbox_aux0: 0.0210, d2.loss_iou_aux0: 0.1080, d3.loss_cls_aux0: 0.0215, d3.loss_bbox_aux0: 0.0210, d3.loss_iou_aux0: 0.1084, d4.loss_cls_aux0: 0.0218, d4.loss_bbox_aux0: 0.0211, d4.loss_iou_aux0: 0.1089, loss_cls_aux1: 0.0173, loss_bbox_aux1: 0.0502, loss_iou_aux1: 0.2701, d0.loss_cls_aux1: 0.0192, d0.loss_bbox_aux1: 0.0591, d0.loss_iou_aux1: 0.3184, d1.loss_cls_aux1: 0.0190, d1.loss_bbox_aux1: 0.0510, d1.loss_iou_aux1: 0.2742, d2.loss_cls_aux1: 0.0169, d2.loss_bbox_aux1: 0.0501, d2.loss_iou_aux1: 0.2697, d3.loss_cls_aux1: 0.0170, d3.loss_bbox_aux1: 0.0501, d3.loss_iou_aux1: 0.2698, d4.loss_cls_aux1: 0.0172, d4.loss_bbox_aux1: 0.0502, d4.loss_iou_aux1: 0.2699, loss: 23.5987, grad_norm: 68.7137
2024-03-18 08:36:17,595 - mmdet - INFO - Epoch [15][200/232]	lr: 2.000e-05, eta: 0:59:26, time: 0.848, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1315, enc_loss_bbox: 0.0750, enc_loss_iou: 0.3875, loss_cls: 0.1087, loss_bbox: 0.0706, loss_iou: 0.3678, d0.loss_cls: 0.1475, d0.loss_bbox: 0.0710, d0.loss_iou: 0.3703, d1.loss_cls: 0.1171, d1.loss_bbox: 0.0706, d1.loss_iou: 0.3674, d2.loss_cls: 0.1103, d2.loss_bbox: 0.0706, d2.loss_iou: 0.3675, d3.loss_cls: 0.1085, d3.loss_bbox: 0.0705, d3.loss_iou: 0.3674, d4.loss_cls: 0.1082, d4.loss_bbox: 0.0705, d4.loss_iou: 0.3675, loss_rpn_cls: 0.0357, loss_rpn_bbox: 0.1462, loss_cls0: 1.5420, acc0: 94.8184, loss_bbox0: 2.7026, loss_cls1: 1.0946, loss_bbox1: 4.0593, loss_centerness1: 7.5057, loss_cls_aux0: 0.0246, loss_bbox_aux0: 0.0250, loss_iou_aux0: 0.1234, d0.loss_cls_aux0: 0.0317, d0.loss_bbox_aux0: 0.0500, d0.loss_iou_aux0: 0.2477, d1.loss_cls_aux0: 0.0275, d1.loss_bbox_aux0: 0.0285, d1.loss_iou_aux0: 0.1413, d2.loss_cls_aux0: 0.0249, d2.loss_bbox_aux0: 0.0249, d2.loss_iou_aux0: 0.1223, d3.loss_cls_aux0: 0.0244, d3.loss_bbox_aux0: 0.0249, d3.loss_iou_aux0: 0.1225, d4.loss_cls_aux0: 0.0241, d4.loss_bbox_aux0: 0.0250, d4.loss_iou_aux0: 0.1229, loss_cls_aux1: 0.0255, loss_bbox_aux1: 0.0535, loss_iou_aux1: 0.2785, d0.loss_cls_aux1: 0.0280, d0.loss_bbox_aux1: 0.0614, d0.loss_iou_aux1: 0.3179, d1.loss_cls_aux1: 0.0274, d1.loss_bbox_aux1: 0.0541, d1.loss_iou_aux1: 0.2825, d2.loss_cls_aux1: 0.0255, d2.loss_bbox_aux1: 0.0534, d2.loss_iou_aux1: 0.2783, d3.loss_cls_aux1: 0.0252, d3.loss_bbox_aux1: 0.0534, d3.loss_iou_aux1: 0.2784, d4.loss_cls_aux1: 0.0250, d4.loss_bbox_aux1: 0.0535, d4.loss_iou_aux1: 0.2784, loss: 24.4280, grad_norm: 59.8174
2024-03-18 08:36:44,735 - mmdet - INFO - Saving checkpoint at 15 epochs
2024-03-18 08:37:07,004 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:37:12,952 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.395
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.600
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.303
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.789
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.550
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.679
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.826

2024-03-18 08:37:12,952 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.045 | Tin      | 0.622 | Thatch   | 0.518 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:37:13,008 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:37:13,008 - mmdet - INFO - Epoch(val) [15][154]	bbox_mAP: 0.3950, bbox_mAP_50: 0.6000, bbox_mAP_75: 0.4680, bbox_mAP_s: 0.3030, bbox_mAP_m: 0.3830, bbox_mAP_l: 0.7890, bbox_mAP_copypaste: 0.395 0.600 0.468 0.303 0.383 0.789
2024-03-18 08:37:56,619 - mmdet - INFO - Epoch [16][50/232]	lr: 2.000e-05, eta: 0:58:05, time: 0.872, data_time: 0.060, memory: 17650, enc_loss_cls: 0.1356, enc_loss_bbox: 0.0728, enc_loss_iou: 0.3881, loss_cls: 0.1076, loss_bbox: 0.0657, loss_iou: 0.3552, d0.loss_cls: 0.1420, d0.loss_bbox: 0.0667, d0.loss_iou: 0.3613, d1.loss_cls: 0.1156, d1.loss_bbox: 0.0657, d1.loss_iou: 0.3549, d2.loss_cls: 0.1087, d2.loss_bbox: 0.0657, d2.loss_iou: 0.3548, d3.loss_cls: 0.1070, d3.loss_bbox: 0.0657, d3.loss_iou: 0.3548, d4.loss_cls: 0.1074, d4.loss_bbox: 0.0656, d4.loss_iou: 0.3549, loss_rpn_cls: 0.0314, loss_rpn_bbox: 0.1167, loss_cls0: 1.3464, acc0: 95.4168, loss_bbox0: 2.4626, loss_cls1: 1.0223, loss_bbox1: 3.8812, loss_centerness1: 7.4976, loss_cls_aux0: 0.0146, loss_bbox_aux0: 0.0225, loss_iou_aux0: 0.1144, d0.loss_cls_aux0: 0.0219, d0.loss_bbox_aux0: 0.0448, d0.loss_iou_aux0: 0.2342, d1.loss_cls_aux0: 0.0169, d1.loss_bbox_aux0: 0.0256, d1.loss_iou_aux0: 0.1294, d2.loss_cls_aux0: 0.0150, d2.loss_bbox_aux0: 0.0222, d2.loss_iou_aux0: 0.1120, d3.loss_cls_aux0: 0.0142, d3.loss_bbox_aux0: 0.0223, d3.loss_iou_aux0: 0.1126, d4.loss_cls_aux0: 0.0144, d4.loss_bbox_aux0: 0.0224, d4.loss_iou_aux0: 0.1134, loss_cls_aux1: 0.0110, loss_bbox_aux1: 0.0521, loss_iou_aux1: 0.2787, d0.loss_cls_aux1: 0.0144, d0.loss_bbox_aux1: 0.0588, d0.loss_iou_aux1: 0.3137, d1.loss_cls_aux1: 0.0129, d1.loss_bbox_aux1: 0.0529, d1.loss_iou_aux1: 0.2817, d2.loss_cls_aux1: 0.0118, d2.loss_bbox_aux1: 0.0520, d2.loss_iou_aux1: 0.2783, d3.loss_cls_aux1: 0.0111, d3.loss_bbox_aux1: 0.0520, d3.loss_iou_aux1: 0.2783, d4.loss_cls_aux1: 0.0112, d4.loss_bbox_aux1: 0.0521, d4.loss_iou_aux1: 0.2785, loss: 23.3481, grad_norm: 63.5345
2024-03-18 08:38:37,888 - mmdet - INFO - Epoch [16][100/232]	lr: 2.000e-05, eta: 0:57:36, time: 0.825, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1312, enc_loss_bbox: 0.0698, enc_loss_iou: 0.3701, loss_cls: 0.1055, loss_bbox: 0.0621, loss_iou: 0.3355, d0.loss_cls: 0.1455, d0.loss_bbox: 0.0635, d0.loss_iou: 0.3421, d1.loss_cls: 0.1160, d1.loss_bbox: 0.0622, d1.loss_iou: 0.3361, d2.loss_cls: 0.1100, d2.loss_bbox: 0.0621, d2.loss_iou: 0.3352, d3.loss_cls: 0.1054, d3.loss_bbox: 0.0620, d3.loss_iou: 0.3353, d4.loss_cls: 0.1051, d4.loss_bbox: 0.0620, d4.loss_iou: 0.3353, loss_rpn_cls: 0.0386, loss_rpn_bbox: 0.1462, loss_cls0: 1.5409, acc0: 94.7418, loss_bbox0: 2.7074, loss_cls1: 1.0109, loss_bbox1: 3.6910, loss_centerness1: 7.4910, loss_cls_aux0: 0.0197, loss_bbox_aux0: 0.0230, loss_iou_aux0: 0.1137, d0.loss_cls_aux0: 0.0271, d0.loss_bbox_aux0: 0.0466, d0.loss_iou_aux0: 0.2321, d1.loss_cls_aux0: 0.0223, d1.loss_bbox_aux0: 0.0272, d1.loss_iou_aux0: 0.1358, d2.loss_cls_aux0: 0.0198, d2.loss_bbox_aux0: 0.0228, d2.loss_iou_aux0: 0.1126, d3.loss_cls_aux0: 0.0203, d3.loss_bbox_aux0: 0.0229, d3.loss_iou_aux0: 0.1128, d4.loss_cls_aux0: 0.0198, d4.loss_bbox_aux0: 0.0229, d4.loss_iou_aux0: 0.1132, loss_cls_aux1: 0.0162, loss_bbox_aux1: 0.0506, loss_iou_aux1: 0.2676, d0.loss_cls_aux1: 0.0190, d0.loss_bbox_aux1: 0.0574, d0.loss_iou_aux1: 0.3026, d1.loss_cls_aux1: 0.0180, d1.loss_bbox_aux1: 0.0514, d1.loss_iou_aux1: 0.2718, d2.loss_cls_aux1: 0.0166, d2.loss_bbox_aux1: 0.0505, d2.loss_iou_aux1: 0.2673, d3.loss_cls_aux1: 0.0166, d3.loss_bbox_aux1: 0.0505, d3.loss_iou_aux1: 0.2674, d4.loss_cls_aux1: 0.0162, d4.loss_bbox_aux1: 0.0506, d4.loss_iou_aux1: 0.2675, loss: 23.4507, grad_norm: 59.7414
2024-03-18 08:39:19,670 - mmdet - INFO - Epoch [16][150/232]	lr: 2.000e-05, eta: 0:57:07, time: 0.836, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1254, enc_loss_bbox: 0.0727, enc_loss_iou: 0.3760, loss_cls: 0.0997, loss_bbox: 0.0676, loss_iou: 0.3530, d0.loss_cls: 0.1348, d0.loss_bbox: 0.0686, d0.loss_iou: 0.3587, d1.loss_cls: 0.1112, d1.loss_bbox: 0.0679, d1.loss_iou: 0.3539, d2.loss_cls: 0.1026, d2.loss_bbox: 0.0676, d2.loss_iou: 0.3528, d3.loss_cls: 0.1008, d3.loss_bbox: 0.0675, d3.loss_iou: 0.3528, d4.loss_cls: 0.0997, d4.loss_bbox: 0.0675, d4.loss_iou: 0.3528, loss_rpn_cls: 0.0455, loss_rpn_bbox: 0.1511, loss_cls0: 1.5585, acc0: 94.7138, loss_bbox0: 2.7369, loss_cls1: 1.0416, loss_bbox1: 3.9496, loss_centerness1: 7.4950, loss_cls_aux0: 0.0162, loss_bbox_aux0: 0.0251, loss_iou_aux0: 0.1256, d0.loss_cls_aux0: 0.0210, d0.loss_bbox_aux0: 0.0489, d0.loss_iou_aux0: 0.2463, d1.loss_cls_aux0: 0.0174, d1.loss_bbox_aux0: 0.0288, d1.loss_iou_aux0: 0.1451, d2.loss_cls_aux0: 0.0162, d2.loss_bbox_aux0: 0.0249, d2.loss_iou_aux0: 0.1244, d3.loss_cls_aux0: 0.0160, d3.loss_bbox_aux0: 0.0250, d3.loss_iou_aux0: 0.1247, d4.loss_cls_aux0: 0.0161, d4.loss_bbox_aux0: 0.0250, d4.loss_iou_aux0: 0.1251, loss_cls_aux1: 0.0119, loss_bbox_aux1: 0.0520, loss_iou_aux1: 0.2748, d0.loss_cls_aux1: 0.0148, d0.loss_bbox_aux1: 0.0596, d0.loss_iou_aux1: 0.3121, d1.loss_cls_aux1: 0.0128, d1.loss_bbox_aux1: 0.0528, d1.loss_iou_aux1: 0.2791, d2.loss_cls_aux1: 0.0122, d2.loss_bbox_aux1: 0.0519, d2.loss_iou_aux1: 0.2745, d3.loss_cls_aux1: 0.0118, d3.loss_bbox_aux1: 0.0519, d3.loss_iou_aux1: 0.2746, d4.loss_cls_aux1: 0.0118, d4.loss_bbox_aux1: 0.0520, d4.loss_iou_aux1: 0.2747, loss: 23.9888, grad_norm: 61.7413
2024-03-18 08:40:01,499 - mmdet - INFO - Epoch [16][200/232]	lr: 2.000e-05, eta: 0:56:37, time: 0.836, data_time: 0.009, memory: 17650, enc_loss_cls: 0.1324, enc_loss_bbox: 0.0713, enc_loss_iou: 0.3729, loss_cls: 0.1061, loss_bbox: 0.0649, loss_iou: 0.3461, d0.loss_cls: 0.1444, d0.loss_bbox: 0.0655, d0.loss_iou: 0.3496, d1.loss_cls: 0.1138, d1.loss_bbox: 0.0655, d1.loss_iou: 0.3472, d2.loss_cls: 0.1081, d2.loss_bbox: 0.0650, d2.loss_iou: 0.3459, d3.loss_cls: 0.1068, d3.loss_bbox: 0.0648, d3.loss_iou: 0.3451, d4.loss_cls: 0.1073, d4.loss_bbox: 0.0646, d4.loss_iou: 0.3450, loss_rpn_cls: 0.0383, loss_rpn_bbox: 0.1287, loss_cls0: 1.4555, acc0: 95.1334, loss_bbox0: 2.5933, loss_cls1: 1.0192, loss_bbox1: 3.7625, loss_centerness1: 7.4840, loss_cls_aux0: 0.0224, loss_bbox_aux0: 0.0231, loss_iou_aux0: 0.1125, d0.loss_cls_aux0: 0.0310, d0.loss_bbox_aux0: 0.0478, d0.loss_iou_aux0: 0.2383, d1.loss_cls_aux0: 0.0266, d1.loss_bbox_aux0: 0.0269, d1.loss_iou_aux0: 0.1306, d2.loss_cls_aux0: 0.0232, d2.loss_bbox_aux0: 0.0229, d2.loss_iou_aux0: 0.1111, d3.loss_cls_aux0: 0.0220, d3.loss_bbox_aux0: 0.0230, d3.loss_iou_aux0: 0.1115, d4.loss_cls_aux0: 0.0223, d4.loss_bbox_aux0: 0.0230, d4.loss_iou_aux0: 0.1120, loss_cls_aux1: 0.0200, loss_bbox_aux1: 0.0519, loss_iou_aux1: 0.2722, d0.loss_cls_aux1: 0.0226, d0.loss_bbox_aux1: 0.0614, d0.loss_iou_aux1: 0.3178, d1.loss_cls_aux1: 0.0214, d1.loss_bbox_aux1: 0.0527, d1.loss_iou_aux1: 0.2759, d2.loss_cls_aux1: 0.0204, d2.loss_bbox_aux1: 0.0518, d2.loss_iou_aux1: 0.2717, d3.loss_cls_aux1: 0.0198, d3.loss_bbox_aux1: 0.0519, d3.loss_iou_aux1: 0.2718, d4.loss_cls_aux1: 0.0199, d4.loss_bbox_aux1: 0.0519, d4.loss_iou_aux1: 0.2720, loss: 23.4713, grad_norm: 69.1503
2024-03-18 08:40:28,911 - mmdet - INFO - Saving checkpoint at 16 epochs
2024-03-18 08:40:51,048 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:40:56,795 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.595
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.303
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.749
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.505
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.701
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.787

2024-03-18 08:40:56,796 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.031 | Tin      | 0.621 | Thatch   | 0.530 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:40:56,850 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:40:56,851 - mmdet - INFO - Epoch(val) [16][154]	bbox_mAP: 0.3940, bbox_mAP_50: 0.5950, bbox_mAP_75: 0.4700, bbox_mAP_s: 0.3030, bbox_mAP_m: 0.3830, bbox_mAP_l: 0.7490, bbox_mAP_copypaste: 0.394 0.595 0.470 0.303 0.383 0.749
2024-03-18 08:41:40,677 - mmdet - INFO - Epoch [17][50/232]	lr: 2.000e-05, eta: 0:55:18, time: 0.876, data_time: 0.061, memory: 17650, enc_loss_cls: 0.1164, enc_loss_bbox: 0.0661, enc_loss_iou: 0.3595, loss_cls: 0.0993, loss_bbox: 0.0613, loss_iou: 0.3357, d0.loss_cls: 0.1353, d0.loss_bbox: 0.0619, d0.loss_iou: 0.3392, d1.loss_cls: 0.1095, d1.loss_bbox: 0.0610, d1.loss_iou: 0.3350, d2.loss_cls: 0.1015, d2.loss_bbox: 0.0612, d2.loss_iou: 0.3351, d3.loss_cls: 0.0992, d3.loss_bbox: 0.0612, d3.loss_iou: 0.3353, d4.loss_cls: 0.0987, d4.loss_bbox: 0.0613, d4.loss_iou: 0.3357, loss_rpn_cls: 0.0418, loss_rpn_bbox: 0.1354, loss_cls0: 1.4087, acc0: 95.2670, loss_bbox0: 2.4649, loss_cls1: 0.9744, loss_bbox1: 3.7065, loss_centerness1: 7.4859, loss_cls_aux0: 0.0244, loss_bbox_aux0: 0.0229, loss_iou_aux0: 0.1190, d0.loss_cls_aux0: 0.0322, d0.loss_bbox_aux0: 0.0453, d0.loss_iou_aux0: 0.2364, d1.loss_cls_aux0: 0.0279, d1.loss_bbox_aux0: 0.0265, d1.loss_iou_aux0: 0.1372, d2.loss_cls_aux0: 0.0249, d2.loss_bbox_aux0: 0.0226, d2.loss_iou_aux0: 0.1161, d3.loss_cls_aux0: 0.0243, d3.loss_bbox_aux0: 0.0227, d3.loss_iou_aux0: 0.1170, d4.loss_cls_aux0: 0.0247, d4.loss_bbox_aux0: 0.0228, d4.loss_iou_aux0: 0.1179, loss_cls_aux1: 0.0180, loss_bbox_aux1: 0.0490, loss_iou_aux1: 0.2657, d0.loss_cls_aux1: 0.0199, d0.loss_bbox_aux1: 0.0557, d0.loss_iou_aux1: 0.3003, d1.loss_cls_aux1: 0.0186, d1.loss_bbox_aux1: 0.0498, d1.loss_iou_aux1: 0.2692, d2.loss_cls_aux1: 0.0180, d2.loss_bbox_aux1: 0.0489, d2.loss_iou_aux1: 0.2649, d3.loss_cls_aux1: 0.0183, d3.loss_bbox_aux1: 0.0489, d3.loss_iou_aux1: 0.2651, d4.loss_cls_aux1: 0.0183, d4.loss_bbox_aux1: 0.0490, d4.loss_iou_aux1: 0.2654, loss: 22.9949, grad_norm: 72.3508
2024-03-18 08:42:22,444 - mmdet - INFO - Epoch [17][100/232]	lr: 2.000e-05, eta: 0:54:49, time: 0.835, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1227, enc_loss_bbox: 0.0687, enc_loss_iou: 0.3591, loss_cls: 0.0977, loss_bbox: 0.0642, loss_iou: 0.3406, d0.loss_cls: 0.1366, d0.loss_bbox: 0.0651, d0.loss_iou: 0.3453, d1.loss_cls: 0.1038, d1.loss_bbox: 0.0643, d1.loss_iou: 0.3413, d2.loss_cls: 0.0983, d2.loss_bbox: 0.0641, d2.loss_iou: 0.3400, d3.loss_cls: 0.0975, d3.loss_bbox: 0.0641, d3.loss_iou: 0.3403, d4.loss_cls: 0.0971, d4.loss_bbox: 0.0642, d4.loss_iou: 0.3406, loss_rpn_cls: 0.0415, loss_rpn_bbox: 0.1293, loss_cls0: 1.4074, acc0: 95.2183, loss_bbox0: 2.6175, loss_cls1: 0.9719, loss_bbox1: 3.7153, loss_centerness1: 7.4906, loss_cls_aux0: 0.0190, loss_bbox_aux0: 0.0224, loss_iou_aux0: 0.1102, d0.loss_cls_aux0: 0.0244, d0.loss_bbox_aux0: 0.0463, d0.loss_iou_aux0: 0.2327, d1.loss_cls_aux0: 0.0203, d1.loss_bbox_aux0: 0.0261, d1.loss_iou_aux0: 0.1296, d2.loss_cls_aux0: 0.0181, d2.loss_bbox_aux0: 0.0222, d2.loss_iou_aux0: 0.1092, d3.loss_cls_aux0: 0.0183, d3.loss_bbox_aux0: 0.0223, d3.loss_iou_aux0: 0.1095, d4.loss_cls_aux0: 0.0185, d4.loss_bbox_aux0: 0.0223, d4.loss_iou_aux0: 0.1098, loss_cls_aux1: 0.0162, loss_bbox_aux1: 0.0501, loss_iou_aux1: 0.2650, d0.loss_cls_aux1: 0.0164, d0.loss_bbox_aux1: 0.0580, d0.loss_iou_aux1: 0.3056, d1.loss_cls_aux1: 0.0154, d1.loss_bbox_aux1: 0.0512, d1.loss_iou_aux1: 0.2700, d2.loss_cls_aux1: 0.0148, d2.loss_bbox_aux1: 0.0501, d2.loss_iou_aux1: 0.2647, d3.loss_cls_aux1: 0.0152, d3.loss_bbox_aux1: 0.0501, d3.loss_iou_aux1: 0.2648, d4.loss_cls_aux1: 0.0156, d4.loss_bbox_aux1: 0.0501, d4.loss_iou_aux1: 0.2649, loss: 23.1083, grad_norm: 66.5626
2024-03-18 08:43:03,561 - mmdet - INFO - Epoch [17][150/232]	lr: 2.000e-05, eta: 0:54:18, time: 0.822, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1305, enc_loss_bbox: 0.0744, enc_loss_iou: 0.4070, loss_cls: 0.1118, loss_bbox: 0.0700, loss_iou: 0.3833, d0.loss_cls: 0.1469, d0.loss_bbox: 0.0707, d0.loss_iou: 0.3879, d1.loss_cls: 0.1181, d1.loss_bbox: 0.0701, d1.loss_iou: 0.3830, d2.loss_cls: 0.1111, d2.loss_bbox: 0.0704, d2.loss_iou: 0.3834, d3.loss_cls: 0.1113, d3.loss_bbox: 0.0700, d3.loss_iou: 0.3826, d4.loss_cls: 0.1124, d4.loss_bbox: 0.0698, d4.loss_iou: 0.3817, loss_rpn_cls: 0.0384, loss_rpn_bbox: 0.1338, loss_cls0: 1.5209, acc0: 94.8409, loss_bbox0: 2.6968, loss_cls1: 1.0304, loss_bbox1: 4.0835, loss_centerness1: 7.5110, loss_cls_aux0: 0.0171, loss_bbox_aux0: 0.0237, loss_iou_aux0: 0.1181, d0.loss_cls_aux0: 0.0258, d0.loss_bbox_aux0: 0.0472, d0.loss_iou_aux0: 0.2401, d1.loss_cls_aux0: 0.0199, d1.loss_bbox_aux0: 0.0272, d1.loss_iou_aux0: 0.1369, d2.loss_cls_aux0: 0.0175, d2.loss_bbox_aux0: 0.0235, d2.loss_iou_aux0: 0.1167, d3.loss_cls_aux0: 0.0166, d3.loss_bbox_aux0: 0.0236, d3.loss_iou_aux0: 0.1171, d4.loss_cls_aux0: 0.0166, d4.loss_bbox_aux0: 0.0236, d4.loss_iou_aux0: 0.1175, loss_cls_aux1: 0.0164, loss_bbox_aux1: 0.0531, loss_iou_aux1: 0.2828, d0.loss_cls_aux1: 0.0190, d0.loss_bbox_aux1: 0.0610, d0.loss_iou_aux1: 0.3246, d1.loss_cls_aux1: 0.0177, d1.loss_bbox_aux1: 0.0547, d1.loss_iou_aux1: 0.2907, d2.loss_cls_aux1: 0.0159, d2.loss_bbox_aux1: 0.0530, d2.loss_iou_aux1: 0.2824, d3.loss_cls_aux1: 0.0158, d3.loss_bbox_aux1: 0.0530, d3.loss_iou_aux1: 0.2825, d4.loss_cls_aux1: 0.0159, d4.loss_bbox_aux1: 0.0530, d4.loss_iou_aux1: 0.2827, loss: 24.3639, grad_norm: 74.9910
2024-03-18 08:43:44,973 - mmdet - INFO - Epoch [17][200/232]	lr: 2.000e-05, eta: 0:53:48, time: 0.828, data_time: 0.009, memory: 17650, enc_loss_cls: 0.1304, enc_loss_bbox: 0.0721, enc_loss_iou: 0.3717, loss_cls: 0.1106, loss_bbox: 0.0653, loss_iou: 0.3415, d0.loss_cls: 0.1409, d0.loss_bbox: 0.0666, d0.loss_iou: 0.3483, d1.loss_cls: 0.1166, d1.loss_bbox: 0.0656, d1.loss_iou: 0.3430, d2.loss_cls: 0.1109, d2.loss_bbox: 0.0653, d2.loss_iou: 0.3415, d3.loss_cls: 0.1100, d3.loss_bbox: 0.0652, d3.loss_iou: 0.3412, d4.loss_cls: 0.1102, d4.loss_bbox: 0.0652, d4.loss_iou: 0.3413, loss_rpn_cls: 0.0396, loss_rpn_bbox: 0.1439, loss_cls0: 1.4743, acc0: 95.0056, loss_bbox0: 2.6551, loss_cls1: 1.0612, loss_bbox1: 3.7965, loss_centerness1: 7.4625, loss_cls_aux0: 0.0186, loss_bbox_aux0: 0.0252, loss_iou_aux0: 0.1223, d0.loss_cls_aux0: 0.0257, d0.loss_bbox_aux0: 0.0489, d0.loss_iou_aux0: 0.2380, d1.loss_cls_aux0: 0.0210, d1.loss_bbox_aux0: 0.0288, d1.loss_iou_aux0: 0.1395, d2.loss_cls_aux0: 0.0185, d2.loss_bbox_aux0: 0.0249, d2.loss_iou_aux0: 0.1203, d3.loss_cls_aux0: 0.0179, d3.loss_bbox_aux0: 0.0250, d3.loss_iou_aux0: 0.1209, d4.loss_cls_aux0: 0.0182, d4.loss_bbox_aux0: 0.0251, d4.loss_iou_aux0: 0.1216, loss_cls_aux1: 0.0162, loss_bbox_aux1: 0.0526, loss_iou_aux1: 0.2764, d0.loss_cls_aux1: 0.0199, d0.loss_bbox_aux1: 0.0619, d0.loss_iou_aux1: 0.3196, d1.loss_cls_aux1: 0.0178, d1.loss_bbox_aux1: 0.0533, d1.loss_iou_aux1: 0.2792, d2.loss_cls_aux1: 0.0168, d2.loss_bbox_aux1: 0.0525, d2.loss_iou_aux1: 0.2757, d3.loss_cls_aux1: 0.0160, d3.loss_bbox_aux1: 0.0525, d3.loss_iou_aux1: 0.2759, d4.loss_cls_aux1: 0.0159, d4.loss_bbox_aux1: 0.0526, d4.loss_iou_aux1: 0.2761, loss: 23.6478, grad_norm: 65.6830
2024-03-18 08:44:11,642 - mmdet - INFO - Saving checkpoint at 17 epochs
2024-03-18 08:44:33,793 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:44:39,489 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.601
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.303
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.385
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.787
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.703
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.703
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.703
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.622
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.706
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.826

2024-03-18 08:44:39,489 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.066 | Tin      | 0.625 | Thatch   | 0.517 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:44:39,542 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:44:39,542 - mmdet - INFO - Epoch(val) [17][154]	bbox_mAP: 0.4020, bbox_mAP_50: 0.6010, bbox_mAP_75: 0.4720, bbox_mAP_s: 0.3030, bbox_mAP_m: 0.3850, bbox_mAP_l: 0.7870, bbox_mAP_copypaste: 0.402 0.601 0.472 0.303 0.385 0.787
2024-03-18 08:45:23,228 - mmdet - INFO - Epoch [18][50/232]	lr: 2.000e-05, eta: 0:52:31, time: 0.873, data_time: 0.059, memory: 17650, enc_loss_cls: 0.1245, enc_loss_bbox: 0.0692, enc_loss_iou: 0.3682, loss_cls: 0.1028, loss_bbox: 0.0639, loss_iou: 0.3429, d0.loss_cls: 0.1382, d0.loss_bbox: 0.0650, d0.loss_iou: 0.3478, d1.loss_cls: 0.1091, d1.loss_bbox: 0.0642, d1.loss_iou: 0.3440, d2.loss_cls: 0.1060, d2.loss_bbox: 0.0638, d2.loss_iou: 0.3422, d3.loss_cls: 0.1035, d3.loss_bbox: 0.0639, d3.loss_iou: 0.3427, d4.loss_cls: 0.1027, d4.loss_bbox: 0.0638, d4.loss_iou: 0.3427, loss_rpn_cls: 0.0383, loss_rpn_bbox: 0.1448, loss_cls0: 1.4473, acc0: 95.0767, loss_bbox0: 2.6113, loss_cls1: 1.0190, loss_bbox1: 3.7954, loss_centerness1: 7.4976, loss_cls_aux0: 0.0151, loss_bbox_aux0: 0.0226, loss_iou_aux0: 0.1117, d0.loss_cls_aux0: 0.0231, d0.loss_bbox_aux0: 0.0483, d0.loss_iou_aux0: 0.2384, d1.loss_cls_aux0: 0.0193, d1.loss_bbox_aux0: 0.0264, d1.loss_iou_aux0: 0.1306, d2.loss_cls_aux0: 0.0166, d2.loss_bbox_aux0: 0.0225, d2.loss_iou_aux0: 0.1104, d3.loss_cls_aux0: 0.0152, d3.loss_bbox_aux0: 0.0225, d3.loss_iou_aux0: 0.1107, d4.loss_cls_aux0: 0.0150, d4.loss_bbox_aux0: 0.0225, d4.loss_iou_aux0: 0.1111, loss_cls_aux1: 0.0145, loss_bbox_aux1: 0.0504, loss_iou_aux1: 0.2671, d0.loss_cls_aux1: 0.0174, d0.loss_bbox_aux1: 0.0595, d0.loss_iou_aux1: 0.3141, d1.loss_cls_aux1: 0.0161, d1.loss_bbox_aux1: 0.0511, d1.loss_iou_aux1: 0.2714, d2.loss_cls_aux1: 0.0150, d2.loss_bbox_aux1: 0.0503, d2.loss_iou_aux1: 0.2665, d3.loss_cls_aux1: 0.0146, d3.loss_bbox_aux1: 0.0503, d3.loss_iou_aux1: 0.2667, d4.loss_cls_aux1: 0.0145, d4.loss_bbox_aux1: 0.0503, d4.loss_iou_aux1: 0.2669, loss: 23.3636, grad_norm: 59.9402
2024-03-18 08:46:03,724 - mmdet - INFO - Epoch [18][100/232]	lr: 2.000e-05, eta: 0:51:59, time: 0.810, data_time: 0.009, memory: 17650, enc_loss_cls: 0.1218, enc_loss_bbox: 0.0692, enc_loss_iou: 0.3702, loss_cls: 0.0990, loss_bbox: 0.0635, loss_iou: 0.3414, d0.loss_cls: 0.1366, d0.loss_bbox: 0.0647, d0.loss_iou: 0.3471, d1.loss_cls: 0.1079, d1.loss_bbox: 0.0643, d1.loss_iou: 0.3432, d2.loss_cls: 0.1010, d2.loss_bbox: 0.0635, d2.loss_iou: 0.3410, d3.loss_cls: 0.0982, d3.loss_bbox: 0.0636, d3.loss_iou: 0.3413, d4.loss_cls: 0.0980, d4.loss_bbox: 0.0635, d4.loss_iou: 0.3413, loss_rpn_cls: 0.0306, loss_rpn_bbox: 0.1359, loss_cls0: 1.3429, acc0: 95.4152, loss_bbox0: 2.4307, loss_cls1: 0.9901, loss_bbox1: 3.7572, loss_centerness1: 7.4844, loss_cls_aux0: 0.0162, loss_bbox_aux0: 0.0224, loss_iou_aux0: 0.1139, d0.loss_cls_aux0: 0.0243, d0.loss_bbox_aux0: 0.0464, d0.loss_iou_aux0: 0.2382, d1.loss_cls_aux0: 0.0195, d1.loss_bbox_aux0: 0.0258, d1.loss_iou_aux0: 0.1308, d2.loss_cls_aux0: 0.0179, d2.loss_bbox_aux0: 0.0223, d2.loss_iou_aux0: 0.1119, d3.loss_cls_aux0: 0.0169, d3.loss_bbox_aux0: 0.0223, d3.loss_iou_aux0: 0.1124, d4.loss_cls_aux0: 0.0164, d4.loss_bbox_aux0: 0.0224, d4.loss_iou_aux0: 0.1131, loss_cls_aux1: 0.0137, loss_bbox_aux1: 0.0503, loss_iou_aux1: 0.2679, d0.loss_cls_aux1: 0.0169, d0.loss_bbox_aux1: 0.0591, d0.loss_iou_aux1: 0.3141, d1.loss_cls_aux1: 0.0161, d1.loss_bbox_aux1: 0.0511, d1.loss_iou_aux1: 0.2723, d2.loss_cls_aux1: 0.0148, d2.loss_bbox_aux1: 0.0502, d2.loss_iou_aux1: 0.2674, d3.loss_cls_aux1: 0.0140, d3.loss_bbox_aux1: 0.0502, d3.loss_iou_aux1: 0.2675, d4.loss_cls_aux1: 0.0136, d4.loss_bbox_aux1: 0.0503, d4.loss_iou_aux1: 0.2677, loss: 22.9622, grad_norm: 65.1723
2024-03-18 08:46:44,736 - mmdet - INFO - Epoch [18][150/232]	lr: 2.000e-05, eta: 0:51:28, time: 0.820, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1320, enc_loss_bbox: 0.0684, enc_loss_iou: 0.3542, loss_cls: 0.1103, loss_bbox: 0.0635, loss_iou: 0.3342, d0.loss_cls: 0.1375, d0.loss_bbox: 0.0652, d0.loss_iou: 0.3398, d1.loss_cls: 0.1165, d1.loss_bbox: 0.0646, d1.loss_iou: 0.3359, d2.loss_cls: 0.1116, d2.loss_bbox: 0.0640, d2.loss_iou: 0.3342, d3.loss_cls: 0.1080, d3.loss_bbox: 0.0641, d3.loss_iou: 0.3346, d4.loss_cls: 0.1088, d4.loss_bbox: 0.0635, d4.loss_iou: 0.3343, loss_rpn_cls: 0.0449, loss_rpn_bbox: 0.1310, loss_cls0: 1.4346, acc0: 95.1047, loss_bbox0: 2.6306, loss_cls1: 1.0246, loss_bbox1: 3.6746, loss_centerness1: 7.4795, loss_cls_aux0: 0.0146, loss_bbox_aux0: 0.0234, loss_iou_aux0: 0.1139, d0.loss_cls_aux0: 0.0222, d0.loss_bbox_aux0: 0.0473, d0.loss_iou_aux0: 0.2330, d1.loss_cls_aux0: 0.0176, d1.loss_bbox_aux0: 0.0271, d1.loss_iou_aux0: 0.1312, d2.loss_cls_aux0: 0.0153, d2.loss_bbox_aux0: 0.0232, d2.loss_iou_aux0: 0.1121, d3.loss_cls_aux0: 0.0144, d3.loss_bbox_aux0: 0.0232, d3.loss_iou_aux0: 0.1126, d4.loss_cls_aux0: 0.0144, d4.loss_bbox_aux0: 0.0233, d4.loss_iou_aux0: 0.1132, loss_cls_aux1: 0.0141, loss_bbox_aux1: 0.0513, loss_iou_aux1: 0.2686, d0.loss_cls_aux1: 0.0167, d0.loss_bbox_aux1: 0.0586, d0.loss_iou_aux1: 0.3042, d1.loss_cls_aux1: 0.0158, d1.loss_bbox_aux1: 0.0522, d1.loss_iou_aux1: 0.2726, d2.loss_cls_aux1: 0.0147, d2.loss_bbox_aux1: 0.0512, d2.loss_iou_aux1: 0.2680, d3.loss_cls_aux1: 0.0138, d3.loss_bbox_aux1: 0.0512, d3.loss_iou_aux1: 0.2682, d4.loss_cls_aux1: 0.0137, d4.loss_bbox_aux1: 0.0513, d4.loss_iou_aux1: 0.2684, loss: 23.2019, grad_norm: 65.7005
2024-03-18 08:47:26,212 - mmdet - INFO - Epoch [18][200/232]	lr: 2.000e-05, eta: 0:50:57, time: 0.829, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1288, enc_loss_bbox: 0.0679, enc_loss_iou: 0.3660, loss_cls: 0.1063, loss_bbox: 0.0642, loss_iou: 0.3457, d0.loss_cls: 0.1391, d0.loss_bbox: 0.0638, d0.loss_iou: 0.3470, d1.loss_cls: 0.1135, d1.loss_bbox: 0.0640, d1.loss_iou: 0.3458, d2.loss_cls: 0.1081, d2.loss_bbox: 0.0641, d2.loss_iou: 0.3453, d3.loss_cls: 0.1058, d3.loss_bbox: 0.0641, d3.loss_iou: 0.3454, d4.loss_cls: 0.1060, d4.loss_bbox: 0.0642, d4.loss_iou: 0.3454, loss_rpn_cls: 0.0351, loss_rpn_bbox: 0.1327, loss_cls0: 1.4500, acc0: 94.8998, loss_bbox0: 2.6716, loss_cls1: 1.0072, loss_bbox1: 3.7422, loss_centerness1: 7.4887, loss_cls_aux0: 0.0169, loss_bbox_aux0: 0.0227, loss_iou_aux0: 0.1133, d0.loss_cls_aux0: 0.0237, d0.loss_bbox_aux0: 0.0475, d0.loss_iou_aux0: 0.2404, d1.loss_cls_aux0: 0.0193, d1.loss_bbox_aux0: 0.0270, d1.loss_iou_aux0: 0.1351, d2.loss_cls_aux0: 0.0168, d2.loss_bbox_aux0: 0.0226, d2.loss_iou_aux0: 0.1119, d3.loss_cls_aux0: 0.0165, d3.loss_bbox_aux0: 0.0226, d3.loss_iou_aux0: 0.1122, d4.loss_cls_aux0: 0.0165, d4.loss_bbox_aux0: 0.0227, d4.loss_iou_aux0: 0.1126, loss_cls_aux1: 0.0163, loss_bbox_aux1: 0.0509, loss_iou_aux1: 0.2705, d0.loss_cls_aux1: 0.0190, d0.loss_bbox_aux1: 0.0580, d0.loss_iou_aux1: 0.3069, d1.loss_cls_aux1: 0.0177, d1.loss_bbox_aux1: 0.0513, d1.loss_iou_aux1: 0.2735, d2.loss_cls_aux1: 0.0164, d2.loss_bbox_aux1: 0.0509, d2.loss_iou_aux1: 0.2701, d3.loss_cls_aux1: 0.0160, d3.loss_bbox_aux1: 0.0509, d3.loss_iou_aux1: 0.2702, d4.loss_cls_aux1: 0.0160, d4.loss_bbox_aux1: 0.0509, d4.loss_iou_aux1: 0.2703, loss: 23.4041, grad_norm: 60.0935
2024-03-18 08:47:53,048 - mmdet - INFO - Saving checkpoint at 18 epochs
2024-03-18 08:48:15,323 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:48:21,072 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.405
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.606
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.474
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.310
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.783
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.692
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.617
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.691
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.819

2024-03-18 08:48:21,072 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.068 | Tin      | 0.629 | Thatch   | 0.519 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:48:21,128 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:48:21,129 - mmdet - INFO - Epoch(val) [18][154]	bbox_mAP: 0.4050, bbox_mAP_50: 0.6060, bbox_mAP_75: 0.4740, bbox_mAP_s: 0.3100, bbox_mAP_m: 0.3980, bbox_mAP_l: 0.7830, bbox_mAP_copypaste: 0.405 0.606 0.474 0.310 0.398 0.783
2024-03-18 08:49:04,565 - mmdet - INFO - Epoch [19][50/232]	lr: 2.000e-05, eta: 0:49:42, time: 0.869, data_time: 0.059, memory: 17650, enc_loss_cls: 0.1183, enc_loss_bbox: 0.0661, enc_loss_iou: 0.3533, loss_cls: 0.0893, loss_bbox: 0.0612, loss_iou: 0.3288, d0.loss_cls: 0.1231, d0.loss_bbox: 0.0621, d0.loss_iou: 0.3337, d1.loss_cls: 0.1002, d1.loss_bbox: 0.0611, d1.loss_iou: 0.3289, d2.loss_cls: 0.0935, d2.loss_bbox: 0.0612, d2.loss_iou: 0.3288, d3.loss_cls: 0.0898, d3.loss_bbox: 0.0612, d3.loss_iou: 0.3288, d4.loss_cls: 0.0891, d4.loss_bbox: 0.0612, d4.loss_iou: 0.3288, loss_rpn_cls: 0.0352, loss_rpn_bbox: 0.1318, loss_cls0: 1.3640, acc0: 95.2790, loss_bbox0: 2.5400, loss_cls1: 0.9345, loss_bbox1: 3.6326, loss_centerness1: 7.4747, loss_cls_aux0: 0.0136, loss_bbox_aux0: 0.0222, loss_iou_aux0: 0.1087, d0.loss_cls_aux0: 0.0234, d0.loss_bbox_aux0: 0.0457, d0.loss_iou_aux0: 0.2290, d1.loss_cls_aux0: 0.0184, d1.loss_bbox_aux0: 0.0265, d1.loss_iou_aux0: 0.1288, d2.loss_cls_aux0: 0.0153, d2.loss_bbox_aux0: 0.0220, d2.loss_iou_aux0: 0.1072, d3.loss_cls_aux0: 0.0133, d3.loss_bbox_aux0: 0.0221, d3.loss_iou_aux0: 0.1076, d4.loss_cls_aux0: 0.0132, d4.loss_bbox_aux0: 0.0221, d4.loss_iou_aux0: 0.1080, loss_cls_aux1: 0.0102, loss_bbox_aux1: 0.0486, loss_iou_aux1: 0.2561, d0.loss_cls_aux1: 0.0136, d0.loss_bbox_aux1: 0.0558, d0.loss_iou_aux1: 0.2933, d1.loss_cls_aux1: 0.0124, d1.loss_bbox_aux1: 0.0494, d1.loss_iou_aux1: 0.2602, d2.loss_cls_aux1: 0.0114, d2.loss_bbox_aux1: 0.0485, d2.loss_iou_aux1: 0.2557, d3.loss_cls_aux1: 0.0102, d3.loss_bbox_aux1: 0.0485, d3.loss_iou_aux1: 0.2558, d4.loss_cls_aux1: 0.0099, d4.loss_bbox_aux1: 0.0486, d4.loss_iou_aux1: 0.2559, loss: 22.5723, grad_norm: 67.0880
2024-03-18 08:49:45,184 - mmdet - INFO - Epoch [19][100/232]	lr: 2.000e-05, eta: 0:49:10, time: 0.812, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1279, enc_loss_bbox: 0.0692, enc_loss_iou: 0.3699, loss_cls: 0.0997, loss_bbox: 0.0646, loss_iou: 0.3468, d0.loss_cls: 0.1321, d0.loss_bbox: 0.0650, d0.loss_iou: 0.3502, d1.loss_cls: 0.1080, d1.loss_bbox: 0.0650, d1.loss_iou: 0.3477, d2.loss_cls: 0.1024, d2.loss_bbox: 0.0647, d2.loss_iou: 0.3468, d3.loss_cls: 0.1005, d3.loss_bbox: 0.0645, d3.loss_iou: 0.3464, d4.loss_cls: 0.0991, d4.loss_bbox: 0.0647, d4.loss_iou: 0.3468, loss_rpn_cls: 0.0340, loss_rpn_bbox: 0.1289, loss_cls0: 1.3913, acc0: 95.2118, loss_bbox0: 2.5813, loss_cls1: 0.9805, loss_bbox1: 3.8627, loss_centerness1: 7.4946, loss_cls_aux0: 0.0132, loss_bbox_aux0: 0.0221, loss_iou_aux0: 0.1089, d0.loss_cls_aux0: 0.0207, d0.loss_bbox_aux0: 0.0459, d0.loss_iou_aux0: 0.2319, d1.loss_cls_aux0: 0.0160, d1.loss_bbox_aux0: 0.0262, d1.loss_iou_aux0: 0.1287, d2.loss_cls_aux0: 0.0136, d2.loss_bbox_aux0: 0.0220, d2.loss_iou_aux0: 0.1074, d3.loss_cls_aux0: 0.0130, d3.loss_bbox_aux0: 0.0220, d3.loss_iou_aux0: 0.1078, d4.loss_cls_aux0: 0.0132, d4.loss_bbox_aux0: 0.0221, d4.loss_iou_aux0: 0.1083, loss_cls_aux1: 0.0105, loss_bbox_aux1: 0.0516, loss_iou_aux1: 0.2749, d0.loss_cls_aux1: 0.0133, d0.loss_bbox_aux1: 0.0595, d0.loss_iou_aux1: 0.3143, d1.loss_cls_aux1: 0.0117, d1.loss_bbox_aux1: 0.0525, d1.loss_iou_aux1: 0.2803, d2.loss_cls_aux1: 0.0108, d2.loss_bbox_aux1: 0.0516, d2.loss_iou_aux1: 0.2747, d3.loss_cls_aux1: 0.0104, d3.loss_bbox_aux1: 0.0516, d3.loss_iou_aux1: 0.2748, d4.loss_cls_aux1: 0.0107, d4.loss_bbox_aux1: 0.0516, d4.loss_iou_aux1: 0.2748, loss: 23.2777, grad_norm: 65.6544
2024-03-18 08:50:26,262 - mmdet - INFO - Epoch [19][150/232]	lr: 2.000e-05, eta: 0:48:38, time: 0.821, data_time: 0.012, memory: 17650, enc_loss_cls: 0.1224, enc_loss_bbox: 0.0669, enc_loss_iou: 0.3627, loss_cls: 0.1005, loss_bbox: 0.0623, loss_iou: 0.3370, d0.loss_cls: 0.1335, d0.loss_bbox: 0.0629, d0.loss_iou: 0.3411, d1.loss_cls: 0.1091, d1.loss_bbox: 0.0622, d1.loss_iou: 0.3374, d2.loss_cls: 0.1019, d2.loss_bbox: 0.0624, d2.loss_iou: 0.3369, d3.loss_cls: 0.1010, d3.loss_bbox: 0.0623, d3.loss_iou: 0.3368, d4.loss_cls: 0.1003, d4.loss_bbox: 0.0623, d4.loss_iou: 0.3369, loss_rpn_cls: 0.0372, loss_rpn_bbox: 0.1338, loss_cls0: 1.4371, acc0: 95.1310, loss_bbox0: 2.6698, loss_cls1: 0.9987, loss_bbox1: 3.6903, loss_centerness1: 7.5033, loss_cls_aux0: 0.0207, loss_bbox_aux0: 0.0219, loss_iou_aux0: 0.1112, d0.loss_cls_aux0: 0.0276, d0.loss_bbox_aux0: 0.0458, d0.loss_iou_aux0: 0.2343, d1.loss_cls_aux0: 0.0231, d1.loss_bbox_aux0: 0.0253, d1.loss_iou_aux0: 0.1297, d2.loss_cls_aux0: 0.0202, d2.loss_bbox_aux0: 0.0218, d2.loss_iou_aux0: 0.1100, d3.loss_cls_aux0: 0.0209, d3.loss_bbox_aux0: 0.0218, d3.loss_iou_aux0: 0.1103, d4.loss_cls_aux0: 0.0206, d4.loss_bbox_aux0: 0.0219, d4.loss_iou_aux0: 0.1107, loss_cls_aux1: 0.0180, loss_bbox_aux1: 0.0498, loss_iou_aux1: 0.2678, d0.loss_cls_aux1: 0.0194, d0.loss_bbox_aux1: 0.0581, d0.loss_iou_aux1: 0.3102, d1.loss_cls_aux1: 0.0185, d1.loss_bbox_aux1: 0.0504, d1.loss_iou_aux1: 0.2707, d2.loss_cls_aux1: 0.0179, d2.loss_bbox_aux1: 0.0497, d2.loss_iou_aux1: 0.2675, d3.loss_cls_aux1: 0.0187, d3.loss_bbox_aux1: 0.0497, d3.loss_iou_aux1: 0.2676, d4.loss_cls_aux1: 0.0182, d4.loss_bbox_aux1: 0.0497, d4.loss_iou_aux1: 0.2677, loss: 23.2365, grad_norm: 64.6708
2024-03-18 08:51:07,690 - mmdet - INFO - Epoch [19][200/232]	lr: 2.000e-05, eta: 0:48:07, time: 0.829, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1258, enc_loss_bbox: 0.0692, enc_loss_iou: 0.3673, loss_cls: 0.0999, loss_bbox: 0.0659, loss_iou: 0.3494, d0.loss_cls: 0.1315, d0.loss_bbox: 0.0663, d0.loss_iou: 0.3514, d1.loss_cls: 0.1092, d1.loss_bbox: 0.0658, d1.loss_iou: 0.3498, d2.loss_cls: 0.1025, d2.loss_bbox: 0.0658, d2.loss_iou: 0.3491, d3.loss_cls: 0.0998, d3.loss_bbox: 0.0658, d3.loss_iou: 0.3495, d4.loss_cls: 0.0999, d4.loss_bbox: 0.0659, d4.loss_iou: 0.3493, loss_rpn_cls: 0.0476, loss_rpn_bbox: 0.1543, loss_cls0: 1.4790, acc0: 94.8243, loss_bbox0: 2.6521, loss_cls1: 0.9877, loss_bbox1: 3.8277, loss_centerness1: 7.4966, loss_cls_aux0: 0.0112, loss_bbox_aux0: 0.0234, loss_iou_aux0: 0.1168, d0.loss_cls_aux0: 0.0189, d0.loss_bbox_aux0: 0.0459, d0.loss_iou_aux0: 0.2321, d1.loss_cls_aux0: 0.0139, d1.loss_bbox_aux0: 0.0268, d1.loss_iou_aux0: 0.1343, d2.loss_cls_aux0: 0.0118, d2.loss_bbox_aux0: 0.0232, d2.loss_iou_aux0: 0.1155, d3.loss_cls_aux0: 0.0116, d3.loss_bbox_aux0: 0.0233, d3.loss_iou_aux0: 0.1158, d4.loss_cls_aux0: 0.0113, d4.loss_bbox_aux0: 0.0233, d4.loss_iou_aux0: 0.1162, loss_cls_aux1: 0.0084, loss_bbox_aux1: 0.0505, loss_iou_aux1: 0.2690, d0.loss_cls_aux1: 0.0124, d0.loss_bbox_aux1: 0.0578, d0.loss_iou_aux1: 0.3050, d1.loss_cls_aux1: 0.0103, d1.loss_bbox_aux1: 0.0515, d1.loss_iou_aux1: 0.2736, d2.loss_cls_aux1: 0.0095, d2.loss_bbox_aux1: 0.0504, d2.loss_iou_aux1: 0.2686, d3.loss_cls_aux1: 0.0089, d3.loss_bbox_aux1: 0.0505, d3.loss_iou_aux1: 0.2687, d4.loss_cls_aux1: 0.0086, d4.loss_bbox_aux1: 0.0505, d4.loss_iou_aux1: 0.2689, loss: 23.4425, grad_norm: 57.4460
2024-03-18 08:51:34,365 - mmdet - INFO - Saving checkpoint at 19 epochs
2024-03-18 08:51:56,528 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:52:02,636 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.604
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.484
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.305
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.709
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.709
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.709
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.640
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.709
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.822

2024-03-18 08:52:02,637 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.069 | Tin      | 0.630 | Thatch   | 0.523 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:52:02,692 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:52:02,692 - mmdet - INFO - Epoch(val) [19][154]	bbox_mAP: 0.4070, bbox_mAP_50: 0.6040, bbox_mAP_75: 0.4840, bbox_mAP_s: 0.3050, bbox_mAP_m: 0.3880, bbox_mAP_l: 0.5850, bbox_mAP_copypaste: 0.407 0.604 0.484 0.305 0.388 0.585
2024-03-18 08:52:46,146 - mmdet - INFO - Epoch [20][50/232]	lr: 2.000e-05, eta: 0:46:53, time: 0.869, data_time: 0.060, memory: 17650, enc_loss_cls: 0.1161, enc_loss_bbox: 0.0651, enc_loss_iou: 0.3620, loss_cls: 0.0908, loss_bbox: 0.0610, loss_iou: 0.3398, d0.loss_cls: 0.1214, d0.loss_bbox: 0.0618, d0.loss_iou: 0.3439, d1.loss_cls: 0.0979, d1.loss_bbox: 0.0607, d1.loss_iou: 0.3400, d2.loss_cls: 0.0935, d2.loss_bbox: 0.0607, d2.loss_iou: 0.3392, d3.loss_cls: 0.0901, d3.loss_bbox: 0.0610, d3.loss_iou: 0.3399, d4.loss_cls: 0.0903, d4.loss_bbox: 0.0609, d4.loss_iou: 0.3396, loss_rpn_cls: 0.0267, loss_rpn_bbox: 0.1360, loss_cls0: 1.4177, acc0: 95.1002, loss_bbox0: 2.5824, loss_cls1: 0.9318, loss_bbox1: 3.6675, loss_centerness1: 7.4985, loss_cls_aux0: 0.0177, loss_bbox_aux0: 0.0220, loss_iou_aux0: 0.1117, d0.loss_cls_aux0: 0.0236, d0.loss_bbox_aux0: 0.0446, d0.loss_iou_aux0: 0.2318, d1.loss_cls_aux0: 0.0198, d1.loss_bbox_aux0: 0.0256, d1.loss_iou_aux0: 0.1300, d2.loss_cls_aux0: 0.0195, d2.loss_bbox_aux0: 0.0218, d2.loss_iou_aux0: 0.1104, d3.loss_cls_aux0: 0.0183, d3.loss_bbox_aux0: 0.0218, d3.loss_iou_aux0: 0.1107, d4.loss_cls_aux0: 0.0180, d4.loss_bbox_aux0: 0.0219, d4.loss_iou_aux0: 0.1111, loss_cls_aux1: 0.0115, loss_bbox_aux1: 0.0487, loss_iou_aux1: 0.2652, d0.loss_cls_aux1: 0.0141, d0.loss_bbox_aux1: 0.0556, d0.loss_iou_aux1: 0.3027, d1.loss_cls_aux1: 0.0124, d1.loss_bbox_aux1: 0.0493, d1.loss_iou_aux1: 0.2686, d2.loss_cls_aux1: 0.0117, d2.loss_bbox_aux1: 0.0486, d2.loss_iou_aux1: 0.2649, d3.loss_cls_aux1: 0.0112, d3.loss_bbox_aux1: 0.0486, d3.loss_iou_aux1: 0.2650, d4.loss_cls_aux1: 0.0115, d4.loss_bbox_aux1: 0.0486, d4.loss_iou_aux1: 0.2651, loss: 22.8798, grad_norm: 61.2093
2024-03-18 08:53:26,997 - mmdet - INFO - Epoch [20][100/232]	lr: 2.000e-05, eta: 0:46:21, time: 0.817, data_time: 0.009, memory: 17650, enc_loss_cls: 0.1245, enc_loss_bbox: 0.0689, enc_loss_iou: 0.3652, loss_cls: 0.0970, loss_bbox: 0.0636, loss_iou: 0.3405, d0.loss_cls: 0.1290, d0.loss_bbox: 0.0642, d0.loss_iou: 0.3431, d1.loss_cls: 0.1043, d1.loss_bbox: 0.0639, d1.loss_iou: 0.3416, d2.loss_cls: 0.0985, d2.loss_bbox: 0.0635, d2.loss_iou: 0.3401, d3.loss_cls: 0.0962, d3.loss_bbox: 0.0634, d3.loss_iou: 0.3404, d4.loss_cls: 0.0962, d4.loss_bbox: 0.0634, d4.loss_iou: 0.3405, loss_rpn_cls: 0.0321, loss_rpn_bbox: 0.1220, loss_cls0: 1.3626, acc0: 95.4209, loss_bbox0: 2.6280, loss_cls1: 0.9651, loss_bbox1: 3.6809, loss_centerness1: 7.4653, loss_cls_aux0: 0.0140, loss_bbox_aux0: 0.0216, loss_iou_aux0: 0.1072, d0.loss_cls_aux0: 0.0203, d0.loss_bbox_aux0: 0.0466, d0.loss_iou_aux0: 0.2334, d1.loss_cls_aux0: 0.0161, d1.loss_bbox_aux0: 0.0252, d1.loss_iou_aux0: 0.1248, d2.loss_cls_aux0: 0.0144, d2.loss_bbox_aux0: 0.0214, d2.loss_iou_aux0: 0.1058, d3.loss_cls_aux0: 0.0142, d3.loss_bbox_aux0: 0.0215, d3.loss_iou_aux0: 0.1062, d4.loss_cls_aux0: 0.0142, d4.loss_bbox_aux0: 0.0215, d4.loss_iou_aux0: 0.1066, loss_cls_aux1: 0.0126, loss_bbox_aux1: 0.0500, loss_iou_aux1: 0.2646, d0.loss_cls_aux1: 0.0151, d0.loss_bbox_aux1: 0.0580, d0.loss_iou_aux1: 0.3060, d1.loss_cls_aux1: 0.0141, d1.loss_bbox_aux1: 0.0508, d1.loss_iou_aux1: 0.2688, d2.loss_cls_aux1: 0.0129, d2.loss_bbox_aux1: 0.0499, d2.loss_iou_aux1: 0.2642, d3.loss_cls_aux1: 0.0124, d3.loss_bbox_aux1: 0.0499, d3.loss_iou_aux1: 0.2643, d4.loss_cls_aux1: 0.0126, d4.loss_bbox_aux1: 0.0500, d4.loss_iou_aux1: 0.2645, loss: 22.9201, grad_norm: 66.8320
2024-03-18 08:54:07,978 - mmdet - INFO - Epoch [20][150/232]	lr: 2.000e-05, eta: 0:45:49, time: 0.820, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1287, enc_loss_bbox: 0.0651, enc_loss_iou: 0.3588, loss_cls: 0.1042, loss_bbox: 0.0599, loss_iou: 0.3319, d0.loss_cls: 0.1312, d0.loss_bbox: 0.0611, d0.loss_iou: 0.3385, d1.loss_cls: 0.1095, d1.loss_bbox: 0.0603, d1.loss_iou: 0.3331, d2.loss_cls: 0.1065, d2.loss_bbox: 0.0597, d2.loss_iou: 0.3311, d3.loss_cls: 0.1048, d3.loss_bbox: 0.0598, d3.loss_iou: 0.3314, d4.loss_cls: 0.1052, d4.loss_bbox: 0.0598, d4.loss_iou: 0.3313, loss_rpn_cls: 0.0375, loss_rpn_bbox: 0.1211, loss_cls0: 1.3537, acc0: 95.3066, loss_bbox0: 2.5289, loss_cls1: 0.9842, loss_bbox1: 3.6089, loss_centerness1: 7.4769, loss_cls_aux0: 0.0145, loss_bbox_aux0: 0.0211, loss_iou_aux0: 0.1043, d0.loss_cls_aux0: 0.0215, d0.loss_bbox_aux0: 0.0449, d0.loss_iou_aux0: 0.2302, d1.loss_cls_aux0: 0.0176, d1.loss_bbox_aux0: 0.0246, d1.loss_iou_aux0: 0.1235, d2.loss_cls_aux0: 0.0149, d2.loss_bbox_aux0: 0.0210, d2.loss_iou_aux0: 0.1037, d3.loss_cls_aux0: 0.0138, d3.loss_bbox_aux0: 0.0210, d3.loss_iou_aux0: 0.1039, d4.loss_cls_aux0: 0.0138, d4.loss_bbox_aux0: 0.0210, d4.loss_iou_aux0: 0.1041, loss_cls_aux1: 0.0136, loss_bbox_aux1: 0.0479, loss_iou_aux1: 0.2569, d0.loss_cls_aux1: 0.0159, d0.loss_bbox_aux1: 0.0556, d0.loss_iou_aux1: 0.2970, d1.loss_cls_aux1: 0.0152, d1.loss_bbox_aux1: 0.0489, d1.loss_iou_aux1: 0.2625, d2.loss_cls_aux1: 0.0137, d2.loss_bbox_aux1: 0.0479, d2.loss_iou_aux1: 0.2568, d3.loss_cls_aux1: 0.0130, d3.loss_bbox_aux1: 0.0479, d3.loss_iou_aux1: 0.2569, d4.loss_cls_aux1: 0.0128, d4.loss_bbox_aux1: 0.0479, d4.loss_iou_aux1: 0.2569, loss: 22.6699, grad_norm: 63.6032
2024-03-18 08:54:49,432 - mmdet - INFO - Epoch [20][200/232]	lr: 2.000e-05, eta: 0:45:17, time: 0.829, data_time: 0.009, memory: 17650, enc_loss_cls: 0.1205, enc_loss_bbox: 0.0730, enc_loss_iou: 0.3789, loss_cls: 0.1029, loss_bbox: 0.0674, loss_iou: 0.3518, d0.loss_cls: 0.1322, d0.loss_bbox: 0.0685, d0.loss_iou: 0.3565, d1.loss_cls: 0.1110, d1.loss_bbox: 0.0673, d1.loss_iou: 0.3518, d2.loss_cls: 0.1052, d2.loss_bbox: 0.0673, d2.loss_iou: 0.3512, d3.loss_cls: 0.1031, d3.loss_bbox: 0.0674, d3.loss_iou: 0.3513, d4.loss_cls: 0.1031, d4.loss_bbox: 0.0675, d4.loss_iou: 0.3516, loss_rpn_cls: 0.0380, loss_rpn_bbox: 0.1586, loss_cls0: 1.5369, acc0: 94.6879, loss_bbox0: 2.7645, loss_cls1: 1.0046, loss_bbox1: 3.8921, loss_centerness1: 7.4845, loss_cls_aux0: 0.0150, loss_bbox_aux0: 0.0237, loss_iou_aux0: 0.1143, d0.loss_cls_aux0: 0.0208, d0.loss_bbox_aux0: 0.0476, d0.loss_iou_aux0: 0.2320, d1.loss_cls_aux0: 0.0165, d1.loss_bbox_aux0: 0.0273, d1.loss_iou_aux0: 0.1315, d2.loss_cls_aux0: 0.0150, d2.loss_bbox_aux0: 0.0235, d2.loss_iou_aux0: 0.1130, d3.loss_cls_aux0: 0.0150, d3.loss_bbox_aux0: 0.0236, d3.loss_iou_aux0: 0.1134, d4.loss_cls_aux0: 0.0152, d4.loss_bbox_aux0: 0.0236, d4.loss_iou_aux0: 0.1138, loss_cls_aux1: 0.0176, loss_bbox_aux1: 0.0511, loss_iou_aux1: 0.2676, d0.loss_cls_aux1: 0.0193, d0.loss_bbox_aux1: 0.0607, d0.loss_iou_aux1: 0.3128, d1.loss_cls_aux1: 0.0178, d1.loss_bbox_aux1: 0.0521, d1.loss_iou_aux1: 0.2723, d2.loss_cls_aux1: 0.0174, d2.loss_bbox_aux1: 0.0511, d2.loss_iou_aux1: 0.2674, d3.loss_cls_aux1: 0.0180, d3.loss_bbox_aux1: 0.0511, d3.loss_iou_aux1: 0.2675, d4.loss_cls_aux1: 0.0181, d4.loss_bbox_aux1: 0.0511, d4.loss_iou_aux1: 0.2675, loss: 23.7941, grad_norm: 67.4226
2024-03-18 08:55:16,132 - mmdet - INFO - Saving checkpoint at 20 epochs
2024-03-18 08:55:38,449 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:55:44,663 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.605
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.483
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.304
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.394
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.778
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.681
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.569
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.688
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.816

2024-03-18 08:55:44,663 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.066 | Tin      | 0.626 | Thatch   | 0.527 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:55:44,730 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:55:44,730 - mmdet - INFO - Epoch(val) [20][154]	bbox_mAP: 0.4060, bbox_mAP_50: 0.6050, bbox_mAP_75: 0.4830, bbox_mAP_s: 0.3040, bbox_mAP_m: 0.3940, bbox_mAP_l: 0.7780, bbox_mAP_copypaste: 0.406 0.605 0.483 0.304 0.394 0.778
2024-03-18 08:56:28,328 - mmdet - INFO - Epoch [21][50/232]	lr: 2.000e-05, eta: 0:44:05, time: 0.872, data_time: 0.061, memory: 17650, enc_loss_cls: 0.1139, enc_loss_bbox: 0.0662, enc_loss_iou: 0.3643, loss_cls: 0.0910, loss_bbox: 0.0617, loss_iou: 0.3407, d0.loss_cls: 0.1309, d0.loss_bbox: 0.0625, d0.loss_iou: 0.3456, d1.loss_cls: 0.0986, d1.loss_bbox: 0.0618, d1.loss_iou: 0.3409, d2.loss_cls: 0.0938, d2.loss_bbox: 0.0616, d2.loss_iou: 0.3405, d3.loss_cls: 0.0914, d3.loss_bbox: 0.0617, d3.loss_iou: 0.3407, d4.loss_cls: 0.0913, d4.loss_bbox: 0.0616, d4.loss_iou: 0.3406, loss_rpn_cls: 0.0292, loss_rpn_bbox: 0.1419, loss_cls0: 1.4015, acc0: 95.1959, loss_bbox0: 2.5748, loss_cls1: 0.9356, loss_bbox1: 3.7495, loss_centerness1: 7.4838, loss_cls_aux0: 0.0130, loss_bbox_aux0: 0.0240, loss_iou_aux0: 0.1175, d0.loss_cls_aux0: 0.0206, d0.loss_bbox_aux0: 0.0463, d0.loss_iou_aux0: 0.2302, d1.loss_cls_aux0: 0.0152, d1.loss_bbox_aux0: 0.0279, d1.loss_iou_aux0: 0.1348, d2.loss_cls_aux0: 0.0137, d2.loss_bbox_aux0: 0.0238, d2.loss_iou_aux0: 0.1150, d3.loss_cls_aux0: 0.0128, d3.loss_bbox_aux0: 0.0238, d3.loss_iou_aux0: 0.1156, d4.loss_cls_aux0: 0.0128, d4.loss_bbox_aux0: 0.0239, d4.loss_iou_aux0: 0.1165, loss_cls_aux1: 0.0101, loss_bbox_aux1: 0.0499, loss_iou_aux1: 0.2681, d0.loss_cls_aux1: 0.0132, d0.loss_bbox_aux1: 0.0566, d0.loss_iou_aux1: 0.3009, d1.loss_cls_aux1: 0.0112, d1.loss_bbox_aux1: 0.0506, d1.loss_iou_aux1: 0.2710, d2.loss_cls_aux1: 0.0106, d2.loss_bbox_aux1: 0.0498, d2.loss_iou_aux1: 0.2678, d3.loss_cls_aux1: 0.0098, d3.loss_bbox_aux1: 0.0499, d3.loss_iou_aux1: 0.2679, d4.loss_cls_aux1: 0.0102, d4.loss_bbox_aux1: 0.0499, d4.loss_iou_aux1: 0.2680, loss: 22.9805, grad_norm: 63.1431
2024-03-18 08:57:08,962 - mmdet - INFO - Epoch [21][100/232]	lr: 2.000e-05, eta: 0:43:32, time: 0.813, data_time: 0.009, memory: 17650, enc_loss_cls: 0.1185, enc_loss_bbox: 0.0724, enc_loss_iou: 0.3730, loss_cls: 0.0958, loss_bbox: 0.0645, loss_iou: 0.3398, d0.loss_cls: 0.1297, d0.loss_bbox: 0.0656, d0.loss_iou: 0.3438, d1.loss_cls: 0.1055, d1.loss_bbox: 0.0647, d1.loss_iou: 0.3400, d2.loss_cls: 0.0985, d2.loss_bbox: 0.0645, d2.loss_iou: 0.3392, d3.loss_cls: 0.0957, d3.loss_bbox: 0.0645, d3.loss_iou: 0.3393, d4.loss_cls: 0.0953, d4.loss_bbox: 0.0645, d4.loss_iou: 0.3396, loss_rpn_cls: 0.0357, loss_rpn_bbox: 0.1317, loss_cls0: 1.3958, acc0: 95.2465, loss_bbox0: 2.5371, loss_cls1: 0.9936, loss_bbox1: 3.7033, loss_centerness1: 7.4804, loss_cls_aux0: 0.0167, loss_bbox_aux0: 0.0239, loss_iou_aux0: 0.1155, d0.loss_cls_aux0: 0.0251, d0.loss_bbox_aux0: 0.0483, d0.loss_iou_aux0: 0.2320, d1.loss_cls_aux0: 0.0213, d1.loss_bbox_aux0: 0.0283, d1.loss_iou_aux0: 0.1343, d2.loss_cls_aux0: 0.0181, d2.loss_bbox_aux0: 0.0237, d2.loss_iou_aux0: 0.1135, d3.loss_cls_aux0: 0.0166, d3.loss_bbox_aux0: 0.0238, d3.loss_iou_aux0: 0.1140, d4.loss_cls_aux0: 0.0168, d4.loss_bbox_aux0: 0.0239, d4.loss_iou_aux0: 0.1147, loss_cls_aux1: 0.0137, loss_bbox_aux1: 0.0504, loss_iou_aux1: 0.2600, d0.loss_cls_aux1: 0.0176, d0.loss_bbox_aux1: 0.0579, d0.loss_iou_aux1: 0.2958, d1.loss_cls_aux1: 0.0161, d1.loss_bbox_aux1: 0.0515, d1.loss_iou_aux1: 0.2659, d2.loss_cls_aux1: 0.0137, d2.loss_bbox_aux1: 0.0503, d2.loss_iou_aux1: 0.2595, d3.loss_cls_aux1: 0.0132, d3.loss_bbox_aux1: 0.0503, d3.loss_iou_aux1: 0.2597, d4.loss_cls_aux1: 0.0135, d4.loss_bbox_aux1: 0.0504, d4.loss_iou_aux1: 0.2598, loss: 23.0017, grad_norm: 75.0203
2024-03-18 08:57:49,783 - mmdet - INFO - Epoch [21][150/232]	lr: 2.000e-05, eta: 0:42:59, time: 0.816, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1128, enc_loss_bbox: 0.0682, enc_loss_iou: 0.3660, loss_cls: 0.0883, loss_bbox: 0.0622, loss_iou: 0.3346, d0.loss_cls: 0.1181, d0.loss_bbox: 0.0634, d0.loss_iou: 0.3417, d1.loss_cls: 0.0944, d1.loss_bbox: 0.0623, d1.loss_iou: 0.3352, d2.loss_cls: 0.0912, d2.loss_bbox: 0.0622, d2.loss_iou: 0.3343, d3.loss_cls: 0.0892, d3.loss_bbox: 0.0622, d3.loss_iou: 0.3346, d4.loss_cls: 0.0883, d4.loss_bbox: 0.0622, d4.loss_iou: 0.3348, loss_rpn_cls: 0.0371, loss_rpn_bbox: 0.1281, loss_cls0: 1.3310, acc0: 95.4361, loss_bbox0: 2.4893, loss_cls1: 0.9511, loss_bbox1: 3.6898, loss_centerness1: 7.4849, loss_cls_aux0: 0.0098, loss_bbox_aux0: 0.0228, loss_iou_aux0: 0.1143, d0.loss_cls_aux0: 0.0181, d0.loss_bbox_aux0: 0.0443, d0.loss_iou_aux0: 0.2260, d1.loss_cls_aux0: 0.0132, d1.loss_bbox_aux0: 0.0253, d1.loss_iou_aux0: 0.1268, d2.loss_cls_aux0: 0.0109, d2.loss_bbox_aux0: 0.0226, d2.loss_iou_aux0: 0.1126, d3.loss_cls_aux0: 0.0102, d3.loss_bbox_aux0: 0.0227, d3.loss_iou_aux0: 0.1131, d4.loss_cls_aux0: 0.0101, d4.loss_bbox_aux0: 0.0228, d4.loss_iou_aux0: 0.1136, loss_cls_aux1: 0.0080, loss_bbox_aux1: 0.0496, loss_iou_aux1: 0.2643, d0.loss_cls_aux1: 0.0110, d0.loss_bbox_aux1: 0.0558, d0.loss_iou_aux1: 0.2979, d1.loss_cls_aux1: 0.0097, d1.loss_bbox_aux1: 0.0500, d1.loss_iou_aux1: 0.2668, d2.loss_cls_aux1: 0.0083, d2.loss_bbox_aux1: 0.0495, d2.loss_iou_aux1: 0.2641, d3.loss_cls_aux1: 0.0083, d3.loss_bbox_aux1: 0.0495, d3.loss_iou_aux1: 0.2641, d4.loss_cls_aux1: 0.0083, d4.loss_bbox_aux1: 0.0495, d4.loss_iou_aux1: 0.2642, loss: 22.6357, grad_norm: 65.3738
2024-03-18 08:58:31,253 - mmdet - INFO - Epoch [21][200/232]	lr: 2.000e-05, eta: 0:42:27, time: 0.830, data_time: 0.009, memory: 17650, enc_loss_cls: 0.1115, enc_loss_bbox: 0.0673, enc_loss_iou: 0.3623, loss_cls: 0.0938, loss_bbox: 0.0615, loss_iou: 0.3343, d0.loss_cls: 0.1326, d0.loss_bbox: 0.0622, d0.loss_iou: 0.3390, d1.loss_cls: 0.1032, d1.loss_bbox: 0.0617, d1.loss_iou: 0.3357, d2.loss_cls: 0.0970, d2.loss_bbox: 0.0615, d2.loss_iou: 0.3341, d3.loss_cls: 0.0941, d3.loss_bbox: 0.0616, d3.loss_iou: 0.3344, d4.loss_cls: 0.0938, d4.loss_bbox: 0.0616, d4.loss_iou: 0.3341, loss_rpn_cls: 0.0376, loss_rpn_bbox: 0.1335, loss_cls0: 1.4593, acc0: 95.0759, loss_bbox0: 2.6247, loss_cls1: 0.9233, loss_bbox1: 3.6981, loss_centerness1: 7.4745, loss_cls_aux0: 0.0226, loss_bbox_aux0: 0.0228, loss_iou_aux0: 0.1125, d0.loss_cls_aux0: 0.0290, d0.loss_bbox_aux0: 0.0452, d0.loss_iou_aux0: 0.2300, d1.loss_cls_aux0: 0.0240, d1.loss_bbox_aux0: 0.0267, d1.loss_iou_aux0: 0.1327, d2.loss_cls_aux0: 0.0227, d2.loss_bbox_aux0: 0.0226, d2.loss_iou_aux0: 0.1114, d3.loss_cls_aux0: 0.0227, d3.loss_bbox_aux0: 0.0227, d3.loss_iou_aux0: 0.1117, d4.loss_cls_aux0: 0.0221, d4.loss_bbox_aux0: 0.0227, d4.loss_iou_aux0: 0.1121, loss_cls_aux1: 0.0186, loss_bbox_aux1: 0.0481, loss_iou_aux1: 0.2628, d0.loss_cls_aux1: 0.0205, d0.loss_bbox_aux1: 0.0557, d0.loss_iou_aux1: 0.3023, d1.loss_cls_aux1: 0.0204, d1.loss_bbox_aux1: 0.0490, d1.loss_iou_aux1: 0.2671, d2.loss_cls_aux1: 0.0193, d2.loss_bbox_aux1: 0.0481, d2.loss_iou_aux1: 0.2624, d3.loss_cls_aux1: 0.0192, d3.loss_bbox_aux1: 0.0481, d3.loss_iou_aux1: 0.2625, d4.loss_cls_aux1: 0.0185, d4.loss_bbox_aux1: 0.0481, d4.loss_iou_aux1: 0.2627, loss: 23.0384, grad_norm: 70.7901
2024-03-18 08:58:58,151 - mmdet - INFO - Saving checkpoint at 21 epochs
2024-03-18 08:59:20,427 - mmdet - INFO - Evaluating bbox...
2024-03-18 08:59:25,914 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.596
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.297
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.389
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.786
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.696
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.696
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.696
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.590
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.704
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.821

2024-03-18 08:59:25,914 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.040 | Tin      | 0.619 | Thatch   | 0.530 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 08:59:25,966 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 08:59:25,967 - mmdet - INFO - Epoch(val) [21][154]	bbox_mAP: 0.3960, bbox_mAP_50: 0.5960, bbox_mAP_75: 0.4720, bbox_mAP_s: 0.2970, bbox_mAP_m: 0.3890, bbox_mAP_l: 0.7860, bbox_mAP_copypaste: 0.396 0.596 0.472 0.297 0.389 0.786
2024-03-18 09:00:09,850 - mmdet - INFO - Epoch [22][50/232]	lr: 2.000e-05, eta: 0:41:17, time: 0.877, data_time: 0.062, memory: 17650, enc_loss_cls: 0.1218, enc_loss_bbox: 0.0644, enc_loss_iou: 0.3578, loss_cls: 0.0980, loss_bbox: 0.0603, loss_iou: 0.3336, d0.loss_cls: 0.1283, d0.loss_bbox: 0.0607, d0.loss_iou: 0.3355, d1.loss_cls: 0.1044, d1.loss_bbox: 0.0603, d1.loss_iou: 0.3331, d2.loss_cls: 0.1005, d2.loss_bbox: 0.0603, d2.loss_iou: 0.3332, d3.loss_cls: 0.0994, d3.loss_bbox: 0.0602, d3.loss_iou: 0.3330, d4.loss_cls: 0.0974, d4.loss_bbox: 0.0603, d4.loss_iou: 0.3337, loss_rpn_cls: 0.0318, loss_rpn_bbox: 0.1286, loss_cls0: 1.3490, acc0: 95.3948, loss_bbox0: 2.5069, loss_cls1: 0.9409, loss_bbox1: 3.6483, loss_centerness1: 7.4683, loss_cls_aux0: 0.0139, loss_bbox_aux0: 0.0213, loss_iou_aux0: 0.1102, d0.loss_cls_aux0: 0.0220, d0.loss_bbox_aux0: 0.0445, d0.loss_iou_aux0: 0.2237, d1.loss_cls_aux0: 0.0177, d1.loss_bbox_aux0: 0.0255, d1.loss_iou_aux0: 0.1297, d2.loss_cls_aux0: 0.0155, d2.loss_bbox_aux0: 0.0212, d2.loss_iou_aux0: 0.1089, d3.loss_cls_aux0: 0.0141, d3.loss_bbox_aux0: 0.0212, d3.loss_iou_aux0: 0.1093, d4.loss_cls_aux0: 0.0139, d4.loss_bbox_aux0: 0.0213, d4.loss_iou_aux0: 0.1097, loss_cls_aux1: 0.0137, loss_bbox_aux1: 0.0480, loss_iou_aux1: 0.2609, d0.loss_cls_aux1: 0.0176, d0.loss_bbox_aux1: 0.0541, d0.loss_iou_aux1: 0.2936, d1.loss_cls_aux1: 0.0164, d1.loss_bbox_aux1: 0.0488, d1.loss_iou_aux1: 0.2651, d2.loss_cls_aux1: 0.0148, d2.loss_bbox_aux1: 0.0479, d2.loss_iou_aux1: 0.2606, d3.loss_cls_aux1: 0.0134, d3.loss_bbox_aux1: 0.0479, d3.loss_iou_aux1: 0.2607, d4.loss_cls_aux1: 0.0136, d4.loss_bbox_aux1: 0.0480, d4.loss_iou_aux1: 0.2608, loss: 22.6399, grad_norm: 70.4547
2024-03-18 09:00:50,300 - mmdet - INFO - Epoch [22][100/232]	lr: 2.000e-05, eta: 0:40:44, time: 0.809, data_time: 0.009, memory: 17650, enc_loss_cls: 0.1222, enc_loss_bbox: 0.0722, enc_loss_iou: 0.3750, loss_cls: 0.0967, loss_bbox: 0.0669, loss_iou: 0.3512, d0.loss_cls: 0.1301, d0.loss_bbox: 0.0679, d0.loss_iou: 0.3564, d1.loss_cls: 0.1061, d1.loss_bbox: 0.0670, d1.loss_iou: 0.3511, d2.loss_cls: 0.0993, d2.loss_bbox: 0.0668, d2.loss_iou: 0.3506, d3.loss_cls: 0.0964, d3.loss_bbox: 0.0668, d3.loss_iou: 0.3509, d4.loss_cls: 0.0963, d4.loss_bbox: 0.0668, d4.loss_iou: 0.3509, loss_rpn_cls: 0.0354, loss_rpn_bbox: 0.1505, loss_cls0: 1.4268, acc0: 95.1044, loss_bbox0: 2.5717, loss_cls1: 0.9575, loss_bbox1: 3.8135, loss_centerness1: 7.4882, loss_cls_aux0: 0.0139, loss_bbox_aux0: 0.0242, loss_iou_aux0: 0.1155, d0.loss_cls_aux0: 0.0215, d0.loss_bbox_aux0: 0.0463, d0.loss_iou_aux0: 0.2307, d1.loss_cls_aux0: 0.0173, d1.loss_bbox_aux0: 0.0276, d1.loss_iou_aux0: 0.1334, d2.loss_cls_aux0: 0.0140, d2.loss_bbox_aux0: 0.0240, d2.loss_iou_aux0: 0.1145, d3.loss_cls_aux0: 0.0133, d3.loss_bbox_aux0: 0.0241, d3.loss_iou_aux0: 0.1148, d4.loss_cls_aux0: 0.0137, d4.loss_bbox_aux0: 0.0241, d4.loss_iou_aux0: 0.1151, loss_cls_aux1: 0.0104, loss_bbox_aux1: 0.0520, loss_iou_aux1: 0.2707, d0.loss_cls_aux1: 0.0130, d0.loss_bbox_aux1: 0.0596, d0.loss_iou_aux1: 0.3100, d1.loss_cls_aux1: 0.0119, d1.loss_bbox_aux1: 0.0527, d1.loss_iou_aux1: 0.2750, d2.loss_cls_aux1: 0.0111, d2.loss_bbox_aux1: 0.0519, d2.loss_iou_aux1: 0.2703, d3.loss_cls_aux1: 0.0104, d3.loss_bbox_aux1: 0.0519, d3.loss_iou_aux1: 0.2704, d4.loss_cls_aux1: 0.0103, d4.loss_bbox_aux1: 0.0519, d4.loss_iou_aux1: 0.2705, loss: 23.2931, grad_norm: 60.7822
2024-03-18 09:01:31,295 - mmdet - INFO - Epoch [22][150/232]	lr: 2.000e-05, eta: 0:40:11, time: 0.820, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1233, enc_loss_bbox: 0.0680, enc_loss_iou: 0.3573, loss_cls: 0.0940, loss_bbox: 0.0631, loss_iou: 0.3355, d0.loss_cls: 0.1268, d0.loss_bbox: 0.0639, d0.loss_iou: 0.3396, d1.loss_cls: 0.0994, d1.loss_bbox: 0.0630, d1.loss_iou: 0.3354, d2.loss_cls: 0.0943, d2.loss_bbox: 0.0630, d2.loss_iou: 0.3347, d3.loss_cls: 0.0928, d3.loss_bbox: 0.0630, d3.loss_iou: 0.3351, d4.loss_cls: 0.0937, d4.loss_bbox: 0.0631, d4.loss_iou: 0.3351, loss_rpn_cls: 0.0343, loss_rpn_bbox: 0.1293, loss_cls0: 1.3329, acc0: 95.3973, loss_bbox0: 2.5270, loss_cls1: 0.9824, loss_bbox1: 3.7521, loss_centerness1: 7.4811, loss_cls_aux0: 0.0105, loss_bbox_aux0: 0.0238, loss_iou_aux0: 0.1147, d0.loss_cls_aux0: 0.0175, d0.loss_bbox_aux0: 0.0479, d0.loss_iou_aux0: 0.2370, d1.loss_cls_aux0: 0.0129, d1.loss_bbox_aux0: 0.0273, d1.loss_iou_aux0: 0.1312, d2.loss_cls_aux0: 0.0111, d2.loss_bbox_aux0: 0.0236, d2.loss_iou_aux0: 0.1125, d3.loss_cls_aux0: 0.0107, d3.loss_bbox_aux0: 0.0236, d3.loss_iou_aux0: 0.1130, d4.loss_cls_aux0: 0.0103, d4.loss_bbox_aux0: 0.0237, d4.loss_iou_aux0: 0.1138, loss_cls_aux1: 0.0091, loss_bbox_aux1: 0.0503, loss_iou_aux1: 0.2630, d0.loss_cls_aux1: 0.0112, d0.loss_bbox_aux1: 0.0585, d0.loss_iou_aux1: 0.3051, d1.loss_cls_aux1: 0.0097, d1.loss_bbox_aux1: 0.0512, d1.loss_iou_aux1: 0.2675, d2.loss_cls_aux1: 0.0089, d2.loss_bbox_aux1: 0.0502, d2.loss_iou_aux1: 0.2623, d3.loss_cls_aux1: 0.0089, d3.loss_bbox_aux1: 0.0502, d3.loss_iou_aux1: 0.2625, d4.loss_cls_aux1: 0.0088, d4.loss_bbox_aux1: 0.0502, d4.loss_iou_aux1: 0.2627, loss: 22.8386, grad_norm: 67.3694
2024-03-18 09:02:12,865 - mmdet - INFO - Epoch [22][200/232]	lr: 2.000e-05, eta: 0:39:38, time: 0.831, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1146, enc_loss_bbox: 0.0665, enc_loss_iou: 0.3532, loss_cls: 0.0903, loss_bbox: 0.0609, loss_iou: 0.3270, d0.loss_cls: 0.1281, d0.loss_bbox: 0.0614, d0.loss_iou: 0.3295, d1.loss_cls: 0.1004, d1.loss_bbox: 0.0609, d1.loss_iou: 0.3272, d2.loss_cls: 0.0955, d2.loss_bbox: 0.0608, d2.loss_iou: 0.3266, d3.loss_cls: 0.0912, d3.loss_bbox: 0.0608, d3.loss_iou: 0.3267, d4.loss_cls: 0.0902, d4.loss_bbox: 0.0609, d4.loss_iou: 0.3266, loss_rpn_cls: 0.0350, loss_rpn_bbox: 0.1238, loss_cls0: 1.3737, acc0: 95.3129, loss_bbox0: 2.5635, loss_cls1: 0.9392, loss_bbox1: 3.4741, loss_centerness1: 7.4685, loss_cls_aux0: 0.0160, loss_bbox_aux0: 0.0222, loss_iou_aux0: 0.1099, d0.loss_cls_aux0: 0.0233, d0.loss_bbox_aux0: 0.0443, d0.loss_iou_aux0: 0.2215, d1.loss_cls_aux0: 0.0188, d1.loss_bbox_aux0: 0.0256, d1.loss_iou_aux0: 0.1255, d2.loss_cls_aux0: 0.0173, d2.loss_bbox_aux0: 0.0220, d2.loss_iou_aux0: 0.1078, d3.loss_cls_aux0: 0.0165, d3.loss_bbox_aux0: 0.0221, d3.loss_iou_aux0: 0.1085, d4.loss_cls_aux0: 0.0163, d4.loss_bbox_aux0: 0.0221, d4.loss_iou_aux0: 0.1091, loss_cls_aux1: 0.0148, loss_bbox_aux1: 0.0485, loss_iou_aux1: 0.2526, d0.loss_cls_aux1: 0.0159, d0.loss_bbox_aux1: 0.0553, d0.loss_iou_aux1: 0.2851, d1.loss_cls_aux1: 0.0148, d1.loss_bbox_aux1: 0.0493, d1.loss_iou_aux1: 0.2559, d2.loss_cls_aux1: 0.0152, d2.loss_bbox_aux1: 0.0484, d2.loss_iou_aux1: 0.2523, d3.loss_cls_aux1: 0.0157, d3.loss_bbox_aux1: 0.0484, d3.loss_iou_aux1: 0.2524, d4.loss_cls_aux1: 0.0155, d4.loss_bbox_aux1: 0.0484, d4.loss_iou_aux1: 0.2525, loss: 22.4270, grad_norm: 73.5967
2024-03-18 09:02:39,712 - mmdet - INFO - Saving checkpoint at 22 epochs
2024-03-18 09:03:01,821 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:03:07,398 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.596
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.472
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.291
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.783
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.698
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.568
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.707
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.822

2024-03-18 09:03:07,399 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.055 | Tin      | 0.621 | Thatch   | 0.520 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:03:07,455 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:03:07,455 - mmdet - INFO - Epoch(val) [22][154]	bbox_mAP: 0.3990, bbox_mAP_50: 0.5960, bbox_mAP_75: 0.4720, bbox_mAP_s: 0.2910, bbox_mAP_m: 0.3860, bbox_mAP_l: 0.7830, bbox_mAP_copypaste: 0.399 0.596 0.472 0.291 0.386 0.783
2024-03-18 09:03:50,947 - mmdet - INFO - Epoch [23][50/232]	lr: 2.000e-05, eta: 0:38:29, time: 0.870, data_time: 0.064, memory: 17650, enc_loss_cls: 0.1122, enc_loss_bbox: 0.0694, enc_loss_iou: 0.3571, loss_cls: 0.0926, loss_bbox: 0.0638, loss_iou: 0.3310, d0.loss_cls: 0.1335, d0.loss_bbox: 0.0646, d0.loss_iou: 0.3341, d1.loss_cls: 0.1028, d1.loss_bbox: 0.0640, d1.loss_iou: 0.3315, d2.loss_cls: 0.0956, d2.loss_bbox: 0.0638, d2.loss_iou: 0.3306, d3.loss_cls: 0.0928, d3.loss_bbox: 0.0638, d3.loss_iou: 0.3308, d4.loss_cls: 0.0925, d4.loss_bbox: 0.0638, d4.loss_iou: 0.3308, loss_rpn_cls: 0.0411, loss_rpn_bbox: 0.1450, loss_cls0: 1.4400, acc0: 95.0787, loss_bbox0: 2.6296, loss_cls1: 0.9732, loss_bbox1: 3.6735, loss_centerness1: 7.4595, loss_cls_aux0: 0.0149, loss_bbox_aux0: 0.0239, loss_iou_aux0: 0.1150, d0.loss_cls_aux0: 0.0225, d0.loss_bbox_aux0: 0.0474, d0.loss_iou_aux0: 0.2344, d1.loss_cls_aux0: 0.0172, d1.loss_bbox_aux0: 0.0280, d1.loss_iou_aux0: 0.1344, d2.loss_cls_aux0: 0.0162, d2.loss_bbox_aux0: 0.0238, d2.loss_iou_aux0: 0.1136, d3.loss_cls_aux0: 0.0151, d3.loss_bbox_aux0: 0.0238, d3.loss_iou_aux0: 0.1139, d4.loss_cls_aux0: 0.0147, d4.loss_bbox_aux0: 0.0239, d4.loss_iou_aux0: 0.1143, loss_cls_aux1: 0.0137, loss_bbox_aux1: 0.0502, loss_iou_aux1: 0.2614, d0.loss_cls_aux1: 0.0169, d0.loss_bbox_aux1: 0.0572, d0.loss_iou_aux1: 0.2954, d1.loss_cls_aux1: 0.0156, d1.loss_bbox_aux1: 0.0511, d1.loss_iou_aux1: 0.2648, d2.loss_cls_aux1: 0.0151, d2.loss_bbox_aux1: 0.0502, d2.loss_iou_aux1: 0.2609, d3.loss_cls_aux1: 0.0134, d3.loss_bbox_aux1: 0.0502, d3.loss_iou_aux1: 0.2610, d4.loss_cls_aux1: 0.0134, d4.loss_bbox_aux1: 0.0502, d4.loss_iou_aux1: 0.2612, loss: 22.9821, grad_norm: 68.5727
2024-03-18 09:04:31,654 - mmdet - INFO - Epoch [23][100/232]	lr: 2.000e-05, eta: 0:37:55, time: 0.814, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1157, enc_loss_bbox: 0.0651, enc_loss_iou: 0.3577, loss_cls: 0.0858, loss_bbox: 0.0604, loss_iou: 0.3323, d0.loss_cls: 0.1245, d0.loss_bbox: 0.0611, d0.loss_iou: 0.3365, d1.loss_cls: 0.0971, d1.loss_bbox: 0.0604, d1.loss_iou: 0.3323, d2.loss_cls: 0.0874, d2.loss_bbox: 0.0604, d2.loss_iou: 0.3320, d3.loss_cls: 0.0854, d3.loss_bbox: 0.0604, d3.loss_iou: 0.3321, d4.loss_cls: 0.0855, d4.loss_bbox: 0.0604, d4.loss_iou: 0.3322, loss_rpn_cls: 0.0345, loss_rpn_bbox: 0.1231, loss_cls0: 1.3480, acc0: 95.3364, loss_bbox0: 2.5101, loss_cls1: 0.8968, loss_bbox1: 3.6098, loss_centerness1: 7.4815, loss_cls_aux0: 0.0084, loss_bbox_aux0: 0.0205, loss_iou_aux0: 0.1068, d0.loss_cls_aux0: 0.0144, d0.loss_bbox_aux0: 0.0433, d0.loss_iou_aux0: 0.2276, d1.loss_cls_aux0: 0.0098, d1.loss_bbox_aux0: 0.0239, d1.loss_iou_aux0: 0.1230, d2.loss_cls_aux0: 0.0083, d2.loss_bbox_aux0: 0.0204, d2.loss_iou_aux0: 0.1051, d3.loss_cls_aux0: 0.0083, d3.loss_bbox_aux0: 0.0204, d3.loss_iou_aux0: 0.1055, d4.loss_cls_aux0: 0.0083, d4.loss_bbox_aux0: 0.0205, d4.loss_iou_aux0: 0.1061, loss_cls_aux1: 0.0075, loss_bbox_aux1: 0.0477, loss_iou_aux1: 0.2590, d0.loss_cls_aux1: 0.0091, d0.loss_bbox_aux1: 0.0547, d0.loss_iou_aux1: 0.2978, d1.loss_cls_aux1: 0.0076, d1.loss_bbox_aux1: 0.0484, d1.loss_iou_aux1: 0.2621, d2.loss_cls_aux1: 0.0071, d2.loss_bbox_aux1: 0.0477, d2.loss_iou_aux1: 0.2586, d3.loss_cls_aux1: 0.0075, d3.loss_bbox_aux1: 0.0477, d3.loss_iou_aux1: 0.2587, d4.loss_cls_aux1: 0.0075, d4.loss_bbox_aux1: 0.0477, d4.loss_iou_aux1: 0.2588, loss: 22.3843, grad_norm: 65.4614
2024-03-18 09:05:12,839 - mmdet - INFO - Epoch [23][150/232]	lr: 2.000e-05, eta: 0:37:22, time: 0.824, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1105, enc_loss_bbox: 0.0677, enc_loss_iou: 0.3628, loss_cls: 0.0855, loss_bbox: 0.0630, loss_iou: 0.3390, d0.loss_cls: 0.1227, d0.loss_bbox: 0.0638, d0.loss_iou: 0.3454, d1.loss_cls: 0.0942, d1.loss_bbox: 0.0632, d1.loss_iou: 0.3398, d2.loss_cls: 0.0875, d2.loss_bbox: 0.0627, d2.loss_iou: 0.3384, d3.loss_cls: 0.0863, d3.loss_bbox: 0.0630, d3.loss_iou: 0.3388, d4.loss_cls: 0.0857, d4.loss_bbox: 0.0630, d4.loss_iou: 0.3389, loss_rpn_cls: 0.0240, loss_rpn_bbox: 0.1225, loss_cls0: 1.3462, acc0: 95.3911, loss_bbox0: 2.5492, loss_cls1: 0.9425, loss_bbox1: 3.7363, loss_centerness1: 7.4659, loss_cls_aux0: 0.0136, loss_bbox_aux0: 0.0203, loss_iou_aux0: 0.0993, d0.loss_cls_aux0: 0.0210, d0.loss_bbox_aux0: 0.0469, d0.loss_iou_aux0: 0.2312, d1.loss_cls_aux0: 0.0159, d1.loss_bbox_aux0: 0.0243, d1.loss_iou_aux0: 0.1198, d2.loss_cls_aux0: 0.0140, d2.loss_bbox_aux0: 0.0202, d2.loss_iou_aux0: 0.0983, d3.loss_cls_aux0: 0.0129, d3.loss_bbox_aux0: 0.0202, d3.loss_iou_aux0: 0.0985, d4.loss_cls_aux0: 0.0135, d4.loss_bbox_aux0: 0.0202, d4.loss_iou_aux0: 0.0988, loss_cls_aux1: 0.0124, loss_bbox_aux1: 0.0486, loss_iou_aux1: 0.2604, d0.loss_cls_aux1: 0.0144, d0.loss_bbox_aux1: 0.0563, d0.loss_iou_aux1: 0.2963, d1.loss_cls_aux1: 0.0130, d1.loss_bbox_aux1: 0.0494, d1.loss_iou_aux1: 0.2633, d2.loss_cls_aux1: 0.0124, d2.loss_bbox_aux1: 0.0485, d2.loss_iou_aux1: 0.2601, d3.loss_cls_aux1: 0.0121, d3.loss_bbox_aux1: 0.0485, d3.loss_iou_aux1: 0.2602, d4.loss_cls_aux1: 0.0126, d4.loss_bbox_aux1: 0.0485, d4.loss_iou_aux1: 0.2603, loss: 22.6742, grad_norm: 71.0638
2024-03-18 09:05:54,349 - mmdet - INFO - Epoch [23][200/232]	lr: 2.000e-05, eta: 0:36:49, time: 0.830, data_time: 0.009, memory: 17650, enc_loss_cls: 0.1169, enc_loss_bbox: 0.0675, enc_loss_iou: 0.3577, loss_cls: 0.0930, loss_bbox: 0.0626, loss_iou: 0.3331, d0.loss_cls: 0.1335, d0.loss_bbox: 0.0630, d0.loss_iou: 0.3371, d1.loss_cls: 0.1039, d1.loss_bbox: 0.0625, d1.loss_iou: 0.3336, d2.loss_cls: 0.0970, d2.loss_bbox: 0.0625, d2.loss_iou: 0.3326, d3.loss_cls: 0.0936, d3.loss_bbox: 0.0626, d3.loss_iou: 0.3329, d4.loss_cls: 0.0931, d4.loss_bbox: 0.0626, d4.loss_iou: 0.3329, loss_rpn_cls: 0.0429, loss_rpn_bbox: 0.1376, loss_cls0: 1.4531, acc0: 95.0081, loss_bbox0: 2.5744, loss_cls1: 0.9233, loss_bbox1: 3.6566, loss_centerness1: 7.4826, loss_cls_aux0: 0.0149, loss_bbox_aux0: 0.0231, loss_iou_aux0: 0.1141, d0.loss_cls_aux0: 0.0201, d0.loss_bbox_aux0: 0.0447, d0.loss_iou_aux0: 0.2247, d1.loss_cls_aux0: 0.0169, d1.loss_bbox_aux0: 0.0270, d1.loss_iou_aux0: 0.1327, d2.loss_cls_aux0: 0.0160, d2.loss_bbox_aux0: 0.0229, d2.loss_iou_aux0: 0.1128, d3.loss_cls_aux0: 0.0155, d3.loss_bbox_aux0: 0.0230, d3.loss_iou_aux0: 0.1132, d4.loss_cls_aux0: 0.0150, d4.loss_bbox_aux0: 0.0231, d4.loss_iou_aux0: 0.1136, loss_cls_aux1: 0.0108, loss_bbox_aux1: 0.0502, loss_iou_aux1: 0.2632, d0.loss_cls_aux1: 0.0136, d0.loss_bbox_aux1: 0.0587, d0.loss_iou_aux1: 0.3063, d1.loss_cls_aux1: 0.0127, d1.loss_bbox_aux1: 0.0511, d1.loss_iou_aux1: 0.2675, d2.loss_cls_aux1: 0.0118, d2.loss_bbox_aux1: 0.0501, d2.loss_iou_aux1: 0.2628, d3.loss_cls_aux1: 0.0113, d3.loss_bbox_aux1: 0.0501, d3.loss_iou_aux1: 0.2629, d4.loss_cls_aux1: 0.0109, d4.loss_bbox_aux1: 0.0502, d4.loss_iou_aux1: 0.2630, loss: 22.8849, grad_norm: 65.2234
2024-03-18 09:06:21,062 - mmdet - INFO - Saving checkpoint at 23 epochs
2024-03-18 09:06:43,118 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:06:49,115 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.581
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.295
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.377
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.529
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.473
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.671
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.786

2024-03-18 09:06:49,116 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.021 | Tin      | 0.615 | Thatch   | 0.521 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:06:49,171 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:06:49,171 - mmdet - INFO - Epoch(val) [23][154]	bbox_mAP: 0.3860, bbox_mAP_50: 0.5810, bbox_mAP_75: 0.4620, bbox_mAP_s: 0.2950, bbox_mAP_m: 0.3770, bbox_mAP_l: 0.5290, bbox_mAP_copypaste: 0.386 0.581 0.462 0.295 0.377 0.529
2024-03-18 09:07:32,624 - mmdet - INFO - Epoch [24][50/232]	lr: 2.000e-05, eta: 0:35:41, time: 0.869, data_time: 0.061, memory: 17650, enc_loss_cls: 0.1041, enc_loss_bbox: 0.0693, enc_loss_iou: 0.3689, loss_cls: 0.0740, loss_bbox: 0.0629, loss_iou: 0.3401, d0.loss_cls: 0.1052, d0.loss_bbox: 0.0637, d0.loss_iou: 0.3450, d1.loss_cls: 0.0827, d1.loss_bbox: 0.0633, d1.loss_iou: 0.3413, d2.loss_cls: 0.0756, d2.loss_bbox: 0.0630, d2.loss_iou: 0.3407, d3.loss_cls: 0.0738, d3.loss_bbox: 0.0628, d3.loss_iou: 0.3401, d4.loss_cls: 0.0734, d4.loss_bbox: 0.0628, d4.loss_iou: 0.3402, loss_rpn_cls: 0.0312, loss_rpn_bbox: 0.1376, loss_cls0: 1.3636, acc0: 95.2951, loss_bbox0: 2.6022, loss_cls1: 0.8554, loss_bbox1: 3.8170, loss_centerness1: 7.4865, loss_cls_aux0: 0.0089, loss_bbox_aux0: 0.0224, loss_iou_aux0: 0.1127, d0.loss_cls_aux0: 0.0159, d0.loss_bbox_aux0: 0.0443, d0.loss_iou_aux0: 0.2281, d1.loss_cls_aux0: 0.0113, d1.loss_bbox_aux0: 0.0259, d1.loss_iou_aux0: 0.1309, d2.loss_cls_aux0: 0.0101, d2.loss_bbox_aux0: 0.0223, d2.loss_iou_aux0: 0.1116, d3.loss_cls_aux0: 0.0090, d3.loss_bbox_aux0: 0.0223, d3.loss_iou_aux0: 0.1119, d4.loss_cls_aux0: 0.0089, d4.loss_bbox_aux0: 0.0224, d4.loss_iou_aux0: 0.1123, loss_cls_aux1: 0.0064, loss_bbox_aux1: 0.0480, loss_iou_aux1: 0.2626, d0.loss_cls_aux1: 0.0083, d0.loss_bbox_aux1: 0.0578, d0.loss_iou_aux1: 0.3121, d1.loss_cls_aux1: 0.0071, d1.loss_bbox_aux1: 0.0499, d1.loss_iou_aux1: 0.2705, d2.loss_cls_aux1: 0.0066, d2.loss_bbox_aux1: 0.0480, d2.loss_iou_aux1: 0.2623, d3.loss_cls_aux1: 0.0065, d3.loss_bbox_aux1: 0.0480, d3.loss_iou_aux1: 0.2624, d4.loss_cls_aux1: 0.0063, d4.loss_bbox_aux1: 0.0480, d4.loss_iou_aux1: 0.2625, loss: 22.7513, grad_norm: 63.0183
2024-03-18 09:08:13,285 - mmdet - INFO - Epoch [24][100/232]	lr: 2.000e-05, eta: 0:35:07, time: 0.813, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1096, enc_loss_bbox: 0.0645, enc_loss_iou: 0.3492, loss_cls: 0.0884, loss_bbox: 0.0575, loss_iou: 0.3179, d0.loss_cls: 0.1236, d0.loss_bbox: 0.0585, d0.loss_iou: 0.3220, d1.loss_cls: 0.0989, d1.loss_bbox: 0.0578, d1.loss_iou: 0.3193, d2.loss_cls: 0.0927, d2.loss_bbox: 0.0574, d2.loss_iou: 0.3177, d3.loss_cls: 0.0886, d3.loss_bbox: 0.0574, d3.loss_iou: 0.3176, d4.loss_cls: 0.0880, d4.loss_bbox: 0.0575, d4.loss_iou: 0.3179, loss_rpn_cls: 0.0293, loss_rpn_bbox: 0.1309, loss_cls0: 1.2626, acc0: 95.6736, loss_bbox0: 2.4584, loss_cls1: 0.8986, loss_bbox1: 3.4766, loss_centerness1: 7.4457, loss_cls_aux0: 0.0118, loss_bbox_aux0: 0.0226, loss_iou_aux0: 0.1118, d0.loss_cls_aux0: 0.0185, d0.loss_bbox_aux0: 0.0454, d0.loss_iou_aux0: 0.2283, d1.loss_cls_aux0: 0.0149, d1.loss_bbox_aux0: 0.0262, d1.loss_iou_aux0: 0.1300, d2.loss_cls_aux0: 0.0128, d2.loss_bbox_aux0: 0.0223, d2.loss_iou_aux0: 0.1102, d3.loss_cls_aux0: 0.0119, d3.loss_bbox_aux0: 0.0224, d3.loss_iou_aux0: 0.1106, d4.loss_cls_aux0: 0.0117, d4.loss_bbox_aux0: 0.0225, d4.loss_iou_aux0: 0.1112, loss_cls_aux1: 0.0103, loss_bbox_aux1: 0.0478, loss_iou_aux1: 0.2557, d0.loss_cls_aux1: 0.0151, d0.loss_bbox_aux1: 0.0552, d0.loss_iou_aux1: 0.2939, d1.loss_cls_aux1: 0.0132, d1.loss_bbox_aux1: 0.0488, d1.loss_iou_aux1: 0.2605, d2.loss_cls_aux1: 0.0117, d2.loss_bbox_aux1: 0.0477, d2.loss_iou_aux1: 0.2553, d3.loss_cls_aux1: 0.0104, d3.loss_bbox_aux1: 0.0477, d3.loss_iou_aux1: 0.2555, d4.loss_cls_aux1: 0.0101, d4.loss_bbox_aux1: 0.0477, d4.loss_iou_aux1: 0.2556, loss: 22.0514, grad_norm: 66.7024
2024-03-18 09:08:54,527 - mmdet - INFO - Epoch [24][150/232]	lr: 2.000e-05, eta: 0:34:34, time: 0.825, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1086, enc_loss_bbox: 0.0683, enc_loss_iou: 0.3625, loss_cls: 0.0822, loss_bbox: 0.0634, loss_iou: 0.3378, d0.loss_cls: 0.1266, d0.loss_bbox: 0.0641, d0.loss_iou: 0.3425, d1.loss_cls: 0.0909, d1.loss_bbox: 0.0637, d1.loss_iou: 0.3387, d2.loss_cls: 0.0834, d2.loss_bbox: 0.0635, d2.loss_iou: 0.3379, d3.loss_cls: 0.0831, d3.loss_bbox: 0.0634, d3.loss_iou: 0.3376, d4.loss_cls: 0.0822, d4.loss_bbox: 0.0635, d4.loss_iou: 0.3380, loss_rpn_cls: 0.0350, loss_rpn_bbox: 0.1410, loss_cls0: 1.4087, acc0: 95.1870, loss_bbox0: 2.5614, loss_cls1: 0.9087, loss_bbox1: 3.7617, loss_centerness1: 7.5084, loss_cls_aux0: 0.0141, loss_bbox_aux0: 0.0225, loss_iou_aux0: 0.1135, d0.loss_cls_aux0: 0.0202, d0.loss_bbox_aux0: 0.0472, d0.loss_iou_aux0: 0.2402, d1.loss_cls_aux0: 0.0157, d1.loss_bbox_aux0: 0.0267, d1.loss_iou_aux0: 0.1331, d2.loss_cls_aux0: 0.0145, d2.loss_bbox_aux0: 0.0224, d2.loss_iou_aux0: 0.1116, d3.loss_cls_aux0: 0.0141, d3.loss_bbox_aux0: 0.0224, d3.loss_iou_aux0: 0.1120, d4.loss_cls_aux0: 0.0143, d4.loss_bbox_aux0: 0.0225, d4.loss_iou_aux0: 0.1126, loss_cls_aux1: 0.0116, loss_bbox_aux1: 0.0499, loss_iou_aux1: 0.2648, d0.loss_cls_aux1: 0.0137, d0.loss_bbox_aux1: 0.0587, d0.loss_iou_aux1: 0.3109, d1.loss_cls_aux1: 0.0118, d1.loss_bbox_aux1: 0.0509, d1.loss_iou_aux1: 0.2700, d2.loss_cls_aux1: 0.0114, d2.loss_bbox_aux1: 0.0498, d2.loss_iou_aux1: 0.2644, d3.loss_cls_aux1: 0.0116, d3.loss_bbox_aux1: 0.0498, d3.loss_iou_aux1: 0.2645, d4.loss_cls_aux1: 0.0120, d4.loss_bbox_aux1: 0.0498, d4.loss_iou_aux1: 0.2646, loss: 22.9265, grad_norm: 66.7791
2024-03-18 09:09:36,109 - mmdet - INFO - Epoch [24][200/232]	lr: 2.000e-05, eta: 0:34:00, time: 0.831, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1186, enc_loss_bbox: 0.0649, enc_loss_iou: 0.3436, loss_cls: 0.0860, loss_bbox: 0.0596, loss_iou: 0.3188, d0.loss_cls: 0.1302, d0.loss_bbox: 0.0608, d0.loss_iou: 0.3250, d1.loss_cls: 0.0978, d1.loss_bbox: 0.0597, d1.loss_iou: 0.3192, d2.loss_cls: 0.0893, d2.loss_bbox: 0.0597, d2.loss_iou: 0.3185, d3.loss_cls: 0.0867, d3.loss_bbox: 0.0595, d3.loss_iou: 0.3184, d4.loss_cls: 0.0852, d4.loss_bbox: 0.0596, d4.loss_iou: 0.3187, loss_rpn_cls: 0.0341, loss_rpn_bbox: 0.1279, loss_cls0: 1.3459, acc0: 95.3948, loss_bbox0: 2.5303, loss_cls1: 0.8998, loss_bbox1: 3.5518, loss_centerness1: 7.4658, loss_cls_aux0: 0.0163, loss_bbox_aux0: 0.0209, loss_iou_aux0: 0.1036, d0.loss_cls_aux0: 0.0197, d0.loss_bbox_aux0: 0.0457, d0.loss_iou_aux0: 0.2284, d1.loss_cls_aux0: 0.0163, d1.loss_bbox_aux0: 0.0253, d1.loss_iou_aux0: 0.1246, d2.loss_cls_aux0: 0.0153, d2.loss_bbox_aux0: 0.0208, d2.loss_iou_aux0: 0.1025, d3.loss_cls_aux0: 0.0156, d3.loss_bbox_aux0: 0.0208, d3.loss_iou_aux0: 0.1027, d4.loss_cls_aux0: 0.0160, d4.loss_bbox_aux0: 0.0209, d4.loss_iou_aux0: 0.1031, loss_cls_aux1: 0.0105, loss_bbox_aux1: 0.0475, loss_iou_aux1: 0.2512, d0.loss_cls_aux1: 0.0119, d0.loss_bbox_aux1: 0.0545, d0.loss_iou_aux1: 0.2871, d1.loss_cls_aux1: 0.0103, d1.loss_bbox_aux1: 0.0482, d1.loss_iou_aux1: 0.2544, d2.loss_cls_aux1: 0.0094, d2.loss_bbox_aux1: 0.0474, d2.loss_iou_aux1: 0.2508, d3.loss_cls_aux1: 0.0097, d3.loss_bbox_aux1: 0.0474, d3.loss_iou_aux1: 0.2509, d4.loss_cls_aux1: 0.0102, d4.loss_bbox_aux1: 0.0474, d4.loss_iou_aux1: 0.2511, loss: 22.2538, grad_norm: 67.5911
2024-03-18 09:10:02,899 - mmdet - INFO - Saving checkpoint at 24 epochs
2024-03-18 09:10:24,923 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:10:30,756 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.580
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.455
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.290
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.379
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.573
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.642
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.470
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.660
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.785

2024-03-18 09:10:30,756 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.045 | Tin      | 0.625 | Thatch   | 0.479 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:10:30,817 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:10:30,817 - mmdet - INFO - Epoch(val) [24][154]	bbox_mAP: 0.3830, bbox_mAP_50: 0.5800, bbox_mAP_75: 0.4550, bbox_mAP_s: 0.2900, bbox_mAP_m: 0.3790, bbox_mAP_l: 0.5730, bbox_mAP_copypaste: 0.383 0.580 0.455 0.290 0.379 0.573
2024-03-18 09:11:14,272 - mmdet - INFO - Epoch [25][50/232]	lr: 2.000e-05, eta: 0:32:53, time: 0.869, data_time: 0.061, memory: 17650, enc_loss_cls: 0.1123, enc_loss_bbox: 0.0699, enc_loss_iou: 0.3594, loss_cls: 0.0760, loss_bbox: 0.0636, loss_iou: 0.3290, d0.loss_cls: 0.1131, d0.loss_bbox: 0.0646, d0.loss_iou: 0.3342, d1.loss_cls: 0.0832, d1.loss_bbox: 0.0642, d1.loss_iou: 0.3317, d2.loss_cls: 0.0783, d2.loss_bbox: 0.0635, d2.loss_iou: 0.3286, d3.loss_cls: 0.0760, d3.loss_bbox: 0.0636, d3.loss_iou: 0.3289, d4.loss_cls: 0.0756, d4.loss_bbox: 0.0636, d4.loss_iou: 0.3290, loss_rpn_cls: 0.0223, loss_rpn_bbox: 0.1186, loss_cls0: 1.2658, acc0: 95.6188, loss_bbox0: 2.3873, loss_cls1: 0.8978, loss_bbox1: 3.6190, loss_centerness1: 7.4712, loss_cls_aux0: 0.0072, loss_bbox_aux0: 0.0214, loss_iou_aux0: 0.1049, d0.loss_cls_aux0: 0.0138, d0.loss_bbox_aux0: 0.0454, d0.loss_iou_aux0: 0.2257, d1.loss_cls_aux0: 0.0091, d1.loss_bbox_aux0: 0.0250, d1.loss_iou_aux0: 0.1234, d2.loss_cls_aux0: 0.0077, d2.loss_bbox_aux0: 0.0213, d2.loss_iou_aux0: 0.1035, d3.loss_cls_aux0: 0.0070, d3.loss_bbox_aux0: 0.0213, d3.loss_iou_aux0: 0.1039, d4.loss_cls_aux0: 0.0071, d4.loss_bbox_aux0: 0.0214, d4.loss_iou_aux0: 0.1044, loss_cls_aux1: 0.0064, loss_bbox_aux1: 0.0487, loss_iou_aux1: 0.2541, d0.loss_cls_aux1: 0.0083, d0.loss_bbox_aux1: 0.0564, d0.loss_iou_aux1: 0.2921, d1.loss_cls_aux1: 0.0067, d1.loss_bbox_aux1: 0.0496, d1.loss_iou_aux1: 0.2584, d2.loss_cls_aux1: 0.0067, d2.loss_bbox_aux1: 0.0486, d2.loss_iou_aux1: 0.2538, d3.loss_cls_aux1: 0.0069, d3.loss_bbox_aux1: 0.0486, d3.loss_iou_aux1: 0.2539, d4.loss_cls_aux1: 0.0068, d4.loss_bbox_aux1: 0.0486, d4.loss_iou_aux1: 0.2540, loss: 22.0726, grad_norm: 66.7388
2024-03-18 09:11:55,171 - mmdet - INFO - Epoch [25][100/232]	lr: 2.000e-05, eta: 0:32:19, time: 0.818, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1100, enc_loss_bbox: 0.0682, enc_loss_iou: 0.3640, loss_cls: 0.0840, loss_bbox: 0.0614, loss_iou: 0.3291, d0.loss_cls: 0.1205, d0.loss_bbox: 0.0620, d0.loss_iou: 0.3333, d1.loss_cls: 0.0923, d1.loss_bbox: 0.0614, d1.loss_iou: 0.3291, d2.loss_cls: 0.0846, d2.loss_bbox: 0.0613, d2.loss_iou: 0.3288, d3.loss_cls: 0.0842, d3.loss_bbox: 0.0613, d3.loss_iou: 0.3288, d4.loss_cls: 0.0836, d4.loss_bbox: 0.0614, d4.loss_iou: 0.3290, loss_rpn_cls: 0.0402, loss_rpn_bbox: 0.1413, loss_cls0: 1.3222, acc0: 95.4973, loss_bbox0: 2.4914, loss_cls1: 0.8941, loss_bbox1: 3.6631, loss_centerness1: 7.4701, loss_cls_aux0: 0.0174, loss_bbox_aux0: 0.0222, loss_iou_aux0: 0.1080, d0.loss_cls_aux0: 0.0178, d0.loss_bbox_aux0: 0.0449, d0.loss_iou_aux0: 0.2252, d1.loss_cls_aux0: 0.0140, d1.loss_bbox_aux0: 0.0254, d1.loss_iou_aux0: 0.1250, d2.loss_cls_aux0: 0.0148, d2.loss_bbox_aux0: 0.0220, d2.loss_iou_aux0: 0.1069, d3.loss_cls_aux0: 0.0155, d3.loss_bbox_aux0: 0.0221, d3.loss_iou_aux0: 0.1072, d4.loss_cls_aux0: 0.0164, d4.loss_bbox_aux0: 0.0221, d4.loss_iou_aux0: 0.1076, loss_cls_aux1: 0.0114, loss_bbox_aux1: 0.0483, loss_iou_aux1: 0.2570, d0.loss_cls_aux1: 0.0095, d0.loss_bbox_aux1: 0.0568, d0.loss_iou_aux1: 0.2998, d1.loss_cls_aux1: 0.0086, d1.loss_bbox_aux1: 0.0493, d1.loss_iou_aux1: 0.2621, d2.loss_cls_aux1: 0.0088, d2.loss_bbox_aux1: 0.0482, d2.loss_iou_aux1: 0.2567, d3.loss_cls_aux1: 0.0095, d3.loss_bbox_aux1: 0.0483, d3.loss_iou_aux1: 0.2568, d4.loss_cls_aux1: 0.0106, d4.loss_bbox_aux1: 0.0483, d4.loss_iou_aux1: 0.2569, loss: 22.4420, grad_norm: 81.1484
2024-03-18 09:12:36,185 - mmdet - INFO - Epoch [25][150/232]	lr: 2.000e-05, eta: 0:31:45, time: 0.820, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1186, enc_loss_bbox: 0.0659, enc_loss_iou: 0.3646, loss_cls: 0.0899, loss_bbox: 0.0619, loss_iou: 0.3431, d0.loss_cls: 0.1239, d0.loss_bbox: 0.0629, d0.loss_iou: 0.3479, d1.loss_cls: 0.0992, d1.loss_bbox: 0.0624, d1.loss_iou: 0.3454, d2.loss_cls: 0.0924, d2.loss_bbox: 0.0620, d2.loss_iou: 0.3438, d3.loss_cls: 0.0896, d3.loss_bbox: 0.0619, d3.loss_iou: 0.3432, d4.loss_cls: 0.0896, d4.loss_bbox: 0.0619, d4.loss_iou: 0.3431, loss_rpn_cls: 0.0279, loss_rpn_bbox: 0.1254, loss_cls0: 1.3512, acc0: 95.3663, loss_bbox0: 2.5449, loss_cls1: 0.9420, loss_bbox1: 3.6846, loss_centerness1: 7.4688, loss_cls_aux0: 0.0097, loss_bbox_aux0: 0.0217, loss_iou_aux0: 0.1099, d0.loss_cls_aux0: 0.0177, d0.loss_bbox_aux0: 0.0451, d0.loss_iou_aux0: 0.2277, d1.loss_cls_aux0: 0.0126, d1.loss_bbox_aux0: 0.0251, d1.loss_iou_aux0: 0.1264, d2.loss_cls_aux0: 0.0110, d2.loss_bbox_aux0: 0.0216, d2.loss_iou_aux0: 0.1085, d3.loss_cls_aux0: 0.0098, d3.loss_bbox_aux0: 0.0216, d3.loss_iou_aux0: 0.1088, d4.loss_cls_aux0: 0.0097, d4.loss_bbox_aux0: 0.0217, d4.loss_iou_aux0: 0.1092, loss_cls_aux1: 0.0085, loss_bbox_aux1: 0.0493, loss_iou_aux1: 0.2645, d0.loss_cls_aux1: 0.0114, d0.loss_bbox_aux1: 0.0562, d0.loss_iou_aux1: 0.3019, d1.loss_cls_aux1: 0.0103, d1.loss_bbox_aux1: 0.0499, d1.loss_iou_aux1: 0.2682, d2.loss_cls_aux1: 0.0096, d2.loss_bbox_aux1: 0.0492, d2.loss_iou_aux1: 0.2641, d3.loss_cls_aux1: 0.0086, d3.loss_bbox_aux1: 0.0492, d3.loss_iou_aux1: 0.2642, d4.loss_cls_aux1: 0.0083, d4.loss_bbox_aux1: 0.0492, d4.loss_iou_aux1: 0.2643, loss: 22.7229, grad_norm: 62.9736
2024-03-18 09:13:17,767 - mmdet - INFO - Epoch [25][200/232]	lr: 2.000e-05, eta: 0:31:11, time: 0.832, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1082, enc_loss_bbox: 0.0684, enc_loss_iou: 0.3613, loss_cls: 0.0845, loss_bbox: 0.0618, loss_iou: 0.3297, d0.loss_cls: 0.1203, d0.loss_bbox: 0.0629, d0.loss_iou: 0.3360, d1.loss_cls: 0.0917, d1.loss_bbox: 0.0621, d1.loss_iou: 0.3303, d2.loss_cls: 0.0865, d2.loss_bbox: 0.0620, d2.loss_iou: 0.3300, d3.loss_cls: 0.0851, d3.loss_bbox: 0.0618, d3.loss_iou: 0.3292, d4.loss_cls: 0.0845, d4.loss_bbox: 0.0618, d4.loss_iou: 0.3295, loss_rpn_cls: 0.0361, loss_rpn_bbox: 0.1547, loss_cls0: 1.4378, acc0: 95.0753, loss_bbox0: 2.6336, loss_cls1: 0.9131, loss_bbox1: 3.6440, loss_centerness1: 7.4766, loss_cls_aux0: 0.0120, loss_bbox_aux0: 0.0234, loss_iou_aux0: 0.1155, d0.loss_cls_aux0: 0.0199, d0.loss_bbox_aux0: 0.0460, d0.loss_iou_aux0: 0.2303, d1.loss_cls_aux0: 0.0147, d1.loss_bbox_aux0: 0.0268, d1.loss_iou_aux0: 0.1329, d2.loss_cls_aux0: 0.0128, d2.loss_bbox_aux0: 0.0232, d2.loss_iou_aux0: 0.1146, d3.loss_cls_aux0: 0.0121, d3.loss_bbox_aux0: 0.0233, d3.loss_iou_aux0: 0.1149, d4.loss_cls_aux0: 0.0121, d4.loss_bbox_aux0: 0.0233, d4.loss_iou_aux0: 0.1152, loss_cls_aux1: 0.0078, loss_bbox_aux1: 0.0491, loss_iou_aux1: 0.2588, d0.loss_cls_aux1: 0.0107, d0.loss_bbox_aux1: 0.0568, d0.loss_iou_aux1: 0.2954, d1.loss_cls_aux1: 0.0090, d1.loss_bbox_aux1: 0.0497, d1.loss_iou_aux1: 0.2623, d2.loss_cls_aux1: 0.0082, d2.loss_bbox_aux1: 0.0490, d2.loss_iou_aux1: 0.2583, d3.loss_cls_aux1: 0.0080, d3.loss_bbox_aux1: 0.0491, d3.loss_iou_aux1: 0.2584, d4.loss_cls_aux1: 0.0079, d4.loss_bbox_aux1: 0.0491, d4.loss_iou_aux1: 0.2586, loss: 22.7627, grad_norm: 64.6431
2024-03-18 09:13:44,526 - mmdet - INFO - Saving checkpoint at 25 epochs
2024-03-18 09:14:06,709 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:14:12,853 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.402
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.593
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.478
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.295
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.387
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.785
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.535
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.677
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.828

2024-03-18 09:14:12,854 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.056 | Tin      | 0.629 | Thatch   | 0.520 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:14:12,905 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:14:12,905 - mmdet - INFO - Epoch(val) [25][154]	bbox_mAP: 0.4020, bbox_mAP_50: 0.5930, bbox_mAP_75: 0.4780, bbox_mAP_s: 0.2950, bbox_mAP_m: 0.3870, bbox_mAP_l: 0.7850, bbox_mAP_copypaste: 0.402 0.593 0.478 0.295 0.387 0.785
2024-03-18 09:14:56,647 - mmdet - INFO - Epoch [26][50/232]	lr: 2.000e-05, eta: 0:30:05, time: 0.875, data_time: 0.064, memory: 17650, enc_loss_cls: 0.1089, enc_loss_bbox: 0.0647, enc_loss_iou: 0.3500, loss_cls: 0.0704, loss_bbox: 0.0591, loss_iou: 0.3229, d0.loss_cls: 0.1039, d0.loss_bbox: 0.0597, d0.loss_iou: 0.3271, d1.loss_cls: 0.0778, d1.loss_bbox: 0.0591, d1.loss_iou: 0.3234, d2.loss_cls: 0.0727, d2.loss_bbox: 0.0590, d2.loss_iou: 0.3227, d3.loss_cls: 0.0702, d3.loss_bbox: 0.0593, d3.loss_iou: 0.3228, d4.loss_cls: 0.0702, d4.loss_bbox: 0.0590, d4.loss_iou: 0.3227, loss_rpn_cls: 0.0255, loss_rpn_bbox: 0.1176, loss_cls0: 1.2414, acc0: 95.7122, loss_bbox0: 2.5809, loss_cls1: 0.8281, loss_bbox1: 3.5619, loss_centerness1: 7.4625, loss_cls_aux0: 0.0089, loss_bbox_aux0: 0.0204, loss_iou_aux0: 0.1018, d0.loss_cls_aux0: 0.0142, d0.loss_bbox_aux0: 0.0438, d0.loss_iou_aux0: 0.2228, d1.loss_cls_aux0: 0.0094, d1.loss_bbox_aux0: 0.0239, d1.loss_iou_aux0: 0.1191, d2.loss_cls_aux0: 0.0080, d2.loss_bbox_aux0: 0.0202, d2.loss_iou_aux0: 0.1001, d3.loss_cls_aux0: 0.0078, d3.loss_bbox_aux0: 0.0202, d3.loss_iou_aux0: 0.1005, d4.loss_cls_aux0: 0.0085, d4.loss_bbox_aux0: 0.0203, d4.loss_iou_aux0: 0.1011, loss_cls_aux1: 0.0061, loss_bbox_aux1: 0.0471, loss_iou_aux1: 0.2538, d0.loss_cls_aux1: 0.0081, d0.loss_bbox_aux1: 0.0551, d0.loss_iou_aux1: 0.2961, d1.loss_cls_aux1: 0.0067, d1.loss_bbox_aux1: 0.0480, d1.loss_iou_aux1: 0.2581, d2.loss_cls_aux1: 0.0057, d2.loss_bbox_aux1: 0.0471, d2.loss_iou_aux1: 0.2536, d3.loss_cls_aux1: 0.0057, d3.loss_bbox_aux1: 0.0471, d3.loss_iou_aux1: 0.2536, d4.loss_cls_aux1: 0.0060, d4.loss_bbox_aux1: 0.0471, d4.loss_iou_aux1: 0.2537, loss: 21.9529, grad_norm: 69.7782
2024-03-18 09:15:37,264 - mmdet - INFO - Epoch [26][100/232]	lr: 2.000e-05, eta: 0:29:31, time: 0.812, data_time: 0.012, memory: 17650, enc_loss_cls: 0.1093, enc_loss_bbox: 0.0662, enc_loss_iou: 0.3601, loss_cls: 0.0790, loss_bbox: 0.0623, loss_iou: 0.3375, d0.loss_cls: 0.1129, d0.loss_bbox: 0.0628, d0.loss_iou: 0.3418, d1.loss_cls: 0.0880, d1.loss_bbox: 0.0622, d1.loss_iou: 0.3377, d2.loss_cls: 0.0828, d2.loss_bbox: 0.0621, d2.loss_iou: 0.3370, d3.loss_cls: 0.0807, d3.loss_bbox: 0.0622, d3.loss_iou: 0.3371, d4.loss_cls: 0.0793, d4.loss_bbox: 0.0622, d4.loss_iou: 0.3372, loss_rpn_cls: 0.0307, loss_rpn_bbox: 0.1254, loss_cls0: 1.2609, acc0: 95.6905, loss_bbox0: 2.3839, loss_cls1: 0.8750, loss_bbox1: 3.7316, loss_centerness1: 7.4951, loss_cls_aux0: 0.0064, loss_bbox_aux0: 0.0233, loss_iou_aux0: 0.1146, d0.loss_cls_aux0: 0.0129, d0.loss_bbox_aux0: 0.0462, d0.loss_iou_aux0: 0.2347, d1.loss_cls_aux0: 0.0089, d1.loss_bbox_aux0: 0.0276, d1.loss_iou_aux0: 0.1373, d2.loss_cls_aux0: 0.0073, d2.loss_bbox_aux0: 0.0230, d2.loss_iou_aux0: 0.1125, d3.loss_cls_aux0: 0.0066, d3.loss_bbox_aux0: 0.0231, d3.loss_iou_aux0: 0.1131, d4.loss_cls_aux0: 0.0066, d4.loss_bbox_aux0: 0.0232, d4.loss_iou_aux0: 0.1137, loss_cls_aux1: 0.0050, loss_bbox_aux1: 0.0492, loss_iou_aux1: 0.2660, d0.loss_cls_aux1: 0.0082, d0.loss_bbox_aux1: 0.0569, d0.loss_iou_aux1: 0.3057, d1.loss_cls_aux1: 0.0067, d1.loss_bbox_aux1: 0.0495, d1.loss_iou_aux1: 0.2680, d2.loss_cls_aux1: 0.0058, d2.loss_bbox_aux1: 0.0491, d2.loss_iou_aux1: 0.2656, d3.loss_cls_aux1: 0.0053, d3.loss_bbox_aux1: 0.0492, d3.loss_iou_aux1: 0.2657, d4.loss_cls_aux1: 0.0052, d4.loss_bbox_aux1: 0.0492, d4.loss_iou_aux1: 0.2658, loss: 22.3802, grad_norm: 63.7035
2024-03-18 09:16:18,620 - mmdet - INFO - Epoch [26][150/232]	lr: 2.000e-05, eta: 0:28:57, time: 0.827, data_time: 0.012, memory: 17650, enc_loss_cls: 0.1157, enc_loss_bbox: 0.0663, enc_loss_iou: 0.3640, loss_cls: 0.0886, loss_bbox: 0.0610, loss_iou: 0.3351, d0.loss_cls: 0.1240, d0.loss_bbox: 0.0625, d0.loss_iou: 0.3427, d1.loss_cls: 0.0966, d1.loss_bbox: 0.0616, d1.loss_iou: 0.3373, d2.loss_cls: 0.0889, d2.loss_bbox: 0.0610, d2.loss_iou: 0.3353, d3.loss_cls: 0.0883, d3.loss_bbox: 0.0610, d3.loss_iou: 0.3351, d4.loss_cls: 0.0885, d4.loss_bbox: 0.0610, d4.loss_iou: 0.3349, loss_rpn_cls: 0.0320, loss_rpn_bbox: 0.1623, loss_cls0: 1.4306, acc0: 95.0954, loss_bbox0: 2.6660, loss_cls1: 0.9126, loss_bbox1: 3.6435, loss_centerness1: 7.4697, loss_cls_aux0: 0.0140, loss_bbox_aux0: 0.0245, loss_iou_aux0: 0.1235, d0.loss_cls_aux0: 0.0193, d0.loss_bbox_aux0: 0.0455, d0.loss_iou_aux0: 0.2338, d1.loss_cls_aux0: 0.0148, d1.loss_bbox_aux0: 0.0281, d1.loss_iou_aux0: 0.1410, d2.loss_cls_aux0: 0.0138, d2.loss_bbox_aux0: 0.0244, d2.loss_iou_aux0: 0.1217, d3.loss_cls_aux0: 0.0133, d3.loss_bbox_aux0: 0.0244, d3.loss_iou_aux0: 0.1223, d4.loss_cls_aux0: 0.0136, d4.loss_bbox_aux0: 0.0245, d4.loss_iou_aux0: 0.1229, loss_cls_aux1: 0.0110, loss_bbox_aux1: 0.0482, loss_iou_aux1: 0.2613, d0.loss_cls_aux1: 0.0110, d0.loss_bbox_aux1: 0.0559, d0.loss_iou_aux1: 0.3001, d1.loss_cls_aux1: 0.0095, d1.loss_bbox_aux1: 0.0490, d1.loss_iou_aux1: 0.2655, d2.loss_cls_aux1: 0.0087, d2.loss_bbox_aux1: 0.0481, d2.loss_iou_aux1: 0.2609, d3.loss_cls_aux1: 0.0091, d3.loss_bbox_aux1: 0.0482, d3.loss_iou_aux1: 0.2610, d4.loss_cls_aux1: 0.0095, d4.loss_bbox_aux1: 0.0482, d4.loss_iou_aux1: 0.2611, loss: 22.9180, grad_norm: 64.4956
2024-03-18 09:17:00,046 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:17:00,047 - mmdet - INFO - Epoch [26][200/232]	lr: 2.000e-05, eta: 0:28:23, time: 0.829, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1124, enc_loss_bbox: 0.0682, enc_loss_iou: 0.3481, loss_cls: 0.0863, loss_bbox: 0.0618, loss_iou: 0.3177, d0.loss_cls: 0.1339, d0.loss_bbox: 0.0629, d0.loss_iou: 0.3219, d1.loss_cls: 0.0980, d1.loss_bbox: 0.0620, d1.loss_iou: 0.3184, d2.loss_cls: 0.0884, d2.loss_bbox: 0.0620, d2.loss_iou: 0.3174, d3.loss_cls: 0.0868, d3.loss_bbox: 0.0617, d3.loss_iou: 0.3173, d4.loss_cls: 0.0864, d4.loss_bbox: 0.0618, d4.loss_iou: 0.3175, loss_rpn_cls: 0.0303, loss_rpn_bbox: 0.1248, loss_cls0: 1.3262, acc0: 95.4865, loss_bbox0: 2.5123, loss_cls1: 0.8977, loss_bbox1: 3.4805, loss_centerness1: 7.4604, loss_cls_aux0: 0.0140, loss_bbox_aux0: 0.0223, loss_iou_aux0: 0.1092, d0.loss_cls_aux0: 0.0194, d0.loss_bbox_aux0: 0.0457, d0.loss_iou_aux0: 0.2279, d1.loss_cls_aux0: 0.0148, d1.loss_bbox_aux0: 0.0259, d1.loss_iou_aux0: 0.1272, d2.loss_cls_aux0: 0.0133, d2.loss_bbox_aux0: 0.0220, d2.loss_iou_aux0: 0.1072, d3.loss_cls_aux0: 0.0136, d3.loss_bbox_aux0: 0.0221, d3.loss_iou_aux0: 0.1077, d4.loss_cls_aux0: 0.0137, d4.loss_bbox_aux0: 0.0222, d4.loss_iou_aux0: 0.1083, loss_cls_aux1: 0.0106, loss_bbox_aux1: 0.0480, loss_iou_aux1: 0.2494, d0.loss_cls_aux1: 0.0122, d0.loss_bbox_aux1: 0.0570, d0.loss_iou_aux1: 0.2960, d1.loss_cls_aux1: 0.0114, d1.loss_bbox_aux1: 0.0491, d1.loss_iou_aux1: 0.2547, d2.loss_cls_aux1: 0.0105, d2.loss_bbox_aux1: 0.0479, d2.loss_iou_aux1: 0.2490, d3.loss_cls_aux1: 0.0103, d3.loss_bbox_aux1: 0.0479, d3.loss_iou_aux1: 0.2491, d4.loss_cls_aux1: 0.0103, d4.loss_bbox_aux1: 0.0479, d4.loss_iou_aux1: 0.2492, loss: 22.1698, grad_norm: 65.7348
2024-03-18 09:17:26,918 - mmdet - INFO - Saving checkpoint at 26 epochs
2024-03-18 09:17:49,015 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:17:54,300 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.601
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.477
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.307
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.390
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.545
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.690
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.626
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.817

2024-03-18 09:17:54,300 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.053 | Tin      | 0.630 | Thatch   | 0.528 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:17:54,356 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:17:54,356 - mmdet - INFO - Epoch(val) [26][154]	bbox_mAP: 0.4030, bbox_mAP_50: 0.6010, bbox_mAP_75: 0.4770, bbox_mAP_s: 0.3070, bbox_mAP_m: 0.3900, bbox_mAP_l: 0.5450, bbox_mAP_copypaste: 0.403 0.601 0.477 0.307 0.390 0.545
2024-03-18 09:18:38,205 - mmdet - INFO - Epoch [27][50/232]	lr: 2.000e-05, eta: 0:27:18, time: 0.877, data_time: 0.061, memory: 17650, enc_loss_cls: 0.1058, enc_loss_bbox: 0.0628, enc_loss_iou: 0.3548, loss_cls: 0.0737, loss_bbox: 0.0595, loss_iou: 0.3391, d0.loss_cls: 0.1121, d0.loss_bbox: 0.0598, d0.loss_iou: 0.3415, d1.loss_cls: 0.0856, d1.loss_bbox: 0.0595, d1.loss_iou: 0.3396, d2.loss_cls: 0.0767, d2.loss_bbox: 0.0595, d2.loss_iou: 0.3387, d3.loss_cls: 0.0737, d3.loss_bbox: 0.0595, d3.loss_iou: 0.3389, d4.loss_cls: 0.0741, d4.loss_bbox: 0.0595, d4.loss_iou: 0.3389, loss_rpn_cls: 0.0257, loss_rpn_bbox: 0.1313, loss_cls0: 1.2310, acc0: 95.7480, loss_bbox0: 2.4969, loss_cls1: 0.8373, loss_bbox1: 3.6836, loss_centerness1: 7.4766, loss_cls_aux0: 0.0078, loss_bbox_aux0: 0.0203, loss_iou_aux0: 0.1042, d0.loss_cls_aux0: 0.0143, d0.loss_bbox_aux0: 0.0434, d0.loss_iou_aux0: 0.2260, d1.loss_cls_aux0: 0.0098, d1.loss_bbox_aux0: 0.0238, d1.loss_iou_aux0: 0.1221, d2.loss_cls_aux0: 0.0079, d2.loss_bbox_aux0: 0.0201, d2.loss_iou_aux0: 0.1028, d3.loss_cls_aux0: 0.0071, d3.loss_bbox_aux0: 0.0202, d3.loss_iou_aux0: 0.1031, d4.loss_cls_aux0: 0.0076, d4.loss_bbox_aux0: 0.0202, d4.loss_iou_aux0: 0.1036, loss_cls_aux1: 0.0060, loss_bbox_aux1: 0.0485, loss_iou_aux1: 0.2636, d0.loss_cls_aux1: 0.0081, d0.loss_bbox_aux1: 0.0565, d0.loss_iou_aux1: 0.3076, d1.loss_cls_aux1: 0.0071, d1.loss_bbox_aux1: 0.0492, d1.loss_iou_aux1: 0.2675, d2.loss_cls_aux1: 0.0060, d2.loss_bbox_aux1: 0.0485, d2.loss_iou_aux1: 0.2632, d3.loss_cls_aux1: 0.0054, d3.loss_bbox_aux1: 0.0485, d3.loss_iou_aux1: 0.2633, d4.loss_cls_aux1: 0.0058, d4.loss_bbox_aux1: 0.0485, d4.loss_iou_aux1: 0.2634, loss: 22.2268, grad_norm: 63.4408
2024-03-18 09:19:18,950 - mmdet - INFO - Epoch [27][100/232]	lr: 2.000e-05, eta: 0:26:43, time: 0.815, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1088, enc_loss_bbox: 0.0665, enc_loss_iou: 0.3538, loss_cls: 0.0827, loss_bbox: 0.0613, loss_iou: 0.3302, d0.loss_cls: 0.1129, d0.loss_bbox: 0.0621, d0.loss_iou: 0.3362, d1.loss_cls: 0.0915, d1.loss_bbox: 0.0612, d1.loss_iou: 0.3306, d2.loss_cls: 0.0850, d2.loss_bbox: 0.0613, d2.loss_iou: 0.3300, d3.loss_cls: 0.0833, d3.loss_bbox: 0.0613, d3.loss_iou: 0.3297, d4.loss_cls: 0.0826, d4.loss_bbox: 0.0613, d4.loss_iou: 0.3300, loss_rpn_cls: 0.0233, loss_rpn_bbox: 0.1271, loss_cls0: 1.2761, acc0: 95.6017, loss_bbox0: 2.5256, loss_cls1: 0.8559, loss_bbox1: 3.6339, loss_centerness1: 7.5059, loss_cls_aux0: 0.0100, loss_bbox_aux0: 0.0222, loss_iou_aux0: 0.1099, d0.loss_cls_aux0: 0.0144, d0.loss_bbox_aux0: 0.0454, d0.loss_iou_aux0: 0.2275, d1.loss_cls_aux0: 0.0108, d1.loss_bbox_aux0: 0.0270, d1.loss_iou_aux0: 0.1328, d2.loss_cls_aux0: 0.0104, d2.loss_bbox_aux0: 0.0219, d2.loss_iou_aux0: 0.1081, d3.loss_cls_aux0: 0.0098, d3.loss_bbox_aux0: 0.0220, d3.loss_iou_aux0: 0.1086, d4.loss_cls_aux0: 0.0097, d4.loss_bbox_aux0: 0.0221, d4.loss_iou_aux0: 0.1092, loss_cls_aux1: 0.0085, loss_bbox_aux1: 0.0481, loss_iou_aux1: 0.2567, d0.loss_cls_aux1: 0.0104, d0.loss_bbox_aux1: 0.0565, d0.loss_iou_aux1: 0.2992, d1.loss_cls_aux1: 0.0092, d1.loss_bbox_aux1: 0.0491, d1.loss_iou_aux1: 0.2620, d2.loss_cls_aux1: 0.0087, d2.loss_bbox_aux1: 0.0480, d2.loss_iou_aux1: 0.2561, d3.loss_cls_aux1: 0.0083, d3.loss_bbox_aux1: 0.0481, d3.loss_iou_aux1: 0.2562, d4.loss_cls_aux1: 0.0083, d4.loss_bbox_aux1: 0.0481, d4.loss_iou_aux1: 0.2565, loss: 22.3297, grad_norm: 74.2723
2024-03-18 09:19:59,955 - mmdet - INFO - Epoch [27][150/232]	lr: 2.000e-05, eta: 0:26:09, time: 0.820, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1058, enc_loss_bbox: 0.0697, enc_loss_iou: 0.3599, loss_cls: 0.0791, loss_bbox: 0.0638, loss_iou: 0.3334, d0.loss_cls: 0.1169, d0.loss_bbox: 0.0645, d0.loss_iou: 0.3378, d1.loss_cls: 0.0897, d1.loss_bbox: 0.0639, d1.loss_iou: 0.3338, d2.loss_cls: 0.0842, d2.loss_bbox: 0.0636, d2.loss_iou: 0.3316, d3.loss_cls: 0.0814, d3.loss_bbox: 0.0636, d3.loss_iou: 0.3317, d4.loss_cls: 0.0802, d4.loss_bbox: 0.0637, d4.loss_iou: 0.3321, loss_rpn_cls: 0.0257, loss_rpn_bbox: 0.1302, loss_cls0: 1.4013, acc0: 95.2141, loss_bbox0: 2.5990, loss_cls1: 0.9013, loss_bbox1: 3.6390, loss_centerness1: 7.4776, loss_cls_aux0: 0.0119, loss_bbox_aux0: 0.0247, loss_iou_aux0: 0.1212, d0.loss_cls_aux0: 0.0157, d0.loss_bbox_aux0: 0.0459, d0.loss_iou_aux0: 0.2272, d1.loss_cls_aux0: 0.0111, d1.loss_bbox_aux0: 0.0291, d1.loss_iou_aux0: 0.1419, d2.loss_cls_aux0: 0.0105, d2.loss_bbox_aux0: 0.0244, d2.loss_iou_aux0: 0.1181, d3.loss_cls_aux0: 0.0111, d3.loss_bbox_aux0: 0.0245, d3.loss_iou_aux0: 0.1190, d4.loss_cls_aux0: 0.0114, d4.loss_bbox_aux0: 0.0246, d4.loss_iou_aux0: 0.1200, loss_cls_aux1: 0.0106, loss_bbox_aux1: 0.0507, loss_iou_aux1: 0.2619, d0.loss_cls_aux1: 0.0109, d0.loss_bbox_aux1: 0.0569, d0.loss_iou_aux1: 0.2930, d1.loss_cls_aux1: 0.0091, d1.loss_bbox_aux1: 0.0513, d1.loss_iou_aux1: 0.2656, d2.loss_cls_aux1: 0.0093, d2.loss_bbox_aux1: 0.0506, d2.loss_iou_aux1: 0.2616, d3.loss_cls_aux1: 0.0098, d3.loss_bbox_aux1: 0.0506, d3.loss_iou_aux1: 0.2616, d4.loss_cls_aux1: 0.0104, d4.loss_bbox_aux1: 0.0506, d4.loss_iou_aux1: 0.2617, loss: 22.6929, grad_norm: 71.3628
2024-03-18 09:20:41,817 - mmdet - INFO - Epoch [27][200/232]	lr: 2.000e-05, eta: 0:25:35, time: 0.837, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1113, enc_loss_bbox: 0.0654, enc_loss_iou: 0.3478, loss_cls: 0.0832, loss_bbox: 0.0587, loss_iou: 0.3168, d0.loss_cls: 0.1149, d0.loss_bbox: 0.0598, d0.loss_iou: 0.3221, d1.loss_cls: 0.0914, d1.loss_bbox: 0.0591, d1.loss_iou: 0.3180, d2.loss_cls: 0.0875, d2.loss_bbox: 0.0586, d2.loss_iou: 0.3159, d3.loss_cls: 0.0834, d3.loss_bbox: 0.0586, d3.loss_iou: 0.3162, d4.loss_cls: 0.0826, d4.loss_bbox: 0.0588, d4.loss_iou: 0.3170, loss_rpn_cls: 0.0345, loss_rpn_bbox: 0.1314, loss_cls0: 1.3190, acc0: 95.4850, loss_bbox0: 2.4965, loss_cls1: 0.8827, loss_bbox1: 3.4227, loss_centerness1: 7.4469, loss_cls_aux0: 0.0066, loss_bbox_aux0: 0.0224, loss_iou_aux0: 0.1105, d0.loss_cls_aux0: 0.0129, d0.loss_bbox_aux0: 0.0456, d0.loss_iou_aux0: 0.2255, d1.loss_cls_aux0: 0.0082, d1.loss_bbox_aux0: 0.0266, d1.loss_iou_aux0: 0.1302, d2.loss_cls_aux0: 0.0067, d2.loss_bbox_aux0: 0.0223, d2.loss_iou_aux0: 0.1092, d3.loss_cls_aux0: 0.0062, d3.loss_bbox_aux0: 0.0223, d3.loss_iou_aux0: 0.1096, d4.loss_cls_aux0: 0.0063, d4.loss_bbox_aux0: 0.0223, d4.loss_iou_aux0: 0.1100, loss_cls_aux1: 0.0054, loss_bbox_aux1: 0.0468, loss_iou_aux1: 0.2477, d0.loss_cls_aux1: 0.0076, d0.loss_bbox_aux1: 0.0528, d0.loss_iou_aux1: 0.2792, d1.loss_cls_aux1: 0.0060, d1.loss_bbox_aux1: 0.0475, d1.loss_iou_aux1: 0.2513, d2.loss_cls_aux1: 0.0052, d2.loss_bbox_aux1: 0.0468, d2.loss_iou_aux1: 0.2473, d3.loss_cls_aux1: 0.0050, d3.loss_bbox_aux1: 0.0468, d3.loss_iou_aux1: 0.2474, d4.loss_cls_aux1: 0.0051, d4.loss_bbox_aux1: 0.0468, d4.loss_iou_aux1: 0.2475, loss: 21.9061, grad_norm: 64.1764
2024-03-18 09:21:09,298 - mmdet - INFO - Saving checkpoint at 27 epochs
2024-03-18 09:21:31,548 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:21:36,946 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.572
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.460
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.289
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.379
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.577
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.528
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.680
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.791

2024-03-18 09:21:36,947 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.033 | Tin      | 0.624 | Thatch   | 0.502 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:21:37,001 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:21:37,002 - mmdet - INFO - Epoch(val) [27][154]	bbox_mAP: 0.3860, bbox_mAP_50: 0.5720, bbox_mAP_75: 0.4600, bbox_mAP_s: 0.2890, bbox_mAP_m: 0.3790, bbox_mAP_l: 0.5770, bbox_mAP_copypaste: 0.386 0.572 0.460 0.289 0.379 0.577
2024-03-18 09:22:20,981 - mmdet - INFO - Epoch [28][50/232]	lr: 2.000e-05, eta: 0:24:30, time: 0.879, data_time: 0.060, memory: 17650, enc_loss_cls: 0.1112, enc_loss_bbox: 0.0683, enc_loss_iou: 0.3642, loss_cls: 0.0829, loss_bbox: 0.0619, loss_iou: 0.3364, d0.loss_cls: 0.1176, d0.loss_bbox: 0.0629, d0.loss_iou: 0.3420, d1.loss_cls: 0.0926, d1.loss_bbox: 0.0626, d1.loss_iou: 0.3390, d2.loss_cls: 0.0860, d2.loss_bbox: 0.0619, d2.loss_iou: 0.3358, d3.loss_cls: 0.0822, d3.loss_bbox: 0.0619, d3.loss_iou: 0.3362, d4.loss_cls: 0.0822, d4.loss_bbox: 0.0619, d4.loss_iou: 0.3361, loss_rpn_cls: 0.0263, loss_rpn_bbox: 0.1303, loss_cls0: 1.2720, acc0: 95.6872, loss_bbox0: 2.4545, loss_cls1: 0.8768, loss_bbox1: 3.6153, loss_centerness1: 7.4627, loss_cls_aux0: 0.0074, loss_bbox_aux0: 0.0223, loss_iou_aux0: 0.1104, d0.loss_cls_aux0: 0.0145, d0.loss_bbox_aux0: 0.0463, d0.loss_iou_aux0: 0.2296, d1.loss_cls_aux0: 0.0098, d1.loss_bbox_aux0: 0.0268, d1.loss_iou_aux0: 0.1312, d2.loss_cls_aux0: 0.0079, d2.loss_bbox_aux0: 0.0222, d2.loss_iou_aux0: 0.1090, d3.loss_cls_aux0: 0.0075, d3.loss_bbox_aux0: 0.0222, d3.loss_iou_aux0: 0.1094, d4.loss_cls_aux0: 0.0075, d4.loss_bbox_aux0: 0.0223, d4.loss_iou_aux0: 0.1098, loss_cls_aux1: 0.0057, loss_bbox_aux1: 0.0476, loss_iou_aux1: 0.2527, d0.loss_cls_aux1: 0.0076, d0.loss_bbox_aux1: 0.0563, d0.loss_iou_aux1: 0.2962, d1.loss_cls_aux1: 0.0066, d1.loss_bbox_aux1: 0.0488, d1.loss_iou_aux1: 0.2589, d2.loss_cls_aux1: 0.0058, d2.loss_bbox_aux1: 0.0476, d2.loss_iou_aux1: 0.2525, d3.loss_cls_aux1: 0.0058, d3.loss_bbox_aux1: 0.0476, d3.loss_iou_aux1: 0.2526, d4.loss_cls_aux1: 0.0058, d4.loss_bbox_aux1: 0.0476, d4.loss_iou_aux1: 0.2526, loss: 22.2381, grad_norm: 58.5219
2024-03-18 09:23:02,505 - mmdet - INFO - Epoch [28][100/232]	lr: 2.000e-05, eta: 0:23:56, time: 0.830, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1054, enc_loss_bbox: 0.0630, enc_loss_iou: 0.3377, loss_cls: 0.0760, loss_bbox: 0.0579, loss_iou: 0.3119, d0.loss_cls: 0.1105, d0.loss_bbox: 0.0582, d0.loss_iou: 0.3165, d1.loss_cls: 0.0867, d1.loss_bbox: 0.0580, d1.loss_iou: 0.3130, d2.loss_cls: 0.0794, d2.loss_bbox: 0.0578, d2.loss_iou: 0.3114, d3.loss_cls: 0.0752, d3.loss_bbox: 0.0578, d3.loss_iou: 0.3116, d4.loss_cls: 0.0759, d4.loss_bbox: 0.0579, d4.loss_iou: 0.3117, loss_rpn_cls: 0.0336, loss_rpn_bbox: 0.1308, loss_cls0: 1.2111, acc0: 95.7846, loss_bbox0: 2.4077, loss_cls1: 0.8301, loss_bbox1: 3.4431, loss_centerness1: 7.4595, loss_cls_aux0: 0.0065, loss_bbox_aux0: 0.0217, loss_iou_aux0: 0.1074, d0.loss_cls_aux0: 0.0131, d0.loss_bbox_aux0: 0.0439, d0.loss_iou_aux0: 0.2207, d1.loss_cls_aux0: 0.0085, d1.loss_bbox_aux0: 0.0249, d1.loss_iou_aux0: 0.1237, d2.loss_cls_aux0: 0.0069, d2.loss_bbox_aux0: 0.0215, d2.loss_iou_aux0: 0.1061, d3.loss_cls_aux0: 0.0065, d3.loss_bbox_aux0: 0.0216, d3.loss_iou_aux0: 0.1064, d4.loss_cls_aux0: 0.0065, d4.loss_bbox_aux0: 0.0216, d4.loss_iou_aux0: 0.1069, loss_cls_aux1: 0.0042, loss_bbox_aux1: 0.0479, loss_iou_aux1: 0.2541, d0.loss_cls_aux1: 0.0072, d0.loss_bbox_aux1: 0.0569, d0.loss_iou_aux1: 0.2978, d1.loss_cls_aux1: 0.0059, d1.loss_bbox_aux1: 0.0486, d1.loss_iou_aux1: 0.2567, d2.loss_cls_aux1: 0.0049, d2.loss_bbox_aux1: 0.0478, d2.loss_iou_aux1: 0.2536, d3.loss_cls_aux1: 0.0042, d3.loss_bbox_aux1: 0.0479, d3.loss_iou_aux1: 0.2538, d4.loss_cls_aux1: 0.0041, d4.loss_bbox_aux1: 0.0479, d4.loss_iou_aux1: 0.2539, loss: 21.6209, grad_norm: 63.5672
2024-03-18 09:23:44,493 - mmdet - INFO - Epoch [28][150/232]	lr: 2.000e-05, eta: 0:23:22, time: 0.840, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1099, enc_loss_bbox: 0.0694, enc_loss_iou: 0.3627, loss_cls: 0.0791, loss_bbox: 0.0638, loss_iou: 0.3366, d0.loss_cls: 0.1151, d0.loss_bbox: 0.0645, d0.loss_iou: 0.3418, d1.loss_cls: 0.0890, d1.loss_bbox: 0.0641, d1.loss_iou: 0.3372, d2.loss_cls: 0.0844, d2.loss_bbox: 0.0638, d2.loss_iou: 0.3362, d3.loss_cls: 0.0807, d3.loss_bbox: 0.0637, d3.loss_iou: 0.3362, d4.loss_cls: 0.0795, d4.loss_bbox: 0.0637, d4.loss_iou: 0.3365, loss_rpn_cls: 0.0394, loss_rpn_bbox: 0.1419, loss_cls0: 1.3869, acc0: 95.2392, loss_bbox0: 2.6232, loss_cls1: 0.8884, loss_bbox1: 3.7764, loss_centerness1: 7.4994, loss_cls_aux0: 0.0103, loss_bbox_aux0: 0.0224, loss_iou_aux0: 0.1135, d0.loss_cls_aux0: 0.0147, d0.loss_bbox_aux0: 0.0458, d0.loss_iou_aux0: 0.2317, d1.loss_cls_aux0: 0.0109, d1.loss_bbox_aux0: 0.0262, d1.loss_iou_aux0: 0.1328, d2.loss_cls_aux0: 0.0096, d2.loss_bbox_aux0: 0.0223, d2.loss_iou_aux0: 0.1121, d3.loss_cls_aux0: 0.0097, d3.loss_bbox_aux0: 0.0223, d3.loss_iou_aux0: 0.1125, d4.loss_cls_aux0: 0.0101, d4.loss_bbox_aux0: 0.0224, d4.loss_iou_aux0: 0.1130, loss_cls_aux1: 0.0096, loss_bbox_aux1: 0.0493, loss_iou_aux1: 0.2626, d0.loss_cls_aux1: 0.0114, d0.loss_bbox_aux1: 0.0605, d0.loss_iou_aux1: 0.3176, d1.loss_cls_aux1: 0.0105, d1.loss_bbox_aux1: 0.0510, d1.loss_iou_aux1: 0.2702, d2.loss_cls_aux1: 0.0094, d2.loss_bbox_aux1: 0.0493, d2.loss_iou_aux1: 0.2624, d3.loss_cls_aux1: 0.0095, d3.loss_bbox_aux1: 0.0493, d3.loss_iou_aux1: 0.2625, d4.loss_cls_aux1: 0.0095, d4.loss_bbox_aux1: 0.0493, d4.loss_iou_aux1: 0.2625, loss: 22.8821, grad_norm: 71.4030
2024-03-18 09:24:26,340 - mmdet - INFO - Epoch [28][200/232]	lr: 2.000e-05, eta: 0:22:47, time: 0.837, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1087, enc_loss_bbox: 0.0669, enc_loss_iou: 0.3512, loss_cls: 0.0790, loss_bbox: 0.0615, loss_iou: 0.3259, d0.loss_cls: 0.1156, d0.loss_bbox: 0.0616, d0.loss_iou: 0.3284, d1.loss_cls: 0.0871, d1.loss_bbox: 0.0614, d1.loss_iou: 0.3257, d2.loss_cls: 0.0801, d2.loss_bbox: 0.0614, d2.loss_iou: 0.3253, d3.loss_cls: 0.0790, d3.loss_bbox: 0.0615, d3.loss_iou: 0.3257, d4.loss_cls: 0.0785, d4.loss_bbox: 0.0614, d4.loss_iou: 0.3257, loss_rpn_cls: 0.0251, loss_rpn_bbox: 0.1233, loss_cls0: 1.2885, acc0: 95.5796, loss_bbox0: 2.5099, loss_cls1: 0.8952, loss_bbox1: 3.5445, loss_centerness1: 7.4522, loss_cls_aux0: 0.0129, loss_bbox_aux0: 0.0204, loss_iou_aux0: 0.0990, d0.loss_cls_aux0: 0.0186, d0.loss_bbox_aux0: 0.0440, d0.loss_iou_aux0: 0.2186, d1.loss_cls_aux0: 0.0142, d1.loss_bbox_aux0: 0.0240, d1.loss_iou_aux0: 0.1163, d2.loss_cls_aux0: 0.0125, d2.loss_bbox_aux0: 0.0202, d2.loss_iou_aux0: 0.0968, d3.loss_cls_aux0: 0.0121, d3.loss_bbox_aux0: 0.0202, d3.loss_iou_aux0: 0.0975, d4.loss_cls_aux0: 0.0127, d4.loss_bbox_aux0: 0.0203, d4.loss_iou_aux0: 0.0982, loss_cls_aux1: 0.0127, loss_bbox_aux1: 0.0484, loss_iou_aux1: 0.2548, d0.loss_cls_aux1: 0.0142, d0.loss_bbox_aux1: 0.0540, d0.loss_iou_aux1: 0.2832, d1.loss_cls_aux1: 0.0139, d1.loss_bbox_aux1: 0.0494, d1.loss_iou_aux1: 0.2594, d2.loss_cls_aux1: 0.0138, d2.loss_bbox_aux1: 0.0483, d2.loss_iou_aux1: 0.2546, d3.loss_cls_aux1: 0.0126, d3.loss_bbox_aux1: 0.0483, d3.loss_iou_aux1: 0.2546, d4.loss_cls_aux1: 0.0128, d4.loss_bbox_aux1: 0.0483, d4.loss_iou_aux1: 0.2547, loss: 22.1068, grad_norm: 76.8793
2024-03-18 09:24:53,134 - mmdet - INFO - Saving checkpoint at 28 epochs
2024-03-18 09:25:15,165 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:25:21,268 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.398
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.597
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.470
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.295
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.385
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.529
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.654
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.479
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.670
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.823

2024-03-18 09:25:21,268 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.052 | Tin      | 0.619 | Thatch   | 0.522 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:25:21,320 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:25:21,320 - mmdet - INFO - Epoch(val) [28][154]	bbox_mAP: 0.3980, bbox_mAP_50: 0.5970, bbox_mAP_75: 0.4700, bbox_mAP_s: 0.2950, bbox_mAP_m: 0.3850, bbox_mAP_l: 0.5290, bbox_mAP_copypaste: 0.398 0.597 0.470 0.295 0.385 0.529
2024-03-18 09:26:04,964 - mmdet - INFO - Epoch [29][50/232]	lr: 2.000e-05, eta: 0:21:43, time: 0.873, data_time: 0.060, memory: 17650, enc_loss_cls: 0.0981, enc_loss_bbox: 0.0625, enc_loss_iou: 0.3510, loss_cls: 0.0724, loss_bbox: 0.0570, loss_iou: 0.3229, d0.loss_cls: 0.1053, d0.loss_bbox: 0.0576, d0.loss_iou: 0.3262, d1.loss_cls: 0.0794, d1.loss_bbox: 0.0572, d1.loss_iou: 0.3236, d2.loss_cls: 0.0744, d2.loss_bbox: 0.0570, d2.loss_iou: 0.3228, d3.loss_cls: 0.0725, d3.loss_bbox: 0.0570, d3.loss_iou: 0.3228, d4.loss_cls: 0.0725, d4.loss_bbox: 0.0570, d4.loss_iou: 0.3228, loss_rpn_cls: 0.0238, loss_rpn_bbox: 0.1291, loss_cls0: 1.2890, acc0: 95.5624, loss_bbox0: 2.5125, loss_cls1: 0.8402, loss_bbox1: 3.6110, loss_centerness1: 7.4652, loss_cls_aux0: 0.0098, loss_bbox_aux0: 0.0200, loss_iou_aux0: 0.1051, d0.loss_cls_aux0: 0.0149, d0.loss_bbox_aux0: 0.0422, d0.loss_iou_aux0: 0.2216, d1.loss_cls_aux0: 0.0103, d1.loss_bbox_aux0: 0.0236, d1.loss_iou_aux0: 0.1232, d2.loss_cls_aux0: 0.0091, d2.loss_bbox_aux0: 0.0199, d2.loss_iou_aux0: 0.1036, d3.loss_cls_aux0: 0.0091, d3.loss_bbox_aux0: 0.0199, d3.loss_iou_aux0: 0.1040, d4.loss_cls_aux0: 0.0097, d4.loss_bbox_aux0: 0.0200, d4.loss_iou_aux0: 0.1045, loss_cls_aux1: 0.0084, loss_bbox_aux1: 0.0461, loss_iou_aux1: 0.2570, d0.loss_cls_aux1: 0.0094, d0.loss_bbox_aux1: 0.0522, d0.loss_iou_aux1: 0.2904, d1.loss_cls_aux1: 0.0083, d1.loss_bbox_aux1: 0.0467, d1.loss_iou_aux1: 0.2598, d2.loss_cls_aux1: 0.0077, d2.loss_bbox_aux1: 0.0460, d2.loss_iou_aux1: 0.2566, d3.loss_cls_aux1: 0.0079, d3.loss_bbox_aux1: 0.0461, d3.loss_iou_aux1: 0.2567, d4.loss_cls_aux1: 0.0084, d4.loss_bbox_aux1: 0.0461, d4.loss_iou_aux1: 0.2569, loss: 22.0237, grad_norm: 64.7997
2024-03-18 09:26:45,598 - mmdet - INFO - Epoch [29][100/232]	lr: 2.000e-05, eta: 0:21:08, time: 0.813, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1030, enc_loss_bbox: 0.0633, enc_loss_iou: 0.3443, loss_cls: 0.0721, loss_bbox: 0.0589, loss_iou: 0.3213, d0.loss_cls: 0.1000, d0.loss_bbox: 0.0597, d0.loss_iou: 0.3255, d1.loss_cls: 0.0785, d1.loss_bbox: 0.0591, d1.loss_iou: 0.3217, d2.loss_cls: 0.0733, d2.loss_bbox: 0.0589, d2.loss_iou: 0.3213, d3.loss_cls: 0.0726, d3.loss_bbox: 0.0588, d3.loss_iou: 0.3209, d4.loss_cls: 0.0717, d4.loss_bbox: 0.0589, d4.loss_iou: 0.3212, loss_rpn_cls: 0.0262, loss_rpn_bbox: 0.1192, loss_cls0: 1.2472, acc0: 95.7426, loss_bbox0: 2.3898, loss_cls1: 0.8250, loss_bbox1: 3.5348, loss_centerness1: 7.4745, loss_cls_aux0: 0.0073, loss_bbox_aux0: 0.0226, loss_iou_aux0: 0.1099, d0.loss_cls_aux0: 0.0136, d0.loss_bbox_aux0: 0.0444, d0.loss_iou_aux0: 0.2277, d1.loss_cls_aux0: 0.0096, d1.loss_bbox_aux0: 0.0255, d1.loss_iou_aux0: 0.1251, d2.loss_cls_aux0: 0.0082, d2.loss_bbox_aux0: 0.0223, d2.loss_iou_aux0: 0.1081, d3.loss_cls_aux0: 0.0075, d3.loss_bbox_aux0: 0.0224, d3.loss_iou_aux0: 0.1086, d4.loss_cls_aux0: 0.0072, d4.loss_bbox_aux0: 0.0225, d4.loss_iou_aux0: 0.1092, loss_cls_aux1: 0.0057, loss_bbox_aux1: 0.0483, loss_iou_aux1: 0.2608, d0.loss_cls_aux1: 0.0082, d0.loss_bbox_aux1: 0.0572, d0.loss_iou_aux1: 0.3088, d1.loss_cls_aux1: 0.0070, d1.loss_bbox_aux1: 0.0492, d1.loss_iou_aux1: 0.2643, d2.loss_cls_aux1: 0.0058, d2.loss_bbox_aux1: 0.0482, d2.loss_iou_aux1: 0.2604, d3.loss_cls_aux1: 0.0057, d3.loss_bbox_aux1: 0.0483, d3.loss_iou_aux1: 0.2605, d4.loss_cls_aux1: 0.0056, d4.loss_bbox_aux1: 0.0483, d4.loss_iou_aux1: 0.2607, loss: 21.8362, grad_norm: 67.9324
2024-03-18 09:27:26,806 - mmdet - INFO - Epoch [29][150/232]	lr: 2.000e-05, eta: 0:20:34, time: 0.824, data_time: 0.009, memory: 17650, enc_loss_cls: 0.1031, enc_loss_bbox: 0.0705, enc_loss_iou: 0.3530, loss_cls: 0.0706, loss_bbox: 0.0642, loss_iou: 0.3263, d0.loss_cls: 0.1068, d0.loss_bbox: 0.0652, d0.loss_iou: 0.3313, d1.loss_cls: 0.0813, d1.loss_bbox: 0.0642, d1.loss_iou: 0.3279, d2.loss_cls: 0.0761, d2.loss_bbox: 0.0642, d2.loss_iou: 0.3264, d3.loss_cls: 0.0722, d3.loss_bbox: 0.0642, d3.loss_iou: 0.3263, d4.loss_cls: 0.0709, d4.loss_bbox: 0.0642, d4.loss_iou: 0.3265, loss_rpn_cls: 0.0341, loss_rpn_bbox: 0.1222, loss_cls0: 1.2383, acc0: 95.7237, loss_bbox0: 2.4622, loss_cls1: 0.8793, loss_bbox1: 3.5574, loss_centerness1: 7.4618, loss_cls_aux0: 0.0057, loss_bbox_aux0: 0.0227, loss_iou_aux0: 0.1071, d0.loss_cls_aux0: 0.0124, d0.loss_bbox_aux0: 0.0455, d0.loss_iou_aux0: 0.2202, d1.loss_cls_aux0: 0.0078, d1.loss_bbox_aux0: 0.0259, d1.loss_iou_aux0: 0.1224, d2.loss_cls_aux0: 0.0059, d2.loss_bbox_aux0: 0.0225, d2.loss_iou_aux0: 0.1053, d3.loss_cls_aux0: 0.0055, d3.loss_bbox_aux0: 0.0226, d3.loss_iou_aux0: 0.1057, d4.loss_cls_aux0: 0.0055, d4.loss_bbox_aux0: 0.0226, d4.loss_iou_aux0: 0.1063, loss_cls_aux1: 0.0051, loss_bbox_aux1: 0.0487, loss_iou_aux1: 0.2508, d0.loss_cls_aux1: 0.0078, d0.loss_bbox_aux1: 0.0566, d0.loss_iou_aux1: 0.2892, d1.loss_cls_aux1: 0.0072, d1.loss_bbox_aux1: 0.0501, d1.loss_iou_aux1: 0.2574, d2.loss_cls_aux1: 0.0064, d2.loss_bbox_aux1: 0.0487, d2.loss_iou_aux1: 0.2506, d3.loss_cls_aux1: 0.0053, d3.loss_bbox_aux1: 0.0487, d3.loss_iou_aux1: 0.2507, d4.loss_cls_aux1: 0.0052, d4.loss_bbox_aux1: 0.0487, d4.loss_iou_aux1: 0.2507, loss: 21.9701, grad_norm: 64.2121
2024-03-18 09:28:08,478 - mmdet - INFO - Epoch [29][200/232]	lr: 2.000e-05, eta: 0:19:59, time: 0.833, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1098, enc_loss_bbox: 0.0673, enc_loss_iou: 0.3548, loss_cls: 0.0830, loss_bbox: 0.0624, loss_iou: 0.3296, d0.loss_cls: 0.1226, d0.loss_bbox: 0.0632, d0.loss_iou: 0.3332, d1.loss_cls: 0.0946, d1.loss_bbox: 0.0630, d1.loss_iou: 0.3300, d2.loss_cls: 0.0875, d2.loss_bbox: 0.0628, d2.loss_iou: 0.3295, d3.loss_cls: 0.0833, d3.loss_bbox: 0.0624, d3.loss_iou: 0.3293, d4.loss_cls: 0.0829, d4.loss_bbox: 0.0624, d4.loss_iou: 0.3293, loss_rpn_cls: 0.0301, loss_rpn_bbox: 0.1611, loss_cls0: 1.4948, acc0: 94.8669, loss_bbox0: 2.7275, loss_cls1: 0.8968, loss_bbox1: 3.6042, loss_centerness1: 7.4769, loss_cls_aux0: 0.0093, loss_bbox_aux0: 0.0260, loss_iou_aux0: 0.1280, d0.loss_cls_aux0: 0.0156, d0.loss_bbox_aux0: 0.0463, d0.loss_iou_aux0: 0.2319, d1.loss_cls_aux0: 0.0121, d1.loss_bbox_aux0: 0.0288, d1.loss_iou_aux0: 0.1421, d2.loss_cls_aux0: 0.0111, d2.loss_bbox_aux0: 0.0257, d2.loss_iou_aux0: 0.1259, d3.loss_cls_aux0: 0.0095, d3.loss_bbox_aux0: 0.0258, d3.loss_iou_aux0: 0.1265, d4.loss_cls_aux0: 0.0093, d4.loss_bbox_aux0: 0.0259, d4.loss_iou_aux0: 0.1272, loss_cls_aux1: 0.0076, loss_bbox_aux1: 0.0488, loss_iou_aux1: 0.2552, d0.loss_cls_aux1: 0.0101, d0.loss_bbox_aux1: 0.0568, d0.loss_iou_aux1: 0.2972, d1.loss_cls_aux1: 0.0087, d1.loss_bbox_aux1: 0.0494, d1.loss_iou_aux1: 0.2589, d2.loss_cls_aux1: 0.0083, d2.loss_bbox_aux1: 0.0487, d2.loss_iou_aux1: 0.2548, d3.loss_cls_aux1: 0.0078, d3.loss_bbox_aux1: 0.0487, d3.loss_iou_aux1: 0.2549, d4.loss_cls_aux1: 0.0075, d4.loss_bbox_aux1: 0.0488, d4.loss_iou_aux1: 0.2551, loss: 22.8885, grad_norm: 65.4378
2024-03-18 09:28:35,404 - mmdet - INFO - Saving checkpoint at 29 epochs
2024-03-18 09:28:57,508 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:29:03,160 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.393
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.592
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.468
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.299
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.515
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.470
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.687
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.551

2024-03-18 09:29:03,160 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.036 | Tin      | 0.617 | Thatch   | 0.525 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:29:03,218 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:29:03,218 - mmdet - INFO - Epoch(val) [29][154]	bbox_mAP: 0.3930, bbox_mAP_50: 0.5920, bbox_mAP_75: 0.4680, bbox_mAP_s: 0.2990, bbox_mAP_m: 0.3830, bbox_mAP_l: 0.5150, bbox_mAP_copypaste: 0.393 0.592 0.468 0.299 0.383 0.515
2024-03-18 09:29:46,739 - mmdet - INFO - Epoch [30][50/232]	lr: 2.000e-05, eta: 0:18:56, time: 0.870, data_time: 0.060, memory: 17650, enc_loss_cls: 0.1095, enc_loss_bbox: 0.0663, enc_loss_iou: 0.3483, loss_cls: 0.0756, loss_bbox: 0.0612, loss_iou: 0.3244, d0.loss_cls: 0.1116, d0.loss_bbox: 0.0623, d0.loss_iou: 0.3308, d1.loss_cls: 0.0872, d1.loss_bbox: 0.0616, d1.loss_iou: 0.3260, d2.loss_cls: 0.0816, d2.loss_bbox: 0.0611, d2.loss_iou: 0.3240, d3.loss_cls: 0.0767, d3.loss_bbox: 0.0611, d3.loss_iou: 0.3241, d4.loss_cls: 0.0755, d4.loss_bbox: 0.0611, d4.loss_iou: 0.3242, loss_rpn_cls: 0.0279, loss_rpn_bbox: 0.1297, loss_cls0: 1.3388, acc0: 95.4958, loss_bbox0: 2.5489, loss_cls1: 0.8678, loss_bbox1: 3.5492, loss_centerness1: 7.4724, loss_cls_aux0: 0.0109, loss_bbox_aux0: 0.0215, loss_iou_aux0: 0.1059, d0.loss_cls_aux0: 0.0174, d0.loss_bbox_aux0: 0.0443, d0.loss_iou_aux0: 0.2232, d1.loss_cls_aux0: 0.0136, d1.loss_bbox_aux0: 0.0253, d1.loss_iou_aux0: 0.1249, d2.loss_cls_aux0: 0.0115, d2.loss_bbox_aux0: 0.0214, d2.loss_iou_aux0: 0.1045, d3.loss_cls_aux0: 0.0110, d3.loss_bbox_aux0: 0.0214, d3.loss_iou_aux0: 0.1048, d4.loss_cls_aux0: 0.0109, d4.loss_bbox_aux0: 0.0215, d4.loss_iou_aux0: 0.1053, loss_cls_aux1: 0.0069, loss_bbox_aux1: 0.0478, loss_iou_aux1: 0.2508, d0.loss_cls_aux1: 0.0082, d0.loss_bbox_aux1: 0.0563, d0.loss_iou_aux1: 0.2944, d1.loss_cls_aux1: 0.0081, d1.loss_bbox_aux1: 0.0485, d1.loss_iou_aux1: 0.2542, d2.loss_cls_aux1: 0.0072, d2.loss_bbox_aux1: 0.0477, d2.loss_iou_aux1: 0.2502, d3.loss_cls_aux1: 0.0068, d3.loss_bbox_aux1: 0.0477, d3.loss_iou_aux1: 0.2504, d4.loss_cls_aux1: 0.0068, d4.loss_bbox_aux1: 0.0477, d4.loss_iou_aux1: 0.2506, loss: 22.1783, grad_norm: 69.6679
2024-03-18 09:30:27,278 - mmdet - INFO - Epoch [30][100/232]	lr: 2.000e-05, eta: 0:18:21, time: 0.811, data_time: 0.010, memory: 17650, enc_loss_cls: 0.1042, enc_loss_bbox: 0.0690, enc_loss_iou: 0.3626, loss_cls: 0.0744, loss_bbox: 0.0643, loss_iou: 0.3412, d0.loss_cls: 0.1094, d0.loss_bbox: 0.0652, d0.loss_iou: 0.3442, d1.loss_cls: 0.0843, d1.loss_bbox: 0.0644, d1.loss_iou: 0.3415, d2.loss_cls: 0.0768, d2.loss_bbox: 0.0644, d2.loss_iou: 0.3412, d3.loss_cls: 0.0737, d3.loss_bbox: 0.0642, d3.loss_iou: 0.3405, d4.loss_cls: 0.0736, d4.loss_bbox: 0.0642, d4.loss_iou: 0.3411, loss_rpn_cls: 0.0283, loss_rpn_bbox: 0.1423, loss_cls0: 1.3703, acc0: 95.2645, loss_bbox0: 2.5742, loss_cls1: 0.8498, loss_bbox1: 3.7098, loss_centerness1: 7.4822, loss_cls_aux0: 0.0084, loss_bbox_aux0: 0.0222, loss_iou_aux0: 0.1115, d0.loss_cls_aux0: 0.0140, d0.loss_bbox_aux0: 0.0447, d0.loss_iou_aux0: 0.2251, d1.loss_cls_aux0: 0.0104, d1.loss_bbox_aux0: 0.0260, d1.loss_iou_aux0: 0.1310, d2.loss_cls_aux0: 0.0089, d2.loss_bbox_aux0: 0.0221, d2.loss_iou_aux0: 0.1106, d3.loss_cls_aux0: 0.0080, d3.loss_bbox_aux0: 0.0221, d3.loss_iou_aux0: 0.1108, d4.loss_cls_aux0: 0.0080, d4.loss_bbox_aux0: 0.0222, d4.loss_iou_aux0: 0.1111, loss_cls_aux1: 0.0047, loss_bbox_aux1: 0.0490, loss_iou_aux1: 0.2593, d0.loss_cls_aux1: 0.0077, d0.loss_bbox_aux1: 0.0566, d0.loss_iou_aux1: 0.2971, d1.loss_cls_aux1: 0.0061, d1.loss_bbox_aux1: 0.0500, d1.loss_iou_aux1: 0.2647, d2.loss_cls_aux1: 0.0052, d2.loss_bbox_aux1: 0.0489, d2.loss_iou_aux1: 0.2591, d3.loss_cls_aux1: 0.0044, d3.loss_bbox_aux1: 0.0490, d3.loss_iou_aux1: 0.2592, d4.loss_cls_aux1: 0.0045, d4.loss_bbox_aux1: 0.0490, d4.loss_iou_aux1: 0.2592, loss: 22.5721, grad_norm: 64.5542
2024-03-18 09:31:08,327 - mmdet - INFO - Epoch [30][150/232]	lr: 2.000e-05, eta: 0:17:46, time: 0.821, data_time: 0.013, memory: 17650, enc_loss_cls: 0.1053, enc_loss_bbox: 0.0621, enc_loss_iou: 0.3452, loss_cls: 0.0776, loss_bbox: 0.0579, loss_iou: 0.3219, d0.loss_cls: 0.1170, d0.loss_bbox: 0.0582, d0.loss_iou: 0.3262, d1.loss_cls: 0.0897, d1.loss_bbox: 0.0579, d1.loss_iou: 0.3226, d2.loss_cls: 0.0825, d2.loss_bbox: 0.0577, d2.loss_iou: 0.3221, d3.loss_cls: 0.0787, d3.loss_bbox: 0.0578, d3.loss_iou: 0.3219, d4.loss_cls: 0.0775, d4.loss_bbox: 0.0578, d4.loss_iou: 0.3218, loss_rpn_cls: 0.0278, loss_rpn_bbox: 0.1241, loss_cls0: 1.3021, acc0: 95.5492, loss_bbox0: 2.5013, loss_cls1: 0.8978, loss_bbox1: 3.4925, loss_centerness1: 7.4669, loss_cls_aux0: 0.0116, loss_bbox_aux0: 0.0205, loss_iou_aux0: 0.1023, d0.loss_cls_aux0: 0.0180, d0.loss_bbox_aux0: 0.0433, d0.loss_iou_aux0: 0.2215, d1.loss_cls_aux0: 0.0138, d1.loss_bbox_aux0: 0.0244, d1.loss_iou_aux0: 0.1224, d2.loss_cls_aux0: 0.0120, d2.loss_bbox_aux0: 0.0204, d2.loss_iou_aux0: 0.1011, d3.loss_cls_aux0: 0.0113, d3.loss_bbox_aux0: 0.0204, d3.loss_iou_aux0: 0.1014, d4.loss_cls_aux0: 0.0112, d4.loss_bbox_aux0: 0.0204, d4.loss_iou_aux0: 0.1018, loss_cls_aux1: 0.0082, loss_bbox_aux1: 0.0470, loss_iou_aux1: 0.2553, d0.loss_cls_aux1: 0.0120, d0.loss_bbox_aux1: 0.0535, d0.loss_iou_aux1: 0.2876, d1.loss_cls_aux1: 0.0108, d1.loss_bbox_aux1: 0.0473, d1.loss_iou_aux1: 0.2569, d2.loss_cls_aux1: 0.0091, d2.loss_bbox_aux1: 0.0469, d2.loss_iou_aux1: 0.2549, d3.loss_cls_aux1: 0.0079, d3.loss_bbox_aux1: 0.0469, d3.loss_iou_aux1: 0.2550, d4.loss_cls_aux1: 0.0079, d4.loss_bbox_aux1: 0.0470, d4.loss_iou_aux1: 0.2551, loss: 22.0190, grad_norm: 75.7209
2024-03-18 09:31:49,891 - mmdet - INFO - Epoch [30][200/232]	lr: 2.000e-05, eta: 0:17:11, time: 0.831, data_time: 0.011, memory: 17650, enc_loss_cls: 0.1105, enc_loss_bbox: 0.0647, enc_loss_iou: 0.3432, loss_cls: 0.0783, loss_bbox: 0.0603, loss_iou: 0.3183, d0.loss_cls: 0.1117, d0.loss_bbox: 0.0603, d0.loss_iou: 0.3207, d1.loss_cls: 0.0866, d1.loss_bbox: 0.0601, d1.loss_iou: 0.3192, d2.loss_cls: 0.0812, d2.loss_bbox: 0.0603, d2.loss_iou: 0.3182, d3.loss_cls: 0.0788, d3.loss_bbox: 0.0604, d3.loss_iou: 0.3181, d4.loss_cls: 0.0786, d4.loss_bbox: 0.0603, d4.loss_iou: 0.3183, loss_rpn_cls: 0.0276, loss_rpn_bbox: 0.1167, loss_cls0: 1.2885, acc0: 95.6249, loss_bbox0: 2.5327, loss_cls1: 0.8611, loss_bbox1: 3.4690, loss_centerness1: 7.4451, loss_cls_aux0: 0.0060, loss_bbox_aux0: 0.0210, loss_iou_aux0: 0.1014, d0.loss_cls_aux0: 0.0133, d0.loss_bbox_aux0: 0.0433, d0.loss_iou_aux0: 0.2139, d1.loss_cls_aux0: 0.0085, d1.loss_bbox_aux0: 0.0239, d1.loss_iou_aux0: 0.1157, d2.loss_cls_aux0: 0.0064, d2.loss_bbox_aux0: 0.0207, d2.loss_iou_aux0: 0.0993, d3.loss_cls_aux0: 0.0060, d3.loss_bbox_aux0: 0.0208, d3.loss_iou_aux0: 0.0998, d4.loss_cls_aux0: 0.0060, d4.loss_bbox_aux0: 0.0209, d4.loss_iou_aux0: 0.1005, loss_cls_aux1: 0.0038, loss_bbox_aux1: 0.0483, loss_iou_aux1: 0.2507, d0.loss_cls_aux1: 0.0074, d0.loss_bbox_aux1: 0.0554, d0.loss_iou_aux1: 0.2860, d1.loss_cls_aux1: 0.0058, d1.loss_bbox_aux1: 0.0492, d1.loss_iou_aux1: 0.2545, d2.loss_cls_aux1: 0.0044, d2.loss_bbox_aux1: 0.0483, d2.loss_iou_aux1: 0.2505, d3.loss_cls_aux1: 0.0038, d3.loss_bbox_aux1: 0.0483, d3.loss_iou_aux1: 0.2506, d4.loss_cls_aux1: 0.0036, d4.loss_bbox_aux1: 0.0483, d4.loss_iou_aux1: 0.2506, loss: 21.8455, grad_norm: 70.3142
2024-03-18 09:32:16,817 - mmdet - INFO - Saving checkpoint at 30 epochs
2024-03-18 09:32:38,963 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:32:44,893 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.392
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.590
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.384
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.576
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.649
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.483
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.666
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.812

2024-03-18 09:32:44,893 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.041 | Tin      | 0.613 | Thatch   | 0.520 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:32:44,953 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:32:44,954 - mmdet - INFO - Epoch(val) [30][154]	bbox_mAP: 0.3920, bbox_mAP_50: 0.5900, bbox_mAP_75: 0.4620, bbox_mAP_s: 0.2930, bbox_mAP_m: 0.3840, bbox_mAP_l: 0.5760, bbox_mAP_copypaste: 0.392 0.590 0.462 0.293 0.384 0.576
2024-03-18 09:33:28,764 - mmdet - INFO - Epoch [31][50/232]	lr: 2.000e-06, eta: 0:16:08, time: 0.876, data_time: 0.060, memory: 17650, enc_loss_cls: 0.1020, enc_loss_bbox: 0.0610, enc_loss_iou: 0.3307, loss_cls: 0.0709, loss_bbox: 0.0587, loss_iou: 0.3171, d0.loss_cls: 0.1006, d0.loss_bbox: 0.0586, d0.loss_iou: 0.3186, d1.loss_cls: 0.0788, d1.loss_bbox: 0.0586, d1.loss_iou: 0.3173, d2.loss_cls: 0.0739, d2.loss_bbox: 0.0586, d2.loss_iou: 0.3167, d3.loss_cls: 0.0714, d3.loss_bbox: 0.0587, d3.loss_iou: 0.3171, d4.loss_cls: 0.0706, d4.loss_bbox: 0.0587, d4.loss_iou: 0.3170, loss_rpn_cls: 0.0287, loss_rpn_bbox: 0.1305, loss_cls0: 1.2400, acc0: 95.7594, loss_bbox0: 2.3852, loss_cls1: 0.8095, loss_bbox1: 3.4837, loss_centerness1: 7.4384, loss_cls_aux0: 0.0059, loss_bbox_aux0: 0.0210, loss_iou_aux0: 0.0991, d0.loss_cls_aux0: 0.0107, d0.loss_bbox_aux0: 0.0415, d0.loss_iou_aux0: 0.2082, d1.loss_cls_aux0: 0.0066, d1.loss_bbox_aux0: 0.0241, d1.loss_iou_aux0: 0.1154, d2.loss_cls_aux0: 0.0055, d2.loss_bbox_aux0: 0.0210, d2.loss_iou_aux0: 0.0989, d3.loss_cls_aux0: 0.0056, d3.loss_bbox_aux0: 0.0210, d3.loss_iou_aux0: 0.0990, d4.loss_cls_aux0: 0.0058, d4.loss_bbox_aux0: 0.0210, d4.loss_iou_aux0: 0.0991, loss_cls_aux1: 0.0053, loss_bbox_aux1: 0.0473, loss_iou_aux1: 0.2512, d0.loss_cls_aux1: 0.0064, d0.loss_bbox_aux1: 0.0517, d0.loss_iou_aux1: 0.2732, d1.loss_cls_aux1: 0.0049, d1.loss_bbox_aux1: 0.0477, d1.loss_iou_aux1: 0.2538, d2.loss_cls_aux1: 0.0047, d2.loss_bbox_aux1: 0.0473, d2.loss_iou_aux1: 0.2512, d3.loss_cls_aux1: 0.0051, d3.loss_bbox_aux1: 0.0473, d3.loss_iou_aux1: 0.2512, d4.loss_cls_aux1: 0.0049, d4.loss_bbox_aux1: 0.0473, d4.loss_iou_aux1: 0.2512, loss: 21.4925, grad_norm: 55.3266
2024-03-18 09:34:09,533 - mmdet - INFO - Epoch [31][100/232]	lr: 2.000e-06, eta: 0:15:33, time: 0.816, data_time: 0.010, memory: 17650, enc_loss_cls: 0.0852, enc_loss_bbox: 0.0557, enc_loss_iou: 0.3094, loss_cls: 0.0580, loss_bbox: 0.0521, loss_iou: 0.2918, d0.loss_cls: 0.0860, d0.loss_bbox: 0.0524, d0.loss_iou: 0.2948, d1.loss_cls: 0.0650, d1.loss_bbox: 0.0523, d1.loss_iou: 0.2928, d2.loss_cls: 0.0601, d2.loss_bbox: 0.0522, d2.loss_iou: 0.2919, d3.loss_cls: 0.0574, d3.loss_bbox: 0.0524, d3.loss_iou: 0.2921, d4.loss_cls: 0.0575, d4.loss_bbox: 0.0521, d4.loss_iou: 0.2918, loss_rpn_cls: 0.0216, loss_rpn_bbox: 0.1164, loss_cls0: 1.1788, acc0: 95.9618, loss_bbox0: 2.3591, loss_cls1: 0.7439, loss_bbox1: 3.1652, loss_centerness1: 7.4390, loss_cls_aux0: 0.0038, loss_bbox_aux0: 0.0179, loss_iou_aux0: 0.0889, d0.loss_cls_aux0: 0.0095, d0.loss_bbox_aux0: 0.0383, d0.loss_iou_aux0: 0.1960, d1.loss_cls_aux0: 0.0054, d1.loss_bbox_aux0: 0.0206, d1.loss_iou_aux0: 0.1026, d2.loss_cls_aux0: 0.0042, d2.loss_bbox_aux0: 0.0178, d2.loss_iou_aux0: 0.0886, d3.loss_cls_aux0: 0.0038, d3.loss_bbox_aux0: 0.0179, d3.loss_iou_aux0: 0.0887, d4.loss_cls_aux0: 0.0038, d4.loss_bbox_aux0: 0.0179, d4.loss_iou_aux0: 0.0888, loss_cls_aux1: 0.0029, loss_bbox_aux1: 0.0426, loss_iou_aux1: 0.2346, d0.loss_cls_aux1: 0.0046, d0.loss_bbox_aux1: 0.0466, d0.loss_iou_aux1: 0.2537, d1.loss_cls_aux1: 0.0034, d1.loss_bbox_aux1: 0.0432, d1.loss_iou_aux1: 0.2377, d2.loss_cls_aux1: 0.0030, d2.loss_bbox_aux1: 0.0426, d2.loss_iou_aux1: 0.2345, d3.loss_cls_aux1: 0.0029, d3.loss_bbox_aux1: 0.0426, d3.loss_iou_aux1: 0.2346, d4.loss_cls_aux1: 0.0030, d4.loss_bbox_aux1: 0.0426, d4.loss_iou_aux1: 0.2346, loss: 20.4507, grad_norm: 51.6129
2024-03-18 09:34:50,486 - mmdet - INFO - Epoch [31][150/232]	lr: 2.000e-06, eta: 0:14:58, time: 0.819, data_time: 0.009, memory: 17650, enc_loss_cls: 0.0895, enc_loss_bbox: 0.0599, enc_loss_iou: 0.3313, loss_cls: 0.0627, loss_bbox: 0.0578, loss_iou: 0.3166, d0.loss_cls: 0.0916, d0.loss_bbox: 0.0578, d0.loss_iou: 0.3174, d1.loss_cls: 0.0709, d1.loss_bbox: 0.0576, d1.loss_iou: 0.3159, d2.loss_cls: 0.0670, d2.loss_bbox: 0.0573, d2.loss_iou: 0.3159, d3.loss_cls: 0.0636, d3.loss_bbox: 0.0578, d3.loss_iou: 0.3165, d4.loss_cls: 0.0626, d4.loss_bbox: 0.0578, d4.loss_iou: 0.3166, loss_rpn_cls: 0.0263, loss_rpn_bbox: 0.1221, loss_cls0: 1.2442, acc0: 95.7409, loss_bbox0: 2.4665, loss_cls1: 0.7895, loss_bbox1: 3.4357, loss_centerness1: 7.4488, loss_cls_aux0: 0.0049, loss_bbox_aux0: 0.0181, loss_iou_aux0: 0.0887, d0.loss_cls_aux0: 0.0122, d0.loss_bbox_aux0: 0.0391, d0.loss_iou_aux0: 0.1993, d1.loss_cls_aux0: 0.0078, d1.loss_bbox_aux0: 0.0211, d1.loss_iou_aux0: 0.1046, d2.loss_cls_aux0: 0.0063, d2.loss_bbox_aux0: 0.0180, d2.loss_iou_aux0: 0.0885, d3.loss_cls_aux0: 0.0053, d3.loss_bbox_aux0: 0.0180, d3.loss_iou_aux0: 0.0886, d4.loss_cls_aux0: 0.0050, d4.loss_bbox_aux0: 0.0181, d4.loss_iou_aux0: 0.0886, loss_cls_aux1: 0.0034, loss_bbox_aux1: 0.0451, loss_iou_aux1: 0.2456, d0.loss_cls_aux1: 0.0065, d0.loss_bbox_aux1: 0.0486, d0.loss_iou_aux1: 0.2638, d1.loss_cls_aux1: 0.0053, d1.loss_bbox_aux1: 0.0457, d1.loss_iou_aux1: 0.2486, d2.loss_cls_aux1: 0.0042, d2.loss_bbox_aux1: 0.0451, d2.loss_iou_aux1: 0.2456, d3.loss_cls_aux1: 0.0034, d3.loss_bbox_aux1: 0.0451, d3.loss_iou_aux1: 0.2456, d4.loss_cls_aux1: 0.0034, d4.loss_bbox_aux1: 0.0451, d4.loss_iou_aux1: 0.2456, loss: 21.3051, grad_norm: 54.6420
2024-03-18 09:35:32,039 - mmdet - INFO - Epoch [31][200/232]	lr: 2.000e-06, eta: 0:14:22, time: 0.831, data_time: 0.011, memory: 17650, enc_loss_cls: 0.0896, enc_loss_bbox: 0.0619, enc_loss_iou: 0.3276, loss_cls: 0.0636, loss_bbox: 0.0588, loss_iou: 0.3119, d0.loss_cls: 0.0879, d0.loss_bbox: 0.0590, d0.loss_iou: 0.3134, d1.loss_cls: 0.0678, d1.loss_bbox: 0.0587, d1.loss_iou: 0.3125, d2.loss_cls: 0.0649, d2.loss_bbox: 0.0587, d2.loss_iou: 0.3117, d3.loss_cls: 0.0643, d3.loss_bbox: 0.0587, d3.loss_iou: 0.3118, d4.loss_cls: 0.0641, d4.loss_bbox: 0.0587, d4.loss_iou: 0.3118, loss_rpn_cls: 0.0279, loss_rpn_bbox: 0.1176, loss_cls0: 1.2107, acc0: 95.8295, loss_bbox0: 2.3940, loss_cls1: 0.7894, loss_bbox1: 3.3688, loss_centerness1: 7.4590, loss_cls_aux0: 0.0050, loss_bbox_aux0: 0.0186, loss_iou_aux0: 0.0905, d0.loss_cls_aux0: 0.0100, d0.loss_bbox_aux0: 0.0387, d0.loss_iou_aux0: 0.1985, d1.loss_cls_aux0: 0.0059, d1.loss_bbox_aux0: 0.0216, d1.loss_iou_aux0: 0.1049, d2.loss_cls_aux0: 0.0049, d2.loss_bbox_aux0: 0.0186, d2.loss_iou_aux0: 0.0902, d3.loss_cls_aux0: 0.0050, d3.loss_bbox_aux0: 0.0186, d3.loss_iou_aux0: 0.0903, d4.loss_cls_aux0: 0.0048, d4.loss_bbox_aux0: 0.0186, d4.loss_iou_aux0: 0.0904, loss_cls_aux1: 0.0045, loss_bbox_aux1: 0.0442, loss_iou_aux1: 0.2343, d0.loss_cls_aux1: 0.0059, d0.loss_bbox_aux1: 0.0488, d0.loss_iou_aux1: 0.2577, d1.loss_cls_aux1: 0.0044, d1.loss_bbox_aux1: 0.0449, d1.loss_iou_aux1: 0.2384, d2.loss_cls_aux1: 0.0040, d2.loss_bbox_aux1: 0.0442, d2.loss_iou_aux1: 0.2342, d3.loss_cls_aux1: 0.0046, d3.loss_bbox_aux1: 0.0442, d3.loss_iou_aux1: 0.2343, d4.loss_cls_aux1: 0.0044, d4.loss_bbox_aux1: 0.0442, d4.loss_iou_aux1: 0.2343, loss: 21.0513, grad_norm: 62.6441
2024-03-18 09:35:58,858 - mmdet - INFO - Saving checkpoint at 31 epochs
2024-03-18 09:36:20,891 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:36:26,849 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.395
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.586
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.297
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.387
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.585
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.490
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.820

2024-03-18 09:36:26,849 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.033 | Tin      | 0.622 | Thatch   | 0.530 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:36:26,905 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:36:26,905 - mmdet - INFO - Epoch(val) [31][154]	bbox_mAP: 0.3950, bbox_mAP_50: 0.5860, bbox_mAP_75: 0.4690, bbox_mAP_s: 0.2970, bbox_mAP_m: 0.3870, bbox_mAP_l: 0.5850, bbox_mAP_copypaste: 0.395 0.586 0.469 0.297 0.387 0.585
2024-03-18 09:37:10,438 - mmdet - INFO - Epoch [32][50/232]	lr: 2.000e-06, eta: 0:13:21, time: 0.870, data_time: 0.061, memory: 17650, enc_loss_cls: 0.0816, enc_loss_bbox: 0.0584, enc_loss_iou: 0.3144, loss_cls: 0.0541, loss_bbox: 0.0551, loss_iou: 0.2984, d0.loss_cls: 0.0802, d0.loss_bbox: 0.0554, d0.loss_iou: 0.2998, d1.loss_cls: 0.0614, d1.loss_bbox: 0.0552, d1.loss_iou: 0.2991, d2.loss_cls: 0.0575, d2.loss_bbox: 0.0551, d2.loss_iou: 0.2984, d3.loss_cls: 0.0552, d3.loss_bbox: 0.0551, d3.loss_iou: 0.2983, d4.loss_cls: 0.0549, d4.loss_bbox: 0.0551, d4.loss_iou: 0.2982, loss_rpn_cls: 0.0259, loss_rpn_bbox: 0.1307, loss_cls0: 1.2464, acc0: 95.7436, loss_bbox0: 2.3848, loss_cls1: 0.7629, loss_bbox1: 3.2751, loss_centerness1: 7.4611, loss_cls_aux0: 0.0057, loss_bbox_aux0: 0.0191, loss_iou_aux0: 0.0928, d0.loss_cls_aux0: 0.0101, d0.loss_bbox_aux0: 0.0384, d0.loss_iou_aux0: 0.1965, d1.loss_cls_aux0: 0.0066, d1.loss_bbox_aux0: 0.0217, d1.loss_iou_aux0: 0.1066, d2.loss_cls_aux0: 0.0058, d2.loss_bbox_aux0: 0.0191, d2.loss_iou_aux0: 0.0926, d3.loss_cls_aux0: 0.0059, d3.loss_bbox_aux0: 0.0191, d3.loss_iou_aux0: 0.0926, d4.loss_cls_aux0: 0.0057, d4.loss_bbox_aux0: 0.0191, d4.loss_iou_aux0: 0.0927, loss_cls_aux1: 0.0037, loss_bbox_aux1: 0.0433, loss_iou_aux1: 0.2355, d0.loss_cls_aux1: 0.0055, d0.loss_bbox_aux1: 0.0471, d0.loss_iou_aux1: 0.2541, d1.loss_cls_aux1: 0.0040, d1.loss_bbox_aux1: 0.0442, d1.loss_iou_aux1: 0.2394, d2.loss_cls_aux1: 0.0039, d2.loss_bbox_aux1: 0.0433, d2.loss_iou_aux1: 0.2355, d3.loss_cls_aux1: 0.0039, d3.loss_bbox_aux1: 0.0433, d3.loss_iou_aux1: 0.2355, d4.loss_cls_aux1: 0.0037, d4.loss_bbox_aux1: 0.0433, d4.loss_iou_aux1: 0.2355, loss: 20.8027, grad_norm: 53.2334
2024-03-18 09:37:51,088 - mmdet - INFO - Epoch [32][100/232]	lr: 2.000e-06, eta: 0:12:45, time: 0.813, data_time: 0.009, memory: 17650, enc_loss_cls: 0.0952, enc_loss_bbox: 0.0603, enc_loss_iou: 0.3205, loss_cls: 0.0680, loss_bbox: 0.0587, loss_iou: 0.3068, d0.loss_cls: 0.0919, d0.loss_bbox: 0.0586, d0.loss_iou: 0.3084, d1.loss_cls: 0.0735, d1.loss_bbox: 0.0588, d1.loss_iou: 0.3087, d2.loss_cls: 0.0697, d2.loss_bbox: 0.0586, d2.loss_iou: 0.3065, d3.loss_cls: 0.0677, d3.loss_bbox: 0.0589, d3.loss_iou: 0.3070, d4.loss_cls: 0.0670, d4.loss_bbox: 0.0587, d4.loss_iou: 0.3074, loss_rpn_cls: 0.0243, loss_rpn_bbox: 0.0991, loss_cls0: 1.0903, acc0: 96.2139, loss_bbox0: 2.1788, loss_cls1: 0.7811, loss_bbox1: 3.2956, loss_centerness1: 7.4405, loss_cls_aux0: 0.0047, loss_bbox_aux0: 0.0173, loss_iou_aux0: 0.0825, d0.loss_cls_aux0: 0.0098, d0.loss_bbox_aux0: 0.0382, d0.loss_iou_aux0: 0.1928, d1.loss_cls_aux0: 0.0057, d1.loss_bbox_aux0: 0.0203, d1.loss_iou_aux0: 0.0971, d2.loss_cls_aux0: 0.0047, d2.loss_bbox_aux0: 0.0173, d2.loss_iou_aux0: 0.0824, d3.loss_cls_aux0: 0.0045, d3.loss_bbox_aux0: 0.0173, d3.loss_iou_aux0: 0.0824, d4.loss_cls_aux0: 0.0047, d4.loss_bbox_aux0: 0.0173, d4.loss_iou_aux0: 0.0824, loss_cls_aux1: 0.0046, loss_bbox_aux1: 0.0447, loss_iou_aux1: 0.2353, d0.loss_cls_aux1: 0.0061, d0.loss_bbox_aux1: 0.0487, d0.loss_iou_aux1: 0.2541, d1.loss_cls_aux1: 0.0050, d1.loss_bbox_aux1: 0.0454, d1.loss_iou_aux1: 0.2384, d2.loss_cls_aux1: 0.0045, d2.loss_bbox_aux1: 0.0447, d2.loss_iou_aux1: 0.2353, d3.loss_cls_aux1: 0.0043, d3.loss_bbox_aux1: 0.0447, d3.loss_iou_aux1: 0.2353, d4.loss_cls_aux1: 0.0044, d4.loss_bbox_aux1: 0.0447, d4.loss_iou_aux1: 0.2353, loss: 20.5376, grad_norm: 55.2177
2024-03-18 09:38:32,304 - mmdet - INFO - Epoch [32][150/232]	lr: 2.000e-06, eta: 0:12:10, time: 0.824, data_time: 0.014, memory: 17650, enc_loss_cls: 0.0816, enc_loss_bbox: 0.0569, enc_loss_iou: 0.3161, loss_cls: 0.0524, loss_bbox: 0.0546, loss_iou: 0.3027, d0.loss_cls: 0.0799, d0.loss_bbox: 0.0549, d0.loss_iou: 0.3043, d1.loss_cls: 0.0589, d1.loss_bbox: 0.0547, d1.loss_iou: 0.3031, d2.loss_cls: 0.0547, d2.loss_bbox: 0.0546, d2.loss_iou: 0.3027, d3.loss_cls: 0.0533, d3.loss_bbox: 0.0546, d3.loss_iou: 0.3025, d4.loss_cls: 0.0525, d4.loss_bbox: 0.0546, d4.loss_iou: 0.3026, loss_rpn_cls: 0.0260, loss_rpn_bbox: 0.1370, loss_cls0: 1.2363, acc0: 95.7142, loss_bbox0: 2.4141, loss_cls1: 0.7473, loss_bbox1: 3.2977, loss_centerness1: 7.4521, loss_cls_aux0: 0.0033, loss_bbox_aux0: 0.0178, loss_iou_aux0: 0.0885, d0.loss_cls_aux0: 0.0080, d0.loss_bbox_aux0: 0.0374, d0.loss_iou_aux0: 0.1942, d1.loss_cls_aux0: 0.0043, d1.loss_bbox_aux0: 0.0204, d1.loss_iou_aux0: 0.1019, d2.loss_cls_aux0: 0.0038, d2.loss_bbox_aux0: 0.0178, d2.loss_iou_aux0: 0.0884, d3.loss_cls_aux0: 0.0032, d3.loss_bbox_aux0: 0.0178, d3.loss_iou_aux0: 0.0884, d4.loss_cls_aux0: 0.0032, d4.loss_bbox_aux0: 0.0178, d4.loss_iou_aux0: 0.0885, loss_cls_aux1: 0.0026, loss_bbox_aux1: 0.0424, loss_iou_aux1: 0.2323, d0.loss_cls_aux1: 0.0038, d0.loss_bbox_aux1: 0.0460, d0.loss_iou_aux1: 0.2512, d1.loss_cls_aux1: 0.0030, d1.loss_bbox_aux1: 0.0432, d1.loss_iou_aux1: 0.2370, d2.loss_cls_aux1: 0.0025, d2.loss_bbox_aux1: 0.0424, d2.loss_iou_aux1: 0.2323, d3.loss_cls_aux1: 0.0024, d3.loss_bbox_aux1: 0.0424, d3.loss_iou_aux1: 0.2323, d4.loss_cls_aux1: 0.0025, d4.loss_bbox_aux1: 0.0424, d4.loss_iou_aux1: 0.2323, loss: 20.7606, grad_norm: 59.4429
2024-03-18 09:39:13,926 - mmdet - INFO - Epoch [32][200/232]	lr: 2.000e-06, eta: 0:11:34, time: 0.832, data_time: 0.010, memory: 17650, enc_loss_cls: 0.0924, enc_loss_bbox: 0.0609, enc_loss_iou: 0.3259, loss_cls: 0.0620, loss_bbox: 0.0585, loss_iou: 0.3139, d0.loss_cls: 0.0880, d0.loss_bbox: 0.0586, d0.loss_iou: 0.3152, d1.loss_cls: 0.0684, d1.loss_bbox: 0.0586, d1.loss_iou: 0.3147, d2.loss_cls: 0.0651, d2.loss_bbox: 0.0584, d2.loss_iou: 0.3135, d3.loss_cls: 0.0628, d3.loss_bbox: 0.0584, d3.loss_iou: 0.3135, d4.loss_cls: 0.0623, d4.loss_bbox: 0.0584, d4.loss_iou: 0.3136, loss_rpn_cls: 0.0268, loss_rpn_bbox: 0.1233, loss_cls0: 1.1950, acc0: 95.9299, loss_bbox0: 2.3259, loss_cls1: 0.7952, loss_bbox1: 3.4610, loss_centerness1: 7.4678, loss_cls_aux0: 0.0057, loss_bbox_aux0: 0.0187, loss_iou_aux0: 0.0887, d0.loss_cls_aux0: 0.0097, d0.loss_bbox_aux0: 0.0398, d0.loss_iou_aux0: 0.1992, d1.loss_cls_aux0: 0.0065, d1.loss_bbox_aux0: 0.0219, d1.loss_iou_aux0: 0.1043, d2.loss_cls_aux0: 0.0060, d2.loss_bbox_aux0: 0.0187, d2.loss_iou_aux0: 0.0886, d3.loss_cls_aux0: 0.0061, d3.loss_bbox_aux0: 0.0187, d3.loss_iou_aux0: 0.0886, d4.loss_cls_aux0: 0.0058, d4.loss_bbox_aux0: 0.0187, d4.loss_iou_aux0: 0.0887, loss_cls_aux1: 0.0040, loss_bbox_aux1: 0.0454, loss_iou_aux1: 0.2441, d0.loss_cls_aux1: 0.0054, d0.loss_bbox_aux1: 0.0494, d0.loss_iou_aux1: 0.2636, d1.loss_cls_aux1: 0.0047, d1.loss_bbox_aux1: 0.0463, d1.loss_iou_aux1: 0.2482, d2.loss_cls_aux1: 0.0044, d2.loss_bbox_aux1: 0.0454, d2.loss_iou_aux1: 0.2441, d3.loss_cls_aux1: 0.0046, d3.loss_bbox_aux1: 0.0454, d3.loss_iou_aux1: 0.2441, d4.loss_cls_aux1: 0.0042, d4.loss_bbox_aux1: 0.0454, d4.loss_iou_aux1: 0.2441, loss: 21.1455, grad_norm: 56.2468
2024-03-18 09:39:40,604 - mmdet - INFO - Saving checkpoint at 32 epochs
2024-03-18 09:40:02,621 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:40:08,520 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.391
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.585
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.459
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.296
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.607
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.651
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.455
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.673
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.823

2024-03-18 09:40:08,521 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.030 | Tin      | 0.621 | Thatch   | 0.521 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:40:08,577 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:40:08,577 - mmdet - INFO - Epoch(val) [32][154]	bbox_mAP: 0.3910, bbox_mAP_50: 0.5850, bbox_mAP_75: 0.4590, bbox_mAP_s: 0.2960, bbox_mAP_m: 0.3830, bbox_mAP_l: 0.6070, bbox_mAP_copypaste: 0.391 0.585 0.459 0.296 0.383 0.607
2024-03-18 09:40:52,540 - mmdet - INFO - Epoch [33][50/232]	lr: 2.000e-06, eta: 0:10:33, time: 0.879, data_time: 0.062, memory: 17650, enc_loss_cls: 0.0898, enc_loss_bbox: 0.0577, enc_loss_iou: 0.3182, loss_cls: 0.0599, loss_bbox: 0.0549, loss_iou: 0.3054, d0.loss_cls: 0.0879, d0.loss_bbox: 0.0551, d0.loss_iou: 0.3065, d1.loss_cls: 0.0650, d1.loss_bbox: 0.0549, d1.loss_iou: 0.3057, d2.loss_cls: 0.0609, d2.loss_bbox: 0.0549, d2.loss_iou: 0.3055, d3.loss_cls: 0.0601, d3.loss_bbox: 0.0548, d3.loss_iou: 0.3052, d4.loss_cls: 0.0597, d4.loss_bbox: 0.0549, d4.loss_iou: 0.3053, loss_rpn_cls: 0.0255, loss_rpn_bbox: 0.1255, loss_cls0: 1.2316, acc0: 95.7512, loss_bbox0: 2.3690, loss_cls1: 0.7632, loss_bbox1: 3.3159, loss_centerness1: 7.4370, loss_cls_aux0: 0.0041, loss_bbox_aux0: 0.0186, loss_iou_aux0: 0.0917, d0.loss_cls_aux0: 0.0093, d0.loss_bbox_aux0: 0.0383, d0.loss_iou_aux0: 0.1963, d1.loss_cls_aux0: 0.0054, d1.loss_bbox_aux0: 0.0213, d1.loss_iou_aux0: 0.1053, d2.loss_cls_aux0: 0.0043, d2.loss_bbox_aux0: 0.0186, d2.loss_iou_aux0: 0.0916, d3.loss_cls_aux0: 0.0042, d3.loss_bbox_aux0: 0.0186, d3.loss_iou_aux0: 0.0916, d4.loss_cls_aux0: 0.0042, d4.loss_bbox_aux0: 0.0186, d4.loss_iou_aux0: 0.0917, loss_cls_aux1: 0.0021, loss_bbox_aux1: 0.0423, loss_iou_aux1: 0.2344, d0.loss_cls_aux1: 0.0039, d0.loss_bbox_aux1: 0.0457, d0.loss_iou_aux1: 0.2519, d1.loss_cls_aux1: 0.0028, d1.loss_bbox_aux1: 0.0428, d1.loss_iou_aux1: 0.2370, d2.loss_cls_aux1: 0.0024, d2.loss_bbox_aux1: 0.0423, d2.loss_iou_aux1: 0.2344, d3.loss_cls_aux1: 0.0022, d3.loss_bbox_aux1: 0.0423, d3.loss_iou_aux1: 0.2344, d4.loss_cls_aux1: 0.0021, d4.loss_bbox_aux1: 0.0423, d4.loss_iou_aux1: 0.2344, loss: 20.8230, grad_norm: 51.3941
2024-03-18 09:41:33,421 - mmdet - INFO - Epoch [33][100/232]	lr: 2.000e-06, eta: 0:09:58, time: 0.818, data_time: 0.011, memory: 17650, enc_loss_cls: 0.0861, enc_loss_bbox: 0.0584, enc_loss_iou: 0.3241, loss_cls: 0.0596, loss_bbox: 0.0562, loss_iou: 0.3113, d0.loss_cls: 0.0886, d0.loss_bbox: 0.0561, d0.loss_iou: 0.3123, d1.loss_cls: 0.0655, d1.loss_bbox: 0.0562, d1.loss_iou: 0.3116, d2.loss_cls: 0.0615, d2.loss_bbox: 0.0560, d2.loss_iou: 0.3108, d3.loss_cls: 0.0603, d3.loss_bbox: 0.0560, d3.loss_iou: 0.3108, d4.loss_cls: 0.0599, d4.loss_bbox: 0.0560, d4.loss_iou: 0.3110, loss_rpn_cls: 0.0207, loss_rpn_bbox: 0.1209, loss_cls0: 1.1945, acc0: 95.9148, loss_bbox0: 2.3471, loss_cls1: 0.7495, loss_bbox1: 3.3644, loss_centerness1: 7.4704, loss_cls_aux0: 0.0076, loss_bbox_aux0: 0.0176, loss_iou_aux0: 0.0855, d0.loss_cls_aux0: 0.0137, d0.loss_bbox_aux0: 0.0382, d0.loss_iou_aux0: 0.1972, d1.loss_cls_aux0: 0.0089, d1.loss_bbox_aux0: 0.0205, d1.loss_iou_aux0: 0.1011, d2.loss_cls_aux0: 0.0083, d2.loss_bbox_aux0: 0.0176, d2.loss_iou_aux0: 0.0853, d3.loss_cls_aux0: 0.0086, d3.loss_bbox_aux0: 0.0176, d3.loss_iou_aux0: 0.0854, d4.loss_cls_aux0: 0.0079, d4.loss_bbox_aux0: 0.0176, d4.loss_iou_aux0: 0.0854, loss_cls_aux1: 0.0047, loss_bbox_aux1: 0.0453, loss_iou_aux1: 0.2433, d0.loss_cls_aux1: 0.0064, d0.loss_bbox_aux1: 0.0488, d0.loss_iou_aux1: 0.2613, d1.loss_cls_aux1: 0.0054, d1.loss_bbox_aux1: 0.0458, d1.loss_iou_aux1: 0.2459, d2.loss_cls_aux1: 0.0056, d2.loss_bbox_aux1: 0.0453, d2.loss_iou_aux1: 0.2433, d3.loss_cls_aux1: 0.0055, d3.loss_bbox_aux1: 0.0453, d3.loss_iou_aux1: 0.2433, d4.loss_cls_aux1: 0.0050, d4.loss_bbox_aux1: 0.0453, d4.loss_iou_aux1: 0.2433, loss: 20.9486, grad_norm: 63.6104
2024-03-18 09:42:15,254 - mmdet - INFO - Epoch [33][150/232]	lr: 2.000e-06, eta: 0:09:22, time: 0.837, data_time: 0.010, memory: 17650, enc_loss_cls: 0.0793, enc_loss_bbox: 0.0558, enc_loss_iou: 0.3050, loss_cls: 0.0520, loss_bbox: 0.0533, loss_iou: 0.2920, d0.loss_cls: 0.0792, d0.loss_bbox: 0.0534, d0.loss_iou: 0.2941, d1.loss_cls: 0.0579, d1.loss_bbox: 0.0532, d1.loss_iou: 0.2925, d2.loss_cls: 0.0544, d2.loss_bbox: 0.0532, d2.loss_iou: 0.2917, d3.loss_cls: 0.0525, d3.loss_bbox: 0.0532, d3.loss_iou: 0.2923, d4.loss_cls: 0.0519, d4.loss_bbox: 0.0532, d4.loss_iou: 0.2923, loss_rpn_cls: 0.0184, loss_rpn_bbox: 0.1152, loss_cls0: 1.2015, acc0: 95.8252, loss_bbox0: 2.4106, loss_cls1: 0.7161, loss_bbox1: 3.2291, loss_centerness1: 7.4750, loss_cls_aux0: 0.0043, loss_bbox_aux0: 0.0160, loss_iou_aux0: 0.0800, d0.loss_cls_aux0: 0.0084, d0.loss_bbox_aux0: 0.0373, d0.loss_iou_aux0: 0.1900, d1.loss_cls_aux0: 0.0049, d1.loss_bbox_aux0: 0.0190, d1.loss_iou_aux0: 0.0944, d2.loss_cls_aux0: 0.0040, d2.loss_bbox_aux0: 0.0160, d2.loss_iou_aux0: 0.0798, d3.loss_cls_aux0: 0.0042, d3.loss_bbox_aux0: 0.0160, d3.loss_iou_aux0: 0.0798, d4.loss_cls_aux0: 0.0043, d4.loss_bbox_aux0: 0.0160, d4.loss_iou_aux0: 0.0799, loss_cls_aux1: 0.0033, loss_bbox_aux1: 0.0426, loss_iou_aux1: 0.2330, d0.loss_cls_aux1: 0.0045, d0.loss_bbox_aux1: 0.0463, d0.loss_iou_aux1: 0.2511, d1.loss_cls_aux1: 0.0032, d1.loss_bbox_aux1: 0.0435, d1.loss_iou_aux1: 0.2366, d2.loss_cls_aux1: 0.0029, d2.loss_bbox_aux1: 0.0426, d2.loss_iou_aux1: 0.2329, d3.loss_cls_aux1: 0.0032, d3.loss_bbox_aux1: 0.0426, d3.loss_iou_aux1: 0.2329, d4.loss_cls_aux1: 0.0033, d4.loss_bbox_aux1: 0.0426, d4.loss_iou_aux1: 0.2330, loss: 20.4831, grad_norm: 51.6339
2024-03-18 09:42:57,232 - mmdet - INFO - Epoch [33][200/232]	lr: 2.000e-06, eta: 0:08:46, time: 0.840, data_time: 0.011, memory: 17650, enc_loss_cls: 0.0876, enc_loss_bbox: 0.0594, enc_loss_iou: 0.3168, loss_cls: 0.0591, loss_bbox: 0.0571, loss_iou: 0.3035, d0.loss_cls: 0.0849, d0.loss_bbox: 0.0570, d0.loss_iou: 0.3044, d1.loss_cls: 0.0645, d1.loss_bbox: 0.0572, d1.loss_iou: 0.3034, d2.loss_cls: 0.0615, d2.loss_bbox: 0.0571, d2.loss_iou: 0.3034, d3.loss_cls: 0.0598, d3.loss_bbox: 0.0571, d3.loss_iou: 0.3034, d4.loss_cls: 0.0593, d4.loss_bbox: 0.0571, d4.loss_iou: 0.3035, loss_rpn_cls: 0.0266, loss_rpn_bbox: 0.1279, loss_cls0: 1.2102, acc0: 95.8145, loss_bbox0: 2.3537, loss_cls1: 0.7780, loss_bbox1: 3.3334, loss_centerness1: 7.4442, loss_cls_aux0: 0.0050, loss_bbox_aux0: 0.0193, loss_iou_aux0: 0.0927, d0.loss_cls_aux0: 0.0105, d0.loss_bbox_aux0: 0.0394, d0.loss_iou_aux0: 0.1992, d1.loss_cls_aux0: 0.0063, d1.loss_bbox_aux0: 0.0223, d1.loss_iou_aux0: 0.1072, d2.loss_cls_aux0: 0.0055, d2.loss_bbox_aux0: 0.0193, d2.loss_iou_aux0: 0.0925, d3.loss_cls_aux0: 0.0050, d3.loss_bbox_aux0: 0.0193, d3.loss_iou_aux0: 0.0926, d4.loss_cls_aux0: 0.0049, d4.loss_bbox_aux0: 0.0193, d4.loss_iou_aux0: 0.0926, loss_cls_aux1: 0.0050, loss_bbox_aux1: 0.0440, loss_iou_aux1: 0.2340, d0.loss_cls_aux1: 0.0072, d0.loss_bbox_aux1: 0.0483, d0.loss_iou_aux1: 0.2538, d1.loss_cls_aux1: 0.0062, d1.loss_bbox_aux1: 0.0449, d1.loss_iou_aux1: 0.2378, d2.loss_cls_aux1: 0.0058, d2.loss_bbox_aux1: 0.0440, d2.loss_iou_aux1: 0.2340, d3.loss_cls_aux1: 0.0053, d3.loss_bbox_aux1: 0.0440, d3.loss_iou_aux1: 0.2340, d4.loss_cls_aux1: 0.0051, d4.loss_bbox_aux1: 0.0440, d4.loss_iou_aux1: 0.2340, loss: 20.8753, grad_norm: 55.0613
2024-03-18 09:43:24,418 - mmdet - INFO - Saving checkpoint at 33 epochs
2024-03-18 09:43:46,748 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:43:52,682 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.390
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.582
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.462
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.294
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.383
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.643
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.441
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.665
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.822

2024-03-18 09:43:52,682 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.025 | Tin      | 0.618 | Thatch   | 0.527 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:43:52,741 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:43:52,741 - mmdet - INFO - Epoch(val) [33][154]	bbox_mAP: 0.3900, bbox_mAP_50: 0.5820, bbox_mAP_75: 0.4620, bbox_mAP_s: 0.2940, bbox_mAP_m: 0.3830, bbox_mAP_l: 0.6080, bbox_mAP_copypaste: 0.390 0.582 0.462 0.294 0.383 0.608
2024-03-18 09:44:37,412 - mmdet - INFO - Epoch [34][50/232]	lr: 2.000e-06, eta: 0:07:46, time: 0.893, data_time: 0.062, memory: 17650, enc_loss_cls: 0.0835, enc_loss_bbox: 0.0572, enc_loss_iou: 0.3129, loss_cls: 0.0585, loss_bbox: 0.0550, loss_iou: 0.3003, d0.loss_cls: 0.0826, d0.loss_bbox: 0.0553, d0.loss_iou: 0.3025, d1.loss_cls: 0.0649, d1.loss_bbox: 0.0550, d1.loss_iou: 0.3002, d2.loss_cls: 0.0613, d2.loss_bbox: 0.0549, d2.loss_iou: 0.3002, d3.loss_cls: 0.0592, d3.loss_bbox: 0.0550, d3.loss_iou: 0.3003, d4.loss_cls: 0.0586, d4.loss_bbox: 0.0550, d4.loss_iou: 0.3003, loss_rpn_cls: 0.0332, loss_rpn_bbox: 0.1214, loss_cls0: 1.1675, acc0: 96.0026, loss_bbox0: 2.3365, loss_cls1: 0.7552, loss_bbox1: 3.2799, loss_centerness1: 7.4565, loss_cls_aux0: 0.0047, loss_bbox_aux0: 0.0172, loss_iou_aux0: 0.0862, d0.loss_cls_aux0: 0.0095, d0.loss_bbox_aux0: 0.0380, d0.loss_iou_aux0: 0.1956, d1.loss_cls_aux0: 0.0056, d1.loss_bbox_aux0: 0.0199, d1.loss_iou_aux0: 0.0993, d2.loss_cls_aux0: 0.0047, d2.loss_bbox_aux0: 0.0171, d2.loss_iou_aux0: 0.0859, d3.loss_cls_aux0: 0.0048, d3.loss_bbox_aux0: 0.0171, d3.loss_iou_aux0: 0.0859, d4.loss_cls_aux0: 0.0047, d4.loss_bbox_aux0: 0.0171, d4.loss_iou_aux0: 0.0860, loss_cls_aux1: 0.0020, loss_bbox_aux1: 0.0428, loss_iou_aux1: 0.2313, d0.loss_cls_aux1: 0.0030, d0.loss_bbox_aux1: 0.0466, d0.loss_iou_aux1: 0.2496, d1.loss_cls_aux1: 0.0021, d1.loss_bbox_aux1: 0.0435, d1.loss_iou_aux1: 0.2341, d2.loss_cls_aux1: 0.0019, d2.loss_bbox_aux1: 0.0428, d2.loss_iou_aux1: 0.2312, d3.loss_cls_aux1: 0.0019, d3.loss_bbox_aux1: 0.0428, d3.loss_iou_aux1: 0.2312, d4.loss_cls_aux1: 0.0019, d4.loss_bbox_aux1: 0.0428, d4.loss_iou_aux1: 0.2313, loss: 20.6054, grad_norm: 54.5286
2024-03-18 09:45:18,341 - mmdet - INFO - Epoch [34][100/232]	lr: 2.000e-06, eta: 0:07:10, time: 0.819, data_time: 0.010, memory: 17650, enc_loss_cls: 0.0805, enc_loss_bbox: 0.0594, enc_loss_iou: 0.3107, loss_cls: 0.0519, loss_bbox: 0.0560, loss_iou: 0.2947, d0.loss_cls: 0.0782, d0.loss_bbox: 0.0560, d0.loss_iou: 0.2968, d1.loss_cls: 0.0572, d1.loss_bbox: 0.0559, d1.loss_iou: 0.2948, d2.loss_cls: 0.0542, d2.loss_bbox: 0.0555, d2.loss_iou: 0.2941, d3.loss_cls: 0.0521, d3.loss_bbox: 0.0559, d3.loss_iou: 0.2945, d4.loss_cls: 0.0520, d4.loss_bbox: 0.0559, d4.loss_iou: 0.2946, loss_rpn_cls: 0.0259, loss_rpn_bbox: 0.1158, loss_cls0: 1.1371, acc0: 96.0691, loss_bbox0: 2.2824, loss_cls1: 0.7265, loss_bbox1: 3.2015, loss_centerness1: 7.4266, loss_cls_aux0: 0.0039, loss_bbox_aux0: 0.0187, loss_iou_aux0: 0.0889, d0.loss_cls_aux0: 0.0089, d0.loss_bbox_aux0: 0.0396, d0.loss_iou_aux0: 0.1958, d1.loss_cls_aux0: 0.0048, d1.loss_bbox_aux0: 0.0220, d1.loss_iou_aux0: 0.1044, d2.loss_cls_aux0: 0.0040, d2.loss_bbox_aux0: 0.0187, d2.loss_iou_aux0: 0.0887, d3.loss_cls_aux0: 0.0038, d3.loss_bbox_aux0: 0.0187, d3.loss_iou_aux0: 0.0888, d4.loss_cls_aux0: 0.0038, d4.loss_bbox_aux0: 0.0187, d4.loss_iou_aux0: 0.0888, loss_cls_aux1: 0.0025, loss_bbox_aux1: 0.0439, loss_iou_aux1: 0.2288, d0.loss_cls_aux1: 0.0042, d0.loss_bbox_aux1: 0.0479, d0.loss_iou_aux1: 0.2474, d1.loss_cls_aux1: 0.0029, d1.loss_bbox_aux1: 0.0447, d1.loss_iou_aux1: 0.2321, d2.loss_cls_aux1: 0.0027, d2.loss_bbox_aux1: 0.0439, d2.loss_iou_aux1: 0.2288, d3.loss_cls_aux1: 0.0026, d3.loss_bbox_aux1: 0.0439, d3.loss_iou_aux1: 0.2288, d4.loss_cls_aux1: 0.0025, d4.loss_bbox_aux1: 0.0439, d4.loss_iou_aux1: 0.2288, loss: 20.3179, grad_norm: 54.9411
2024-03-18 09:45:59,430 - mmdet - INFO - Epoch [34][150/232]	lr: 2.000e-06, eta: 0:06:34, time: 0.822, data_time: 0.012, memory: 17650, enc_loss_cls: 0.0841, enc_loss_bbox: 0.0591, enc_loss_iou: 0.3127, loss_cls: 0.0505, loss_bbox: 0.0575, loss_iou: 0.3011, d0.loss_cls: 0.0806, d0.loss_bbox: 0.0570, d0.loss_iou: 0.3022, d1.loss_cls: 0.0589, d1.loss_bbox: 0.0566, d1.loss_iou: 0.3005, d2.loss_cls: 0.0547, d2.loss_bbox: 0.0566, d2.loss_iou: 0.2999, d3.loss_cls: 0.0527, d3.loss_bbox: 0.0567, d3.loss_iou: 0.3000, d4.loss_cls: 0.0522, d4.loss_bbox: 0.0567, d4.loss_iou: 0.3004, loss_rpn_cls: 0.0211, loss_rpn_bbox: 0.1186, loss_cls0: 1.1736, acc0: 96.0201, loss_bbox0: 2.3240, loss_cls1: 0.7513, loss_bbox1: 3.2810, loss_centerness1: 7.4668, loss_cls_aux0: 0.0038, loss_bbox_aux0: 0.0175, loss_iou_aux0: 0.0828, d0.loss_cls_aux0: 0.0094, d0.loss_bbox_aux0: 0.0387, d0.loss_iou_aux0: 0.1920, d1.loss_cls_aux0: 0.0054, d1.loss_bbox_aux0: 0.0205, d1.loss_iou_aux0: 0.0967, d2.loss_cls_aux0: 0.0044, d2.loss_bbox_aux0: 0.0175, d2.loss_iou_aux0: 0.0827, d3.loss_cls_aux0: 0.0040, d3.loss_bbox_aux0: 0.0175, d3.loss_iou_aux0: 0.0827, d4.loss_cls_aux0: 0.0037, d4.loss_bbox_aux0: 0.0175, d4.loss_iou_aux0: 0.0828, loss_cls_aux1: 0.0027, loss_bbox_aux1: 0.0438, loss_iou_aux1: 0.2302, d0.loss_cls_aux1: 0.0043, d0.loss_bbox_aux1: 0.0477, d0.loss_iou_aux1: 0.2491, d1.loss_cls_aux1: 0.0031, d1.loss_bbox_aux1: 0.0446, d1.loss_iou_aux1: 0.2334, d2.loss_cls_aux1: 0.0029, d2.loss_bbox_aux1: 0.0438, d2.loss_iou_aux1: 0.2302, d3.loss_cls_aux1: 0.0029, d3.loss_bbox_aux1: 0.0438, d3.loss_iou_aux1: 0.2302, d4.loss_cls_aux1: 0.0028, d4.loss_bbox_aux1: 0.0438, d4.loss_iou_aux1: 0.2302, loss: 20.5561, grad_norm: 58.7366
2024-03-18 09:46:41,165 - mmdet - INFO - Epoch [34][200/232]	lr: 2.000e-06, eta: 0:05:59, time: 0.835, data_time: 0.011, memory: 17650, enc_loss_cls: 0.0880, enc_loss_bbox: 0.0565, enc_loss_iou: 0.3142, loss_cls: 0.0594, loss_bbox: 0.0545, loss_iou: 0.3021, d0.loss_cls: 0.0822, d0.loss_bbox: 0.0547, d0.loss_iou: 0.3032, d1.loss_cls: 0.0653, d1.loss_bbox: 0.0545, d1.loss_iou: 0.3021, d2.loss_cls: 0.0605, d2.loss_bbox: 0.0544, d2.loss_iou: 0.3014, d3.loss_cls: 0.0595, d3.loss_bbox: 0.0545, d3.loss_iou: 0.3018, d4.loss_cls: 0.0593, d4.loss_bbox: 0.0545, d4.loss_iou: 0.3018, loss_rpn_cls: 0.0275, loss_rpn_bbox: 0.1057, loss_cls0: 1.1586, acc0: 96.0567, loss_bbox0: 2.3280, loss_cls1: 0.7477, loss_bbox1: 3.2160, loss_centerness1: 7.4596, loss_cls_aux0: 0.0036, loss_bbox_aux0: 0.0158, loss_iou_aux0: 0.0770, d0.loss_cls_aux0: 0.0085, d0.loss_bbox_aux0: 0.0374, d0.loss_iou_aux0: 0.1885, d1.loss_cls_aux0: 0.0045, d1.loss_bbox_aux0: 0.0190, d1.loss_iou_aux0: 0.0929, d2.loss_cls_aux0: 0.0035, d2.loss_bbox_aux0: 0.0158, d2.loss_iou_aux0: 0.0769, d3.loss_cls_aux0: 0.0032, d3.loss_bbox_aux0: 0.0158, d3.loss_iou_aux0: 0.0770, d4.loss_cls_aux0: 0.0035, d4.loss_bbox_aux0: 0.0158, d4.loss_iou_aux0: 0.0770, loss_cls_aux1: 0.0021, loss_bbox_aux1: 0.0419, loss_iou_aux1: 0.2299, d0.loss_cls_aux1: 0.0039, d0.loss_bbox_aux1: 0.0452, d0.loss_iou_aux1: 0.2471, d1.loss_cls_aux1: 0.0026, d1.loss_bbox_aux1: 0.0425, d1.loss_iou_aux1: 0.2328, d2.loss_cls_aux1: 0.0023, d2.loss_bbox_aux1: 0.0419, d2.loss_iou_aux1: 0.2299, d3.loss_cls_aux1: 0.0020, d3.loss_bbox_aux1: 0.0419, d3.loss_iou_aux1: 0.2299, d4.loss_cls_aux1: 0.0020, d4.loss_bbox_aux1: 0.0419, d4.loss_iou_aux1: 0.2299, loss: 20.4328, grad_norm: 55.8284
2024-03-18 09:47:08,317 - mmdet - INFO - Saving checkpoint at 34 epochs
2024-03-18 09:47:30,523 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:47:36,577 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.396
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.589
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.469
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.390
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.608
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.438
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.655
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.822

2024-03-18 09:47:36,578 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.045 | Tin      | 0.618 | Thatch   | 0.526 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:47:36,633 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:47:36,633 - mmdet - INFO - Epoch(val) [34][154]	bbox_mAP: 0.3960, bbox_mAP_50: 0.5890, bbox_mAP_75: 0.4690, bbox_mAP_s: 0.2930, bbox_mAP_m: 0.3900, bbox_mAP_l: 0.6080, bbox_mAP_copypaste: 0.396 0.589 0.469 0.293 0.390 0.608
2024-03-18 09:48:20,355 - mmdet - INFO - Epoch [35][50/232]	lr: 2.000e-06, eta: 0:04:58, time: 0.874, data_time: 0.061, memory: 17650, enc_loss_cls: 0.0808, enc_loss_bbox: 0.0572, enc_loss_iou: 0.3130, loss_cls: 0.0525, loss_bbox: 0.0545, loss_iou: 0.2988, d0.loss_cls: 0.0793, d0.loss_bbox: 0.0548, d0.loss_iou: 0.3011, d1.loss_cls: 0.0592, d1.loss_bbox: 0.0546, d1.loss_iou: 0.2992, d2.loss_cls: 0.0555, d2.loss_bbox: 0.0545, d2.loss_iou: 0.2984, d3.loss_cls: 0.0520, d3.loss_bbox: 0.0545, d3.loss_iou: 0.2988, d4.loss_cls: 0.0527, d4.loss_bbox: 0.0545, d4.loss_iou: 0.2987, loss_rpn_cls: 0.0209, loss_rpn_bbox: 0.1214, loss_cls0: 1.1691, acc0: 96.0513, loss_bbox0: 2.2926, loss_cls1: 0.7321, loss_bbox1: 3.2879, loss_centerness1: 7.4738, loss_cls_aux0: 0.0039, loss_bbox_aux0: 0.0181, loss_iou_aux0: 0.0872, d0.loss_cls_aux0: 0.0097, d0.loss_bbox_aux0: 0.0377, d0.loss_iou_aux0: 0.1922, d1.loss_cls_aux0: 0.0059, d1.loss_bbox_aux0: 0.0206, d1.loss_iou_aux0: 0.1002, d2.loss_cls_aux0: 0.0046, d2.loss_bbox_aux0: 0.0181, d2.loss_iou_aux0: 0.0870, d3.loss_cls_aux0: 0.0040, d3.loss_bbox_aux0: 0.0181, d3.loss_iou_aux0: 0.0871, d4.loss_cls_aux0: 0.0040, d4.loss_bbox_aux0: 0.0181, d4.loss_iou_aux0: 0.0872, loss_cls_aux1: 0.0021, loss_bbox_aux1: 0.0435, loss_iou_aux1: 0.2339, d0.loss_cls_aux1: 0.0045, d0.loss_bbox_aux1: 0.0474, d0.loss_iou_aux1: 0.2519, d1.loss_cls_aux1: 0.0036, d1.loss_bbox_aux1: 0.0444, d1.loss_iou_aux1: 0.2375, d2.loss_cls_aux1: 0.0027, d2.loss_bbox_aux1: 0.0435, d2.loss_iou_aux1: 0.2339, d3.loss_cls_aux1: 0.0021, d3.loss_bbox_aux1: 0.0435, d3.loss_iou_aux1: 0.2339, d4.loss_cls_aux1: 0.0022, d4.loss_bbox_aux1: 0.0435, d4.loss_iou_aux1: 0.2339, loss: 20.5342, grad_norm: 57.5106
2024-03-18 09:49:00,815 - mmdet - INFO - Epoch [35][100/232]	lr: 2.000e-06, eta: 0:04:22, time: 0.809, data_time: 0.013, memory: 17650, enc_loss_cls: 0.0805, enc_loss_bbox: 0.0599, enc_loss_iou: 0.3218, loss_cls: 0.0558, loss_bbox: 0.0570, loss_iou: 0.3075, d0.loss_cls: 0.0802, d0.loss_bbox: 0.0571, d0.loss_iou: 0.3098, d1.loss_cls: 0.0599, d1.loss_bbox: 0.0570, d1.loss_iou: 0.3084, d2.loss_cls: 0.0581, d2.loss_bbox: 0.0568, d2.loss_iou: 0.3067, d3.loss_cls: 0.0569, d3.loss_bbox: 0.0568, d3.loss_iou: 0.3067, d4.loss_cls: 0.0558, d4.loss_bbox: 0.0570, d4.loss_iou: 0.3075, loss_rpn_cls: 0.0192, loss_rpn_bbox: 0.1092, loss_cls0: 1.1659, acc0: 95.9801, loss_bbox0: 2.3297, loss_cls1: 0.7309, loss_bbox1: 3.3632, loss_centerness1: 7.4519, loss_cls_aux0: 0.0042, loss_bbox_aux0: 0.0176, loss_iou_aux0: 0.0853, d0.loss_cls_aux0: 0.0098, d0.loss_bbox_aux0: 0.0383, d0.loss_iou_aux0: 0.1952, d1.loss_cls_aux0: 0.0058, d1.loss_bbox_aux0: 0.0204, d1.loss_iou_aux0: 0.0998, d2.loss_cls_aux0: 0.0049, d2.loss_bbox_aux0: 0.0176, d2.loss_iou_aux0: 0.0851, d3.loss_cls_aux0: 0.0044, d3.loss_bbox_aux0: 0.0176, d3.loss_iou_aux0: 0.0852, d4.loss_cls_aux0: 0.0043, d4.loss_bbox_aux0: 0.0176, d4.loss_iou_aux0: 0.0852, loss_cls_aux1: 0.0022, loss_bbox_aux1: 0.0437, loss_iou_aux1: 0.2335, d0.loss_cls_aux1: 0.0038, d0.loss_bbox_aux1: 0.0477, d0.loss_iou_aux1: 0.2528, d1.loss_cls_aux1: 0.0027, d1.loss_bbox_aux1: 0.0447, d1.loss_iou_aux1: 0.2383, d2.loss_cls_aux1: 0.0026, d2.loss_bbox_aux1: 0.0437, d2.loss_iou_aux1: 0.2335, d3.loss_cls_aux1: 0.0023, d3.loss_bbox_aux1: 0.0437, d3.loss_iou_aux1: 0.2335, d4.loss_cls_aux1: 0.0022, d4.loss_bbox_aux1: 0.0437, d4.loss_iou_aux1: 0.2335, loss: 20.6934, grad_norm: 57.3843
2024-03-18 09:49:42,056 - mmdet - INFO - Epoch [35][150/232]	lr: 2.000e-06, eta: 0:03:47, time: 0.825, data_time: 0.012, memory: 17650, enc_loss_cls: 0.0802, enc_loss_bbox: 0.0567, enc_loss_iou: 0.3069, loss_cls: 0.0517, loss_bbox: 0.0545, loss_iou: 0.2932, d0.loss_cls: 0.0791, d0.loss_bbox: 0.0549, d0.loss_iou: 0.2948, d1.loss_cls: 0.0594, d1.loss_bbox: 0.0545, d1.loss_iou: 0.2938, d2.loss_cls: 0.0562, d2.loss_bbox: 0.0543, d2.loss_iou: 0.2931, d3.loss_cls: 0.0528, d3.loss_bbox: 0.0544, d3.loss_iou: 0.2932, d4.loss_cls: 0.0522, d4.loss_bbox: 0.0544, d4.loss_iou: 0.2932, loss_rpn_cls: 0.0241, loss_rpn_bbox: 0.1191, loss_cls0: 1.1359, acc0: 96.0512, loss_bbox0: 2.2794, loss_cls1: 0.7274, loss_bbox1: 3.1475, loss_centerness1: 7.4655, loss_cls_aux0: 0.0033, loss_bbox_aux0: 0.0181, loss_iou_aux0: 0.0878, d0.loss_cls_aux0: 0.0081, d0.loss_bbox_aux0: 0.0374, d0.loss_iou_aux0: 0.1918, d1.loss_cls_aux0: 0.0045, d1.loss_bbox_aux0: 0.0205, d1.loss_iou_aux0: 0.1001, d2.loss_cls_aux0: 0.0036, d2.loss_bbox_aux0: 0.0181, d2.loss_iou_aux0: 0.0878, d3.loss_cls_aux0: 0.0033, d3.loss_bbox_aux0: 0.0181, d3.loss_iou_aux0: 0.0878, d4.loss_cls_aux0: 0.0033, d4.loss_bbox_aux0: 0.0181, d4.loss_iou_aux0: 0.0878, loss_cls_aux1: 0.0026, loss_bbox_aux1: 0.0424, loss_iou_aux1: 0.2263, d0.loss_cls_aux1: 0.0044, d0.loss_bbox_aux1: 0.0454, d0.loss_iou_aux1: 0.2423, d1.loss_cls_aux1: 0.0034, d1.loss_bbox_aux1: 0.0429, d1.loss_iou_aux1: 0.2288, d2.loss_cls_aux1: 0.0029, d2.loss_bbox_aux1: 0.0424, d2.loss_iou_aux1: 0.2263, d3.loss_cls_aux1: 0.0026, d3.loss_bbox_aux1: 0.0424, d3.loss_iou_aux1: 0.2263, d4.loss_cls_aux1: 0.0027, d4.loss_bbox_aux1: 0.0424, d4.loss_iou_aux1: 0.2263, loss: 20.2343, grad_norm: 50.3404
2024-03-18 09:50:23,748 - mmdet - INFO - Epoch [35][200/232]	lr: 2.000e-06, eta: 0:03:11, time: 0.834, data_time: 0.009, memory: 17650, enc_loss_cls: 0.0888, enc_loss_bbox: 0.0552, enc_loss_iou: 0.3104, loss_cls: 0.0574, loss_bbox: 0.0530, loss_iou: 0.2947, d0.loss_cls: 0.0825, d0.loss_bbox: 0.0533, d0.loss_iou: 0.2966, d1.loss_cls: 0.0623, d1.loss_bbox: 0.0530, d1.loss_iou: 0.2959, d2.loss_cls: 0.0595, d2.loss_bbox: 0.0529, d2.loss_iou: 0.2944, d3.loss_cls: 0.0582, d3.loss_bbox: 0.0528, d3.loss_iou: 0.2943, d4.loss_cls: 0.0576, d4.loss_bbox: 0.0528, d4.loss_iou: 0.2947, loss_rpn_cls: 0.0226, loss_rpn_bbox: 0.1209, loss_cls0: 1.0997, acc0: 96.2839, loss_bbox0: 2.2360, loss_cls1: 0.7250, loss_bbox1: 3.1666, loss_centerness1: 7.4377, loss_cls_aux0: 0.0047, loss_bbox_aux0: 0.0182, loss_iou_aux0: 0.0888, d0.loss_cls_aux0: 0.0095, d0.loss_bbox_aux0: 0.0376, d0.loss_iou_aux0: 0.1923, d1.loss_cls_aux0: 0.0058, d1.loss_bbox_aux0: 0.0208, d1.loss_iou_aux0: 0.1028, d2.loss_cls_aux0: 0.0048, d2.loss_bbox_aux0: 0.0182, d2.loss_iou_aux0: 0.0887, d3.loss_cls_aux0: 0.0044, d3.loss_bbox_aux0: 0.0182, d3.loss_iou_aux0: 0.0887, d4.loss_cls_aux0: 0.0046, d4.loss_bbox_aux0: 0.0182, d4.loss_iou_aux0: 0.0888, loss_cls_aux1: 0.0028, loss_bbox_aux1: 0.0423, loss_iou_aux1: 0.2322, d0.loss_cls_aux1: 0.0044, d0.loss_bbox_aux1: 0.0450, d0.loss_iou_aux1: 0.2460, d1.loss_cls_aux1: 0.0038, d1.loss_bbox_aux1: 0.0427, d1.loss_iou_aux1: 0.2337, d2.loss_cls_aux1: 0.0029, d2.loss_bbox_aux1: 0.0423, d2.loss_iou_aux1: 0.2322, d3.loss_cls_aux1: 0.0023, d3.loss_bbox_aux1: 0.0423, d3.loss_iou_aux1: 0.2322, d4.loss_cls_aux1: 0.0026, d4.loss_bbox_aux1: 0.0423, d4.loss_iou_aux1: 0.2322, loss: 20.2278, grad_norm: 60.2462
2024-03-18 09:50:50,516 - mmdet - INFO - Saving checkpoint at 35 epochs
2024-03-18 09:51:12,553 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:51:18,783 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.388
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.582
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.459
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.292
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.380
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.610
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.630
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.435
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.823

2024-03-18 09:51:18,784 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.024 | Tin      | 0.618 | Thatch   | 0.522 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:51:18,839 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:51:18,839 - mmdet - INFO - Epoch(val) [35][154]	bbox_mAP: 0.3880, bbox_mAP_50: 0.5820, bbox_mAP_75: 0.4590, bbox_mAP_s: 0.2920, bbox_mAP_m: 0.3800, bbox_mAP_l: 0.6100, bbox_mAP_copypaste: 0.388 0.582 0.459 0.292 0.380 0.610
2024-03-18 09:52:02,659 - mmdet - INFO - Epoch [36][50/232]	lr: 2.000e-06, eta: 0:02:11, time: 0.876, data_time: 0.061, memory: 17650, enc_loss_cls: 0.0774, enc_loss_bbox: 0.0576, enc_loss_iou: 0.3071, loss_cls: 0.0479, loss_bbox: 0.0550, loss_iou: 0.2952, d0.loss_cls: 0.0780, d0.loss_bbox: 0.0552, d0.loss_iou: 0.2963, d1.loss_cls: 0.0553, d1.loss_bbox: 0.0550, d1.loss_iou: 0.2953, d2.loss_cls: 0.0506, d2.loss_bbox: 0.0551, d2.loss_iou: 0.2951, d3.loss_cls: 0.0488, d3.loss_bbox: 0.0550, d3.loss_iou: 0.2952, d4.loss_cls: 0.0481, d4.loss_bbox: 0.0550, d4.loss_iou: 0.2952, loss_rpn_cls: 0.0257, loss_rpn_bbox: 0.1219, loss_cls0: 1.1380, acc0: 96.0921, loss_bbox0: 2.2373, loss_cls1: 0.7197, loss_bbox1: 3.2218, loss_centerness1: 7.4579, loss_cls_aux0: 0.0032, loss_bbox_aux0: 0.0182, loss_iou_aux0: 0.0872, d0.loss_cls_aux0: 0.0079, d0.loss_bbox_aux0: 0.0376, d0.loss_iou_aux0: 0.1877, d1.loss_cls_aux0: 0.0044, d1.loss_bbox_aux0: 0.0208, d1.loss_iou_aux0: 0.1004, d2.loss_cls_aux0: 0.0036, d2.loss_bbox_aux0: 0.0181, d2.loss_iou_aux0: 0.0871, d3.loss_cls_aux0: 0.0032, d3.loss_bbox_aux0: 0.0181, d3.loss_iou_aux0: 0.0871, d4.loss_cls_aux0: 0.0032, d4.loss_bbox_aux0: 0.0181, d4.loss_iou_aux0: 0.0872, loss_cls_aux1: 0.0019, loss_bbox_aux1: 0.0419, loss_iou_aux1: 0.2245, d0.loss_cls_aux1: 0.0033, d0.loss_bbox_aux1: 0.0461, d0.loss_iou_aux1: 0.2446, d1.loss_cls_aux1: 0.0023, d1.loss_bbox_aux1: 0.0425, d1.loss_iou_aux1: 0.2275, d2.loss_cls_aux1: 0.0021, d2.loss_bbox_aux1: 0.0419, d2.loss_iou_aux1: 0.2244, d3.loss_cls_aux1: 0.0019, d3.loss_bbox_aux1: 0.0419, d3.loss_iou_aux1: 0.2244, d4.loss_cls_aux1: 0.0019, d4.loss_bbox_aux1: 0.0419, d4.loss_iou_aux1: 0.2244, loss: 20.2286, grad_norm: 56.8784
2024-03-18 09:52:43,284 - mmdet - INFO - Epoch [36][100/232]	lr: 2.000e-06, eta: 0:01:35, time: 0.812, data_time: 0.010, memory: 17650, enc_loss_cls: 0.0866, enc_loss_bbox: 0.0606, enc_loss_iou: 0.3151, loss_cls: 0.0547, loss_bbox: 0.0578, loss_iou: 0.3005, d0.loss_cls: 0.0836, d0.loss_bbox: 0.0584, d0.loss_iou: 0.3019, d1.loss_cls: 0.0590, d1.loss_bbox: 0.0587, d1.loss_iou: 0.3019, d2.loss_cls: 0.0569, d2.loss_bbox: 0.0576, d2.loss_iou: 0.3001, d3.loss_cls: 0.0555, d3.loss_bbox: 0.0576, d3.loss_iou: 0.3001, d4.loss_cls: 0.0549, d4.loss_bbox: 0.0578, d4.loss_iou: 0.3005, loss_rpn_cls: 0.0207, loss_rpn_bbox: 0.1137, loss_cls0: 1.1084, acc0: 96.2279, loss_bbox0: 2.2498, loss_cls1: 0.7510, loss_bbox1: 3.2783, loss_centerness1: 7.4312, loss_cls_aux0: 0.0040, loss_bbox_aux0: 0.0176, loss_iou_aux0: 0.0841, d0.loss_cls_aux0: 0.0094, d0.loss_bbox_aux0: 0.0387, d0.loss_iou_aux0: 0.1918, d1.loss_cls_aux0: 0.0056, d1.loss_bbox_aux0: 0.0204, d1.loss_iou_aux0: 0.0985, d2.loss_cls_aux0: 0.0045, d2.loss_bbox_aux0: 0.0176, d2.loss_iou_aux0: 0.0839, d3.loss_cls_aux0: 0.0039, d3.loss_bbox_aux0: 0.0176, d3.loss_iou_aux0: 0.0840, d4.loss_cls_aux0: 0.0040, d4.loss_bbox_aux0: 0.0176, d4.loss_iou_aux0: 0.0841, loss_cls_aux1: 0.0028, loss_bbox_aux1: 0.0439, loss_iou_aux1: 0.2298, d0.loss_cls_aux1: 0.0048, d0.loss_bbox_aux1: 0.0479, d0.loss_iou_aux1: 0.2491, d1.loss_cls_aux1: 0.0037, d1.loss_bbox_aux1: 0.0449, d1.loss_iou_aux1: 0.2347, d2.loss_cls_aux1: 0.0031, d2.loss_bbox_aux1: 0.0439, d2.loss_iou_aux1: 0.2298, d3.loss_cls_aux1: 0.0026, d3.loss_bbox_aux1: 0.0439, d3.loss_iou_aux1: 0.2298, d4.loss_cls_aux1: 0.0027, d4.loss_bbox_aux1: 0.0439, d4.loss_iou_aux1: 0.2298, loss: 20.4113, grad_norm: 53.8761
2024-03-18 09:53:24,372 - mmdet - INFO - Epoch [36][150/232]	lr: 2.000e-06, eta: 0:00:59, time: 0.822, data_time: 0.012, memory: 17650, enc_loss_cls: 0.0795, enc_loss_bbox: 0.0576, enc_loss_iou: 0.3117, loss_cls: 0.0511, loss_bbox: 0.0560, loss_iou: 0.3013, d0.loss_cls: 0.0757, d0.loss_bbox: 0.0563, d0.loss_iou: 0.3040, d1.loss_cls: 0.0563, d1.loss_bbox: 0.0563, d1.loss_iou: 0.3031, d2.loss_cls: 0.0531, d2.loss_bbox: 0.0560, d2.loss_iou: 0.3010, d3.loss_cls: 0.0516, d3.loss_bbox: 0.0560, d3.loss_iou: 0.3012, d4.loss_cls: 0.0511, d4.loss_bbox: 0.0560, d4.loss_iou: 0.3012, loss_rpn_cls: 0.0245, loss_rpn_bbox: 0.1110, loss_cls0: 1.1251, acc0: 96.1471, loss_bbox0: 2.2640, loss_cls1: 0.7210, loss_bbox1: 3.2691, loss_centerness1: 7.4461, loss_cls_aux0: 0.0043, loss_bbox_aux0: 0.0168, loss_iou_aux0: 0.0802, d0.loss_cls_aux0: 0.0101, d0.loss_bbox_aux0: 0.0371, d0.loss_iou_aux0: 0.1906, d1.loss_cls_aux0: 0.0064, d1.loss_bbox_aux0: 0.0195, d1.loss_iou_aux0: 0.0941, d2.loss_cls_aux0: 0.0050, d2.loss_bbox_aux0: 0.0168, d2.loss_iou_aux0: 0.0801, d3.loss_cls_aux0: 0.0043, d3.loss_bbox_aux0: 0.0168, d3.loss_iou_aux0: 0.0801, d4.loss_cls_aux0: 0.0042, d4.loss_bbox_aux0: 0.0168, d4.loss_iou_aux0: 0.0802, loss_cls_aux1: 0.0020, loss_bbox_aux1: 0.0433, loss_iou_aux1: 0.2338, d0.loss_cls_aux1: 0.0046, d0.loss_bbox_aux1: 0.0469, d0.loss_iou_aux1: 0.2507, d1.loss_cls_aux1: 0.0035, d1.loss_bbox_aux1: 0.0441, d1.loss_iou_aux1: 0.2370, d2.loss_cls_aux1: 0.0026, d2.loss_bbox_aux1: 0.0433, d2.loss_iou_aux1: 0.2338, d3.loss_cls_aux1: 0.0021, d3.loss_bbox_aux1: 0.0433, d3.loss_iou_aux1: 0.2338, d4.loss_cls_aux1: 0.0020, d4.loss_bbox_aux1: 0.0433, d4.loss_iou_aux1: 0.2338, loss: 20.3645, grad_norm: 56.9313
2024-03-18 09:54:06,455 - mmdet - INFO - Epoch [36][200/232]	lr: 2.000e-06, eta: 0:00:23, time: 0.842, data_time: 0.008, memory: 17650, enc_loss_cls: 0.0865, enc_loss_bbox: 0.0590, enc_loss_iou: 0.3189, loss_cls: 0.0563, loss_bbox: 0.0561, loss_iou: 0.3050, d0.loss_cls: 0.0831, d0.loss_bbox: 0.0566, d0.loss_iou: 0.3074, d1.loss_cls: 0.0642, d1.loss_bbox: 0.0561, d1.loss_iou: 0.3048, d2.loss_cls: 0.0584, d2.loss_bbox: 0.0561, d2.loss_iou: 0.3050, d3.loss_cls: 0.0566, d3.loss_bbox: 0.0561, d3.loss_iou: 0.3050, d4.loss_cls: 0.0560, d4.loss_bbox: 0.0561, d4.loss_iou: 0.3050, loss_rpn_cls: 0.0246, loss_rpn_bbox: 0.1266, loss_cls0: 1.1995, acc0: 95.8237, loss_bbox0: 2.3379, loss_cls1: 0.7335, loss_bbox1: 3.3468, loss_centerness1: 7.4589, loss_cls_aux0: 0.0039, loss_bbox_aux0: 0.0181, loss_iou_aux0: 0.0891, d0.loss_cls_aux0: 0.0097, d0.loss_bbox_aux0: 0.0384, d0.loss_iou_aux0: 0.1971, d1.loss_cls_aux0: 0.0049, d1.loss_bbox_aux0: 0.0207, d1.loss_iou_aux0: 0.1034, d2.loss_cls_aux0: 0.0039, d2.loss_bbox_aux0: 0.0181, d2.loss_iou_aux0: 0.0889, d3.loss_cls_aux0: 0.0037, d3.loss_bbox_aux0: 0.0181, d3.loss_iou_aux0: 0.0890, d4.loss_cls_aux0: 0.0038, d4.loss_bbox_aux0: 0.0181, d4.loss_iou_aux0: 0.0890, loss_cls_aux1: 0.0026, loss_bbox_aux1: 0.0446, loss_iou_aux1: 0.2373, d0.loss_cls_aux1: 0.0047, d0.loss_bbox_aux1: 0.0483, d0.loss_iou_aux1: 0.2558, d1.loss_cls_aux1: 0.0031, d1.loss_bbox_aux1: 0.0453, d1.loss_iou_aux1: 0.2406, d2.loss_cls_aux1: 0.0026, d2.loss_bbox_aux1: 0.0446, d2.loss_iou_aux1: 0.2373, d3.loss_cls_aux1: 0.0024, d3.loss_bbox_aux1: 0.0446, d3.loss_iou_aux1: 0.2373, d4.loss_cls_aux1: 0.0024, d4.loss_bbox_aux1: 0.0446, d4.loss_iou_aux1: 0.2373, loss: 20.7895, grad_norm: 53.8276
2024-03-18 09:54:33,286 - mmdet - INFO - Saving checkpoint at 36 epochs
2024-03-18 09:54:55,669 - mmdet - INFO - Evaluating bbox...
2024-03-18 09:55:01,863 - mmdet - INFO - 
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.386
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.579
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.452
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.293
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.379
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.650
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.634
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.430
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.657
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.819

2024-03-18 09:55:01,863 - mmdet - INFO - 
+----------+-------+----------+-------+----------+-------+
| category | AP    | category | AP    | category | AP    |
+----------+-------+----------+-------+----------+-------+
| Other    | 0.025 | Tin      | 0.617 | Thatch   | 0.514 |
+----------+-------+----------+-------+----------+-------+
2024-03-18 09:55:01,919 - mmdet - INFO - Exp name: co_deformable_detr_swin_base_3x_coco.py
2024-03-18 09:55:01,919 - mmdet - INFO - Epoch(val) [36][154]	bbox_mAP: 0.3860, bbox_mAP_50: 0.5790, bbox_mAP_75: 0.4520, bbox_mAP_s: 0.2930, bbox_mAP_m: 0.3790, bbox_mAP_l: 0.6500, bbox_mAP_copypaste: 0.386 0.579 0.452 0.293 0.379 0.650
